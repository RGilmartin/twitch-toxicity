{"version":3,"file":"byte_chunk_iterator_test.js","sourceRoot":"","sources":["../../src/iterators/byte_chunk_iterator_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;GAgBG;AAEH,OAAO,EAAC,GAAG,EAAC,MAAM,uBAAuB,CAAC;AAC1C,OAAO,EAAC,iBAAiB,EAAC,MAAM,uBAAuB,CAAC;AAExD,MAAM,KAAK,GAAG;;sCAEwB,CAAC;AAEvC,MAAM,QAAQ,GACV,GAAG,EAAE,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,IAAI,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;AAErE,QAAQ,CAAC,gCAAgC,EAAE,GAAG,EAAE;IAC9C,EAAE,CAAC,wCAAwC,EAAE,KAAK,IAAI,EAAE;QACtD,MAAM,iBAAiB,GAAG,IAAI,iBAAiB,CAAC,QAAQ,EAAE,EAAC,SAAS,EAAE,EAAE,EAAC,CAAC,CAAC;QAC3E,MAAM,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,YAAY,CAAC,CAAC,CAAC,CAAE,QAAiB,CAAC,IAAI,CAAC,CAAC;YACxB,QAAmB,CAAC,UAAU,CAAC,CAAC;aAC9D,OAAO,CAAC,GAAG,CAAC,CAAC;QAClB,MAAM,YAAY,GAAG,iBAAiB,CAAC,UAAU,EAAE,CAAC;QAEpD,MAAM,MAAM,GAAG,MAAM,YAAY,CAAC,cAAc,EAAE,CAAC;QACnD,mEAAmE;QACnE,qEAAqE;QACrE,sEAAsE;QACtE,qEAAqE;QACrE,sBAAsB;QACtB,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,eAAe,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;QAC1E,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\nimport {FileChunkIterator} from './file_chunk_iterator';\n\nconst runes = `ᚠᛇᚻ᛫ᛒᛦᚦ᛫ᚠᚱᚩᚠᚢᚱ᛫ᚠᛁᚱᚪ᛫ᚷᛖᚻᚹᛦᛚᚳᚢᛗ\nᛋᚳᛖᚪᛚ᛫ᚦᛖᚪᚻ᛫ᛗᚪᚾᚾᚪ᛫ᚷᛖᚻᚹᛦᛚᚳ᛫ᛗᛁᚳᛚᚢᚾ᛫ᚻᛦᛏ᛫ᛞᚫᛚᚪᚾ\nᚷᛁᚠ᛫ᚻᛖ᛫ᚹᛁᛚᛖ᛫ᚠᚩᚱ᛫ᛞᚱᛁᚻᛏᚾᛖ᛫ᛞᚩᛗᛖᛋ᛫ᚻᛚᛇᛏᚪᚾ᛬`;\n\nconst testData =\n    env().get('IS_BROWSER') ? new Blob([runes]) : Buffer.from(runes);\n\ndescribe('ByteChunkIterator.decodeUTF8()', () => {\n  it('Correctly reassembles split characters', async () => {\n    const byteChunkIterator = new FileChunkIterator(testData, {chunkSize: 50});\n    expect((env().get('IS_BROWSER') ? (testData as Blob).size :\n                                      (testData as Buffer).byteLength))\n        .toEqual(323);\n    const utf8Iterator = byteChunkIterator.decodeUTF8();\n\n    const result = await utf8Iterator.toArrayForTest();\n    // The test string is 109 characters long; its UTF8 encoding is 323\n    // bytes. We read it in chunks of 50 bytes, so there were 7 chunks of\n    // bytes. The UTF decoder slightly adjusted the boundaries between the\n    // chunks to allow decoding, but did not change the number of chunks,\n    // so 7 chunks remain.\n    expect(result.length).toEqual(7);\n    const totalCharacters = result.map(x => x.length).reduce((a, b) => a + b);\n    expect(totalCharacters).toEqual(109);\n    expect(result.join('')).toEqual(runes);\n  });\n});\n"]}