{"version":3,"file":"activations.js","sourceRoot":"","sources":["../src/activations.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;AAEH,6BAA6B;AAC7B,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAC,aAAa,EAAU,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAClE,OAAO,KAAK,CAAC,MAAM,wBAAwB,CAAC;AAE5C,OAAO,EAAC,sBAAsB,EAAC,MAAM,uBAAuB,CAAC;AAE7D;;;;;;GAMG;AACH,MAAM,OAAgB,UAAW,SAAQ,aAAa,CAAC,YAAY;IAEjE,SAAS;QACP,OAAO,EAAE,CAAC;IACZ,CAAC;CACF;AAED;;;GAGG;AACH,MAAM,OAAO,GAAI,SAAQ,UAAU;IAGjC;;;;;;OAMG;IACH,KAAK,CAAC,CAAS,EAAE,KAAK,GAAG,CAAC;QACxB,OAAO,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;IACzB,CAAC;;AAXD,kBAAkB;AACF,aAAS,GAAG,KAAK,CAAC;AAYpC,aAAa,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC;AAEjC;;;;;;GAMG;AACH,MAAM,OAAO,IAAK,SAAQ,UAAU;IAGlC,KAAK,CAAC,CAAS;QACb,OAAO,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IACrB,CAAC;;AAJD,kBAAkB;AACF,cAAS,GAAG,MAAM,CAAC;AAKrC,aAAa,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;AAElC;;GAEG;AACH,MAAM,OAAO,IAAK,SAAQ,UAAU;IAGlC,KAAK,CAAC,CAAS;QACb,OAAO,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IACrB,CAAC;;AAJD,kBAAkB;AACF,cAAS,GAAG,MAAM,CAAC;AAKrC,aAAa,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;AAElC;;GAEG;AACH,MAAM,OAAO,KAAM,SAAQ,UAAU;IAGnC,KAAK,CAAC,CAAS;QACb,OAAO,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACnD,CAAC;;AAJD,kBAAkB;AACF,eAAS,GAAG,OAAO,CAAC;AAKtC,aAAa,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;AAEnC,gCAAgC;AAChC,MAAM,OAAO,MAAO,SAAQ,UAAU;IAGpC,KAAK,CAAC,CAAS;QACb,OAAO,CAAC,CAAC;IACX,CAAC;;AAJD,kBAAkB;AACF,gBAAS,GAAG,QAAQ,CAAC;AAKvC,aAAa,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;AAEpC;;GAEG;AACH,MAAM,OAAO,OAAQ,SAAQ,UAAU;IAGrC,KAAK,CAAC,CAAS;QACb,OAAO,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACxB,CAAC;;AAJD,kBAAkB;AACF,iBAAS,GAAG,SAAS,CAAC;AAKxC,aAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AAErC;;GAEG;AACH,MAAM,OAAO,WAAY,SAAQ,UAAU;IAGzC,KAAK,CAAC,CAAS;QACb,OAAO,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;IAC1B,CAAC;;AAJD,kBAAkB;AACF,qBAAS,GAAG,aAAa,CAAC;AAK5C,aAAa,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;AAEzC;;GAEG;AACH,MAAM,OAAO,QAAS,SAAQ,UAAU;IAGtC,KAAK,CAAC,CAAS;QACb,OAAO,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC;IACzB,CAAC;;AAJD,kBAAkB;AACF,kBAAS,GAAG,UAAU,CAAC;AAKzC,aAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;AAEtC;;GAEG;AACH,MAAM,OAAO,QAAS,SAAQ,UAAU;IAGtC,KAAK,CAAC,CAAS;QACb,OAAO,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC;;AAJD,kBAAkB;AACF,kBAAS,GAAG,UAAU,CAAC;AAKzC,aAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;AAEtC;;GAEG;AACH,MAAM,OAAO,IAAK,SAAQ,UAAU;IAGlC,KAAK,CAAC,CAAS;QACb,OAAO,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IACrB,CAAC;;AAJD,kBAAkB;AACF,cAAS,GAAG,MAAM,CAAC;AAKrC,aAAa,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;AAElC;;GAEG;AACH,MAAM,OAAO,OAAQ,SAAQ,UAAU;IAGrC;;;;;;;;;;;OAWG;IACH,KAAK,CAAC,CAAS,EAAE,OAAe,CAAC,CAAC,CAAC,CAAC;QAClC,OAAO,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;IAC9B,CAAC;;AAhBD,kBAAkB;AACF,iBAAS,GAAG,SAAS,CAAC;AAiBxC,aAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AAErC;;GAEG;AACH,MAAM,OAAO,UAAW,SAAQ,UAAU;IAGxC;;;;;;;;;;;;OAYG;IACH,KAAK,CAAC,CAAS,EAAE,OAAe,CAAC,CAAC,CAAC,CAAC;QAClC,OAAO,GAAG,CAAC,UAAU,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;IACjC,CAAC;;AAjBD,kBAAkB;AACF,oBAAS,GAAG,YAAY,CAAC;AAkB3C,aAAa,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC;AAExC;;GAEG;AACH,MAAM,OAAO,KAAM,SAAQ,UAAU;IAGnC;;;;;;OAMG;IACH,KAAK,CAAC,CAAS,EAAE,KAAK,GAAG,CAAC;QACxB,OAAO,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;IACtD,CAAC;;AAXD,kBAAkB;AACF,eAAS,GAAG,OAAO,CAAC;AAYtC,aAAa,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;AAEnC;;GAEG;AACH,MAAM,OAAO,IAAK,SAAQ,UAAU;IAGlC;;;;;OAKG;IACH,KAAK,CAAC,CAAS;QACb,OAAO,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3D,CAAC;;AAVD,kBAAkB;AACF,cAAS,GAAG,MAAM,CAAC;AAWrC,aAAa,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;AAElC,MAAM,UAAU,mBAAmB,CAAC,UAAsB;IACxD,OAAO,UAAU,CAAC,YAAY,EAAE,CAAC;AACnC,CAAC;AAED,MAAM,UAAU,qBAAqB,CAClC,MAAgC,EAChC,gBAA0C,EAAE;IAC7C,OAAO,sBAAsB,CACzB,MAAM,EAAE,aAAa,CAAC,gBAAgB,CAAC,MAAM,EAAE,CAAC,YAAY,EAC5D,aAAa,EAAE,YAAY,CAAC,CAAC;AACnC,CAAC;AAED,MAAM,UAAU,aAAa,CAAC,UACmC;IAC/D,IAAI,UAAU,IAAI,IAAI,EAAE;QACtB,MAAM,MAAM,GAA6B,EAAE,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,GAAG,QAAQ,CAAC;QAC/B,MAAM,CAAC,QAAQ,CAAC,GAAG,EAAE,CAAC;QACtB,OAAO,qBAAqB,CAAC,MAAM,CAAC,CAAC;KACtC;IACD,IAAI,OAAO,UAAU,KAAK,QAAQ,EAAE;QAClC,MAAM,MAAM,GAA6B,EAAE,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,GAAG,UAAU,CAAC;QACjC,MAAM,CAAC,QAAQ,CAAC,GAAG,EAAE,CAAC;QACtB,OAAO,qBAAqB,CAAC,MAAM,CAAC,CAAC;KACtC;SAAM,IAAI,UAAU,YAAY,UAAU,EAAE;QAC3C,OAAO,UAAU,CAAC;KACnB;SAAM;QACL,OAAO,qBAAqB,CAAC,UAAU,CAAC,CAAC;KAC1C;AACH,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n// Layer activation functions\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {serialization, Tensor, tidy} from '@tensorflow/tfjs-core';\nimport * as K from './backend/tfjs_backend';\nimport {ActivationIdentifier} from './keras_format/activation_config';\nimport {deserializeKerasObject} from './utils/generic_utils';\n\n/**\n * Base class for Activations.\n *\n * Special note: due to cross-language compatibility reasons, the\n * static readonly className field in this family of classes must be set to\n * the initialLowerCamelCase name of the activation.\n */\nexport abstract class Activation extends serialization.Serializable {\n  abstract apply(tensor: Tensor, axis?: number): Tensor;\n  getConfig(): serialization.ConfigDict {\n    return {};\n  }\n}\n\n/**\n * Exponential linear unit (ELU).\n * Reference: https://arxiv.org/abs/1511.07289\n */\nexport class Elu extends Activation {\n  /** @nocollapse */\n  static readonly className = 'elu';\n  /**\n   * Calculate the activation function.\n   *\n   * @param x: Input.\n   * @param alpha: Scaling factor the negative section.\n   * @return Output of the ELU activation.\n   */\n  apply(x: Tensor, alpha = 1): Tensor {\n    return K.elu(x, alpha);\n  }\n}\nserialization.registerClass(Elu);\n\n/**\n * Scaled Exponential Linear Unit. (Klambauer et al., 2017).\n * Reference: Self-Normalizing Neural Networks, https://arxiv.org/abs/1706.02515\n * Notes:\n *   - To be used together with the initialization \"lecunNormal\".\n *   - To be used together with the dropout variant \"AlphaDropout\".\n */\nexport class Selu extends Activation {\n  /** @nocollapse */\n  static readonly className = 'selu';\n  apply(x: Tensor): Tensor {\n    return tfc.selu(x);\n  }\n}\nserialization.registerClass(Selu);\n\n/**\n *  Rectified linear unit\n */\nexport class Relu extends Activation {\n  /** @nocollapse */\n  static readonly className = 'relu';\n  apply(x: Tensor): Tensor {\n    return tfc.relu(x);\n  }\n}\nserialization.registerClass(Relu);\n\n/**\n * Rectified linear unit activation maxing out at 6.0.\n */\nexport class Relu6 extends Activation {\n  /** @nocollapse */\n  static readonly className = 'relu6';\n  apply(x: Tensor): Tensor {\n    return tidy(() => tfc.minimum(6.0, tfc.relu(x)));\n  }\n}\nserialization.registerClass(Relu6);\n\n//* Linear activation (no-op) */\nexport class Linear extends Activation {\n  /** @nocollapse */\n  static readonly className = 'linear';\n  apply(x: Tensor): Tensor {\n    return x;\n  }\n}\nserialization.registerClass(Linear);\n\n/**\n * Sigmoid activation function.\n */\nexport class Sigmoid extends Activation {\n  /** @nocollapse */\n  static readonly className = 'sigmoid';\n  apply(x: Tensor): Tensor {\n    return tfc.sigmoid(x);\n  }\n}\nserialization.registerClass(Sigmoid);\n\n/**\n * Segment-wise linear approximation of sigmoid.\n */\nexport class HardSigmoid extends Activation {\n  /** @nocollapse */\n  static readonly className = 'hardSigmoid';\n  apply(x: Tensor): Tensor {\n    return K.hardSigmoid(x);\n  }\n}\nserialization.registerClass(HardSigmoid);\n\n/**\n * Softplus activation function.\n */\nexport class Softplus extends Activation {\n  /** @nocollapse */\n  static readonly className = 'softplus';\n  apply(x: Tensor): Tensor {\n    return tfc.softplus(x);\n  }\n}\nserialization.registerClass(Softplus);\n\n/**\n * Softsign activation function.\n */\nexport class Softsign extends Activation {\n  /** @nocollapse */\n  static readonly className = 'softsign';\n  apply(x: Tensor): Tensor {\n    return K.softsign(x);\n  }\n}\nserialization.registerClass(Softsign);\n\n/**\n * Hyperbolic tangent function.\n */\nexport class Tanh extends Activation {\n  /** @nocollapse */\n  static readonly className = 'tanh';\n  apply(x: Tensor): Tensor {\n    return tfc.tanh(x);\n  }\n}\nserialization.registerClass(Tanh);\n\n/**\n * Softmax activation function\n */\nexport class Softmax extends Activation {\n  /** @nocollapse */\n  static readonly className = 'softmax';\n  /**\n   * Calculate the activation function.\n   *\n   * @param x Tensor.\n   * @param axis Integer, axis along which the softmax normalization is applied.\n   * Invalid if < 2, as softmax across 1 (the batch dimension) is assumed to be\n   * an error.\n   *\n   * @returns a Tensor of the same shape as x\n   *\n   * @throws ValueError: In case `dim(x) < 2`.\n   */\n  apply(x: Tensor, axis: number = (-1)): Tensor {\n    return tfc.softmax(x, axis);\n  }\n}\nserialization.registerClass(Softmax);\n\n/**\n * Log softmax activation function\n */\nexport class LogSoftmax extends Activation {\n  /** @nocollapse */\n  static readonly className = 'logSoftmax';\n  /**\n   * Calculate the activation function of log softmax:\n   * log( exp(x_i) / sum(exp(x)) )\n   *\n   * @param x Tensor.\n   * @param axis Integer, axis along which the softmax normalization is applied.\n   * Invalid if < 2, as softmax across 1 (the batch dimension) is assumed to be\n   * an error.\n   *\n   * @returns a Tensor of the same shape as x\n   *\n   * @throws ValueError: In case `dim(x) < 2`.\n   */\n  apply(x: Tensor, axis: number = (-1)): Tensor {\n    return tfc.logSoftmax(x, axis);\n  }\n}\nserialization.registerClass(LogSoftmax);\n\n/**\n * Swish activation function\n */\nexport class Swish extends Activation {\n  /** @nocollapse */\n  static readonly className = 'swish';\n  /**\n   * Calculate the activation function.\n   *\n   * @param x Tensor.\n   * @param alpha Scaling factor for the sigmoid function.\n   * @returns a Tensor of the same shape as x\n   */\n  apply(x: Tensor, alpha = 1): Tensor {\n    return tidy(() => tfc.sigmoid(x.mul(alpha)).mul(x));\n  }\n}\nserialization.registerClass(Swish);\n\n/**\n * Mish activation function\n */\nexport class Mish extends Activation {\n  /** @nocollapse */\n  static readonly className = 'mish';\n  /**\n   * Calculate the activation function.\n   *\n   * @param x Tensor.\n   * @returns a Tensor of the same shape as x\n   */\n  apply(x: Tensor): Tensor {\n    return tidy(() => tfc.mul(x, tfc.tanh(tfc.softplus(x))));\n  }\n}\nserialization.registerClass(Mish);\n\nexport function serializeActivation(activation: Activation): string {\n  return activation.getClassName();\n}\n\nexport function deserializeActivation(\n   config: serialization.ConfigDict,\n   customObjects: serialization.ConfigDict = {}): Activation {\n  return deserializeKerasObject(\n      config, serialization.SerializationMap.getMap().classNameMap,\n      customObjects, 'activation');\n}\n\nexport function getActivation(identifier: ActivationIdentifier|\n                              serialization.ConfigDict|Activation): Activation {\n  if (identifier == null) {\n    const config: serialization.ConfigDict = {};\n    config['className'] = 'linear';\n    config['config'] = {};\n    return deserializeActivation(config);\n  }\n  if (typeof identifier === 'string') {\n    const config: serialization.ConfigDict = {};\n    config['className'] = identifier;\n    config['config'] = {};\n    return deserializeActivation(config);\n  } else if (identifier instanceof Activation) {\n    return identifier;\n  } else {\n    return deserializeActivation(identifier);\n  }\n}\n"]}