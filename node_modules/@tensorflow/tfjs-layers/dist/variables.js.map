{"version":3,"file":"variables.js","sourceRoot":"","sources":["../src/variables.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAmB,aAAa,EAAC,MAAM,uBAAuB,CAAC;AAEtE,OAAO,EAAC,qBAAqB,EAAC,MAAM,iBAAiB,CAAC;AACtD,OAAO,EAAC,mBAAmB,EAAE,mBAAmB,EAAC,MAAM,UAAU,CAAC;AAElE,OAAO,EAAC,mBAAmB,EAAC,MAAM,UAAU,CAAC;AAI7C,MAAM,4BAA4B,GAAG,UAAU,CAAC;AAEhD;;;;;GAKG;AACH,MAAM,OAAO,aAAa;IAexB;;;;;;;;;;;;;OAaG;IACH,YACI,GAAW,EAAE,QAAkB,SAAS,EACxC,IAAI,GAAG,4BAA4B,EAAE,SAAS,GAAG,IAAI,EACrD,aAAyB,IAAI;QAC/B,IAAI,CAAC,KAAK,GAAG,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC;QAC/C,IAAI,CAAC,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC;QACvB,IAAI,CAAC,EAAE,GAAG,qBAAqB,EAAE,CAAC;QAElC,IAAI,GAAG,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,4BAA4B,CAAC,CAAC,CAAC,IAAI,CAAC;QAC1D,IAAI,CAAC,YAAY,GAAG,mBAAmB,CAAC,IAAI,CAAC,CAAC;QAC9C,IAAI,CAAC,IAAI,GAAG,mBAAmB,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;QAEnD,IAAI,CAAC,UAAU,GAAG,SAAS,CAAC;QAC5B,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;QAE7B,IAAI,CAAC,GAAG,GAAG,GAAG,CAAC,QAAQ,CAAC,GAAG,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC;IACvE,CAAC;IAED;;;;;;OAMG;IACH,IAAI;QACF,IAAI,CAAC,iBAAiB,EAAE,CAAC;QACzB,OAAO,IAAI,CAAC,GAAG,CAAC;IAClB,CAAC;IAED;;;;;;OAMG;IACH,KAAK,CAAC,MAAc;QAClB,yEAAyE;QACzE,IAAI,CAAC,iBAAiB,EAAE,CAAC;QACzB,gBAAgB,CAAC,IAAI,CAAC,GAAG,EAAE,MAAM,CAAC,CAAC;QACnC,kDAAkD;QAClD,IAAI,IAAI,CAAC,GAAG,CAAC,EAAE,KAAK,MAAM,CAAC,EAAE,EAAE;YAC7B,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACxB,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;gBAC3B,IAAI,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;aAClD;SACF;QACD,OAAO,IAAI,CAAC;IACd,CAAC;IAED;;OAEG;IACH,OAAO;QACL,IAAI,CAAC,iBAAiB,EAAE,CAAC;QACzB,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,CAAC;IACrB,CAAC;IAES,iBAAiB;QACzB,IAAI,IAAI,CAAC,GAAG,CAAC,UAAU,EAAE;YACvB,MAAM,IAAI,KAAK,CAAC,kBAAkB,IAAI,CAAC,IAAI,uBAAuB,CAAC,CAAC;SACrE;IACH,CAAC;IAED,IAAI,SAAS;QACX,OAAO,IAAI,CAAC,UAAU,CAAC;IACzB,CAAC;IAED,IAAI,SAAS,CAAC,SAAkB;QAC9B,IAAI,CAAC,UAAU,GAAG,SAAS,CAAC;QAC5B,IAAI,CAAC,GAAG,CAAC,SAAS,GAAG,SAAS,CAAC;IACjC,CAAC;CACF;AAED,SAAS,gBAAgB,CAAC,CAAW,EAAE,CAAW;IAChD,IAAI,CAAC,CAAC,KAAK,CAAC,QAAQ,EAAE,KAAK,CAAC,CAAC,KAAK,CAAC,QAAQ,EAAE,EAAE;QAC7C,MAAM,IAAI,KAAK,CACX,kBAAkB,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC,GAAG,OAAO;YACtD,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC;KAC9B;AACH,CAAC;AAED;;;;;;;;GAQG;AACH,MAAM,UAAU,QAAQ,CACpB,CAAS,EAAE,KAAgB,EAAE,IAAa,EAC1C,UAAuB;IACzB,OAAO,IAAI,aAAa,CAAC,CAAC,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,EAAE,UAAU,CAAC,CAAC;AAC7D,CAAC;AAED;;;;;;;GAOG;AACH,MAAM,UAAU,aAAa,CACzB,KAAY,EAAE,KAAgB,EAAE,IAAa;IAC/C,yCAAyC;IACzC,OAAO,IAAI,aAAa,CAAC,GAAG,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AAC1D,CAAC;AAED;;;;;;;GAOG;AACH,MAAM,UAAU,SAAS,CACrB,CAAS,EAAE,KAAgB,EAAE,IAAa;IAC5C,OAAO,IAAI,aAAa,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AAC1D,CAAC;AAED;;;;;;;GAOG;AACH,MAAM,UAAU,YAAY,CACxB,KAAY,EAAE,KAAgB,EAAE,IAAa;IAC/C,yCAAyC;IACzC,MAAM,SAAS,GAAG,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;IAClC,OAAO,IAAI,aAAa,CAAC,SAAS,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AACnD,CAAC;AAED;;;;;;;GAOG;AACH,MAAM,UAAU,QAAQ,CACpB,CAAS,EAAE,KAAgB,EAAE,IAAa;IAC5C,MAAM,SAAS,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC;IAClC,OAAO,IAAI,aAAa,CAAC,SAAS,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AACnD,CAAC;AAED;;;;;;;GAOG;AACH,MAAM,UAAU,WAAW,CACvB,IAAY,EAAE,KAAgB,EAAE,IAAa;IAC/C,OAAO,IAAI,aAAa,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AACvD,CAAC;AAED;;;;;;;;;GASG;AACH,MAAM,UAAU,qBAAqB,CACjC,KAAY,EAAE,MAAc,EAAE,MAAc,EAAE,KAAgB,EAC9D,IAAa,EAAE,IAAI,GAAG,eAAe;IACvC,OAAO,IAAI,aAAa,CACpB,GAAG,CAAC,aAAa,CAAC,KAAK,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AACpE,CAAC;AAED;;;;;;;;;GASG;AACH,MAAM,UAAU,uBAAuB,CACnC,KAAY,EAAE,IAAI,GAAG,GAAG,EAAE,MAAM,GAAG,GAAG,EAAE,KAAgB,EAAE,IAAa,EACvE,IAAI,GAAG,iBAAiB;IAC1B,yEAAyE;IACzE,mBAAmB;IACnB,KAAK,GAAG,KAAK,IAAI,SAAS,CAAC;IAC3B,IAAI,KAAK,KAAK,SAAS,IAAI,KAAK,KAAK,OAAO,EAAE;QAC5C,MAAM,IAAI,mBAAmB,CACzB,uCAAuC,KAAK,GAAG,CAAC,CAAC;KACtD;IACD,OAAO,IAAI,aAAa,CACpB,GAAG,CAAC,eAAe,CAAC,KAAK,EAAE,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,IAAI,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AAC1E,CAAC;AACD;;;;;;;;;GASG;AACH,MAAM,UAAU,oBAAoB,CAChC,KAAY,EAAE,IAAI,GAAG,GAAG,EAAE,MAAM,GAAG,GAAG,EAAE,KAAgB,EAAE,IAAa,EACvE,IAAI,GAAG,cAAc;IACvB,KAAK,GAAG,KAAK,IAAI,SAAS,CAAC;IAC3B,IAAI,KAAK,KAAK,SAAS,IAAI,KAAK,KAAK,OAAO,EAAE;QAC5C,MAAM,IAAI,mBAAmB,CACzB,+CAA+C,KAAK,GAAG,CAAC,CAAC;KAC9D;IACD,OAAO,IAAI,aAAa,CACpB,GAAG,CAAC,YAAY,CAAC,KAAK,EAAE,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,IAAI,CAAC,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;AACvE,CAAC;AAED;;;;;GAKG;AACH,MAAM,UAAU,MAAM,CAAC,CAAgB,EAAE,IAAY;IACnD,OAAO,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;AACvB,CAAC;AAED;;;;;GAKG;AACH,MAAM,UAAU,SAAS,CAAC,CAAgB,EAAE,SAAiB;IAC3D,OAAO,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,EAAE,EAAE,SAAS,CAAC,CAAC,CAAC;AAC/C,CAAC;AAED;;;;;GAKG;AACH,MAAM,UAAU,SAAS,CAAC,CAAgB,EAAE,SAAiB;IAC3D,OAAO,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,EAAE,EAAE,SAAS,CAAC,CAAC,CAAC;AAC/C,CAAC;AAED;;;;;GAKG;AACH,MAAM,UAAU,aAAa,CAAC,EAAmB;IAC/C,OAAO,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC;AAC/B,CAAC;AAED;;;;;;;GAOG;AACH,MAAM,UAAU,aAAa,CACzB,kBAAkD;IACpD,kBAAkB,CAAC,OAAO,CAAC,gBAAgB,CAAC,EAAE;QAC5C,MAAM,QAAQ,GAAkB,gBAAgB,CAAC,CAAC,CAAC,CAAC;QACpD,QAAQ,CAAC,KAAK,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC;IACtC,CAAC,CAAC,CAAC;AACL,CAAC;AAED;;;;;;;GAOG;AACH,MAAM,UAAU,SAAS,CACrB,MAAwB,EAAE,SAA0B;IACtD,6EAA6E;IAC7E,mCAAmC;IACnC,MAAM,YAAY,GACd,SAAS,CAAC,GAAG,CAAC,QAAQ,CAAC,EAAE,CAAC,QAAQ,CAAC,IAAI,EAAkB,CAAC,CAAC;IAC/D,MAAM,aAAa,GAAG,aAAa,CAAC,MAAM,EAAE,YAAY,CAAC,CAAC;IAC1D,OAAO,SAAS,CAAC,GAAG,CAAC,QAAQ,CAAC,EAAE,CAAC,aAAa,CAAC,KAAK,CAAC,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;AACvE,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {DataType, Tensor, variableGrads} from '@tensorflow/tfjs-core';\n\nimport {getNextUniqueTensorId} from './backend/state';\nimport {getScopedTensorName, getUniqueTensorName} from './common';\nimport {Constraint} from './constraints';\nimport {NotImplementedError} from './errors';\nimport {Shape} from './keras_format/common';\nimport {HasShape} from './types';\n\nconst DEFAULT_VARIABLE_NAME_PREFIX = 'Variable';\n\n/**\n * A `tf.layers.LayerVariable` is similar to a `tf.Tensor` in that it has a\n * dtype and shape, but its value is mutable.  The value is itself represented\n * as a`tf.Tensor`, and can be read with the `read()` method and updated with\n * the `write()` method.\n */\nexport class LayerVariable {\n  readonly dtype: DataType;\n  readonly shape: Shape;\n\n  readonly id: number;\n  // The fully scoped name of this Variable, including a unique suffix if needed\n  readonly name: string;\n  // The originally requested fully scoped name of this Variable, not including\n  // any unique suffix.  This may be needed when restoring weights because this\n  // original name is used as a key.\n  readonly originalName: string;\n  private trainable_: boolean;\n\n  protected readonly val: tfc.Variable;\n  readonly constraint: Constraint;\n  /**\n   * Construct Variable from a `tf.Tensor`.\n   *\n   * If not explicitly named, the Variable will be given a name with the\n   * prefix 'Variable'. Variable names are unique. In the case of name\n   * collision, suffixies '_<num>' will be added to the name.\n   *\n   * @param val Initial value of the Variable.\n   * @param name Name of the variable. If `null` or `undefined` is provided, it\n   *   will default a name with the prefix 'Variable'.\n   * @param constraint Optional, projection function to be applied to the\n   * variable after optimize updates\n   * @throws ValueError if `name` is `null` or `undefined`.\n   */\n  constructor(\n      val: Tensor, dtype: DataType = 'float32',\n      name = DEFAULT_VARIABLE_NAME_PREFIX, trainable = true,\n      constraint: Constraint = null) {\n    this.dtype = dtype == null ? 'float32' : dtype;\n    this.shape = val.shape;\n    this.id = getNextUniqueTensorId();\n\n    name = name == null ? DEFAULT_VARIABLE_NAME_PREFIX : name;\n    this.originalName = getScopedTensorName(name);\n    this.name = getUniqueTensorName(this.originalName);\n\n    this.trainable_ = trainable;\n    this.constraint = constraint;\n\n    this.val = tfc.variable(val, this.trainable_, this.name, this.dtype);\n  }\n\n  /**\n   * Get a snapshot of the Variable's value.\n   *\n   * The returned value is a snapshot of the Variable's value at the time of\n   * the invocation. Future mutations in the value of the tensor will only\n   * be reflected by future calls to this method.\n   */\n  read(): Tensor {\n    this.assertNotDisposed();\n    return this.val;\n  }\n\n  /**\n   * Update the value of the Variable.\n   *\n   * @param newVal: The new value to update to. Must be consistent with the\n   *   dtype and shape of the Variable.\n   * @return This Variable.\n   */\n  write(newVal: Tensor) {\n    // TODO(cais): Once  TF.js Core supports Tensor.dtype, check dtype match.\n    this.assertNotDisposed();\n    checkShapesMatch(this.val, newVal);\n    // Skip updating if this is the exact same tensor.\n    if (this.val.id !== newVal.id) {\n      this.val.assign(newVal);\n      if (this.constraint != null) {\n        this.val.assign(this.constraint.apply(this.val));\n      }\n    }\n    return this;\n  }\n\n  /**\n   * Dispose this LayersVariable instance from memory.\n   */\n  dispose(): void {\n    this.assertNotDisposed();\n    this.val.dispose();\n  }\n\n  protected assertNotDisposed(): void {\n    if (this.val.isDisposed) {\n      throw new Error(`LayersVariable ${this.name} is already disposed.`);\n    }\n  }\n\n  get trainable(): boolean {\n    return this.trainable_;\n  }\n\n  set trainable(trainable: boolean) {\n    this.trainable_ = trainable;\n    this.val.trainable = trainable;\n  }\n}\n\nfunction checkShapesMatch(x: HasShape, y: HasShape): void {\n  if (x.shape.toString() !== y.shape.toString()) {\n    throw new Error(\n        'Shape mismatch: ' + JSON.stringify(x.shape) + ' vs. ' +\n        JSON.stringify(y.shape));\n  }\n}\n\n/**\n * Create a Variable.\n * @param x The initial value of the `Variable`.\n * @param dtype optional, the type of the variable.\n * @param name optional, the name of the variable, default provided by\n * Variable.\n * @param constraint optional, a constraint to be applied after every update.\n * @return The newly instantiated `Variable`.\n */\nexport function variable(\n    x: Tensor, dtype?: DataType, name?: string,\n    constraint?: Constraint): LayerVariable {\n  return new LayerVariable(x, dtype, name, true, constraint);\n}\n\n/**\n * Instantiates an all-zeros Variable and returns it.\n *\n * @param shape Shape of the tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return An all-zero Variable.\n */\nexport function zerosVariable(\n    shape: Shape, dtype?: DataType, name?: string): LayerVariable {\n  // TODO(cais): Implement logic for dtype.\n  return new LayerVariable(tfc.zeros(shape), dtype, name);\n}\n\n/**\n * Instantiates an all-zeros tensor of the same shape as another tensor.\n *\n * @param x The other tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return A newly instantiated Variable.\n */\nexport function zerosLike(\n    x: Tensor, dtype?: DataType, name?: string): LayerVariable {\n  return new LayerVariable(tfc.zerosLike(x), dtype, name);\n}\n\n/**\n * Instantiates an all-ones tensor and returns it.\n *\n * @param shape Shape of the tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return An all-ones Variable.\n */\nexport function onesVariable(\n    shape: Shape, dtype?: DataType, name?: string): LayerVariable {\n  // TODO(cais): Implement logic for dtype.\n  const allocated = tfc.ones(shape);\n  return new LayerVariable(allocated, dtype, name);\n}\n\n/**\n * Instantiates an all-ones tensor of the same shape as another tensor.\n *\n * @param x The other tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return A newly instantiated Variable.\n */\nexport function onesLike(\n    x: Tensor, dtype?: DataType, name?: string): LayerVariable {\n  const allocated = tfc.onesLike(x);\n  return new LayerVariable(allocated, dtype, name);\n}\n\n/**\n * Instantiate an identity matrix and returns it, as a Variable\n *\n * @param size Number of rows/columns.\n * @param dtype Data type of returned Variable.\n * @param name Name of returned Variable.\n * @return A Variable, an identity matrix.\n */\nexport function eyeVariable(\n    size: number, dtype?: DataType, name?: string): LayerVariable {\n  return new LayerVariable(tfc.eye(size), dtype, name);\n}\n\n/**\n * Get a Variable with uniform distribution of values.\n * @param shape Shape of the tensor.\n * @param minval Lower bound of the uniform distribution.\n * @param maxval Upper bound of the uniform distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The uniform-random Variable.\n */\nexport function randomUniformVariable(\n    shape: Shape, minval: number, maxval: number, dtype?: DataType,\n    seed?: number, name = 'randomUniform'): LayerVariable {\n  return new LayerVariable(\n      tfc.randomUniform(shape, minval, maxval, dtype), dtype, name);\n}\n\n/**\n * Get a Variable with truncated-normal distribution of values.\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The truncated-normal-random Variable.\n */\nexport function truncatedNormalVariable(\n    shape: Shape, mean = 0.0, stddev = 1.0, dtype?: DataType, seed?: number,\n    name = 'truncatedNormal'): LayerVariable {\n  // TODO(cais): Implement logic for dtype and seed once they are supported\n  // by deeplearn.js.\n  dtype = dtype || 'float32';\n  if (dtype !== 'float32' && dtype !== 'int32') {\n    throw new NotImplementedError(\n        `randomNormal does not support dType ${dtype}.`);\n  }\n  return new LayerVariable(\n      tfc.truncatedNormal(shape, mean, stddev, dtype, seed), dtype, name);\n}\n/**\n * Get a Variable with normal distribution of values.\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The truncated-normal-random Variable.\n */\nexport function randomNormalVariable(\n    shape: Shape, mean = 0.0, stddev = 1.0, dtype?: DataType, seed?: number,\n    name = 'randomNormal'): LayerVariable {\n  dtype = dtype || 'float32';\n  if (dtype !== 'float32' && dtype !== 'int32') {\n    throw new NotImplementedError(\n        `randomNormalVariable does not support dType ${dtype}.`);\n  }\n  return new LayerVariable(\n      tfc.randomNormal(shape, mean, stddev, dtype, seed), dtype, name);\n}\n\n/**\n * Update the value of a Variable.\n * @param x The Variable to be updated.\n * @param xNew The new value to update to.\n * @return The Variable updated.\n */\nexport function update(x: LayerVariable, xNew: Tensor): LayerVariable {\n  return x.write(xNew);\n}\n\n/**\n * Update the value of a Variable by adding an increment.\n * @param x The Variable to be updated.\n * @param increment The incrment to add to `x`.\n * @return The Variable updated.\n */\nexport function updateAdd(x: LayerVariable, increment: Tensor): LayerVariable {\n  return x.write(tfc.add(x.read(), increment));\n}\n\n/**\n * Update the value of a Variable by subtracting a decrement.\n * @param x The Variable to be updated.\n * @param decrement The decrement to subtract from `x`.\n * @return The Variable updated.\n */\nexport function updateSub(x: LayerVariable, decrement: Tensor): LayerVariable {\n  return x.write(tfc.sub(x.read(), decrement));\n}\n\n/**\n * Get the values of an array of Variables.\n *\n * @param tensors An `Array` of `Variable`s to get the values of.\n * @return The values of the inputs, as an `Array` of`tf.Tensor`s.\n */\nexport function batchGetValue(xs: LayerVariable[]): Tensor[] {\n  return xs.map(x => x.read());\n}\n\n/**\n * Update the value of multiple Variables at once.\n *\n * @param variablesAndValues An `Array`, each element is of type\n *   [Variable, Tensor]. The first item is the\n *   `Variable` of which the value is to be updated. The second item\n *   carries the new value.\n */\nexport function batchSetValue(\n    variablesAndValues: Array<[LayerVariable, Tensor]>): void {\n  variablesAndValues.forEach(variableAndValue => {\n    const variable: LayerVariable = variableAndValue[0];\n    variable.write(variableAndValue[1]);\n  });\n}\n\n/**\n * Returns the gradients of `variables` w.r.t. the return value of `lossFn`.\n * @param lossFn A function which returns a Scalar to be used as the function\n *   value (i.e., numerator) for differentiation.\n * @param variables List of variables to be used as the independent variables\n *   (i.e., denominator) for differentiation.\n * @returns An Array of gradients tensors.\n */\nexport function gradients(\n    lossFn: () => tfc.Scalar, variables: LayerVariable[]): Tensor[] {\n  // TODO(cais): The return type signature can be simplified if deeplearn makes\n  //   the corresponding type public.\n  const variableList =\n      variables.map(variable => variable.read() as tfc.Variable);\n  const valudAndGrads = variableGrads(lossFn, variableList);\n  return variables.map(variable => valudAndGrads.grads[variable.name]);\n}\n"]}