{"version":3,"file":"losses_test.js","sourceRoot":"","sources":["../src/losses_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;AAEH;;GAEG;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAC,MAAM,EAAU,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAC,MAAM,uBAAuB,CAAC;AAEnF,OAAO,EAAC,OAAO,EAAC,MAAM,kBAAkB,CAAC;AACzC,OAAO,KAAK,MAAM,MAAM,UAAU,CAAC;AACnC,OAAO,EAAC,qBAAqB,EAAE,kBAAkB,EAAC,MAAM,oBAAoB,CAAC;AAE7E,qBAAqB,CAAC,kBAAkB,EAAE,GAAG,EAAE;IAC7C,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,WAAW,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;QACxD,MAAM,MAAM,GAAG,MAAM,CAAC,gBAAgB,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACrD,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,WAAW,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACzE,MAAM,MAAM,GAAG,MAAM,CAAC,gBAAgB,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACrD,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,mBAAmB,EAAE,GAAG,EAAE;IAC9C,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;QAC5C,MAAM,MAAM,GAAG,MAAM,CAAC,iBAAiB,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACtD,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrD,MAAM,WAAW,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,MAAM,GAAG,MAAM,CAAC,iBAAiB,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACtD,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,6BAA6B,EAAE,GAAG,EAAE;IACxD,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,MAAM,WAAW,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC;QAC5D,MAAM,MAAM,GAAG,MAAM,CAAC,2BAA2B,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAChE,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,WAAW,GACb,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC;QACjE,MAAM,MAAM,GAAG,MAAM,CAAC,2BAA2B,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAChE,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,6BAA6B,EAAE,GAAG,EAAE;IACxD,SAAS,6BAA6B,CAAC,CAAW,EAAE,CAAW;QAC7D,MAAM,OAAO,GAAG,CAAC,GAAW,EAAE,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,OAAO,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QACxE,MAAM,IAAI,GAAG,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC;QAC5B,MAAM,IAAI,GAAG,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC;QAC5B,IAAI,GAAG,GAAG,GAAG,CAAC;QACd,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YACjC,MAAM,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;YAC/B,GAAG,IAAI,IAAI,GAAG,IAAI,CAAC;SACpB;QACD,OAAO,GAAG,GAAG,CAAC,CAAC,MAAM,CAAC;IACxB,CAAC;IAED,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,WAAW,GAAG,QAAQ,CAAC;YAC3B,6BAA6B,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;YAC7C,6BAA6B,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;SAC9C,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,MAAM,CAAC,2BAA2B,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAChE,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,cAAc,EAAE,GAAG,EAAE;IACzC,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,mDAAmD;QACnD,MAAM,SAAS,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;QAC/D,MAAM,WAAW,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GAAG,MAAM,CAAC,YAAY,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACjD,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,OAAO,EAAE,GAAG,EAAE;IAClC,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,mDAAmD;QACnD,MAAM,SAAS,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,WAAW,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GAAG,MAAM,CAAC,KAAK,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAC1C,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,kBAAkB,EAAE,GAAG,EAAE;IAC7C,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvD,mDAAmD;QACnD,MAAM,YAAY,GAAG,CAAC,GAAG,CAAC,CAAC;QAC3B,MAAM,YAAY,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QAC5C,MAAM,YAAY,GAAG,YAAY,GAAG,YAAY,GAAG,CAAC,CAAC;QACrD,MAAM,WAAW,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC;QAChD,MAAM,MAAM,GAAG,MAAM,CAAC,gBAAgB,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACrD,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,SAAS,EAAE,GAAG,EAAE;IACpC,SAAS,QAAQ,CAAC,CAAS;QACzB,OAAO,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;IAC1D,CAAC;IACD,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;QACtC,MAAM,SAAS,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;QACvC,MAAM,QAAQ,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QACjD,MAAM,SAAS,GAAG,CAAC,SAAS,CAAC,CAAC,CAAC,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QACpD,MAAM,WAAW,GAAG,QAAQ,CAAC,CAAC,QAAQ,EAAE,SAAS,CAAC,CAAC,CAAC;QACpD,MAAM,MAAM,GAAG,MAAM,CAAC,OAAO,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAC5C,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,0BAA0B,EAAE,GAAG,EAAE;IACrD,EAAE,CAAC,aAAa,EAAE,GAAG,EAAE;QACrB,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,MAAM,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5D,MAAM,QAAQ,GAAG,QAAQ,CAAC;YACxB,CAAC,CAAC;gBACE,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI;oBAC1D,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC;YAChE,CAAC,CAAC;gBACE,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG;oBACzD,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC;SAChE,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,MAAM,CAAC,uBAAuB,CAAC,MAAM,EAAE,CAAC,EAAE,IAAI,CAAC,CAAC;QAC/D,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,cAAc,EAAE,GAAG,EAAE;QACtB,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrD,MAAM,MAAM,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5D,MAAM,QAAQ,GAAG,QAAQ,CAAC;YACxB,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,IAAI,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC;YAClD,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,GAAG,CAAC;SACjD,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,MAAM,CAAC,uBAAuB,CAAC,MAAM,EAAE,CAAC,EAAE,KAAK,CAAC,CAAC;QAChE,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,wBAAwB;IACxB,YAAY;IACZ,qBAAqB;IACrB,0BAA0B;IAC1B,+BAA+B;IAC/B,EAAE;IACF,6EAA6E;IAC7E,gEAAgE;IAChE,EAAE;IACF,6BAA6B;IAC7B,8CAA8C;IAC9C,mDAAmD;IACnD,0DAA0D;IAC1D,kCAAkC;IAClC,oBAAoB;IACpB,6BAA6B;IAC7B,QAAQ;IACR,MAAM;IACN,EAAE,CAAC,+BAA+B,EAAE,GAAG,EAAE;QACvC,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE;YACzE,CAAC;YACD,CAAC;YACD,CAAC;SACF,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzE,MAAM,MAAM,GAAG,MAAM,CAAC,uBAAuB,CAAC,MAAM,EAAE,CAAC,EAAE,KAAK,CAAC,CAAC;QAChE,kBAAkB,CACd,MAAM,EAAE,QAAQ,CAAC,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,EAAE,CAAC,UAAU,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,gCAAgC,EAAE,GAAG,EAAE;IAC3D,oCAAoC;IACpC,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,6BAA6B;IAC7B,8CAA8C;IAC9C,gDAAgD;IAChD,qEAAqE;IACrE,mBAAmB;IACnB,oBAAoB;IACpB,sBAAsB;IACtB,oBAAoB;IACpB,4DAA4D;IAC5D,2CAA2C;IAC3C,uDAAuD;IACvD,eAAe;IACf,eAAe;IACf,MAAM;IACN,EAAE,CAAC,+BAA+B,EAAE,GAAG,EAAE;QACvC,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/D,MAAM,MAAM,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,MAAM,GAAG,MAAM,CAAC,6BAA6B,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;QAC/D,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC;IAC/D,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,+BAA+B,EAAE,GAAG,EAAE;IAC1D,EAAE,CAAC,+BAA+B,EAAE,GAAG,EAAE;QACvC,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,MAAM,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5D,MAAM,gBAAgB,GAAG,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC;QAC7D,MAAM,QAAQ,GAAG,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,kBAAkB,GAAG,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC;QACjE,MAAM,QAAQ,GAAG,GAAG,CAAC,GAAG,CACpB,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,EAC3C,GAAG,CAAC,GAAG,CAAC,gBAAgB,EAAE,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GAAG,MAAM,CAAC,6BAA6B,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;QAC/D,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,oCAAoC;IACpC,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,8BAA8B;IAC9B,EAAE;IACF,sCAAsC;IACtC,mCAAmC;IACnC,gCAAgC;IAChC,sCAAsC;IACtC,mDAAmD;IACnD,kCAAkC;IAClC,kCAAkC;IAClC,kCAAkC;IAClC,kCAAkC;IAClC,qDAAqD;IACrD,EAAE;IACF,iDAAiD;IACjD,qCAAqC;IACrC,MAAM;IACN,EAAE,CAAC,8CAA8C,EAAE,GAAG,EAAE;QACtD,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5E,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,EAAE,GAAG,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,GAAG,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,GAAG,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,GAAG,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACvE,MAAM,OAAO,GAAG,MAAM,CAAC,6BAA6B,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;QACrE,kBAAkB,CAAC,OAAO,EAAE,QAAQ,CAAC;YAChB,CAAC,aAAa,EAAE,aAAa,EAAE,aAAa,CAAC;YAC7C,CAAC,aAAa,EAAE,aAAa,EAAE,aAAa,CAAC;YAC7C,CAAC,aAAa,EAAE,aAAa,EAAE,aAAa,CAAC;YAC7C,CAAC,aAAa,EAAE,aAAa,EAAE,aAAa,CAAC;YAC7C,CAAC,aAAa,EAAE,aAAa,EAAE,aAAa,CAAC;SAC9C,CAAC,CAAC,CAAC;IACzB,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,yBAAyB,EAAE,GAAG,EAAE;IACpD,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,KAAK,CAAC;QACpB,MAAM,WAAW,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,MAAM,GAAG,MAAM,CAAC,uBAAuB,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAC5D,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,+BAA+B,EAAE,GAAG,EAAE;IAC1D,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/B,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,WAAW,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,MAAM,GAAG,MAAM,CAAC,6BAA6B,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAClE,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,oBAAoB,EAAE,GAAG,EAAE;IAC/C,SAAS,mBAAmB,CAAC,MAAc,EAAE,MAAc;QACzD,MAAM,gBAAgB,GAAG,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC;QAC7D,MAAM,gBAAgB,GAAG,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC;QAC7D,OAAO,GAAG,CAAC,IAAI,CACX,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CACX,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,EAChC,GAAG,CAAC,GAAG,CAAC,gBAAgB,EAAE,GAAG,CAAC,GAAG,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,EAC1D,CAAC,CAAC,CAAC,CAAC;IACV,CAAC;IAED,EAAE,CAAC,cAAc,EAAE,GAAG,EAAE;QACtB,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrD,MAAM,MAAM,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5D,MAAM,QAAQ,GAAG,mBAAmB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;QAChD,MAAM,MAAM,GAAG,MAAM,CAAC,kBAAkB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;QACpD,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,2BAA2B,EAAE,GAAG,EAAE;IACtD,SAAS,SAAS,CAAC,MAAc,EAAE,SAAiB;QAClD,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,CAAC,CAAC;QACrC,SAAS,GAAG,IAAI,CAAC,GAAG,CAAC,SAAS,EAAE,OAAO,EAAE,CAAC,CAAC;QAC3C,OAAO,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,MAAM,GAAG,SAAS,CAAC,CAAC;IAC/C,CAAC;IAED,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,WAAW,GAAG,QAAQ,CAAC;YAC3B,SAAS,CAAC,CAAC,EAAE,IAAI,CAAC,GAAG,SAAS,CAAC,CAAC,EAAE,IAAI,CAAC;YACvC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC;SACtC,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,MAAM,CAAC,yBAAyB,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAC9D,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,SAAS,EAAE,GAAG,EAAE;IACpC,SAAS,cAAc,CAAC,MAAc,EAAE,SAAiB;QACvD,OAAO,SAAS,GAAG,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,SAAS,GAAG,OAAO,EAAE,CAAC,CAAC;IAC9D,CAAC;IAED,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,WAAW,GAAG,QAAQ,CAAC;YAC3B,CAAC,cAAc,CAAC,CAAC,EAAE,IAAI,CAAC,GAAG,cAAc,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,GAAG,CAAC;YACvD,CAAC,cAAc,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,cAAc,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC;SACtD,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,MAAM,CAAC,OAAO,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QAC5C,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,iBAAiB,EAAE,GAAG,EAAE;IAC5C,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE;QACZ,MAAM,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QAC3B,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,WAAW,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,MAAM,GAAG,MAAM,CAAC,eAAe,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;QACpD,kBAAkB,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,QAAQ,CAAC,YAAY,EAAE,GAAG,EAAE;IAC1B,KAAK,MAAM,QAAQ,IACP,CAAC,kBAAkB,EAAE,mBAAmB;QACvC,6BAA6B,EAAE,6BAA6B;QAC5D,cAAc,EAAE,OAAO,EAAE,kBAAkB,EAAE,SAAS;QACtD,yBAAyB,EAAE,+BAA+B;QAC1D,oBAAoB,EAAE,2BAA2B,EAAE,SAAS;QAC5D,iBAAiB,CAAC,EAAE;QAC/B,EAAE,CAAC,WAAW,QAAQ,EAAE,EAAE,GAAG,EAAE;YAC7B,MAAM,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;QACvB,CAAC,CAAC,CAAC;KACJ;IAED,EAAE,CAAC,uBAAuB,EAAE,GAAG,EAAE;QAC/B,MAAM,UAAU,GAAG,CAAC,CAAS,EAAE,CAAS,EAAE,EAAE,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;QAC1D,MAAM,CAAC,MAAM,CAAC,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;IACrD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,aAAa,EAAE,GAAG,EAAE;IACxC,EAAE,CAAC,kCAAkC,EAAE,GAAG,EAAE;QAC1C,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;QACtD,MAAM,QAAQ,GACV,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,EAAE,CAAC,GAAG,IAAI,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QACrC,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,6BAA6B,EAAE,GAAG,EAAE;QACrC,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,SAAS,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;QAC3C,MAAM,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;QAC5C,MAAM,QAAQ,GAAG,QAAQ,CACrB,CAAC,CAAC,CAAC,GAAG,SAAS,EAAE,CAAC,GAAG,SAAS,CAAC,EAAE,CAAC,CAAC,GAAG,UAAU,EAAE,CAAC,GAAG,UAAU,CAAC,CAAC,EAClE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACZ,MAAM,MAAM,GAAG,MAAM,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzC,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wBAAwB,EAAE,GAAG,EAAE;QAChC,MAAM,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5B,MAAM,MAAM,GAAG,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QACrC,kBAAkB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;IAChC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,oCAAoC,EAAE,GAAG,EAAE;QAC5C,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;QACtD,MAAM,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;QACtD,MAAM,QAAQ,GACV,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,EAAE,CAAC,GAAG,IAAI,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QACrC,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;QAC3C,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC;QAC7C,MAAM,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;QACtC,MAAM,QAAQ,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,EAAE,CAAC,GAAG,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,MAAM,GAAG,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QACrC,kBAAkB,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Unit tests for activations.ts.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {scalar, Tensor, tensor1d, tensor2d, tensor3d} from '@tensorflow/tfjs-core';\n\nimport {epsilon} from './backend/common';\nimport * as losses from './losses';\nimport {describeMathCPUAndGPU, expectTensorsClose} from './utils/test_utils';\n\ndescribeMathCPUAndGPU('meanSquaredError', () => {\n  it('1D', () => {\n    const yTrue = tfc.zeros([3]);\n    const yPred = tensor1d([1, 2, 3]);\n    const expectedVal = scalar((1 * 1 + 2 * 2 + 3 * 3) / 3);\n    const result = losses.meanSquaredError(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n\n  it('2D', () => {\n    const yTrue = tfc.zeros([2, 2]);\n    const yPred = tensor2d([[1, 2], [3, 4]], [2, 2]);\n    const expectedVal = tensor1d([(1 * 1 + 2 * 2) / 2, (3 * 3 + 4 * 4) / 2]);\n    const result = losses.meanSquaredError(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('meanAbsoluteError', () => {\n  it('1D', () => {\n    const yTrue = tfc.zeros([3]);\n    const yPred = tensor1d([-1, -2, -3]);\n    const expectedVal = scalar((1 + 2 + 3) / 3);\n    const result = losses.meanAbsoluteError(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n\n  it('2D', () => {\n    const yTrue = tfc.zeros([2, 2]);\n    const yPred = tensor2d([[-1, -2], [-3, -4]], [2, 2]);\n    const expectedVal = tensor1d([(1 + 2) / 2, (3 + 4) / 2]);\n    const result = losses.meanAbsoluteError(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('meanAbsolutePercentageError', () => {\n  it('1D', () => {\n    const yTrue = tensor1d([-1, -2, -3]);\n    const yPred = tfc.zeros([3]);\n    const expectedVal = scalar((1 + 2 + 3) / (1 + 2 + 3) * 100);\n    const result = losses.meanAbsolutePercentageError(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n\n  it('2D', () => {\n    const yTrue = tensor2d([[-1, -2], [-3, -4]], [2, 2]);\n    const yPred = tfc.zeros([2, 2]);\n    const expectedVal =\n        tensor1d([(1 + 2) / (1 + 2) * 100, (3 + 4) / (3 + 4) * 100]);\n    const result = losses.meanAbsolutePercentageError(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('meanSquaredLogarithmicError', () => {\n  function meanSquaredLogErrorFor1DArray(x: number[], y: number[]): number {\n    const calcLog = (val: number) => Math.log(Math.max(val, epsilon()) + 1);\n    const logX = x.map(calcLog);\n    const logY = y.map(calcLog);\n    let acc = 0.0;\n    for (let i = 0; i < x.length; i++) {\n      const diff = logX[i] - logY[i];\n      acc += diff * diff;\n    }\n    return acc / x.length;\n  }\n\n  it('2D', () => {\n    const yTrue = tfc.zeros([2, 2]);\n    const yPred = tensor2d([[1, 2], [3, 4]], [2, 2]);\n    const expectedVal = tensor1d([\n      meanSquaredLogErrorFor1DArray([1, 2], [0, 0]),\n      meanSquaredLogErrorFor1DArray([3, 4], [0, 0])\n    ]);\n    const result = losses.meanSquaredLogarithmicError(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('squaredHinge', () => {\n  it('2D', () => {\n    const yTrue = tensor2d([[-1, 2], [-3, 2]], [2, 2]);\n    const yPred = tensor2d([[-3, 5], [3, -2]], [2, 2]);\n    // First row has correct predictions, so loss is 0.\n    const secondRow = [1 - (-3 * 3), 1 - (2 * -2)].map(x => x * x);\n    const expectedVal = tensor1d([0, (secondRow[0] + secondRow[1]) / 2]);\n    const result = losses.squaredHinge(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('hinge', () => {\n  it('2D', () => {\n    const yTrue = tensor2d([[-1, 2], [-3, 2]], [2, 2]);\n    const yPred = tensor2d([[-3, 5], [3, -2]], [2, 2]);\n    // First row has correct predictions, so loss is 0.\n    const secondRow = [1 - (-3 * 3), 1 - (2 * -2)];\n    const expectedVal = tensor1d([0, (secondRow[0] + secondRow[1]) / 2]);\n    const result = losses.hinge(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('categoricalHinge', () => {\n  it('2D', () => {\n    const yTrue = tensor2d([[0, 1, 0], [1, 0, 0]], [2, 3]);\n    const yPred = tensor2d([[0, 2, 0], [1, 3, 2]], [2, 3]);\n    // First row has correct predictions, so loss is 0.\n    const secondRowPos = 1 * 1;\n    const secondRowNeg = Math.max(1 * 3, 1 * 2);\n    const secondRowVal = secondRowNeg - secondRowPos + 1;\n    const expectedVal = tensor1d([0, secondRowVal]);\n    const result = losses.categoricalHinge(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('logcosh', () => {\n  function _logcosh(x: number): number {\n    return x + Math.log(Math.exp(-2 * x) + 1) - Math.log(2);\n  }\n  it('2D', () => {\n    const yTrue = tfc.zeros([2, 2]);\n    const yPred = tensor2d([[1, 2], [3, 4]], [2, 2]);\n    const firstRow = [1, 2].map(_logcosh);\n    const secondRow = [3, 4].map(_logcosh);\n    const firstVal = (firstRow[0] + firstRow[1]) / 2;\n    const secondVal = (secondRow[0] + secondRow[1]) / 2;\n    const expectedVal = tensor1d([firstVal, secondVal]);\n    const result = losses.logcosh(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('categoricalCrossentropy ', () => {\n  it('from logits', () => {\n    const x = tensor2d([[1, 2], [3, 4]], [2, 2]);\n    const target = tensor2d([[0.25, 0.75], [0.1, 0.9]], [2, 2]);\n    const expected = tensor1d([\n      -1 *\n          (Math.log(Math.exp(1) / (Math.exp(1) + Math.exp(2))) * 0.25 +\n           Math.log(Math.exp(2) / (Math.exp(1) + Math.exp(2))) * 0.75),\n      -1 *\n          (Math.log(Math.exp(3) / (Math.exp(3) + Math.exp(4))) * 0.1 +\n           Math.log(Math.exp(4) / (Math.exp(3) + Math.exp(4))) * 0.9)\n    ]);\n    const result = losses.categoricalCrossentropy(target, x, true);\n    expectTensorsClose(result, expected);\n  });\n\n  it('from softmax', () => {\n    const x = tensor2d([[0.3, 0.7], [0.4, 0.6]], [2, 2]);\n    const target = tensor2d([[0.25, 0.75], [0.1, 0.9]], [2, 2]);\n    const expected = tensor1d([\n      -1 * (Math.log(0.3) * 0.25 + Math.log(0.7) * 0.75),\n      -1 * (Math.log(0.4) * 0.1 + Math.log(0.6) * 0.9)\n    ]);\n    const result = losses.categoricalCrossentropy(target, x, false);\n    expectTensorsClose(result, expected);\n  });\n\n  // Reference Python code\n  // ```python\n  // import numpy as np\n  // import tensorflow as tf\n  // from tensorflow import keras\n  //\n  // x_value = np.array([[[0.3, 0.7], [0.4, 0.6]], [[0.2, 0.8], [0.55, 0.45]]])\n  // target_value = np.array([[[0, 1], [1, 0]], [[0, 1], [1, 0]]])\n  //\n  // with tf.Session() as sess:\n  //   x = tf.placeholder(tf.float32, [2, 2, 2])\n  //   target = tf.placeholder(tf.float32, [2, 2, 2])\n  //   y = keras.backend.categorical_crossentropy(target, x)\n  //   print(sess.run(y, feed_dict={\n  //       x: x_value,\n  //       target: target_value\n  //   }))\n  // ```\n  it('from softmax, sequence output', () => {\n    const x = tensor3d([[[0.3, 0.7], [0.4, 0.6]], [[0.2, 0.8], [0.55, 0.45]]], [\n      2,\n      2,\n      2,\n    ]);\n    const target = tensor3d([[[0, 1], [1, 0]], [[0, 1], [1, 0]]], [2, 2, 2]);\n    const result = losses.categoricalCrossentropy(target, x, false);\n    expectTensorsClose(\n        result, tensor2d([[0.35667497, 0.9162907], [0.22314353, 0.597837]]));\n  });\n});\n\ndescribeMathCPUAndGPU('sparseCategoricalCrossentropy ', () => {\n  // Reference Python TensorFlow code:\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // with tf.Session() as sess:\n  //   x = tf.placeholder(tf.float32, [None, 3])\n  //   target = tf.placeholder(tf.float32, [None])\n  //   crossentropy = tf.keras.backend.sparse_categorical_crossentropy(\n  //       target, x)\n  //   out = sess.run(\n  //       crossentropy,\n  //       feed_dict={\n  //           x: np.array([[0.1, 0.2, 0.7], [0.2, 0.3, 0.5]],\n  //                       dtype=np.float32),\n  //           target: np.array([0, 2], dtype=np.float32)\n  //           })\n  //   print(out)\n  // ```\n  it('sparseCategoricalCrossentropy', () => {\n    const x = tensor2d([[0.1, 0.2, 0.7], [0.2, 0.3, 0.5]], [2, 3]);\n    const target = tensor1d([0, 2]);\n    const result = losses.sparseCategoricalCrossentropy(target, x);\n    expectTensorsClose(result, tensor1d([2.3025851, 0.6931472]));\n  });\n});\n\ndescribeMathCPUAndGPU('sigmoidCrossEntropyWithLogits', () => {\n  it('outputs sigmoid cross-entropy', () => {\n    const x = tensor2d([[1, 2], [3, 4]], [2, 2]);\n    const target = tensor2d([[0.25, 0.75], [0.1, 0.9]], [2, 2]);\n    const targetComplement = tfc.add(scalar(1), tfc.neg(target));\n    const sigmoidX = tfc.sigmoid(x);\n    const sigmoidXComplement = tfc.add(scalar(1), tfc.neg(sigmoidX));\n    const expected = tfc.add(\n        tfc.mul(target, tfc.neg(tfc.log(sigmoidX))),\n        tfc.mul(targetComplement, tfc.neg(tfc.log(sigmoidXComplement))));\n    const result = losses.sigmoidCrossEntropyWithLogits(target, x);\n    expectTensorsClose(result, expected);\n  });\n\n  // Python TensorFlow reference code:\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution()\n  //\n  // logits = np.array([[-10, -10, -10],\n  //                    [-5, -5, -5],\n  //                    [0, 0, 0],\n  //                    [0.5, 0.5, 0.5],\n  //                    [2, 2, 2]], dtype=np.float32)\n  // labels = np.array([[0, 0.5, 1],\n  //                    [0, 0.5, 1],\n  //                    [0, 0.5, 1],\n  //                    [0, 0.5, 1],\n  //                    [0, 0.5, 1]], dtype=np.float32)\n  //\n  // print(tf.nn.sigmoid_cross_entropy_with_logits(\n  //     logits=logits, labels=labels))\n  // ```\n  it('Comparison with TensorFlow references values', () => {\n    const logits = tensor2d(\n        [[-10, -10, -10], [-5, -5, -5], [0, 0, 0], [0.5, 0.5, 0.5], [2, 2, 2]]);\n    const labels = tensor2d(\n        [[0, 0.5, 1], [0, 0.5, 1], [0, 0.5, 1], [0, 0.5, 1], [0, 0.5, 1]]);\n    const outputs = losses.sigmoidCrossEntropyWithLogits(labels, logits);\n    expectTensorsClose(outputs, tensor2d([\n                         [4.5398901e-05, 5.0000453e+00, 1.0000046e+01],\n                         [6.7153485e-03, 2.5067153e+00, 5.0067153e+00],\n                         [6.9314718e-01, 6.9314718e-01, 6.9314718e-01],\n                         [9.7407699e-01, 7.2407699e-01, 4.7407699e-01],\n                         [2.1269281e+00, 1.1269280e+00, 1.2692800e-01]\n                       ]));\n  });\n});\n\ndescribeMathCPUAndGPU('categoricalCrossentropy', () => {\n  it('2D', () => {\n    const yTrue = tensor2d([[1, 0], [0, 1]], [2, 2]);\n    const yPred = yTrue;\n    const expectedVal = tfc.zeros([2]);\n    const result = losses.categoricalCrossentropy(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('sparseCategoricalCrossentropy', () => {\n  it('2D', () => {\n    const yTrue = tensor1d([0, 1]);\n    const yPred = tensor2d([[1, 0], [0, 1]], [2, 2]);\n    const expectedVal = tfc.zeros([2]);\n    const result = losses.sparseCategoricalCrossentropy(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('binaryCrossentropy', () => {\n  function _binaryCrossentropy(target: Tensor, output: Tensor): Tensor {\n    const targetComplement = tfc.add(scalar(1), tfc.neg(target));\n    const outputComplement = tfc.add(scalar(1), tfc.neg(output));\n    return tfc.mean(\n        tfc.neg(tfc.add(\n            tfc.mul(target, tfc.log(output)),\n            tfc.mul(targetComplement, tfc.log(outputComplement)))),\n        -1);\n  }\n\n  it('from sigmoid', () => {\n    const x = tensor2d([[0.3, 0.7], [0.4, 0.6]], [2, 2]);\n    const target = tensor2d([[0.25, 0.75], [0.1, 0.9]], [2, 2]);\n    const expected = _binaryCrossentropy(target, x);\n    const result = losses.binaryCrossentropy(target, x);\n    expectTensorsClose(result, expected);\n  });\n});\n\ndescribeMathCPUAndGPU('kullbackLeiblerDivergence', () => {\n  function klElement(actual: number, predicted: number): number {\n    actual = Math.max(actual, epsilon());\n    predicted = Math.max(predicted, epsilon());\n    return actual * Math.log(actual / predicted);\n  }\n\n  it('2D', () => {\n    const yTrue = tensor2d([[1, 0], [1, 0]], [2, 2]);\n    const yPred = tensor2d([[0.25, 0.75], [0.9, 0.1]], [2, 2]);\n    const expectedVal = tensor1d([\n      klElement(1, 0.25) + klElement(0, 0.75),\n      klElement(1, 0.9) + klElement(0, 0.1),\n    ]);\n    const result = losses.kullbackLeiblerDivergence(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('poisson', () => {\n  function poissonElement(actual: number, predicted: number): number {\n    return predicted - actual * Math.log(predicted + epsilon());\n  }\n\n  it('2D', () => {\n    const yTrue = tensor2d([[1, 0], [1, 0]], [2, 2]);\n    const yPred = tensor2d([[0.25, 0.75], [0.9, 0.1]], [2, 2]);\n    const expectedVal = tensor1d([\n      (poissonElement(1, 0.25) + poissonElement(0, 0.75)) / 2,\n      (poissonElement(1, 0.9) + poissonElement(0, 0.1)) / 2,\n    ]);\n    const result = losses.poisson(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribeMathCPUAndGPU('cosineProximity', () => {\n  it('2D', () => {\n    const z = Math.sqrt(2) / 2;\n    const yTrue = tensor2d([[1, 0], [1, 0]], [2, 2]);\n    const yPred = tensor2d([[z, z], [0, 1]], [2, 2]);\n    const expectedVal = tensor1d([-1 * z, 0]);\n    const result = losses.cosineProximity(yTrue, yPred);\n    expectTensorsClose(result, expectedVal);\n  });\n});\n\ndescribe('losses get', () => {\n  for (const lossName\n           of ['meanSquaredError', 'meanAbsoluteError',\n               'meanAbsolutePercentageError', 'meanSquaredLogarithmicError',\n               'squaredHinge', 'hinge', 'categoricalHinge', 'logcosh',\n               'categoricalCrossentropy', 'sparseCategoricalCrossentropy',\n               'binaryCrossentropy', 'kullbackLeiblerDivergence', 'poisson',\n               'cosineProximity']) {\n    it(`can get ${lossName}`, () => {\n      losses.get(lossName);\n    });\n  }\n\n  it(`get custom loss works`, () => {\n    const customLoss = (x: Tensor, y: Tensor) => scalar(42.0);\n    expect(losses.get(customLoss)).toEqual(customLoss);\n  });\n});\n\ndescribeMathCPUAndGPU('l2Normalize', () => {\n  it('normalizes with no axis defined.', () => {\n    const x = tensor2d([[1, 2], [3, 4]], [2, 2]);\n    const norm = Math.sqrt(1 * 1 + 2 * 2 + 3 * 3 + 4 * 4);\n    const expected =\n        tensor2d([[1 / norm, 2 / norm], [3 / norm, 4 / norm]], [2, 2]);\n    const result = losses.l2Normalize(x);\n    expectTensorsClose(result, expected);\n  });\n\n  it('normalizes along axis = -1.', () => {\n    const x = tensor2d([[1, 2], [3, 4]], [2, 2]);\n    const firstNorm = Math.sqrt(1 * 1 + 2 * 2);\n    const secondNorm = Math.sqrt(3 * 3 + 4 * 4);\n    const expected = tensor2d(\n        [[1 / firstNorm, 2 / firstNorm], [3 / secondNorm, 4 / secondNorm]],\n        [2, 2]);\n    const result = losses.l2Normalize(x, -1);\n    expectTensorsClose(result, expected);\n  });\n\n  it('normalizes with zeros.', () => {\n    const x = tfc.zeros([2, 2]);\n    const result = losses.l2Normalize(x);\n    expectTensorsClose(result, x);\n  });\n\n  it('normalizes casts int32 as float32.', () => {\n    const x = tensor2d([[1, 2], [3, 4]], [2, 2], 'int32');\n    const norm = Math.sqrt(1 * 1 + 2 * 2 + 3 * 3 + 4 * 4);\n    const expected =\n        tensor2d([[1 / norm, 2 / norm], [3 / norm, 4 / norm]], [2, 2]);\n    const result = losses.l2Normalize(x);\n    expectTensorsClose(result, expected);\n  });\n\n  it('normalizes casts bool as float32.', () => {\n    const x = tensor2d([[1, 1]], [1, 2], 'bool');\n    const norm = Math.sqrt(1 * 1 + 1 * 1);\n    const expected = tensor2d([[1 / norm, 1 / norm]], [1, 2]);\n    const result = losses.l2Normalize(x);\n    expectTensorsClose(result, expected);\n  });\n});\n"]}