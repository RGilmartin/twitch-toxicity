{"version":3,"file":"training_dataset_test.js","sourceRoot":"","sources":["../../src/engine/training_dataset_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;AAEH;;;GAGG;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAC,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAE3C,OAAO,EAAC,cAAc,EAAE,sBAAsB,EAAC,MAAM,mBAAmB,CAAC;AACzE,OAAO,KAAK,GAAG,MAAM,UAAU,CAAC;AAEhC,OAAO,EAAC,qBAAqB,EAAE,kBAAkB,EAAC,MAAM,qBAAqB,CAAC;AAE9E,OAAO,EAAC,kBAAkB,EAAC,MAAM,iBAAiB,CAAC;AAEnD,SAAS,gBAAgB;IACvB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;IAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;IAC9D,OAAO,KAAK,CAAC;AACf,CAAC;AAED,qBAAqB,CAAC,wBAAwB,EAAE,GAAG,EAAE;IACnD,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,uDAAuD;IACvD,uDAAuD;IACvD,2EAA2E;IAC3E,EAAE;IACF,gCAAgC;IAChC,mCAAmC;IACnC,SAAS;IACT,uBAAuB;IACvB,mCAAmC;IACnC,4DAA4D;IAC5D,EAAE;IACF,2EAA2E;IAC3E,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,mEAAmE,EACnE,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC9D,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;QAC/D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,iEAAiE,EACjE,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC7C,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAC,CAAC,CAAC;QAC1D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,+BAA+B;IAC/B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,uDAAuD;IACvD,uDAAuD;IACvD,2EAA2E;IAC3E,EAAE;IACF,gCAAgC;IAChC,mCAAmC;IACnC,SAAS;IACT,uBAAuB;IACvB,mCAAmC;IACnC,2CAA2C;IAC3C,iCAAiC;IACjC,iCAAiC;IACjC,EAAE;IACF,2EAA2E;IAC3E,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,kEAAkE,EAClE,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC9D,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;QAC/D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,gEAAgE,EAChE,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC7C,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAC,CAAC,CAAC;QAC1D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,+BAA+B;IAC/B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,uDAAuD;IACvD,uDAAuD;IACvD,2EAA2E;IAC3E,yCAAyC;IACzC,yCAAyC;IACzC,EAAE;IACF,gCAAgC;IAChC,mCAAmC;IACnC,SAAS;IACT,uBAAuB;IACvB,mCAAmC;IACnC,4DAA4D;IAC5D,wBAAwB;IACxB,EAAE;IACF,qDAAqD;IACrD,yCAAyC;IACzC,qDAAqD;IACrD,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,0CAA0C;IAC1C,wDAAwD;IACxD,oDAAoD;IACpD,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,4DAA4D;QACxD,sBAAsB,EAC1B,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QACH,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE5C,4DAA4D;QAC5D,6CAA6C;QAC7C,MAAM,KAAK,CAAC,UAAU,CAClB,OAAO,EACP,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAE,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,EAAC,CAAC,CAAC;QAClE,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,eAAe;YACf,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,iBAAiB,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;oBACtC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;gBACrC,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,CAAC;YAClD,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,SAAS;SACrC,CAAC,IAAI,EAAE,CAAC,CAAC;QACV,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAClD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QAEtD,MAAM,CAAC,iBAAiB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACnD,MAAM,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACnD,MAAM,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,4DAA4D;QACxD,oBAAoB,EACxB,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QACH,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE5C,4DAA4D;QAC5D,6CAA6C;QAC7C,MAAM,KAAK,CAAC,UAAU,CAClB,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAE,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,EAAC,CAAC,CAAC;QAC1D,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,iBAAiB,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;oBACtC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;gBACrC,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,CAAC;YAClD,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,SAAS;SACrC,CAAC,IAAI,EAAE,CAAC,CAAC;QACV,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAClD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QAEtD,MAAM,CAAC,iBAAiB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACnD,MAAM,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACnD,MAAM,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,kCAAkC,EAAE,KAAK,IAAI,EAAE;QAChD,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,MAAM,SAAS,GAAW,EAAE,CAAC;QAC7B,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,MAAM;YACN,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACvB,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACpC,0EAA0E;QAC1E,SAAS;QACT,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;IAC3D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,sDAAsD,EAAE,KAAK,IAAI,EAAE;QACpE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,IAAI,aAAqB,CAAC;QAC1B,MAAM,YAAa,SAAQ,cAAc;YACvC;gBACE,KAAK,CAAC;oBACJ,YAAY,EAAE,KAAK,EAAE,IAAW,EAAE,EAAE;wBAClC,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC,KAAe,CAAC;oBAC9C,CAAC;iBACF,CAAC,CAAC;YACL,CAAC;SACF;QAED,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QACzE,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAE,SAAS,EAAE,IAAI,YAAY,EAAE,EAAC,CAAC,CAAC;QAEzE,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC;QAC9C,MAAM,CAAC,aAAa,CAAC,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC;IACjD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4DAA4D,EAAE,KAAK,IAAI,EAAE;QAC1E,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,UAAU,GAAG,CAAC,CAAC;QACrB,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU;YACV,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,IAAI,aAAqB,CAAC;QAC1B,MAAM,YAAa,SAAQ,cAAc;YACvC;gBACE,KAAK,CAAC;oBACJ,YAAY,EAAE,KAAK,EAAE,IAAW,EAAE,EAAE;wBAClC,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC,KAAe,CAAC;oBAC9C,CAAC;iBACF,CAAC,CAAC;YACL,CAAC;SACF;QAED,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QACzE,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,MAAM;YACN,eAAe,EAAE,UAAU,GAAG,CAAC;YAC/B,SAAS,EAAE,IAAI,YAAY,EAAE;SAC9B,CAAC,CAAC;QAEH,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;QACzC,MAAM,CAAC,aAAa,CAAC,CAAC,OAAO,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,8BAA8B;IAC9B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,uDAAuD;IACvD,uDAAuD;IACvD,2EAA2E;IAC3E,yCAAyC;IACzC,yCAAyC;IACzC,oDAAoD;IACpD,0CAA0C;IAC1C,EAAE;IACF,gCAAgC;IAChC,mCAAmC;IACnC,SAAS;IACT,uBAAuB;IACvB,mCAAmC;IACnC,2CAA2C;IAC3C,mEAAmE;IACnE,sCAAsC;IACtC,EAAE;IACF,qDAAqD;IACrD,yCAAyC;IACzC,qDAAqD;IACrD,EAAE;IACF,yCAAyC;IACzC,qDAAqD;IACrD,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,oCAAoC;IACpC,0CAA0C;IAC1C,mDAAmD;IACnD,oDAAoD;IACpD,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,6DAA6D;QACzD,sBAAsB,EAC1B,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,oBAAoB;QACpB,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,sBAAsB;QACtB,MAAM,eAAe,GAAG,GAAG,EAAE,CACzB,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACpD,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACpD,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,eAAe,GAAG,GAAG,EAAE,CACzB,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACpD,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACpD,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,UAAU,GAAG,IAAI,kBAAkB,CAAC;YACxC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY,EAAE,eAAe;YAC7B,YAAY,EAAE,eAAe;SAC9B,CAAC,CAAC;QAEH,4DAA4D;QAC5D,6CAA6C;QAC7C,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,eAAe;YACf,MAAM;YACN,cAAc,EAAE,UAAU;YAC1B,iBAAiB,EAAE,eAAe,GAAG,MAAM;SAC5C,CAAC,CAAC;QACH,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,eAAe;YACf,MAAM;YACN,cAAc,EAAE,UAAU;YAC1B,iBAAiB,EAAE,eAAe,GAAG,MAAM;YAC3C,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,iBAAiB,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;oBACtC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;gBACrC,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,CAAC;YAClD,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,SAAS;SACrC,CAAC,IAAI,EAAE,CAAC,CAAC;QACV,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAClD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QAEtD,MAAM,CAAC,iBAAiB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACnD,MAAM,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACnD,MAAM,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,6DAA6D;QACzD,oBAAoB,EACxB,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,oBAAoB;QACpB,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,sBAAsB;QACtB,MAAM,eAAe,GAAG,GAAG,EAAE,CACzB,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACpD,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,eAAe,GAAG,GAAG,EAAE,CACzB,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACpD,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAChC,MAAM,UAAU,GAAG,IAAI,kBAAkB,CAAC;YACxC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY,EAAE,eAAe;YAC7B,YAAY,EAAE,eAAe;SAC9B,CAAC,CAAC;QAEH,4DAA4D;QAC5D,6CAA6C;QAC7C,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAE,cAAc,EAAE,UAAU,EAAC,CAAC,CAAC;QACtE,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,MAAM;YACN,cAAc,EAAE,UAAU;YAC1B,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,iBAAiB,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;oBACtC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;gBACrC,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,CAAC;YAClD,MAAM,EAAE,KAAK,EAAE,UAAU,EAAE,SAAS;SACrC,CAAC,IAAI,EAAE,CAAC,CAAC;QACV,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAClD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QAEtD,MAAM,CAAC,iBAAiB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACnD,MAAM,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACnD,MAAM,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,oEAAoE,EACpE,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;SACrC,CAAC,CAAC;QACH,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE5C,4DAA4D;QAC5D,6CAA6C;QAC7C,MAAM,KAAK,CAAC,UAAU,CAClB,OAAO,EACP,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAE,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,EAAC,CAAC,CAAC;QAClE,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,eAAe;YACf,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;gBACvD,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,kEAAkE,EAClE,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAClC,EAAC,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,UAAU,EAAE,eAAe,EAAC,CAAC,CAAC;QACxE,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE5C,4DAA4D;QAC5D,6CAA6C;QAC7C,MAAM,KAAK,CAAC,UAAU,CAClB,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAE,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,EAAC,CAAC,CAAC;QAC1D,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;gBACvD,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEN,gCAAgC;IAChC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,+BAA+B;IAC/B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,uDAAuD;IACvD,uDAAuD;IACvD,2EAA2E;IAC3E,EAAE;IACF,gCAAgC;IAChC,mCAAmC;IACnC,SAAS;IACT,uBAAuB;IACvB,mCAAmC;IACnC,4DAA4D;IAC5D,wBAAwB;IACxB,EAAE;IACF,qDAAqD;IACrD,yCAAyC;IACzC,qDAAqD;IACrD,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,oDAAoD;IACpD,yBAAyB;IACzB,MAAM;IACN,EAAE,CAAC,wDAAwD;QACpD,sBAAsB,EAC1B,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC9D,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,IAAI,iBAAiB,GAAG,CAAC,CAAC;QAC1B,IAAI,eAAe,GAAG,CAAC,CAAC;QACxB,MAAM,gBAAgB,GAAa,EAAE,CAAC;QACtC,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,MAAM,YAAY,GAAa,EAAE,CAAC;QAClC,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,MAAM,YAAY,GAAa,EAAE,CAAC;QAClC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,eAAe;YACf,MAAM;YACN,SAAS,EAAE;gBACT,YAAY,EAAE,KAAK,IAAI,EAAE;oBACvB,iBAAiB,EAAE,CAAC;gBACtB,CAAC;gBACD,UAAU,EAAE,KAAK,IAAI,EAAE;oBACrB,eAAe,EAAE,CAAC;gBACpB,CAAC;gBACD,YAAY,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE;oBAC5B,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAC/B,CAAC;gBACD,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,cAAc,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC3B,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;oBAC/B,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;gBAC9B,CAAC;gBACD,YAAY,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAClC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAChC,CAAC;gBACD,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,eAAe,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC5B,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;oBAC/B,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;gBAC9B,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QAEtD,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,gBAAgB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzC,MAAM,CAAC,cAAc,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACzC,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAChD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAChD,MAAM,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QACvC,kBAAkB,CACd,cAAc,EAAE,CAAC,CAAC,EAAE,MAAM,EAAE,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,0EAA0E,EAC1E,KAAK,IAAI,EAAE;QACT,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC7C,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,IAAI,iBAAiB,GAAG,CAAC,CAAC;QAC1B,IAAI,eAAe,GAAG,CAAC,CAAC;QACxB,MAAM,gBAAgB,GAAa,EAAE,CAAC;QACtC,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,MAAM,YAAY,GAAa,EAAE,CAAC;QAClC,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,MAAM,YAAY,GAAa,EAAE,CAAC;QAClC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,MAAM;YACN,SAAS,EAAE;gBACT,YAAY,EAAE,KAAK,IAAI,EAAE;oBACvB,iBAAiB,EAAE,CAAC;gBACtB,CAAC;gBACD,UAAU,EAAE,KAAK,IAAI,EAAE;oBACrB,eAAe,EAAE,CAAC;gBACpB,CAAC;gBACD,YAAY,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE;oBAC5B,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAC/B,CAAC;gBACD,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,cAAc,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC3B,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;oBAC/B,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;gBAC9B,CAAC;gBACD,YAAY,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAClC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAChC,CAAC;gBACD,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,eAAe,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC5B,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;oBAC/B,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;gBAC9B,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QAEtD,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,gBAAgB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzC,MAAM,CAAC,cAAc,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACzC,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAChD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAChD,MAAM,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QACvC,kBAAkB,CACd,cAAc,EAAE,CAAC,CAAC,EAAE,MAAM,EAAE,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;IAEN,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,oDAAoD;IACpD,oDAAoD;IACpD,yDAAyD;IACzD,6BAA6B;IAC7B,+CAA+C;IAC/C,iEAAiE;IACjE,iBAAiB;IACjB,gEAAgE;IAChE,oBAAoB;IACpB,kBAAkB;IAClB,qBAAqB;IACrB,qBAAqB;IACrB,EAAE;IACF,wDAAwD;IACxD,wDAAwD;IACxD,uDAAuD;IACvD,gDAAgD;IAChD,sDAAsD;IACtD,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,mEAAmE,EACnE,KAAK,IAAI,EAAE;QACT,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC9D,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;QAC/D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,iEAAiE,EACjE,KAAK,IAAI,EAAE;QACT,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC7C,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAC,CAAC,CAAC;QAC1D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,8BAA8B;IAC9B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,oDAAoD;IACpD,oDAAoD;IACpD,yDAAyD;IACzD,6BAA6B;IAC7B,+CAA+C;IAC/C,iEAAiE;IACjE,iBAAiB;IACjB,iCAAiC;IACjC,yDAAyD;IACzD,4BAA4B;IAC5B,kBAAkB;IAClB,qBAAqB;IACrB,qBAAqB;IACrB,EAAE;IACF,wDAAwD;IACxD,wDAAwD;IACxD,uDAAuD;IACvD,gDAAgD;IAChD,sDAAsD;IACtD,EAAE;IACF,uCAAuC;IACvC,uCAAuC;IACvC,qCAAqC;IACrC,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,6CAA6C;IAC7C,wDAAwD;IACxD,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,yDAAyD;QACrD,sBAAsB,EAC1B,KAAK,IAAI,EAAE;QACT,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,iBAAiB;QACjB,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,mBAAmB;QACnB,MAAM,KAAK,GACP,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAExC,oEAAoE;QACpE,qCAAqC;QACrC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,eAAe;YACf,MAAM,EAAE,CAAC;YACT,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,eAAe;YACf,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,CAAC;YAClD,KAAK,EAAE,MAAM,EAAE,SAAS,EAAE,UAAU;SACrC,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACpD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACpD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,yDAAyD;QACrD,oBAAoB,EACxB,KAAK,IAAI,EAAE;QACT,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,iBAAiB;QACjB,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,mBAAmB;QACnB,MAAM,KAAK,GACP,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAExC,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,MAAM,EAAE,CAAC;YACT,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,CAAC;YAClD,KAAK,EAAE,MAAM,EAAE,SAAS,EAAE,UAAU;SACrC,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACpD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACpD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,8BAA8B;IAC9B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,oDAAoD;IACpD,oDAAoD;IACpD,yDAAyD;IACzD,6BAA6B;IAC7B,+CAA+C;IAC/C,iEAAiE;IACjE,iBAAiB;IACjB,iCAAiC;IACjC,yDAAyD;IACzD,4BAA4B;IAC5B,kBAAkB;IAClB,qBAAqB;IACrB,qBAAqB;IACrB,EAAE;IACF,wDAAwD;IACxD,wDAAwD;IACxD,uDAAuD;IACvD,gDAAgD;IAChD,sDAAsD;IACtD,EAAE;IACF,aAAa;IACb,uCAAuC;IACvC,sCAAsC;IACtC,IAAI;IACJ,qCAAqC;IACrC,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,6CAA6C;IAC7C,wDAAwD;IACxD,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,wDAAwD;QACpD,sBAAsB,EAC1B,KAAK,IAAI,EAAE;QACT,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,iBAAiB;QACjB,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,mBAAmB;QACnB,MAAM,KAAK,GAAuB,EAAE,CAAC;QACrC,KAAK,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/C,KAAK,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAExC,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,eAAe;YACf,MAAM,EAAE,CAAC;YACT,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,eAAe;YACf,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,CAAC;YAClD,KAAK,EAAE,MAAM,EAAE,SAAS,EAAE,UAAU;SACrC,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACpD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACpD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,wDAAwD;QACpD,oBAAoB,EACxB,KAAK,IAAI,EAAE;QACT,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,iBAAiB;QACjB,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,mBAAmB;QACnB,MAAM,KAAK,GAAuB,EAAE,CAAC;QACrC,KAAK,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/C,KAAK,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAExC,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,MAAM,EAAE,CAAC;YACT,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,CAAC;YAClD,KAAK,EAAE,MAAM,EAAE,SAAS,EAAE,UAAU;SACrC,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACpD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACpD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,2DAA2D,EAAE,KAAK,IAAI,EAAE;QACzE,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,uDAAuD;YACvD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,IAAI,WAAkB,CAAC;QACvB,IAAI;YACF,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;SAC5D;QAAC,OAAO,GAAG,EAAE;YACZ,WAAW,GAAG,GAAG,CAAC;SACnB;QACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;aACtB,OAAO,CACJ,+DAA+D;YAC/D,cAAc,MAAM,CAAC,IAAI,IAAI,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yDAAyD,EAAE,KAAK,IAAI,EAAE;QACvE,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,uDAAuD;YACvD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,IAAI,WAAkB,CAAC;QACvB,IAAI;YACF,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAC,CAAC,CAAC;SAC3C;QAAC,OAAO,GAAG,EAAE;YACZ,WAAW,GAAG,GAAG,CAAC;SACnB;QACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;aACtB,OAAO,CACJ,+DAA+D;YAC/D,cAAc,MAAM,CAAC,IAAI,IAAI,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IAEH,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,0CAA0C;IAC1C,EAAE;IACF,mCAAmC;IACnC,wCAAwC;IACxC,mCAAmC;IACnC,wCAAwC;IACxC,EAAE;IACF,+DAA+D;IAC/D,iBAAiB;IACjB,gEAAgE;IAChE,oBAAoB;IACpB,kBAAkB;IAClB,uCAAuC;IACvC,uCAAuC;IACvC,sBAAsB;IACtB,sBAAsB;IACtB,EAAE;IACF,uDAAuD;IACvD,wDAAwD;IACxD,wDAAwD;IACxD,gDAAgD;IAChD,sEAAsE;IACtE,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,mEAAmE,EACnE,KAAK,IAAI,EAAE;QACT,4CAA4C;QAC5C,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QAClE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QAEF,MAAM,MAAM,GAA+B,EAAE,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM;YACN,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC9D,KAAK,CAAC,UAAU,CAAC;YACf,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;SACrE,CAAC,CAAC;QAEH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;QAE/D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QAEzC,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QACvD,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QAEvD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC;YAC3C,MAAM,EAAE,eAAe,EAAE,eAAe,EAAE,cAAc;YACxD,cAAc;SACf,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,iEAAiE,EACjE,KAAK,IAAI,EAAE;QACT,4CAA4C;QAC5C,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QAClE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QAEF,MAAM,MAAM,GAA+B,EAAE,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM;YACN,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC7C,KAAK,CAAC,UAAU,CAAC;YACf,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;SACrE,CAAC,CAAC;QAEH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAC,CAAC,CAAC;QAE1D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QAEzC,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QACvD,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QAEvD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC;YAC3C,MAAM,EAAE,eAAe,EAAE,eAAe,EAAE,cAAc;YACxD,cAAc;SACf,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,0CAA0C;IAC1C,EAAE;IACF,mCAAmC;IACnC,wCAAwC;IACxC,mCAAmC;IACnC,wCAAwC;IACxC,EAAE;IACF,+DAA+D;IAC/D,iBAAiB;IACjB,gEAAgE;IAChE,oBAAoB;IACpB,kBAAkB;IAClB,uCAAuC;IACvC,uCAAuC;IACvC,sBAAsB;IACtB,sBAAsB;IACtB,EAAE;IACF,uDAAuD;IACvD,wDAAwD;IACxD,wDAAwD;IACxD,gDAAgD;IAChD,sEAAsE;IACtE,EAAE;IACF,qCAAqC;IACrC,qDAAqD;IACrD,qDAAqD;IACrD,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,wDAAwD;IACxD,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,yDAAyD;QACrD,sBAAsB,EAC1B,KAAK,IAAI,EAAE;QACT,4CAA4C;QAC5C,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QAClE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QAEF,MAAM,MAAM,GAA+B,EAAE,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM;YACN,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,mBAAmB;QACnB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,KAAK,GAAuB,EAAE,CAAC;QACrC,KAAK,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACxD,KAAK,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,eAAe;YACf,MAAM,EAAE,CAAC;YACT,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,KAAK,CAAC,UAAU,CAAC;YACf,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;SACrE,CAAC,CAAC;QAEH,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,eAAe;YACf,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QAEH,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QACvD,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QACvD,MAAM,iBAAiB,GAAG,MAAM,GAAG,cAAc,CAAC;QAClD,MAAM,kBAAkB,GAAG,MAAM,GAAG,eAAe,CAAC;QACpD,MAAM,iBAAiB,GAAG,MAAM,GAAG,cAAc,CAAC;QAClD,MAAM,kBAAkB,GAAG,MAAM,GAAG,eAAe,CAAC;QAEpD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC;YAC3C,UAAU,EAAE,kBAAkB,EAAE,kBAAkB,EAAE,iBAAiB;YACrE,iBAAiB,EAAE,MAAM,EAAE,eAAe,EAAE,eAAe;YAC3D,cAAc,EAAE,cAAc;SAC/B,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACpE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACpE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC7D,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,yDAAyD;QACrD,oBAAoB,EACxB,KAAK,IAAI,EAAE;QACT,4CAA4C;QAC5C,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QAClE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QAEF,MAAM,MAAM,GAA+B,EAAE,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM;YACN,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,mBAAmB;QACnB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,KAAK,GAAuB,EAAE,CAAC;QACrC,KAAK,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACxD,KAAK,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9B,MAAM,EAAE,CAAC;YACT,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QACH,KAAK,CAAC,UAAU,CAAC;YACf,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;SACrE,CAAC,CAAC;QAEH,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,MAAM;YACN,cAAc,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC;YAC9B,mBAAmB,EAAE,SAAS;SAC/B,CAAC,CAAC;QAEH,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QACvD,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QACvD,MAAM,iBAAiB,GAAG,MAAM,GAAG,cAAc,CAAC;QAClD,MAAM,kBAAkB,GAAG,MAAM,GAAG,eAAe,CAAC;QACpD,MAAM,iBAAiB,GAAG,MAAM,GAAG,cAAc,CAAC;QAClD,MAAM,kBAAkB,GAAG,MAAM,GAAG,eAAe,CAAC;QAEpD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC;YAC3C,UAAU,EAAE,kBAAkB,EAAE,kBAAkB,EAAE,iBAAiB;YACrE,iBAAiB,EAAE,MAAM,EAAE,eAAe,EAAE,eAAe;YAC3D,cAAc,EAAE,cAAc;SAC/B,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACpE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACpE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC7D,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,8DAA8D,EAC9D,KAAK,IAAI,EAAE;QACT,4CAA4C;QAC5C,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QAClE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QAEF,MAAM,MAAM,GAA+B,EAAE,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM;YACN,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,IAAI,WAAkB,CAAC;QACvB,IAAI;YACF,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;SAC5D;QAAC,OAAO,GAAG,EAAE;YACZ,WAAW,GAAG,GAAG,CAAC;SACnB;QACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;aACtB,OAAO,CACJ,+DAA+D;YAC/D,eAAe,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;IACnD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,4DAA4D,EAAE,KAAK,IAAI,EAAE;QAC1E,4CAA4C;QAC5C,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAC9C,CAAC;QACvB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QAClE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QAEF,MAAM,MAAM,GAA+B,EAAE,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM;YACN,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,IAAI,WAAkB,CAAC;QACvB,IAAI;YACF,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAC,CAAC,CAAC;SAC3C;QAAC,OAAO,GAAG,EAAE;YACZ,WAAW,GAAG,GAAG,CAAC;SACnB;QACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;aACtB,OAAO,CACJ,+DAA+D;YAC/D,eAAe,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;IACnD,CAAC,CAAC,CAAC;IAEH,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,aAAa;IACb,EAAE;IACF,gDAAgD;IAChD,gDAAgD;IAChD,yDAAyD;IACzD,EAAE;IACF,mCAAmC;IACnC,6CAA6C;IAC7C,mCAAmC;IACnC,6CAA6C;IAC7C,EAAE;IACF,0BAA0B;IAC1B,gCAAgC;IAChC,mCAAmC;IACnC,iBAAiB;IACjB,gEAAgE;IAChE,oBAAoB;IACpB,kBAAkB;IAClB,uCAAuC;IACvC,uCAAuC;IACvC,YAAY;IACZ,YAAY;IACZ,sBAAsB;IACtB,sBAAsB;IACtB,EAAE;IACF,wDAAwD;IACxD,wDAAwD;IACxD,wDAAwD;IACxD,wDAAwD;IACxD,gDAAgD;IAChD,SAAS;IACT,kBAAkB;IAClB,iBAAiB;IACjB,WAAW;IACX,4BAA4B;IAC5B,2BAA2B;IAC3B,6BAA6B;IAC7B,EAAE;IACF,+BAA+B;IAC/B,mDAAmD;IACnD,qCAAqC;IACrC,yBAAyB;IACzB,gCAAgC;IAChC,gCAAgC;IAChC,gCAAgC;IAChC,gCAAgC;IAChC,MAAM;IACN,EAAE,CAAC,oEAAoE,EACpE,KAAK,IAAI,EAAE;QACT,yDAAyD;QACzD,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,OAAO,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACzD,MAAM,OAAO,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACzD,MAAM,KAAK,GACP,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QACvE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,iBAAiB;QACjB,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACnD,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QAEF,MAAM,MAAM,GAA+B,EAAE,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM;YACN,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC9D,KAAK,CAAC,UAAU,CAAC;YACf,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;SACrE,CAAC,CAAC;QAEH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;QAE/D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QAEzC,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QACvD,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QAEvD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC;YAC3C,MAAM,EAAE,eAAe,EAAE,eAAe,EAAE,cAAc;YACxD,cAAc;SACf,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,kEAAkE,EAClE,KAAK,IAAI,EAAE;QACT,yDAAyD;QACzD,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,OAAO,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACzD,MAAM,OAAO,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACzD,MAAM,KAAK,GACP,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QACvE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,iBAAiB;QACjB,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG;gBAC7B,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QAEF,MAAM,MAAM,GAA+B,EAAE,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM;YACN,SAAS;YACT,UAAU,EAAE,eAAe;YAC3B,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC7C,KAAK,CAAC,UAAU,CAAC;YACf,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;SACrE,CAAC,CAAC;QAEH,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAC,CAAC,CAAC;QAE1D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QAEzC,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QACvD,MAAM,cAAc,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;QACrD,MAAM,eAAe,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,OAAO,CAAC;QAEvD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC;YAC3C,MAAM,EAAE,eAAe,EAAE,eAAe,EAAE,cAAc;YACxD,cAAc;SACf,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1D,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;QACtD,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,CAAC;QAChE,kBAAkB,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,yDAAyD,EAAE,KAAK,IAAI,EAAE;QACvE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAC5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAClC,EAAC,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,UAAU,EAAE,eAAe,EAAC,CAAC,CAAC;QACxE,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC9D,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,KAAK,CAAC,OAAO,EAAE,MAAM,CAAC;aACjB,GAAG,CAAC,QAAQ,CAAC,CAAC,GAAW,EAAE,EAAE,CAAC,eAAe,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;QAC9D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;QAC3E,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;QACvD,6DAA6D;QAC7D,mEAAmE;QACnE,cAAc;QACd,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;aACrB,OAAO,CAAC,gDAAgD,CAAC,CAAC;QAC/D,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;aACrB,OAAO,CAAC,gDAAgD,CAAC,CAAC;IACjE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;QACrE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QAEjC,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,UAAU,GAAG,CAAC,CAAC;QACrB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU;SACX,CAAC,CAAC;QAEH,IAAI,WAAkB,CAAC;QACvB,IAAI;YACF,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,MAAM,EAAC,CAAC,CAAC;SAC3C;QAAC,OAAO,GAAG,EAAE;YACZ,WAAW,GAAG,GAAG,CAAC;SACnB;QACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;aACtB,OAAO,CAAC,mDAAmD,CAAC,CAAC;IACpE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,KAAK,IAAI,EAAE;QACtD,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QACzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,oBAAoB;QACpB,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;SACrC,CAAC,CAAC;QACH,sBAAsB;QACtB,MAAM,UAAU,GAAG,IAAI,kBAAkB,CAAC;YACxC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;SACrC,CAAC,CAAC;QACH,4DAA4D;QAC5D,6CAA6C;QAC7C,IAAI,WAAkB,CAAC;QACvB,IAAI;YACF,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;gBAC9B,eAAe;gBACf,MAAM;gBACN,cAAc,EAAE,UAAU;gBAC1B,iBAAiB,EAAE,CAAC;aACrB,CAAC,CAAC;SACJ;QAAC,OAAO,GAAG,EAAE;YACZ,WAAW,GAAG,GAAG,CAAC;SACnB;QACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;aACtB,OAAO,CAAC,6DAA6D,CAAC,CAAC;IAC9E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wDAAwD,EAAE,KAAK,IAAI,EAAE;QACtE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAE1B,oBAAoB;QACpB,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;SACrC,CAAC,CAAC;QAEH,IAAI,WAAkB,CAAC;QACvB,IAAI;YACF,MAAM,KAAK,CAAC,UAAU,CAClB,OAAO;YACP,kCAAkC;YAClC,EAAC,MAAM,EAAE,CAAC,EAAE,eAAe,EAAE,CAAC,EAAE,eAAe,EAAE,IAAI,EAAQ,CAAC,CAAC;SACpE;QAAC,OAAO,GAAG,EAAE;YACZ,WAAW,GAAG,GAAG,CAAC;SACnB;QACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;aACtB,OAAO,CAAC,kDAAkD,CAAC,CAAC;IACnE,CAAC,CAAC,CAAC;IAEH,MAAM,iBAAkB,SAAQ,GAAG,CAAC,QAAQ;QAE1C,YAAY,aAAqB;YAC/B,KAAK,EAAE,CAAC;YACR,IAAI,CAAC,cAAc,GAAG,aAAa,CAAC;QACtC,CAAC;QAED,KAAK,CAAC,UAAU,CAAC,KAAa,EAAE,IAAW;YACzC,IAAI,KAAK,KAAK,IAAI,CAAC,cAAc,GAAG,CAAC,EAAE;gBACrC,IAAI,CAAC,KAAK,CAAC,YAAY,GAAG,IAAI,CAAC;aAChC;QACH,CAAC;KACF;IAED,EAAE,CAAC,2DAA2D,EAAE,KAAK,IAAI,EAAE;QACzE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/D,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/D,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,eAAe,GAAG,MAAM;YACpC,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QACH,0EAA0E;QAC1E,wEAAwE;QACxE,WAAW;QACX,IAAI,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAChC,OAAO,EACP,EAAC,eAAe,EAAE,MAAM,EAAE,SAAS,EAAE,CAAC,IAAI,iBAAiB,CAAC,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACtE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAE/C,wDAAwD;QACxD,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE,EAAC,eAAe,EAAE,MAAM,EAAC,CAAC,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACjD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,+BAA+B,EAAE,KAAK,IAAI,EAAE;QAC7C,MAAM,IAAI,GAAG,sBAAsB,CAAC;QACpC,MAAM,gBAAgB,GAAG;YACvB,CAAC;YACD,CAAC;YACD,CAAC;YACD,IAAI,GAAG,CAAC;YACR,IAAI,GAAG,CAAC;YACR,CAAC;YACD,CAAC;SACF,CAAC;QACF,IAAI,OAAO,GAAG,CAAC,CAAC;QAChB,IAAI,QAAQ,GAAG,CAAC,CAAC;QACjB,KAAK,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,EAAE;YACnC,QAAQ,IAAI,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC;YACxC,OAAO,QAAQ,CAAC;QAClB,CAAC,CAAC,CAAC;QACH,IAAI,kBAAkB,GAAG,CAAC,CAAC;QAC3B,KAAK,CAAC,GAAG,EAAE,WAAW,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,IAAI,EAAE;YAC9C,kBAAkB,EAAE,CAAC;QACvB,CAAC,CAAC,CAAC;QAEH,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACxB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACxB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;SAC5B,CAAC;QACF,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACxB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACxB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;SAC5B,CAAC;QACF,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,CAAC;YACb,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QACH,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,iBAAiB,GAAa,EAAE,CAAC;QAEvC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;YAC9C,MAAM;YACN,SAAS,EAAE;gBACT,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE;oBACrC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC9B,eAAe,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAC9B,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,yEAAyE;QACzE,uDAAuD;QACvD,MAAM,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yDAAyD,EAAE,KAAK,EAAC,IAAI,EAAC,EAAE;QACzE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACxB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACxB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;SAC5B,CAAC;QACF,MAAM,YAAY,GAAG,GAAG,EAAE,CACtB,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACxB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;YACxB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;SAC5B,CAAC;QACF,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,CAAC;YACb,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QACH,IAAI;YACF,MAAM,KAAK,CAAC,UAAU,CAAC,OAAO,EAAE;gBAC9B,MAAM;gBACN,UAAU,EAAE,OAAO;gBACnB,SAAS,EAAE,EAAC,OAAO,EAAE,KAAK,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,EAAE,GAAE,CAAC,EAAC;aAC1D,CAAC,CAAC;YACH,IAAI,CAAC,IAAI,CAAC,uBAAuB,CAAC,CAAC;SACpC;QAAC,WAAM;YACN,IAAI,EAAE,CAAC;SACR;IACH,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,mEAAmE;AAEnE,qBAAqB,CAAC,6BAA6B,EAAE,GAAG,EAAE;IACxD,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,8BAA8B;IAC9B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,EAAE;IACF,8CAA8C;IAC9C,8CAA8C;IAC9C,2EAA2E;IAC3E,EAAE;IACF,gCAAgC;IAChC,mCAAmC;IACnC,SAAS;IACT,uBAAuB;IACvB,mCAAmC;IACnC,2CAA2C;IAC3C,mEAAmE;IACnE,EAAE;IACF,oDAAoD;IACpD,aAAa;IACb,MAAM;IACN,EAAE,CAAC,sDAAsD,EAAE,KAAK,IAAI,EAAE;QACpE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,OAAO,GAAG,CAAC,CAAC;QAClB,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,OAAO;YACnB,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,GAAG,CAAC,OAAO,CACP,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAC,OAAO,EAAC,CAAiB,CAAC,CAAC;QAErE,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAC,OAAO,EAAC,CAAe,CAAC;QAClE,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACrC,kBAAkB,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;QAC1C,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;QACrB,GAAG,CAAC,OAAO,CAAC,YAAY,CAAC,CAAC;QAC1B,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,oDAAoD,EAAE,KAAK,IAAI,EAAE;QAClE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,OAAO,GAAG,CAAC,CAAC;QAClB,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,OAAO;YACnB,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,GAAG,CAAC,OAAO,CAAC,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAE,CAAiB,CAAC,CAAC;QAEtE,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAE,CAAe,CAAC;QACvE,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACrC,kBAAkB,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;QAC1C,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;QACrB,GAAG,CAAC,OAAO,CAAC,YAAY,CAAC,CAAC;QAC1B,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,8BAA8B;IAC9B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,EAAE;IACF,8CAA8C;IAC9C,8CAA8C;IAC9C,2EAA2E;IAC3E,EAAE;IACF,gCAAgC;IAChC,mCAAmC;IACnC,SAAS;IACT,uBAAuB;IACvB,mCAAmC;IACnC,2CAA2C;IAC3C,mEAAmE;IACnE,sCAAsC;IACtC,EAAE;IACF,oDAAoD;IACpD,aAAa;IACb,MAAM;IACN,EAAE,CAAC,qDAAqD,EAAE,KAAK,IAAI,EAAE;QACnE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QAEpE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,OAAO,GAAG,CAAC,CAAC;QAClB,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,OAAO;YACnB,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,GAAG,CAAC,OAAO,CACP,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAC,OAAO,EAAC,CAAiB,CAAC,CAAC;QAErE,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAC,OAAO,EAAC,CAAiB,CAAC;QACpE,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACpC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;QAC7C,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC;QAC5C,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;QACrB,GAAG,CAAC,OAAO,CAAC,CAAC,YAAY,EAAE,WAAW,CAAC,CAAC,CAAC;QACzC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,mDAAmD,EAAE,KAAK,IAAI,EAAE;QACjE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QAEpE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,OAAO,GAAG,CAAC,CAAC;QAClB,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,OAAO;YACnB,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,GAAG,CAAC,OAAO,CAAC,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAE,CAAiB,CAAC,CAAC;QAEtE,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAE,CAAiB,CAAC;QACzE,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACpC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;QAC7C,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC;QAC5C,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;QACrB,GAAG,CAAC,OAAO,CAAC,CAAC,YAAY,EAAE,WAAW,CAAC,CAAC,CAAC;QACzC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qDAAqD,EAAE,KAAK,IAAI,EAAE;QACnE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QAEpE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,OAAO,GAAG,CAAC,CAAC;QAClB,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,OAAO;YACnB,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gDAAgD;QAChD,GAAG,CAAC,OAAO,CAAC,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,CAAiB,CAAC,CAAC;QAElE,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,8CAA8C;QAC9C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,CAAiB,CAAC;QACrE,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACpC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;QAC7C,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC;QAC5C,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;QACrB,GAAG,CAAC,OAAO,CAAC,CAAC,YAAY,EAAE,WAAW,CAAC,CAAC,CAAC;QACzC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qDAAqD,EAAE,KAAK,IAAI,EAAE;QACnE,MAAM,KAAK,GAAG,gBAAgB,EAAE,CAAC;QACjC,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,OAAO,GAAG,CAAC,CAAC;QAClB,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAClC,EAAC,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,UAAU,EAAE,OAAO,EAAC,CAAC,CAAC;QAEhE,yEAAyE;QACzE,gCAAgC;QAChC,GAAG,CAAC,OAAO,CACP,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAC,OAAO,EAAC,CAAiB,CAAC,CAAC;QAErE,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,KAAK,CAAC,OAAO,EAAE,MAAM,CAAC;aACjB,GAAG,CAAC,QAAQ,CAAC,CAAC,GAAW,EAAE,EAAE,CAAC,eAAe,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;QAE9D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,GAAG,CAAC,OAAO,CAAC,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAC,OAAO,EAAE,OAAO,GAAG,CAAC,EAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QAEzC,MAAM,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;aACrB,OAAO,CACJ,8DAA8D,CAAC,CAAC;IAC1E,CAAC,CAAC,CAAC;IAEH,kCAAkC;IAClC,EAAE;IACF,QAAQ;IACR,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,8BAA8B;IAC9B,EAAE;IACF,iBAAiB;IACjB,kBAAkB;IAClB,EAAE;IACF,+CAA+C;IAC/C,+CAA+C;IAC/C,8CAA8C;IAC9C,gDAAgD;IAChD,8DAA8D;IAC9D,EAAE;IACF,oDAAoD;IACpD,oDAAoD;IACpD,yDAAyD;IACzD,kCAAkC;IAClC,SAAS;IACT,uBAAuB;IACvB,gDAAgD;IAChD,kEAAkE;IAClE,2CAA2C;IAC3C,mEAAmE;IACnE,sCAAsC;IACtC,EAAE;IACF,oDAAoD;IACpD,aAAa;IACb,MAAM;IACN,EAAE,CAAC,qEAAqE,EACrE,KAAK,IAAI,EAAE;QACT,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,OAAO,GAAG,CAAC,CAAC;QAClB,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,OAAO;YACnB,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAC,OAAO,EAAC,CAAC,CAAC;QAChD,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAC,OAAO,EAAC,CAAiB,CAAC;QACpE,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACpC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;QAC7C,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC;QAC5C,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;QACrB,GAAG,CAAC,OAAO,CAAC,CAAC,YAAY,EAAE,WAAW,CAAC,CAAC,CAAC;QACzC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,mEAAmE,EACnE,KAAK,IAAI,EAAE;QACT,2CAA2C;QAC3C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC9C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnD,KAAK,CAAC,MAAM,CAAuB,CAAC;QACnD,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,OAAO,GAAG,CAAC,CAAC;QAClB,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,GAAmC,EAAE,CAAC;YAClD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG;gBACpB,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;gBAClD,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;aACzB,CAAC;YACF,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC;QACF,MAAM,YAAY,GACd,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC;gBAClE,SAAS,EAAE,CAAC;aACb,CAAC,CAAC,CAAC;QACR,MAAM,OAAO,GAAG,IAAI,kBAAkB,CAAC;YACrC,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,MAAM,EAAE,CAAC,CAAC,CAAC;YACX,SAAS;YACT,UAAU,EAAE,OAAO;YACnB,YAAY;YACZ,YAAY;SACb,CAAC,CAAC;QAEH,yEAAyE;QACzE,gCAAgC;QAChC,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAE,CAAC,CAAC;QACzC,KAAK,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEtD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,eAAe,CAAC,OAAO,EAAE,EAAE,CAAiB,CAAC;QACzE,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACpC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;QAC7C,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC;QAC5C,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;QACrB,GAAG,CAAC,OAAO,CAAC,CAAC,YAAY,EAAE,WAAW,CAAC,CAAC,CAAC;QACzC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;AACR,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Unit tests for training.ts, focusing on the tf.LayersModel.fitDataset() and\n * tf.LayersModel.evaluateDataset() methods.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nimport {CustomCallback, DEFAULT_YIELD_EVERY_MS} from '../base_callbacks';\nimport * as tfl from '../index';\nimport {Logs} from '../logs';\nimport {describeMathCPUAndGPU, expectTensorsClose} from '../utils/test_utils';\n\nimport {FakeNumericDataset} from './dataset_fakes';\n\nfunction createDenseModel(): tfl.LayersModel {\n  const model = tfl.sequential();\n  model.add(tfl.layers.dense(\n      {units: 1, inputShape: [1], kernelInitializer: 'zeros'}));\n  return model;\n}\n\ndescribeMathCPUAndGPU('LayersModel.fitDataset', () => {\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // xs = np.ones([batch_size * num_batches * epochs, 1])\n  // ys = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices((xs, ys)).batch(batch_size)\n  //\n  // model = tf.keras.Sequential()\n  // model.add(tf.keras.layers.Dense(\n  //     1,\n  //     input_shape=[1],\n  //     kernel_initializer='zeros'))\n  // model.compile(loss='mean_squared_error', optimizer='sgd')\n  //\n  // history = model.fit(dataset, steps_per_epoch=num_batches, epochs=epochs)\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // ```\n  it('1 input, 1 output, no metric, no validation, with batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const yTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {batchesPerEpoch, epochs: 1});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history =\n           await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history)).toEqual(['loss']);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n     });\n\n  it('1 input, 1 output, no metric, no validation, no batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {epochs: 1});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {epochs});\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history)).toEqual(['loss']);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n     });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution():\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // xs = np.ones([batch_size * num_batches * epochs, 1])\n  // ys = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices((xs, ys)).batch(batch_size)\n  //\n  // model = tf.keras.Sequential()\n  // model.add(tf.keras.layers.Dense(\n  //     1,\n  //     input_shape=[1],\n  //     kernel_initializer='zeros'))\n  // model.compile(loss='mean_squared_error',\n  //               optimizer='sgd',\n  //               metrics=['acc'])\n  //\n  // history = model.fit(dataset, steps_per_epoch=num_batches, epochs=epochs)\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // ```\n  it('1 input, 1 output, 1 metric, no validation, with batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const yTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {batchesPerEpoch, epochs: 1});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history =\n           await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history)).toEqual(['loss', 'acc']);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n     });\n\n  it('1 input, 1 output, 1 metric, no validation, no batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {epochs: 1});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {epochs});\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history)).toEqual(['loss', 'acc']);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n     });\n\n  // Reference Python tf.keras code.\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution():\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // xs = np.ones([batch_size * num_batches * epochs, 1])\n  // ys = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices((xs, ys)).batch(batch_size)\n  // val_xs = np.zeros([batch_size * 2, 1])\n  // val_ys = np.zeros([batch_size * 2, 1])\n  //\n  // model = tf.keras.Sequential()\n  // model.add(tf.keras.layers.Dense(\n  //     1,\n  //     input_shape=[1],\n  //     kernel_initializer='zeros'))\n  // model.compile(loss='mean_squared_error', optimizer='sgd',\n  // metrics=['accuracy'])\n  //\n  // class CustomCallback(tf.keras.callbacks.Callback):\n  //   def on_epoch_end(self, epoch, logs):\n  //     print('epoch = %d; logs = %s' % (epoch, logs))\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs,\n  //                     validation_steps=2,\n  //                     validation_data=(val_xs, val_ys),\n  //                     callbacks=[CustomCallback()])\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // ```\n  it('1 input, 1 output, 1 metric, tensor validation, callback, ' +\n         'with batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const yTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n       const valXs = tfc.zeros([batchSize * 2, 1]);\n       const valYs = tfc.zeros([batchSize * 2, 1]);\n\n       // Do a burn-in call to account for initialization of cached\n       // tensors (for the memory-leak check below).\n       await model.fitDataset(\n           dataset,\n           {batchesPerEpoch, epochs: 1, validationData: [valXs, valYs]});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const epochEndValLosses: number[] = [];\n       const epochEndValAccs: number[] = [];\n       const history = await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs,\n         validationData: [valXs, valYs],\n         callbacks: {\n           onEpochEnd: async (epoch, logs) => {\n             epochEndValLosses.push(logs.val_loss);\n             epochEndValAccs.push(logs.val_acc);\n           }\n         }\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history).sort()).toEqual([\n         'loss', 'acc', 'val_loss', 'val_acc'\n       ].sort());\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003321);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.011799);\n       expect(history.history.val_acc.length).toEqual(2);\n       expect(history.history.val_acc[0]).toBeCloseTo(1);\n       expect(history.history.val_acc[1]).toBeCloseTo(1);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n\n       expect(epochEndValLosses.length).toEqual(2);\n       expect(epochEndValLosses[0]).toBeCloseTo(0.003321);\n       expect(epochEndValLosses[1]).toBeCloseTo(0.011799);\n       expect(epochEndValAccs.length).toEqual(2);\n       expect(epochEndValAccs[0]).toBeCloseTo(1);\n       expect(epochEndValAccs[1]).toBeCloseTo(1);\n     });\n\n  it('1 input, 1 output, 1 metric, tensor validation, callback, ' +\n         'no batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n       const valXs = tfc.zeros([batchSize * 2, 1]);\n       const valYs = tfc.zeros([batchSize * 2, 1]);\n\n       // Do a burn-in call to account for initialization of cached\n       // tensors (for the memory-leak check below).\n       await model.fitDataset(\n           dataset, {epochs: 1, validationData: [valXs, valYs]});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const epochEndValLosses: number[] = [];\n       const epochEndValAccs: number[] = [];\n       const history = await model.fitDataset(dataset, {\n         epochs,\n         validationData: [valXs, valYs],\n         callbacks: {\n           onEpochEnd: async (epoch, logs) => {\n             epochEndValLosses.push(logs.val_loss);\n             epochEndValAccs.push(logs.val_acc);\n           }\n         }\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history).sort()).toEqual([\n         'loss', 'acc', 'val_loss', 'val_acc'\n       ].sort());\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003321);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.011799);\n       expect(history.history.val_acc.length).toEqual(2);\n       expect(history.history.val_acc[0]).toBeCloseTo(1);\n       expect(history.history.val_acc[1]).toBeCloseTo(1);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n\n       expect(epochEndValLosses.length).toEqual(2);\n       expect(epochEndValLosses[0]).toBeCloseTo(0.003321);\n       expect(epochEndValLosses[1]).toBeCloseTo(0.011799);\n       expect(epochEndValAccs.length).toEqual(2);\n       expect(epochEndValAccs[0]).toBeCloseTo(1);\n       expect(epochEndValAccs[1]).toBeCloseTo(1);\n     });\n\n  it('Earlier logs are not overwritten', async () => {\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n    const batchSize = 8;\n    const epochs = 2;\n    const batchesPerEpoch = 3;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batchesPerEpoch,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    const trainLogs: Logs[] = [];\n    await model.fitDataset(dataset, {\n      epochs,\n      callbacks: {\n        onEpochEnd: async (epoch, logs) => {\n          trainLogs.push(logs);\n        }\n      }\n    });\n    expect(trainLogs.length).toEqual(2);\n    // Assert that the the first log and the second logs do not overwrite each\n    // other.\n    expect(trainLogs[0].loss).not.toEqual(trainLogs[1].loss);\n  });\n\n  it('dataset.size != null feeds stepPerEpoch to callbacks', async () => {\n    const batchSize = 8;\n    const batchesPerEpoch = 3;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batchesPerEpoch,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    let recordedSteps: number;\n    class TestCallback extends CustomCallback {\n      constructor() {\n        super({\n          onTrainBegin: async (logs?: Logs) => {\n            recordedSteps = this.params.steps as number;\n          }\n        });\n      }\n    }\n\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n    const epochs = 1;\n    await model.fitDataset(dataset, {epochs, callbacks: new TestCallback()});\n\n    expect(dataset.size).toEqual(batchesPerEpoch);\n    expect(recordedSteps).toEqual(batchesPerEpoch);\n  });\n\n  it('explicit stepPerEpoch overrides dataset.size for callbacks', async () => {\n    const batchSize = 8;\n    const numBatches = 3;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    let recordedSteps: number;\n    class TestCallback extends CustomCallback {\n      constructor() {\n        super({\n          onTrainBegin: async (logs?: Logs) => {\n            recordedSteps = this.params.steps as number;\n          }\n        });\n      }\n    }\n\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n    const epochs = 1;\n    await model.fitDataset(dataset, {\n      epochs,\n      batchesPerEpoch: numBatches - 1,\n      callbacks: new TestCallback()\n    });\n\n    expect(dataset.size).toEqual(numBatches);\n    expect(recordedSteps).toEqual(numBatches - 1);\n  });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution()\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // xs = np.ones([batch_size * num_batches * epochs, 1])\n  // ys = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices((xs, ys)).batch(batch_size)\n  // val_xs = np.zeros([batch_size * 2, 1])\n  // val_ys = np.zeros([batch_size * 2, 1])\n  // val_dataset = tf.data.Dataset.from_tensor_slices(\n  //     (val_xs, val_ys)).batch(batch_size)\n  //\n  // model = tf.keras.Sequential()\n  // model.add(tf.keras.layers.Dense(\n  //     1,\n  //     input_shape=[1],\n  //     kernel_initializer='zeros'))\n  // model.compile(loss='mean_squared_error',\n  //               optimizer=tf.train.GradientDescentOptimizer(0.01),\n  //               metrics=['accuracy'])\n  //\n  // class CustomCallback(tf.keras.callbacks.Callback):\n  //   def on_batch_end(self, batch, logs):\n  //     print('batch = %d; logs = %s' % (batch, logs))\n  //\n  //   def on_epoch_end(self, epoch, logs):\n  //     print('epoch = %d; logs = %s' % (epoch, logs))\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs,\n  //                     batch_size=4,\n  //                     validation_steps=2,\n  //                     validation_data=val_dataset,\n  //                     callbacks=[CustomCallback()])\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // ```\n  it('1 input, 1 output, 1 metric, dataset validation, callback, ' +\n         'with batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       // Training dataset.\n       const xTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const yTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Validation dataset.\n       const valXTensorsFunc = () =>\n           [tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1]),\n            tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1]),\n            tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1])];\n       const valYTensorsFunc = () =>\n           [tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1]),\n            tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1]),\n            tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1])];\n       const valDataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc: valXTensorsFunc,\n         yTensorsFunc: valYTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached\n       // tensors (for the memory-leak check below).\n       await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs,\n         validationData: valDataset,\n         validationBatches: batchesPerEpoch * epochs\n       });\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const epochEndValLosses: number[] = [];\n       const epochEndValAccs: number[] = [];\n       const history = await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs,\n         validationData: valDataset,\n         validationBatches: batchesPerEpoch * epochs,\n         callbacks: {\n           onEpochEnd: async (epoch, logs) => {\n             epochEndValLosses.push(logs.val_loss);\n             epochEndValAccs.push(logs.val_acc);\n           }\n         }\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history).sort()).toEqual([\n         'loss', 'acc', 'val_loss', 'val_acc'\n       ].sort());\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003321);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.011799);\n       expect(history.history.val_acc.length).toEqual(2);\n       expect(history.history.val_acc[0]).toBeCloseTo(1);\n       expect(history.history.val_acc[1]).toBeCloseTo(1);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n\n       expect(epochEndValLosses.length).toEqual(2);\n       expect(epochEndValLosses[0]).toBeCloseTo(0.003321);\n       expect(epochEndValLosses[1]).toBeCloseTo(0.011799);\n       expect(epochEndValAccs.length).toEqual(2);\n       expect(epochEndValAccs[0]).toBeCloseTo(1);\n       expect(epochEndValAccs[1]).toBeCloseTo(1);\n     });\n\n  it('1 input, 1 output, 1 metric, dataset validation, callback, ' +\n         'no batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       // Training dataset.\n       const xTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Validation dataset.\n       const valXTensorsFunc = () =>\n           [tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1]),\n            tfc.zeros([batchSize, 1])];\n       const valYTensorsFunc = () =>\n           [tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1]),\n            tfc.zeros([batchSize, 1])];\n       const valDataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc: valXTensorsFunc,\n         yTensorsFunc: valYTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached\n       // tensors (for the memory-leak check below).\n       await model.fitDataset(dataset, {epochs, validationData: valDataset});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const epochEndValLosses: number[] = [];\n       const epochEndValAccs: number[] = [];\n       const history = await model.fitDataset(dataset, {\n         epochs,\n         validationData: valDataset,\n         callbacks: {\n           onEpochEnd: async (epoch, logs) => {\n             epochEndValLosses.push(logs.val_loss);\n             epochEndValAccs.push(logs.val_acc);\n           }\n         }\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history).sort()).toEqual([\n         'loss', 'acc', 'val_loss', 'val_acc'\n       ].sort());\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003321);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.011799);\n       expect(history.history.val_acc.length).toEqual(2);\n       expect(history.history.val_acc[0]).toBeCloseTo(1);\n       expect(history.history.val_acc[1]).toBeCloseTo(1);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n\n       expect(epochEndValLosses.length).toEqual(2);\n       expect(epochEndValLosses[0]).toBeCloseTo(0.003321);\n       expect(epochEndValLosses[1]).toBeCloseTo(0.011799);\n       expect(epochEndValAccs.length).toEqual(2);\n       expect(epochEndValAccs[0]).toBeCloseTo(1);\n       expect(epochEndValAccs[1]).toBeCloseTo(1);\n     });\n\n  it('Memory leak check with metric and validation, with batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 3;\n       const batchesPerEpoch = 3;\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs\n       });\n       const valXs = tfc.zeros([batchSize * 2, 1]);\n       const valYs = tfc.zeros([batchSize * 2, 1]);\n\n       // Do a burn-in call to account for initialization of cached\n       // tensors (for the memory-leak check below).\n       await model.fitDataset(\n           dataset,\n           {batchesPerEpoch, epochs: 1, validationData: [valXs, valYs]});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs,\n         validationData: [valXs, valYs],\n         callbacks: {\n           onEpochEnd: async (epoch, logs) => {\n             expect(tfc.memory().numTensors).toEqual(numTensors0);\n           }\n         }\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n     });\n\n  it('Memory leak check with metric and validation, no batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 3;\n       const batchesPerEpoch = 3;\n       const dataset = new FakeNumericDataset(\n           {xShape: [1], yShape: [1], batchSize, numBatches: batchesPerEpoch});\n       const valXs = tfc.zeros([batchSize * 2, 1]);\n       const valYs = tfc.zeros([batchSize * 2, 1]);\n\n       // Do a burn-in call to account for initialization of cached\n       // tensors (for the memory-leak check below).\n       await model.fitDataset(\n           dataset, {epochs: 1, validationData: [valXs, valYs]});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       await model.fitDataset(dataset, {\n         epochs,\n         validationData: [valXs, valYs],\n         callbacks: {\n           onEpochEnd: async (epoch, logs) => {\n             expect(tfc.memory().numTensors).toEqual(numTensors0);\n           }\n         }\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n     });\n\n  // Refence Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution():\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // xs = np.ones([batch_size * num_batches * epochs, 1])\n  // ys = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices((xs, ys)).batch(batch_size)\n  //\n  // model = tf.keras.Sequential()\n  // model.add(tf.keras.layers.Dense(\n  //     1,\n  //     input_shape=[1],\n  //     kernel_initializer='zeros'))\n  // model.compile(loss='mean_squared_error', optimizer='sgd',\n  // metrics=['accuracy'])\n  //\n  // class CustomCallback(tf.keras.callbacks.Callback):\n  //   def on_batch_end(self, batch, logs):\n  //     print('batch = %d; logs = %s' % (batch, logs))\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs,\n  //                     callbacks=[CustomCallback()])\n  // print(history.history)\n  // ```\n  it('1 input, 1 output, 1 metric, no validation, callback, ' +\n         'with batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const yTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {batchesPerEpoch, epochs: 1});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       let onTrainBeginCalls = 0;\n       let onTrainEndCalls = 0;\n       const epochBeginEpochs: number[] = [];\n       const epochEndEpochs: number[] = [];\n       const batchBeginBatches: number[] = [];\n       const batchEndBatches: number[] = [];\n       const epochEndLosses: number[] = [];\n       const epochEndAccs: number[] = [];\n       const batchEndLosses: number[] = [];\n       const batchEndAccs: number[] = [];\n       const history = await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs,\n         callbacks: {\n           onTrainBegin: async () => {\n             onTrainBeginCalls++;\n           },\n           onTrainEnd: async () => {\n             onTrainEndCalls++;\n           },\n           onEpochBegin: async (epoch) => {\n             epochBeginEpochs.push(epoch);\n           },\n           onEpochEnd: async (epoch, logs) => {\n             epochEndEpochs.push(epoch);\n             epochEndLosses.push(logs.loss);\n             epochEndAccs.push(logs.acc);\n           },\n           onBatchBegin: async (batch, logs) => {\n             batchBeginBatches.push(batch);\n           },\n           onBatchEnd: async (batch, logs) => {\n             batchEndBatches.push(batch);\n             batchEndLosses.push(logs.loss);\n             batchEndAccs.push(logs.acc);\n           },\n         }\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history)).toEqual(['loss', 'acc']);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n\n       expect(onTrainBeginCalls).toEqual(1);\n       expect(onTrainEndCalls).toEqual(1);\n       expect(epochBeginEpochs).toEqual([0, 1]);\n       expect(epochEndEpochs).toEqual([0, 1]);\n       expect(batchBeginBatches).toEqual([0, 1, 2, 0, 1, 2]);\n       expect(batchEndBatches).toEqual([0, 1, 2, 0, 1, 2]);\n       expect(epochEndLosses.length).toEqual(2);\n       expect(epochEndLosses[0]).toBeCloseTo(0.923649);\n       expect(epochEndLosses[1]).toBeCloseTo(0.722993);\n       expect(epochEndAccs.length).toEqual(2);\n       expect(epochEndAccs[0]).toBeCloseTo(0);\n       expect(epochEndAccs[1]).toBeCloseTo(0);\n       expectTensorsClose(\n           batchEndLosses, [1, 0.9216, 0.849347, 0.782758, 0.721390, 0.664832]);\n     });\n\n  it('1 input, 1 output, 1 metric, no validation, callback, no batchesPerEpoch',\n     async () => {\n       const model = createDenseModel();\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {epochs: 1});\n       model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       let onTrainBeginCalls = 0;\n       let onTrainEndCalls = 0;\n       const epochBeginEpochs: number[] = [];\n       const epochEndEpochs: number[] = [];\n       const batchBeginBatches: number[] = [];\n       const batchEndBatches: number[] = [];\n       const epochEndLosses: number[] = [];\n       const epochEndAccs: number[] = [];\n       const batchEndLosses: number[] = [];\n       const batchEndAccs: number[] = [];\n       const history = await model.fitDataset(dataset, {\n         epochs,\n         callbacks: {\n           onTrainBegin: async () => {\n             onTrainBeginCalls++;\n           },\n           onTrainEnd: async () => {\n             onTrainEndCalls++;\n           },\n           onEpochBegin: async (epoch) => {\n             epochBeginEpochs.push(epoch);\n           },\n           onEpochEnd: async (epoch, logs) => {\n             epochEndEpochs.push(epoch);\n             epochEndLosses.push(logs.loss);\n             epochEndAccs.push(logs.acc);\n           },\n           onBatchBegin: async (batch, logs) => {\n             batchBeginBatches.push(batch);\n           },\n           onBatchEnd: async (batch, logs) => {\n             batchEndBatches.push(batch);\n             batchEndLosses.push(logs.loss);\n             batchEndAccs.push(logs.acc);\n           },\n         }\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history)).toEqual(['loss', 'acc']);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.923649);\n       expect(history.history.loss[1]).toBeCloseTo(0.722993);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n\n       expect(onTrainBeginCalls).toEqual(1);\n       expect(onTrainEndCalls).toEqual(1);\n       expect(epochBeginEpochs).toEqual([0, 1]);\n       expect(epochEndEpochs).toEqual([0, 1]);\n       expect(batchBeginBatches).toEqual([0, 1, 2, 0, 1, 2]);\n       expect(batchEndBatches).toEqual([0, 1, 2, 0, 1, 2]);\n       expect(epochEndLosses.length).toEqual(2);\n       expect(epochEndLosses[0]).toBeCloseTo(0.923649);\n       expect(epochEndLosses[1]).toBeCloseTo(0.722993);\n       expect(epochEndAccs.length).toEqual(2);\n       expect(epochEndAccs[0]).toBeCloseTo(0);\n       expect(epochEndAccs[1]).toBeCloseTo(0);\n       expectTensorsClose(\n           batchEndLosses, [1, 0.9216, 0.849347, 0.782758, 0.721390, 0.664832]);\n     });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // input1 = tf.keras.Input(shape = [1], name = 'x1')\n  // input2 = tf.keras.Input(shape = [1], name = 'x2')\n  // concat = tf.keras.layers.concatenate([input1, input2])\n  // y = tf.keras.layers.Dense(\n  //     1, kernel_initializer = 'zeros')(concat)\n  // model = tf.keras.Model(inputs = [input1, input2], outputs = y)\n  // model.compile(\n  //     loss = 'mean_squared_error', optimizer = 'sgd', metrics =\n  //     ['accuracy'])\n  // model.summary()\n  // print(input1.name)\n  // print(input2.name)\n  //\n  // xs1 = np.ones([batch_size * num_batches * epochs, 1])\n  // xs2 = np.ones([batch_size * num_batches * epochs, 1])\n  // ys = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices(\n  //     ({'x1': xs1, 'x2': xs2}, ys)).batch(batch_size)\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs)\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // ```\n  it('2 inputs, 1 output, 1 metric, no validation, with batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 inputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                     .apply(concat) as tfl.SymbolicTensor;\n       const model = tfl.model({inputs: [input1, input2], outputs: y});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {batchesPerEpoch, epochs: 1});\n       model.setWeights([tfc.zeros([2, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history =\n           await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history)).toEqual(['loss', 'acc']);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.888116);\n       expect(history.history.loss[1]).toBeCloseTo(0.612685);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.103377, 0.103377]);\n       expectTensorsClose(model.getWeights()[1], [0.103377]);\n     });\n\n  it('2 inputs, 1 output, 1 metric, no validation, no batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 inputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                     .apply(concat) as tfl.SymbolicTensor;\n       const model = tfl.model({inputs: [input1, input2], outputs: y});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {epochs: 1});\n       model.setWeights([tfc.zeros([2, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {epochs});\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history)).toEqual(['loss', 'acc']);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.888116);\n       expect(history.history.loss[1]).toBeCloseTo(0.612685);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.103377, 0.103377]);\n       expectTensorsClose(model.getWeights()[1], [0.103377]);\n     });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution()\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // input1 = tf.keras.Input(shape = [1], name = 'x1')\n  // input2 = tf.keras.Input(shape = [1], name = 'x2')\n  // concat = tf.keras.layers.concatenate([input1, input2])\n  // y = tf.keras.layers.Dense(\n  //     1, kernel_initializer = 'zeros')(concat)\n  // model = tf.keras.Model(inputs = [input1, input2], outputs = y)\n  // model.compile(\n  //     loss='mean_squared_error',\n  //     optimizer=tf.train.GradientDescentOptimizer(0.01),\n  //     metrics=['accuracy'])\n  // model.summary()\n  // print(input1.name)\n  // print(input2.name)\n  //\n  // xs1 = np.ones([batch_size * num_batches * epochs, 1])\n  // xs2 = np.ones([batch_size * num_batches * epochs, 1])\n  // ys = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices(\n  //     ({'x1': xs1, 'x2': xs2}, ys)).batch(batch_size)\n  //\n  // val_xs = [np.zeros([batch_size, 1]),\n  //           np.zeros([batch_size, 1])]\n  // val_ys = np.zeros([batch_size, 1])\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs,\n  //                     batch_size=batch_size,\n  //                     validation_data=[val_xs, val_ys])\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // ```\n  it('2 inputs, 1 output, 1 metric, tensor array validation, ' +\n         'with batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 inputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                     .apply(concat) as tfl.SymbolicTensor;\n       const model = tfl.model({inputs: [input1, input2], outputs: y});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       // Training data.\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Validation data.\n       const valXs: tfc.Tensor[] =\n           [tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1])];\n       const valYs = tfc.zeros([batchSize, 1]);\n\n       // Do a burn-in call to account for initialization of cached tensors\n       // (for the memory-leak check below).\n       await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs: 1,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       model.setWeights([tfc.zeros([2, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history).sort()).toEqual([\n         'acc', 'loss', 'val_acc', 'val_loss'\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.888116);\n       expect(history.history.loss[1]).toBeCloseTo(0.612685);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003189);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.010687);\n       expect(history.history.val_acc.length).toEqual(2);\n       expect(history.history.val_acc[0]).toBeCloseTo(1.0);\n       expect(history.history.val_acc[1]).toBeCloseTo(1.0);\n       expectTensorsClose(model.getWeights()[0], [0.103377, 0.103377]);\n       expectTensorsClose(model.getWeights()[1], [0.103377]);\n     });\n\n  it('2 inputs, 1 output, 1 metric, tensor array validation, ' +\n         'no batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 inputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                     .apply(concat) as tfl.SymbolicTensor;\n       const model = tfl.model({inputs: [input1, input2], outputs: y});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       // Training data.\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Validation data.\n       const valXs: tfc.Tensor[] =\n           [tfc.zeros([batchSize, 1]), tfc.zeros([batchSize, 1])];\n       const valYs = tfc.zeros([batchSize, 1]);\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {\n         epochs: 1,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       model.setWeights([tfc.zeros([2, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {\n         epochs,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history).sort()).toEqual([\n         'acc', 'loss', 'val_acc', 'val_loss'\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.888116);\n       expect(history.history.loss[1]).toBeCloseTo(0.612685);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003189);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.010687);\n       expect(history.history.val_acc.length).toEqual(2);\n       expect(history.history.val_acc[0]).toBeCloseTo(1.0);\n       expect(history.history.val_acc[1]).toBeCloseTo(1.0);\n       expectTensorsClose(model.getWeights()[0], [0.103377, 0.103377]);\n       expectTensorsClose(model.getWeights()[1], [0.103377]);\n     });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution()\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // input1 = tf.keras.Input(shape = [1], name = 'x1')\n  // input2 = tf.keras.Input(shape = [1], name = 'x2')\n  // concat = tf.keras.layers.concatenate([input1, input2])\n  // y = tf.keras.layers.Dense(\n  //     1, kernel_initializer = 'zeros')(concat)\n  // model = tf.keras.Model(inputs = [input1, input2], outputs = y)\n  // model.compile(\n  //     loss='mean_squared_error',\n  //     optimizer=tf.train.GradientDescentOptimizer(0.01),\n  //     metrics=['accuracy'])\n  // model.summary()\n  // print(input1.name)\n  // print(input2.name)\n  //\n  // xs1 = np.ones([batch_size * num_batches * epochs, 1])\n  // xs2 = np.ones([batch_size * num_batches * epochs, 1])\n  // ys = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices(\n  //     ({'x1': xs1, 'x2': xs2}, ys)).batch(batch_size)\n  //\n  // val_xs = {\n  //     'x1': np.zeros([batch_size, 1]),\n  //     'x2': np.zeros([batch_size, 1])\n  // }\n  // val_ys = np.zeros([batch_size, 1])\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs,\n  //                     batch_size=batch_size,\n  //                     validation_data=[val_xs, val_ys])\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // ```\n  it('2 input, 1 output, 1 metric, tensor array validation, ' +\n         'with batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 inputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                     .apply(concat) as tfl.SymbolicTensor;\n       const model = tfl.model({inputs: [input1, input2], outputs: y});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       // Training data.\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Validation data.\n       const valXs: tfc.NamedTensorMap = {};\n       valXs[input1.name] = tfc.zeros([batchSize, 1]);\n       valXs[input2.name] = tfc.zeros([batchSize, 1]);\n       const valYs = tfc.zeros([batchSize, 1]);\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs: 1,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       model.setWeights([tfc.zeros([2, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history).sort()).toEqual([\n         'acc', 'loss', 'val_acc', 'val_loss'\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.888116);\n       expect(history.history.loss[1]).toBeCloseTo(0.612685);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003189);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.010687);\n       expect(history.history.val_acc.length).toEqual(2);\n       expect(history.history.val_acc[0]).toBeCloseTo(1.0);\n       expect(history.history.val_acc[1]).toBeCloseTo(1.0);\n       expectTensorsClose(model.getWeights()[0], [0.103377, 0.103377]);\n       expectTensorsClose(model.getWeights()[1], [0.103377]);\n     });\n\n  it('2 input, 1 output, 1 metric, tensor array validation, ' +\n         'no batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 inputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                     .apply(concat) as tfl.SymbolicTensor;\n       const model = tfl.model({inputs: [input1, input2], outputs: y});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       // Training data.\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Validation data.\n       const valXs: tfc.NamedTensorMap = {};\n       valXs[input1.name] = tfc.zeros([batchSize, 1]);\n       valXs[input2.name] = tfc.zeros([batchSize, 1]);\n       const valYs = tfc.zeros([batchSize, 1]);\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {\n         epochs: 1,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       model.setWeights([tfc.zeros([2, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {\n         epochs,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n       expect(Object.keys(history.history).sort()).toEqual([\n         'acc', 'loss', 'val_acc', 'val_loss'\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(0.888116);\n       expect(history.history.loss[1]).toBeCloseTo(0.612685);\n       expect(history.history.acc.length).toEqual(2);\n       expect(history.history.acc[0]).toBeCloseTo(0);\n       expect(history.history.acc[1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003189);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.010687);\n       expect(history.history.val_acc.length).toEqual(2);\n       expect(history.history.val_acc[0]).toBeCloseTo(1.0);\n       expect(history.history.val_acc[1]).toBeCloseTo(1.0);\n       expectTensorsClose(model.getWeights()[0], [0.103377, 0.103377]);\n       expectTensorsClose(model.getWeights()[1], [0.103377]);\n     });\n\n  it('2 input, 1 missing input in dataset, with batchesPerEpoch', async () => {\n    // Create a functional model with 2 inputs.\n    const input1 = tfl.layers.input({shape: [1]});\n    const input2 = tfl.layers.input({shape: [1]});\n    const concat = tfl.layers.concatenate().apply([input1, input2]);\n    const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                  .apply(concat) as tfl.SymbolicTensor;\n    const model = tfl.model({inputs: [input1, input2], outputs: y});\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const batchSize = 8;\n    const epochs = 2;\n    const batchesPerEpoch = 3;\n    const xTensorsFunc = () => {\n      const output: {[name: string]: tfc.Tensor[]} = {};\n      output[input1.name] = [\n        tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n        tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n        tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n      ];\n      // Note: input2 is missing from the data, by intention.\n      return output;\n    };\n    const yTensorsFunc = () =>\n        [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batchesPerEpoch * epochs,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    let errorCaught: Error;\n    try {\n      await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n    } catch (err) {\n      errorCaught = err;\n    }\n    expect(errorCaught.message)\n        .toEqual(\n            'The feature data generated by the dataset lacks the required ' +\n            `input key '${input2.name}'.`);\n  });\n\n  it('2 input, 1 missing input in dataset, no batchesPerEpoch', async () => {\n    // Create a functional model with 2 inputs.\n    const input1 = tfl.layers.input({shape: [1]});\n    const input2 = tfl.layers.input({shape: [1]});\n    const concat = tfl.layers.concatenate().apply([input1, input2]);\n    const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                  .apply(concat) as tfl.SymbolicTensor;\n    const model = tfl.model({inputs: [input1, input2], outputs: y});\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const batchSize = 8;\n    const epochs = 2;\n    const batchesPerEpoch = 3;\n    const xTensorsFunc = () => {\n      const output: {[name: string]: tfc.Tensor[]} = {};\n      output[input1.name] = [\n        tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n        tfc.ones([batchSize, 1])\n      ];\n      // Note: input2 is missing from the data, by intention.\n      return output;\n    };\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batchesPerEpoch,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    let errorCaught: Error;\n    try {\n      await model.fitDataset(dataset, {epochs});\n    } catch (err) {\n      errorCaught = err;\n    }\n    expect(errorCaught.message)\n        .toEqual(\n            'The feature data generated by the dataset lacks the required ' +\n            `input key '${input2.name}'.`);\n  });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // x = tf.keras.Input(shape=[1], name='x')\n  //\n  // output1 = tf.keras.layers.Dense(\n  //     1, kernel_initializer='zeros')(x)\n  // output2 = tf.keras.layers.Dense(\n  //     1, kernel_initializer='zeros')(x)\n  //\n  // model = tf.keras.Model(inputs=x, outputs=[output1, output2])\n  // model.compile(\n  //     loss = 'mean_squared_error', optimizer = 'sgd', metrics =\n  //     ['accuracy'])\n  // model.summary()\n  // output1_name = model.output_names[0]\n  // output2_name = model.output_names[1]\n  // print(output1_name)\n  // print(output2_name)\n  //\n  // xs = np.ones([batch_size * num_batches * epochs, 1])\n  // ys1 = np.ones([batch_size * num_batches * epochs, 1])\n  // ys2 = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices(\n  //     (xs, {output1_name: ys1, output2_name: ys2})).batch(batch_size)\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs)\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // print(model.get_weights()[2])\n  // print(model.get_weights()[3])\n  // ```\n  it('1 input, 2 outputs, 1 metric, no validation, with batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 outputs.\n       const x = tfl.layers.input({shape: [1]});\n       const output1 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const output2 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const model = tfl.model({inputs: x, outputs: [output1, output2]});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       const xTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const yTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[model.outputNames[0]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         output[model.outputNames[1]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n\n       const yShape: {[name: string]: number[]} = {};\n       yShape[model.outputNames[0]] = [1];\n       yShape[model.outputNames[1]] = [1];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape,\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {batchesPerEpoch, epochs: 1});\n       model.setWeights([\n         tfc.zeros([1, 1]), tfc.zeros([1]), tfc.zeros([1, 1]), tfc.zeros([1])\n       ]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history =\n           await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n\n       const output1AccName = model.outputNames[0] + '_acc';\n       const output1LossName = model.outputNames[0] + '_loss';\n       const output2AccName = model.outputNames[1] + '_acc';\n       const output2LossName = model.outputNames[1] + '_loss';\n\n       expect(Object.keys(history.history)).toEqual([\n         'loss', output1LossName, output2LossName, output1AccName,\n         output2AccName\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(1.847297);\n       expect(history.history.loss[1]).toBeCloseTo(1.445986);\n       expect(history.history[output1LossName].length).toEqual(2);\n       expect(history.history[output1LossName][0]).toBeCloseTo(0.923648);\n       expect(history.history[output1LossName][1]).toBeCloseTo(0.722993);\n       expect(history.history[output2LossName].length).toEqual(2);\n       expect(history.history[output2LossName][0]).toBeCloseTo(0.923648);\n       expect(history.history[output2LossName][1]).toBeCloseTo(0.722993);\n       expect(history.history[output1AccName].length).toEqual(2);\n       expect(history.history[output1AccName][0]).toBeCloseTo(0);\n       expect(history.history[output1AccName][1]).toBeCloseTo(0);\n       expect(history.history[output2AccName].length).toEqual(2);\n       expect(history.history[output2AccName][0]).toBeCloseTo(0);\n       expect(history.history[output2AccName][1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n       expectTensorsClose(model.getWeights()[2], [0.108621]);\n       expectTensorsClose(model.getWeights()[3], [0.108621]);\n     });\n\n  it('1 input, 2 outputs, 1 metric, no validation, no batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 outputs.\n       const x = tfl.layers.input({shape: [1]});\n       const output1 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const output2 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const model = tfl.model({inputs: x, outputs: [output1, output2]});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       const xTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const yTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[model.outputNames[0]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[model.outputNames[1]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n\n       const yShape: {[name: string]: number[]} = {};\n       yShape[model.outputNames[0]] = [1];\n       yShape[model.outputNames[1]] = [1];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape,\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {epochs: 1});\n       model.setWeights([\n         tfc.zeros([1, 1]), tfc.zeros([1]), tfc.zeros([1, 1]), tfc.zeros([1])\n       ]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {epochs});\n\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n\n       const output1AccName = model.outputNames[0] + '_acc';\n       const output1LossName = model.outputNames[0] + '_loss';\n       const output2AccName = model.outputNames[1] + '_acc';\n       const output2LossName = model.outputNames[1] + '_loss';\n\n       expect(Object.keys(history.history)).toEqual([\n         'loss', output1LossName, output2LossName, output1AccName,\n         output2AccName\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(1.847297);\n       expect(history.history.loss[1]).toBeCloseTo(1.445986);\n       expect(history.history[output1LossName].length).toEqual(2);\n       expect(history.history[output1LossName][0]).toBeCloseTo(0.923648);\n       expect(history.history[output1LossName][1]).toBeCloseTo(0.722993);\n       expect(history.history[output2LossName].length).toEqual(2);\n       expect(history.history[output2LossName][0]).toBeCloseTo(0.923648);\n       expect(history.history[output2LossName][1]).toBeCloseTo(0.722993);\n       expect(history.history[output1AccName].length).toEqual(2);\n       expect(history.history[output1AccName][0]).toBeCloseTo(0);\n       expect(history.history[output1AccName][1]).toBeCloseTo(0);\n       expect(history.history[output2AccName].length).toEqual(2);\n       expect(history.history[output2AccName][0]).toBeCloseTo(0);\n       expect(history.history[output2AccName][1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n       expectTensorsClose(model.getWeights()[2], [0.108621]);\n       expectTensorsClose(model.getWeights()[3], [0.108621]);\n     });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // x = tf.keras.Input(shape=[1], name='x')\n  //\n  // output1 = tf.keras.layers.Dense(\n  //     1, kernel_initializer='zeros')(x)\n  // output2 = tf.keras.layers.Dense(\n  //     1, kernel_initializer='zeros')(x)\n  //\n  // model = tf.keras.Model(inputs=x, outputs=[output1, output2])\n  // model.compile(\n  //     loss = 'mean_squared_error', optimizer = 'sgd', metrics =\n  //     ['accuracy'])\n  // model.summary()\n  // output1_name = model.output_names[0]\n  // output2_name = model.output_names[1]\n  // print(output1_name)\n  // print(output2_name)\n  //\n  // xs = np.ones([batch_size * num_batches * epochs, 1])\n  // ys1 = np.ones([batch_size * num_batches * epochs, 1])\n  // ys2 = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices(\n  //     (xs, {output1_name: ys1, output2_name: ys2})).batch(batch_size)\n  //\n  // val_xs = np.zeros([batch_size, 1])\n  // val_ys = {output1_name: np.zeros([batch_size, 1]),\n  //           output1_name: np.zeros([batch_size, 1])}\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs,\n  //                     validation_data=[val_xs, val_ys])\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // print(model.get_weights()[2])\n  // print(model.get_weights()[3])\n  // ```\n  it('1 input, 2 outputs, 1 metric, tensor array validation, ' +\n         'with batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 outputs.\n       const x = tfl.layers.input({shape: [1]});\n       const output1 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const output2 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const model = tfl.model({inputs: x, outputs: [output1, output2]});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       const xTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const yTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[model.outputNames[0]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         output[model.outputNames[1]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n\n       const yShape: {[name: string]: number[]} = {};\n       yShape[model.outputNames[0]] = [1];\n       yShape[model.outputNames[1]] = [1];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape,\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Validation data.\n       const valXs = tfc.zeros([batchSize, 1]);\n       const valYs: tfc.NamedTensorMap = {};\n       valYs[model.outputNames[0]] = tfc.zeros([batchSize, 1]);\n       valYs[model.outputNames[1]] = tfc.zeros([batchSize, 1]);\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs: 1,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       model.setWeights([\n         tfc.zeros([1, 1]), tfc.zeros([1]), tfc.zeros([1, 1]), tfc.zeros([1])\n       ]);\n\n       const history = await model.fitDataset(dataset, {\n         batchesPerEpoch,\n         epochs,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n\n       const output1AccName = model.outputNames[0] + '_acc';\n       const output1LossName = model.outputNames[0] + '_loss';\n       const output2AccName = model.outputNames[1] + '_acc';\n       const output2LossName = model.outputNames[1] + '_loss';\n       const valOutput1AccName = 'val_' + output1AccName;\n       const valOutput1LossName = 'val_' + output1LossName;\n       const valOutput2AccName = 'val_' + output2AccName;\n       const valOutput2LossName = 'val_' + output2LossName;\n\n       expect(Object.keys(history.history)).toEqual([\n         'val_loss', valOutput1LossName, valOutput2LossName, valOutput1AccName,\n         valOutput2AccName, 'loss', output1LossName, output2LossName,\n         output1AccName, output2AccName\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(1.847297);\n       expect(history.history.loss[1]).toBeCloseTo(1.445986);\n       expect(history.history[output1LossName].length).toEqual(2);\n       expect(history.history[output1LossName][0]).toBeCloseTo(0.923648);\n       expect(history.history[output1LossName][1]).toBeCloseTo(0.722993);\n       expect(history.history[output2LossName].length).toEqual(2);\n       expect(history.history[output2LossName][0]).toBeCloseTo(0.923648);\n       expect(history.history[output2LossName][1]).toBeCloseTo(0.722993);\n       expect(history.history[output1AccName].length).toEqual(2);\n       expect(history.history[output1AccName][0]).toBeCloseTo(0);\n       expect(history.history[output1AccName][1]).toBeCloseTo(0);\n       expect(history.history[output2AccName].length).toEqual(2);\n       expect(history.history[output2AccName][0]).toBeCloseTo(0);\n       expect(history.history[output2AccName][1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003321);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.011798);\n       expect(history.history[valOutput1LossName].length).toEqual(2);\n       expect(history.history[valOutput1LossName][0]).toBeCloseTo(0.006642);\n       expect(history.history[valOutput1LossName][1]).toBeCloseTo(0.023597);\n       expect(history.history[valOutput2LossName].length).toEqual(2);\n       expect(history.history[valOutput2LossName][0]).toBeCloseTo(0.003321);\n       expect(history.history[valOutput2LossName][1]).toBeCloseTo(0.011798);\n       expect(history.history[valOutput1AccName].length).toEqual(2);\n       expect(history.history[valOutput1AccName][0]).toBeCloseTo(0.003321);\n       expect(history.history[valOutput1AccName][1]).toBeCloseTo(0.011798);\n       expect(history.history[valOutput2AccName].length).toEqual(2);\n       expect(history.history[valOutput2AccName][0]).toBeCloseTo(1);\n       expect(history.history[valOutput2AccName][1]).toBeCloseTo(1);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n       expectTensorsClose(model.getWeights()[2], [0.108621]);\n       expectTensorsClose(model.getWeights()[3], [0.108621]);\n     });\n\n  it('1 input, 2 outputs, 1 metric, tensor array validation, ' +\n         'no batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 outputs.\n       const x = tfl.layers.input({shape: [1]});\n       const output1 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const output2 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const model = tfl.model({inputs: x, outputs: [output1, output2]});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       const xTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const yTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[model.outputNames[0]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[model.outputNames[1]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n\n       const yShape: {[name: string]: number[]} = {};\n       yShape[model.outputNames[0]] = [1];\n       yShape[model.outputNames[1]] = [1];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape,\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Validation data.\n       const valXs = tfc.zeros([batchSize, 1]);\n       const valYs: tfc.NamedTensorMap = {};\n       valYs[model.outputNames[0]] = tfc.zeros([batchSize, 1]);\n       valYs[model.outputNames[1]] = tfc.zeros([batchSize, 1]);\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {\n         epochs: 1,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n       model.setWeights([\n         tfc.zeros([1, 1]), tfc.zeros([1]), tfc.zeros([1, 1]), tfc.zeros([1])\n       ]);\n\n       const history = await model.fitDataset(dataset, {\n         epochs,\n         validationData: [valXs, valYs],\n         validationBatchSize: batchSize\n       });\n\n       const output1AccName = model.outputNames[0] + '_acc';\n       const output1LossName = model.outputNames[0] + '_loss';\n       const output2AccName = model.outputNames[1] + '_acc';\n       const output2LossName = model.outputNames[1] + '_loss';\n       const valOutput1AccName = 'val_' + output1AccName;\n       const valOutput1LossName = 'val_' + output1LossName;\n       const valOutput2AccName = 'val_' + output2AccName;\n       const valOutput2LossName = 'val_' + output2LossName;\n\n       expect(Object.keys(history.history)).toEqual([\n         'val_loss', valOutput1LossName, valOutput2LossName, valOutput1AccName,\n         valOutput2AccName, 'loss', output1LossName, output2LossName,\n         output1AccName, output2AccName\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(1.847297);\n       expect(history.history.loss[1]).toBeCloseTo(1.445986);\n       expect(history.history[output1LossName].length).toEqual(2);\n       expect(history.history[output1LossName][0]).toBeCloseTo(0.923648);\n       expect(history.history[output1LossName][1]).toBeCloseTo(0.722993);\n       expect(history.history[output2LossName].length).toEqual(2);\n       expect(history.history[output2LossName][0]).toBeCloseTo(0.923648);\n       expect(history.history[output2LossName][1]).toBeCloseTo(0.722993);\n       expect(history.history[output1AccName].length).toEqual(2);\n       expect(history.history[output1AccName][0]).toBeCloseTo(0);\n       expect(history.history[output1AccName][1]).toBeCloseTo(0);\n       expect(history.history[output2AccName].length).toEqual(2);\n       expect(history.history[output2AccName][0]).toBeCloseTo(0);\n       expect(history.history[output2AccName][1]).toBeCloseTo(0);\n       expect(history.history.val_loss.length).toEqual(2);\n       expect(history.history.val_loss[0]).toBeCloseTo(0.003321);\n       expect(history.history.val_loss[1]).toBeCloseTo(0.011798);\n       expect(history.history[valOutput1LossName].length).toEqual(2);\n       expect(history.history[valOutput1LossName][0]).toBeCloseTo(0.006642);\n       expect(history.history[valOutput1LossName][1]).toBeCloseTo(0.023597);\n       expect(history.history[valOutput2LossName].length).toEqual(2);\n       expect(history.history[valOutput2LossName][0]).toBeCloseTo(0.003321);\n       expect(history.history[valOutput2LossName][1]).toBeCloseTo(0.011798);\n       expect(history.history[valOutput1AccName].length).toEqual(2);\n       expect(history.history[valOutput1AccName][0]).toBeCloseTo(0.003321);\n       expect(history.history[valOutput1AccName][1]).toBeCloseTo(0.011798);\n       expect(history.history[valOutput2AccName].length).toEqual(2);\n       expect(history.history[valOutput2AccName][0]).toBeCloseTo(1);\n       expect(history.history[valOutput2AccName][1]).toBeCloseTo(1);\n       expectTensorsClose(model.getWeights()[0], [0.108621]);\n       expectTensorsClose(model.getWeights()[1], [0.108621]);\n       expectTensorsClose(model.getWeights()[2], [0.108621]);\n       expectTensorsClose(model.getWeights()[3], [0.108621]);\n     });\n\n  it('2 outputs, 1 missing output in dataset, with batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 outputs.\n       const x = tfl.layers.input({shape: [1]});\n       const output1 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const output2 =\n           tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n           tfl.SymbolicTensor;\n       const model = tfl.model({inputs: x, outputs: [output1, output2]});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       const xTensorsFunc = () =>\n           [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n            tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n       const yTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[model.outputNames[0]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n\n       const yShape: {[name: string]: number[]} = {};\n       yShape[model.outputNames[0]] = [1];\n       yShape[model.outputNames[1]] = [1];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape,\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       let errorCaught: Error;\n       try {\n         await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n       } catch (err) {\n         errorCaught = err;\n       }\n       expect(errorCaught.message)\n           .toEqual(\n               'The feature data generated by the dataset lacks the required ' +\n               `output key '${model.outputNames[1]}'.`);\n     });\n\n  it('2 outputs, 1 missing output in dataset, no batchesPerEpoch', async () => {\n    // Create a functional model with 2 outputs.\n    const x = tfl.layers.input({shape: [1]});\n    const output1 =\n        tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n        tfl.SymbolicTensor;\n    const output2 =\n        tfl.layers.dense({units: 1, kernelInitializer: 'zeros'}).apply(x) as\n        tfl.SymbolicTensor;\n    const model = tfl.model({inputs: x, outputs: [output1, output2]});\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n    const batchSize = 8;\n    const epochs = 2;\n    const batchesPerEpoch = 3;\n\n    const xTensorsFunc = () =>\n        [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n    const yTensorsFunc = () => {\n      const output: {[name: string]: tfc.Tensor[]} = {};\n      output[model.outputNames[0]] = [\n        tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n        tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n        tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n      ];\n      return output;\n    };\n\n    const yShape: {[name: string]: number[]} = {};\n    yShape[model.outputNames[0]] = [1];\n    yShape[model.outputNames[1]] = [1];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape,\n      batchSize,\n      numBatches: batchesPerEpoch,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    let errorCaught: Error;\n    try {\n      await model.fitDataset(dataset, {epochs});\n    } catch (err) {\n      errorCaught = err;\n    }\n    expect(errorCaught.message)\n        .toEqual(\n            'The feature data generated by the dataset lacks the required ' +\n            `output key '${model.outputNames[1]}'.`);\n  });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // batch_size = 8\n  // num_batches = 3\n  // epochs = 2\n  //\n  // input1 = tf.keras.Input(shape=[1], name='x1')\n  // input2 = tf.keras.Input(shape=[1], name='x2')\n  // concat = tf.keras.layers.concatenate([input1, input2])\n  //\n  // output1 = tf.keras.layers.Dense(\n  //     1, kernel_initializer='zeros')(concat)\n  // output2 = tf.keras.layers.Dense(\n  //     1, kernel_initializer='zeros')(concat)\n  //\n  // model = tf.keras.Model(\n  //      inputs=[input1, input2],\n  //      outputs=[output1, output2])\n  // model.compile(\n  //     loss = 'mean_squared_error', optimizer = 'sgd', metrics =\n  //     ['accuracy'])\n  // model.summary()\n  // output1_name = model.output_names[0]\n  // output2_name = model.output_names[1]\n  // print(x1)\n  // print(x2)\n  // print(output1_name)\n  // print(output2_name)\n  //\n  // xs1 = np.ones([batch_size * num_batches * epochs, 1])\n  // xs2 = np.ones([batch_size * num_batches * epochs, 1])\n  // ys1 = np.ones([batch_size * num_batches * epochs, 1])\n  // ys2 = np.ones([batch_size * num_batches * epochs, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices(\n  //     ({\n  //        x1: xs1,\n  //        x2: xs2\n  //      },{\n  //        output1_name: ys1,\n  //        output2_name: ys2\n  //      })).batch(batch_size)\n  //\n  // history = model.fit(dataset,\n  //                     steps_per_epoch=num_batches,\n  //                     epochs=epochs)\n  // print(history.history)\n  // print(model.get_weights()[0])\n  // print(model.get_weights()[1])\n  // print(model.get_weights()[2])\n  // print(model.get_weights()[3])\n  // ```\n  it('2 inputs, 2 outputs, 1 metric, no validation, with batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 inputs and 2 outputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const output1 = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                           .apply(concat) as tfl.SymbolicTensor;\n       const output2 = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                           .apply(concat) as tfl.SymbolicTensor;\n       const model =\n           tfl.model({inputs: [input1, input2], outputs: [output1, output2]});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       // Training data.\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[model.outputNames[0]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         output[model.outputNames[1]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n\n       const yShape: {[name: string]: number[]} = {};\n       yShape[model.outputNames[0]] = [1];\n       yShape[model.outputNames[1]] = [1];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape,\n         batchSize,\n         numBatches: batchesPerEpoch * epochs,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {batchesPerEpoch, epochs: 1});\n       model.setWeights([\n         tfc.zeros([2, 1]), tfc.zeros([1]), tfc.zeros([2, 1]), tfc.zeros([1])\n       ]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history =\n           await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n\n       const output1AccName = model.outputNames[0] + '_acc';\n       const output1LossName = model.outputNames[0] + '_loss';\n       const output2AccName = model.outputNames[1] + '_acc';\n       const output2LossName = model.outputNames[1] + '_loss';\n\n       expect(Object.keys(history.history)).toEqual([\n         'loss', output1LossName, output2LossName, output1AccName,\n         output2AccName\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(1.776232);\n       expect(history.history.loss[1]).toBeCloseTo(1.225369);\n       expect(history.history[output1LossName].length).toEqual(2);\n       expect(history.history[output1LossName][0]).toBeCloseTo(0.888116);\n       expect(history.history[output1LossName][1]).toBeCloseTo(0.612684);\n       expect(history.history[output2LossName].length).toEqual(2);\n       expect(history.history[output2LossName][0]).toBeCloseTo(0.888116);\n       expect(history.history[output2LossName][1]).toBeCloseTo(0.612684);\n       expect(history.history[output1AccName].length).toEqual(2);\n       expect(history.history[output1AccName][0]).toBeCloseTo(0);\n       expect(history.history[output1AccName][1]).toBeCloseTo(0);\n       expect(history.history[output2AccName].length).toEqual(2);\n       expect(history.history[output2AccName][0]).toBeCloseTo(0);\n       expect(history.history[output2AccName][1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.103376, 0.103376]);\n       expectTensorsClose(model.getWeights()[1], [0.103376]);\n       expectTensorsClose(model.getWeights()[2], [0.103376, 0.103376]);\n       expectTensorsClose(model.getWeights()[3], [0.103376]);\n     });\n\n  it('2 inputs, 2 outputs, 1 metric, no validation, no batchesPerEpoch',\n     async () => {\n       // Create a functional model with 2 inputs and 2 outputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const output1 = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                           .apply(concat) as tfl.SymbolicTensor;\n       const output2 = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                           .apply(concat) as tfl.SymbolicTensor;\n       const model =\n           tfl.model({inputs: [input1, input2], outputs: [output1, output2]});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const epochs = 2;\n       const batchesPerEpoch = 3;\n\n       // Training data.\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[model.outputNames[0]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[model.outputNames[1]] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n\n       const yShape: {[name: string]: number[]} = {};\n       yShape[model.outputNames[0]] = [1];\n       yShape[model.outputNames[1]] = [1];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape,\n         batchSize,\n         numBatches: batchesPerEpoch,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.fitDataset(dataset, {epochs: 1});\n       model.setWeights([\n         tfc.zeros([2, 1]), tfc.zeros([1]), tfc.zeros([2, 1]), tfc.zeros([1])\n       ]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const history = await model.fitDataset(dataset, {epochs});\n\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n\n       const output1AccName = model.outputNames[0] + '_acc';\n       const output1LossName = model.outputNames[0] + '_loss';\n       const output2AccName = model.outputNames[1] + '_acc';\n       const output2LossName = model.outputNames[1] + '_loss';\n\n       expect(Object.keys(history.history)).toEqual([\n         'loss', output1LossName, output2LossName, output1AccName,\n         output2AccName\n       ]);\n       expect(history.history.loss.length).toEqual(2);\n       expect(history.history.loss[0]).toBeCloseTo(1.776232);\n       expect(history.history.loss[1]).toBeCloseTo(1.225369);\n       expect(history.history[output1LossName].length).toEqual(2);\n       expect(history.history[output1LossName][0]).toBeCloseTo(0.888116);\n       expect(history.history[output1LossName][1]).toBeCloseTo(0.612684);\n       expect(history.history[output2LossName].length).toEqual(2);\n       expect(history.history[output2LossName][0]).toBeCloseTo(0.888116);\n       expect(history.history[output2LossName][1]).toBeCloseTo(0.612684);\n       expect(history.history[output1AccName].length).toEqual(2);\n       expect(history.history[output1AccName][0]).toBeCloseTo(0);\n       expect(history.history[output1AccName][1]).toBeCloseTo(0);\n       expect(history.history[output2AccName].length).toEqual(2);\n       expect(history.history[output2AccName][0]).toBeCloseTo(0);\n       expect(history.history[output2AccName][1]).toBeCloseTo(0);\n       expectTensorsClose(model.getWeights()[0], [0.103376, 0.103376]);\n       expectTensorsClose(model.getWeights()[1], [0.103376]);\n       expectTensorsClose(model.getWeights()[2], [0.103376, 0.103376]);\n       expectTensorsClose(model.getWeights()[3], [0.103376]);\n     });\n\n  it('Exhausting iterator with batchesPerEpoch throws warning', async () => {\n    const model = createDenseModel();\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n    const batchSize = 8;\n    const batchesPerEpoch = 3;\n    const dataset = new FakeNumericDataset(\n        {xShape: [1], yShape: [1], batchSize, numBatches: batchesPerEpoch});\n    // Do a burn-in call to account for initialization of cached tensors (for\n    // the memory-leak check below).\n    await model.fitDataset(dataset, {batchesPerEpoch, epochs: 1});\n    model.setWeights([tfc.zeros([1, 1]), tfc.zeros([1])]);\n    const warningMessages: string[] = [];\n    spyOn(console, 'warn')\n        .and.callFake((msg: string) => warningMessages.push(msg));\n    const numTensors0 = tfc.memory().numTensors;\n    const epochs = 3;\n    const history = await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n    const numTensors1 = tfc.memory().numTensors;\n    expect(numTensors1).toEqual(numTensors0);\n    expect(Object.keys(history.history)).toEqual(['loss']);\n    // Only the loss value from the first epoch should be logged.\n    // The 2nd and 3rd epochs are cut short because of dataset iterator\n    // exhaustion.\n    expect(history.history.loss.length).toEqual(1);\n    expect(warningMessages.length).toEqual(2);\n    expect(warningMessages[0])\n        .toMatch(/You provided `batchesPerEpoch` as .* 9 batches/);\n    expect(warningMessages[1])\n        .toMatch(/You provided `batchesPerEpoch` as .* 9 batches/);\n  });\n\n  it('Calling fitDataset() without calling compile() errors', async () => {\n    const model = createDenseModel();\n\n    const batchSize = 8;\n    const numBatches = 3;\n    const epochs = 2;\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches,\n    });\n\n    let errorCaught: Error;\n    try {\n      await model.fitDataset(dataset, {epochs});\n    } catch (err) {\n      errorCaught = err;\n    }\n    expect(errorCaught.message)\n        .toEqual('The model needs to be compiled before being used.');\n  });\n\n  it('Wrong validationBatches leads to Error', async () => {\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n    const batchSize = 8;\n    const epochs = 2;\n    const batchesPerEpoch = 3;\n    // Training dataset.\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batchesPerEpoch * epochs\n    });\n    // Validation dataset.\n    const valDataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batchesPerEpoch * epochs\n    });\n    // Do a burn-in call to account for initialization of cached\n    // tensors (for the memory-leak check below).\n    let errorCaught: Error;\n    try {\n      await model.fitDataset(dataset, {\n        batchesPerEpoch,\n        epochs,\n        validationData: valDataset,\n        validationBatches: 0\n      });\n    } catch (err) {\n      errorCaught = err;\n    }\n    expect(errorCaught.message)\n        .toMatch(/fitDataset.*dataset-based validation.*not to be provided.*0/);\n  });\n\n  it('Calling fitDataset with validationSplit leads to Error', async () => {\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n    const batchSize = 8;\n    const epochs = 2;\n    const batchesPerEpoch = 3;\n\n    // Training dataset.\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batchesPerEpoch * epochs\n    });\n\n    let errorCaught: Error;\n    try {\n      await model.fitDataset(\n          dataset,\n          // tslint:disable-next-line:no-any\n          {epochs: 1, batchesPerEpoch: 2, validationSplit: 0.25} as any);\n    } catch (err) {\n      errorCaught = err;\n    }\n    expect(errorCaught.message)\n        .toMatch(/.*validationSplit.*not supported.*validationData/);\n  });\n\n  class StopAfterNBatches extends tfl.Callback {\n    private readonly batchesToTrain: number;\n    constructor(epochsToTrain: number) {\n      super();\n      this.batchesToTrain = epochsToTrain;\n    }\n\n    async onBatchEnd(batch: number, logs?: Logs) {\n      if (batch === this.batchesToTrain - 1) {\n        this.model.stopTraining = true;\n      }\n    }\n  }\n\n  it('Stop training resets at start of LayersModel.fitDataset()', async () => {\n    const model = createDenseModel();\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const batchSize = 8;\n    const epochs = 2;\n    const batchesPerEpoch = 1;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batchesPerEpoch * epochs,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n    // Order 2 epochs of training, but the training should stop after only one\n    // epochs due to the callback that orders the training to stop after one\n    // batches.\n    let history = await model.fitDataset(\n        dataset,\n        {batchesPerEpoch, epochs, callbacks: [new StopAfterNBatches(1)]});\n    expect(history.history.loss.length).toEqual(1);\n\n    // Running fitDataset again should now run to completion\n    history = await model.fitDataset(dataset, {batchesPerEpoch, epochs});\n    expect(history.history.loss.length).toEqual(2);\n  });\n\n  it('onYield with yieldEvery: auto', async () => {\n    const wait = DEFAULT_YIELD_EVERY_MS;\n    const timeBetweenCalls = [\n      0,\n      1,\n      1,\n      wait + 1,  // Should call.\n      wait + 1,  // Should call.\n      1,\n      1,\n    ];\n    let counter = 0;\n    let prevTime = 0;\n    spyOn(util, 'now').and.callFake(() => {\n      prevTime += timeBetweenCalls[counter++];\n      return prevTime;\n    });\n    let nextFrameCallCount = 0;\n    spyOn(tfc, 'nextFrame').and.callFake(async () => {\n      nextFrameCallCount++;\n    });\n\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n    const epochs = 2;\n    const batchSize = 8;\n    const xTensorsFunc = () =>\n        [tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]),\n    ];\n    const yTensorsFunc = () =>\n        [tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]),\n    ];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: 3,\n      xTensorsFunc,\n      yTensorsFunc,\n    });\n    const onYieldEpochIds: number[] = [];\n    const onYieldBatchesIds: number[] = [];\n\n    const history = await model.fitDataset(dataset, {\n      epochs,\n      callbacks: {\n        onYield: async (epoch, batch, _logs) => {\n          onYieldBatchesIds.push(batch);\n          onYieldEpochIds.push(epoch);\n        }\n      }\n    });\n    expect(history.history.loss.length).toEqual(epochs);\n    // There are 5 batches in total (1 batch per epoch). We expect next frame\n    // to be called twice, after epoch 1 and after epoch 2.\n    expect(nextFrameCallCount).toBe(2);\n    expect(onYieldEpochIds).toEqual([0, 1]);\n    expect(onYieldBatchesIds).toEqual([2, 0]);\n  });\n\n  it('fails when onYield is provided, but yieldEvery is never', async done => {\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n    const epochs = 2;\n    const batchSize = 8;\n    const xTensorsFunc = () =>\n        [tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]),\n    ];\n    const yTensorsFunc = () =>\n        [tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]),\n         tfc.ones([batchSize, 1]),\n    ];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: 3,\n      xTensorsFunc,\n      yTensorsFunc,\n    });\n    try {\n      await model.fitDataset(dataset, {\n        epochs,\n        yieldEvery: 'never',\n        callbacks: {onYield: async (_epoch, _batch, _logs) => {}},\n      });\n      done.fail('Model.fit should fail');\n    } catch {\n      done();\n    }\n  });\n});\n\n// TODO(cais): The corresponding test for predict() and evaluate().\n\ndescribeMathCPUAndGPU('LayersModel.evaluateDataset', () => {\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution()\n  //\n  // batch_size = 8\n  // num_batches = 3\n  //\n  // xs = np.ones([batch_size * num_batches, 1])\n  // ys = np.ones([batch_size * num_batches, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices((xs, ys)).batch(batch_size)\n  //\n  // model = tf.keras.Sequential()\n  // model.add(tf.keras.layers.Dense(\n  //     1,\n  //     input_shape=[1],\n  //     kernel_initializer='zeros'))\n  // model.compile(loss='mean_squared_error',\n  //               optimizer=tf.train.GradientDescentOptimizer(0.01))\n  //\n  // out = model.evaluate(dataset, steps=3, verbose=0)\n  // print(out)\n  // ```\n  it('1 input, 1 output, no metric, with batches specified', async () => {\n    const model = createDenseModel();\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const batchSize = 8;\n    const batches = 3;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batches,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    // Do a burn-in call to account for initialization of cached tensors (for\n    // the memory-leak check below).\n    tfc.dispose(\n        await model.evaluateDataset(dataset, {batches}) as tfc.Scalar[]);\n\n    const numTensors0 = tfc.memory().numTensors;\n    const evalOut =\n        await model.evaluateDataset(dataset, {batches}) as tfc.Scalar;\n    const expectedLoss = tfc.scalar(1.0);\n    expectTensorsClose(evalOut, expectedLoss);\n    tfc.dispose(evalOut);\n    tfc.dispose(expectedLoss);\n    const numTensors1 = tfc.memory().numTensors;\n    expect(numTensors1).toEqual(numTensors0);\n  });\n\n  it('1 input, 1 output, no metric, no batches specified', async () => {\n    const model = createDenseModel();\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const batchSize = 8;\n    const batches = 3;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batches,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    // Do a burn-in call to account for initialization of cached tensors (for\n    // the memory-leak check below).\n    tfc.dispose(await model.evaluateDataset(dataset, {}) as tfc.Scalar[]);\n\n    const numTensors0 = tfc.memory().numTensors;\n    const evalOut = await model.evaluateDataset(dataset, {}) as tfc.Scalar;\n    const expectedLoss = tfc.scalar(1.0);\n    expectTensorsClose(evalOut, expectedLoss);\n    tfc.dispose(evalOut);\n    tfc.dispose(expectedLoss);\n    const numTensors1 = tfc.memory().numTensors;\n    expect(numTensors1).toEqual(numTensors0);\n  });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution()\n  //\n  // batch_size = 8\n  // num_batches = 3\n  //\n  // xs = np.ones([batch_size * num_batches, 1])\n  // ys = np.ones([batch_size * num_batches, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices((xs, ys)).batch(batch_size)\n  //\n  // model = tf.keras.Sequential()\n  // model.add(tf.keras.layers.Dense(\n  //     1,\n  //     input_shape=[1],\n  //     kernel_initializer='zeros'))\n  // model.compile(loss='mean_squared_error',\n  //               optimizer=tf.train.GradientDescentOptimizer(0.01),\n  //               metrics=['accuracy'])\n  //\n  // out = model.evaluate(dataset, steps=3, verbose=0)\n  // print(out)\n  // ```\n  it('1 input, 1 output, 1 metric, with batches specified', async () => {\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['acc']});\n\n    const batchSize = 8;\n    const batches = 3;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batches,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    // Do a burn-in call to account for initialization of cached tensors (for\n    // the memory-leak check below).\n    tfc.dispose(\n        await model.evaluateDataset(dataset, {batches}) as tfc.Scalar[]);\n\n    const numTensors0 = tfc.memory().numTensors;\n    const evalOut =\n        await model.evaluateDataset(dataset, {batches}) as tfc.Scalar[];\n    expect(evalOut.length).toEqual(2);\n    const expectedLoss = tfc.scalar(1.0);\n    const expectedAcc = tfc.scalar(0.0);\n    expectTensorsClose(evalOut[0], expectedLoss);\n    expectTensorsClose(evalOut[1], expectedAcc);\n    tfc.dispose(evalOut);\n    tfc.dispose([expectedLoss, expectedAcc]);\n    const numTensors1 = tfc.memory().numTensors;\n    expect(numTensors1).toEqual(numTensors0);\n  });\n\n  it('1 input, 1 output, 1 metric, no batches specified', async () => {\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['acc']});\n\n    const batchSize = 8;\n    const batches = 3;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batches,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    // Do a burn-in call to account for initialization of cached tensors (for\n    // the memory-leak check below).\n    tfc.dispose(await model.evaluateDataset(dataset, {}) as tfc.Scalar[]);\n\n    const numTensors0 = tfc.memory().numTensors;\n    const evalOut = await model.evaluateDataset(dataset, {}) as tfc.Scalar[];\n    expect(evalOut.length).toEqual(2);\n    const expectedLoss = tfc.scalar(1.0);\n    const expectedAcc = tfc.scalar(0.0);\n    expectTensorsClose(evalOut[0], expectedLoss);\n    expectTensorsClose(evalOut[1], expectedAcc);\n    tfc.dispose(evalOut);\n    tfc.dispose([expectedLoss, expectedAcc]);\n    const numTensors1 = tfc.memory().numTensors;\n    expect(numTensors1).toEqual(numTensors0);\n  });\n\n  it('1 input, 1 output, 1 metric, no batches, only 1 arg', async () => {\n    const model = createDenseModel();\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['acc']});\n\n    const batchSize = 8;\n    const batches = 3;\n    const xTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const yTensorsFunc =\n        () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n          batchSize, 1\n        ])];\n    const dataset = new FakeNumericDataset({\n      xShape: [1],\n      yShape: [1],\n      batchSize,\n      numBatches: batches,\n      xTensorsFunc,\n      yTensorsFunc\n    });\n\n    // Do a burn-in call to account for initialization of cached tensors (for\n    // the memory-leak check below). Use 1-arg call.\n    tfc.dispose(await model.evaluateDataset(dataset) as tfc.Scalar[]);\n\n    const numTensors0 = tfc.memory().numTensors;\n    // Use 1-arg call, omitting the config object.\n    const evalOut = await model.evaluateDataset(dataset) as tfc.Scalar[];\n    expect(evalOut.length).toEqual(2);\n    const expectedLoss = tfc.scalar(1.0);\n    const expectedAcc = tfc.scalar(0.0);\n    expectTensorsClose(evalOut[0], expectedLoss);\n    expectTensorsClose(evalOut[1], expectedAcc);\n    tfc.dispose(evalOut);\n    tfc.dispose([expectedLoss, expectedAcc]);\n    const numTensors1 = tfc.memory().numTensors;\n    expect(numTensors1).toEqual(numTensors0);\n  });\n\n  it('1 input, 1 output, iterator exhaustion with batches', async () => {\n    const model = createDenseModel();\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const batchSize = 8;\n    const batches = 3;\n    const dataset = new FakeNumericDataset(\n        {xShape: [1], yShape: [1], batchSize, numBatches: batches});\n\n    // Do a burn-in call to account for initialization of cached tensors (for\n    // the memory-leak check below).\n    tfc.dispose(\n        await model.evaluateDataset(dataset, {batches}) as tfc.Scalar[]);\n\n    const warningMessages: string[] = [];\n    spyOn(console, 'warn')\n        .and.callFake((msg: string) => warningMessages.push(msg));\n\n    const numTensors0 = tfc.memory().numTensors;\n    tfc.dispose(await model.evaluateDataset(dataset, {batches: batches + 2}));\n    const numTensors1 = tfc.memory().numTensors;\n    expect(numTensors1).toEqual(numTensors0);\n\n    expect(warningMessages.length).toEqual(1);\n    expect(warningMessages[0])\n        .toMatch(\n            /dataset iterator ran out of data during evaluate.* 5 batches/);\n  });\n\n  // Reference Python tf.keras code:\n  //\n  // ```py\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // tf.enable_eager_execution()\n  //\n  // batch_size = 8\n  // num_batches = 3\n  //\n  // xs1 = np.ones([batch_size * num_batches, 1])\n  // xs2 = np.ones([batch_size * num_batches, 1])\n  // ys = np.ones([batch_size * num_batches, 1])\n  // dataset = tf.data.Dataset.from_tensor_slices(\n  //     ({'input1': xs1, 'input2': xs2}, ys)).batch(batch_size)\n  //\n  // input1 = tf.keras.Input(shape=[1], name='input1')\n  // input2 = tf.keras.Input(shape=[1], name='input2')\n  // concat = tf.keras.layers.concatenate([input1, input2])\n  // output = tf.keras.layers.Dense(\n  //     1,\n  //     input_shape=[1],\n  //     kernel_initializer='zeros').apply(concat)\n  // model = tf.keras.Model(inputs=[input1, input2], outputs=output)\n  // model.compile(loss='mean_squared_error',\n  //               optimizer=tf.train.GradientDescentOptimizer(0.01),\n  //               metrics=['accuracy'])\n  //\n  // out = model.evaluate(dataset, steps=3, verbose=0)\n  // print(out)\n  // ```\n  it('2 inputs, 1 output, 1 metric, no validation, with batches specified',\n     async () => {\n       // Create a functional model with 2 inputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                     .apply(concat) as tfl.SymbolicTensor;\n       const model = tfl.model({inputs: [input1, input2], outputs: y});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const batches = 3;\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batches,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.evaluateDataset(dataset, {batches});\n       model.setWeights([tfc.zeros([2, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const evalOut =\n           await model.evaluateDataset(dataset, {batches}) as tfc.Scalar[];\n       const expectedLoss = tfc.scalar(1.0);\n       const expectedAcc = tfc.scalar(0.0);\n       expectTensorsClose(evalOut[0], expectedLoss);\n       expectTensorsClose(evalOut[1], expectedAcc);\n       tfc.dispose(evalOut);\n       tfc.dispose([expectedLoss, expectedAcc]);\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n     });\n\n  it('2 inputs, 1 output, 1 metric, no validation, no batches specified',\n     async () => {\n       // Create a functional model with 2 inputs.\n       const input1 = tfl.layers.input({shape: [1]});\n       const input2 = tfl.layers.input({shape: [1]});\n       const concat = tfl.layers.concatenate().apply([input1, input2]);\n       const y = tfl.layers.dense({units: 1, kernelInitializer: 'zeros'})\n                     .apply(concat) as tfl.SymbolicTensor;\n       const model = tfl.model({inputs: [input1, input2], outputs: y});\n       model.compile(\n           {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['accuracy']});\n\n       const batchSize = 8;\n       const batches = 3;\n       const xTensorsFunc = () => {\n         const output: {[name: string]: tfc.Tensor[]} = {};\n         output[input1.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         output[input2.name] = [\n           tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]),\n           tfc.ones([batchSize, 1])\n         ];\n         return output;\n       };\n       const yTensorsFunc =\n           () => [tfc.ones([batchSize, 1]), tfc.ones([batchSize, 1]), tfc.ones([\n             batchSize, 1\n           ])];\n       const dataset = new FakeNumericDataset({\n         xShape: [1],\n         yShape: [1],\n         batchSize,\n         numBatches: batches,\n         xTensorsFunc,\n         yTensorsFunc\n       });\n\n       // Do a burn-in call to account for initialization of cached tensors (for\n       // the memory-leak check below).\n       await model.evaluateDataset(dataset, {});\n       model.setWeights([tfc.zeros([2, 1]), tfc.zeros([1])]);\n\n       const numTensors0 = tfc.memory().numTensors;\n       const evalOut = await model.evaluateDataset(dataset, {}) as tfc.Scalar[];\n       const expectedLoss = tfc.scalar(1.0);\n       const expectedAcc = tfc.scalar(0.0);\n       expectTensorsClose(evalOut[0], expectedLoss);\n       expectTensorsClose(evalOut[1], expectedAcc);\n       tfc.dispose(evalOut);\n       tfc.dispose([expectedLoss, expectedAcc]);\n       const numTensors1 = tfc.memory().numTensors;\n       expect(numTensors1).toEqual(numTensors0);\n     });\n});\n"]}