{"version":3,"file":"training_test.js","sourceRoot":"","sources":["../../src/engine/training_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;AAEH;;GAEG;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAC,GAAG,EAAE,IAAI,EAAE,MAAM,EAAE,GAAG,EAAkB,IAAI,EAAU,MAAM,EAAE,YAAY,EAAU,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAE,SAAS,EAAE,IAAI,EAAE,KAAK,EAAC,MAAM,uBAAuB,CAAC;AAE/K,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,cAAc,EAAsB,sBAAsB,EAAS,MAAM,mBAAmB,CAAC;AACrG,OAAO,KAAK,GAAG,MAAM,UAAU,CAAC;AAChC,OAAO,KAAK,IAAI,MAAM,SAAS,CAAC;AAIhC,OAAO,EAAC,YAAY,EAAE,YAAY,EAAE,MAAM,EAAC,MAAM,wBAAwB,CAAC;AAC1E,OAAO,EAAC,eAAe,EAAE,qBAAqB,EAAE,eAAe,EAAE,kBAAkB,EAAC,MAAM,qBAAqB,CAAC;AAIhH,OAAO,EAAC,iBAAiB,EAAE,cAAc,EAAE,WAAW,EAAE,UAAU,EAAE,YAAY,EAAE,oBAAoB,EAAC,MAAM,YAAY,CAAC;AAC1H,OAAO,EAAC,WAAW,EAAE,oBAAoB,EAAC,MAAM,oBAAoB,CAAC;AAErE,eAAe,CAAC,cAAc,EAAE,GAAG,EAAE;IACnC,MAAM,CAAC,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IAEjC,EAAE,CAAC,eAAe,EAAE,GAAG,EAAE;QACvB,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,gBAAgB,EAAE,GAAG,EAAE;QACxB,MAAM,CAAC,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC5C,MAAM,CAAC,YAAY,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAChD,MAAM,CAAC,YAAY,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,aAAa,EAAE,GAAG,EAAE;IAClC,MAAM,CAAC,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IAEjC,EAAE,CAAC,eAAe,EAAE,GAAG,EAAE;QACvB,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC1C,MAAM,CAAC,WAAW,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,gBAAgB,EAAE,GAAG,EAAE;QACxB,MAAM,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QACtC,MAAM,CAAC,WAAW,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC/C,MAAM,CAAC,WAAW,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,YAAY,EAAE,GAAG,EAAE;IACjC,MAAM,CAAC,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;IACjC,EAAE,CAAC,eAAe,EAAE,GAAG,EAAE;QACvB,MAAM,CAAC,UAAU,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC7C,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,gBAAgB,EAAE,GAAG,EAAE;QACxB,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QACrC,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC1C,MAAM,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,sBAAsB,EAAE,GAAG,EAAE;IAC3C,MAAM,IAAI,GAAG,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IACxC,MAAM,IAAI,GAAG,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAExC,EAAE,CAAC,qCAAqC,EAAE,GAAG,EAAE;QAC7C,MAAM,OAAO,GAAG,oBAAoB,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,OAAO,GAAG,oBAAoB,CAAC,CAAC,IAAI,EAAE,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QACxD,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,OAAO,GAAG,oBAAoB,CAAC,CAAC,IAAI,EAAE,EAAE,IAAI,EAAE,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACvE,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC;QACvC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,yCAAyC,EAAE,GAAG,EAAE;QACjD,MAAM,OAAO,GACT,oBAAoB,CAAC,EAAC,KAAK,EAAE,IAAI,EAAE,EAAE,KAAK,EAAE,IAAI,EAAE,EAAC,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACzE,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC;QACvC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,sDAAsD,EAAE,GAAG,EAAE;QAC9D,MAAM,CAAC,GAAG,EAAE,CAAC,oBAAoB,CAAC,IAAI,EAAE,EAAE,EAAE,CAAC,CAAC;aACzC,YAAY,CAAC,kBAAkB,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,0DAA0D,EAAE,GAAG,EAAE;QAClE,MAAM,CAAC,GAAG,EAAE,CAAC,oBAAoB,CAAC,CAAC,IAAI,EAAE,EAAE,IAAI,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC;aACnD,YAAY,CAAC,kBAAkB,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,CAAC,GAAG,EAAE,CAAC,oBAAoB,CAAC,EAAC,KAAK,EAAE,IAAI,EAAE,EAAC,EAAE,EAAE,CAAC,CAAC;aAClD,YAAY,CAAC,kBAAkB,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,kDAAkD,EAAE,GAAG,EAAE;QAC1D,MAAM,CAAC,GAAG,EAAE,CAAC,oBAAoB,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;aACrD,YAAY,CAAC,0CAA0C,CAAC,CAAC;IAChE,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,iDAAiD,EAAE,GAAG,EAAE;QACzD,MAAM,CAAC,GAAG,EAAE,CAAC,oBAAoB,CAAC,CAAC,IAAI,EAAE,EAAE,MAAM,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;aAC7D,YAAY,CAAC,0BAA0B,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,8CAA8C,EAAE,GAAG,EAAE;QACtD,MAAM,CAAC,GAAG,EAAE,CAAC,oBAAoB,CAAC,EAAC,KAAK,EAAE,IAAI,EAAE,EAAC,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;aAC9D,YAAY,CAAC,8BAA8B,CAAC,CAAC;IACpD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,mBAAmB,EAAE,GAAG,EAAE;IACxC,EAAE,CAAC,0BAA0B,EAAE,GAAG,EAAE;QAClC,MAAM,MAAM,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,OAAO,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,GAAG,EAAE,CAAC,iBAAiB,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;aAC3C,YAAY,CAAC,qDAAqD,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,2BAA2B,EAAE,GAAG,EAAE;QACnC,MAAM,MAAM,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,OAAO,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,GAAG,EAAE,CAAC,iBAAiB,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;aAC3C,YAAY,CAAC,sDAAsD,CAAC,CAAC;IAC5E,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,2CAA2C,EAAE,GAAG,EAAE;QACnD,MAAM,MAAM,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,OAAO,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,GAAG,EAAE,CAAC,iBAAiB,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;aAC3C,YAAY,CACT,gEAAgE,CAAC,CAAC;IAC5E,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,gBAAgB,EAAE,GAAG,EAAE;IAC3C,EAAE,CAAC,uBAAuB,EAAE,GAAG,EAAE;QAC/B,MAAM,OAAO,GAAG,KAAK,CAAC;QACtB,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAC9D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,iBAAiB,EAAE,GAAG,EAAE;QACzB,MAAM,OAAO,GAAG,GAAG,CAAC,OAAO,CAAC,gBAAgB,CAAC;QAC7C,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAC9D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;IAClD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,gCAAgC,EAAE,GAAG,EAAE;QACxC,MAAM,OAAO,GAAG,CAAC,KAAK,EAAE,cAAc,CAAC,CAAC;QACxC,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAC9D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,2BAA2B,EAAE,GAAG,EAAE;QACnC,MAAM,OAAO,GAAG,CAAC,GAAG,CAAC,OAAO,CAAC,gBAAgB,EAAE,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;QACtE,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAC9D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;IACrD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,4DAA4D,EAAE,GAAG,EAAE;QACpE,MAAM,OAAO,GAAG,CAAC,KAAK,EAAE,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;QAC/C,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAC9D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;IACrD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,+BAA+B,EAAE,GAAG,EAAE;QACvC,MAAM,OAAO,GAAG,EAAC,QAAQ,EAAE,KAAK,EAAC,CAAC;QAClC,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAC9D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,0BAA0B,EAAE,GAAG,EAAE;QAClC,MAAM,OAAO,GAAG,EAAC,QAAQ,EAAE,GAAG,CAAC,OAAO,CAAC,gBAAgB,EAAC,CAAC;QACzD,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAC9D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC;IAC5D,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,cAAc,EAAE,GAAG,EAAE;QACtB,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,IAAI,EAAE,WAAW,CAAC,CAAC;QAC3D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,8BAA8B,EAAE,GAAG,EAAE;QACtC,MAAM,WAAW,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC/B,MAAM,gBAAgB,GAAG,cAAc,CAAC,EAAE,EAAE,WAAW,CAAC,CAAC;QACzD,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,uBAAuB,EAAE,GAAG,EAAE;QAC/B,MAAM,OAAO,GAAG,CAAC,KAAK,CAAC,CAAC;QACxB,MAAM,WAAW,GAAG,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC;QAC3C,MAAM,gBAAgB,GAAG,cAAc,CAAC,OAAO,EAAE,WAAW,CAAC,CAAC;QAC9D,MAAM,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,sBAAsB,EAAE,GAAG,EAAE;IACjD,EAAE,CAAC,WAAW,EAAE,GAAG,EAAE;QACnB,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrD,MAAM,CAAC,GAAG,oBAAoB,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAW,CAAC;QAC9D,kBAAkB,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC5D,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,kBAAkB,EAAE,GAAG,EAAE;QAC1B,MAAM,EAAE,GAAG;YACT,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;YAC1C,QAAQ,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;SACjD,CAAC;QACF,MAAM,EAAE,GAAG,oBAAoB,CAAC,EAAE,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAa,CAAC;QAClE,MAAM,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7B,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9D,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACpE,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,kBAAkB,EAAE,GAAG,EAAE;QAC1B,MAAM,EAAE,GAAG;YACT,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAC1C,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;SAC9C,CAAC;QACF,MAAM,EAAE,GAAG,oBAAoB,CAAC,EAAE,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAa,CAAC;QAClE,MAAM,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7B,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC/D,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACnE,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,kBAAkB,EAAE,GAAG,EAAE;QAC1B,MAAM,CAAC,oBAAoB,CAAC,IAAI,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,QAAQ,EAAE,CAAC;IAClE,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,6BAA6B,EAAE,GAAG,EAAE;QACrC,MAAM,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrD,MAAM,CAAC,GACH,oBAAoB,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,SAAS,CAAC,CAAW,CAAC;QACvE,kBAAkB,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC5D,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,QAAQ,CAAC,aAAa,EAAE,GAAG,EAAE;IAC3B,EAAE,CAAC,WAAW,EAAE,GAAG,EAAE;QACnB,MAAM,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACtD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,aAAa,EAAE,GAAG,EAAE;QACrB,MAAM,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5D,MAAM,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC9C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,YAAY,EAAE,GAAG,EAAE;QACpB,MAAM,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,qBAAqB,EAAE,GAAG,EAAE;IAChD,EAAE,CAAC,mBAAmB,EAAE,GAAG,EAAE;QAC3B,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QAC5D,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACxD,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAC7B,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,UAAU,EAAC,CAAC,CAAC;QAClE,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5B,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAW,CAAC;QACvD,kBAAkB,CAAC,EAAE,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,sBAAsB,EAAE,GAAG,EAAE;QAC9B,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC;QAEzD,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAE,iBAAiB;QACzC,2BAA2B;QAC3B,GAAG,CAAC,OAAO,CAAC,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAW,CAAC;QACvD,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,EAAE,CAAC,OAAO,EAAE,CAAC;QACb,yBAAyB;QACzB,MAAM,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IACnD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,6CAA6C,EAAE,GAAG,EAAE;QACrD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QAC5D,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACxD,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAC7B,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,UAAU,EAAC,CAAC,CAAC;QAClE,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5B,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QACvC,kBAAkB,CAAC,EAAE,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4BAA4B,EAAE,GAAG,EAAE;QACpC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QAC5D,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACxD,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAC7B,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,UAAU,EAAC,CAAC,CAAC;QAClE,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5B,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAW,CAAC;QACzD,kBAAkB,CAAC,EAAE,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,oBAAoB,EAAE,GAAG,EAAE;QAC5B,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QAC5D,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACzD,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC;QACpC,MAAM,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAChE,MAAM,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,OAAO,CAAuB,CAAC;QAC5D,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAC7B,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAE,IAAI,EAAE,UAAU,EAAC,CAAC,CAAC;QAC5E,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5B,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAa,CAAC;QACzD,MAAM,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7B,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5C,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qBAAqB,EAAE,GAAG,EAAE;QAC7B,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CACjC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QAC5D,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CACjC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QAC5D,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACzD,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC;QACpC,MAAM,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,YAAY,CAAuB,CAAC;QACjE,MAAM,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,YAAY,CAAuB,CAAC;QACjE,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC;YAChC,MAAM,EAAE,CAAC,YAAY,EAAE,YAAY,CAAC;YACpC,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC;YAC3B,IAAI,EAAE,UAAU;SACjB,CAAC,CAAC;QACH,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7B,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7B,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAa,CAAC;QACjE,MAAM,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7B,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5C,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uDAAuD,EAAE,GAAG,EAAE;QAC/D,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,kBAAkB,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QACjE,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACxD,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAC7B,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,eAAe,EAAC,CAAC,CAAC;QACvE,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE7B,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC;YACzB,GAAG,EAAE,GAAG;SACT,CAAC,CAAC,CAAC,YAAY,CAAC,sCAAsC,CAAC,CAAC;IAC3D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uDAAuD,EAAE,GAAG,EAAE;QAC/D,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CACjC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,kBAAkB,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QACjE,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CACjC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,kBAAkB,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QACjE,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACzD,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC;QACpC,MAAM,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,YAAY,CAAuB,CAAC;QACjE,MAAM,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,YAAY,CAAuB,CAAC;QACjE,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC;YAChC,MAAM,EAAE,CAAC,YAAY,EAAE,YAAY,CAAC;YACpC,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC;YAC3B,IAAI,EAAE,eAAe;SACtB,CAAC,CAAC;QACH,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE7B,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC;YACzB,GAAG,EAAE,GAAG,EAAE,GAAG;SACd,CAAC,CAAC,CAAC,YAAY,CAAC,sCAAsC,CAAC,CAAC;IAC3D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,kBAAkB,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QACjE,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACxD,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAC7B,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAE,IAAI,EAAE,eAAe,EAAC,CAAC,CAAC;QACvE,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE5B,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC;aAC3B,YAAY,CAAC,qDAAqD,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,CACxB,EAAC,MAAM,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QAC/D,MAAM,EAAE,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7B,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;aAC1C,YAAY,CACT,2DAA2D,CAAC,CAAC;QACrE,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;aAC3C,YAAY,CACT,4DAA4D,CAAC,CAAC;QACtE,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,IAAI,EAAC,CAAC,CAAC;aAC7C,YAAY,CACT,+DAA+D,CAAC,CAAC;QACzE,kCAAkC;QAClC,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,GAAU,EAAC,CAAC,CAAC;aACnD,YAAY,CACT,2DAA2D,CAAC,CAAC;IACvE,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,iBAAiB,EAAE,GAAG,EAAE;IAC5C,MAAM,SAAS,GAAG,CAAC,CAAC,CAAG,8CAA8C;IACrE,MAAM,UAAU,GAAG,CAAC,CAAC,CAAE,mDAAmD;IAC1E,MAAM,UAAU,GAAG,CAAC,CAAC,CAAE,mDAAmD;IAC1E,MAAM,UAAU,GAAG,CAAC,CAAC,CAAE,gCAAgC;IAEvD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,SAAS,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;IACjE,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CACjC,EAAC,KAAK,EAAE,CAAC,UAAU,CAAC,EAAE,IAAI,EAAE,gBAAgB,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;IACrE,MAAM,YAAY,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CACjC,EAAC,KAAK,EAAE,CAAC,UAAU,CAAC,EAAE,IAAI,EAAE,gBAAgB,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;IAErE,4BAA4B;IAC5B,IAAI,KAAsB,CAAC;IAC3B,IAAI,MAAc,CAAC;IACnB,IAAI,OAAe,CAAC;IAEpB,+CAA+C;IAC/C,IAAI,cAA+B,CAAC;IACpC,IAAI,OAAe,CAAC;IACpB,IAAI,OAAe,CAAC;IACpB,IAAI,QAAgB,CAAC;IACrB,IAAI,QAAgB,CAAC;IAErB,SAAS,uBAAuB,CAC5B,OAAO,GAAG,KAAK,EACf,iBAAsC,EACtC,eAAoC;QAEtC,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAC1B,EAAC,KAAK,EAAE,CAAC,EAAE,OAAO,EAAE,iBAAiB,EAAE,MAAM,EAAE,iBAAiB,EAAC,CAAC,CAAC;QACvE,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAC,CAAC,CAAC;QACxE,MAAM,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACvC,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;IAClC,CAAC;IAED,SAAS,kCAAkC,CAAC,OAAO,GAAG,KAAK;QACzD,MAAM,KAAK,GACP,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,OAAO,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAC,CAAC,CAAC;QACxE,MAAM,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACvC,OAAO,GAAG,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,UAAU,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IAC5C,CAAC;IAED,SAAS,+BAA+B,CAAC,OAAO,GAAG,KAAK;QACtD,MAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,EAAE,EAAE,OAAO,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC;QACtE,MAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,OAAO,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GACR,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAuB,CAAC;QAClE,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAC,CAAC,CAAC;QACxE,MAAM,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACvC,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;IAC1B,CAAC;IAED,SAAS,qCAAqC;QAC5C,MAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,OAAO,EAAE,KAAK,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC;QAC5E,MAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,OAAO,EAAE,KAAK,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC;QAC5E,MAAM,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,YAAY,CAAuB,CAAC;QACjE,MAAM,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,YAAY,CAAuB,CAAC;QACjE,cAAc,GAAG,IAAI,GAAG,CAAC,WAAW,CAChC,EAAC,MAAM,EAAE,CAAC,YAAY,EAAE,YAAY,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QACzE,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QACzC,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QACzC,QAAQ,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;QACjC,QAAQ,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;IACnC,CAAC;IAED,EAAE,CAAC,+DAA+D,EAC/D,KAAK,IAAI,EAAE;QACT,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,yDAAyD;QACzD,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAEzE,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,eAAe,GAAG,KAAK,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QAEzD,MAAM,EAAE,GAAG,IAAI,CAAC,CAAE,4CAA4C;QAC9D,MAAM,kBAAkB,GACpB,YAAY,CAAC,CAAC,GAAG,GAAG,CAAC,SAAS,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC;QAC9D,kBAAkB,CACd,eAAe,EAAE,QAAQ,CAAC,kBAAkB,EAAE,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACrE,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,iDAAiD,EAAE,KAAK,IAAI,EAAE;QAC/D,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC;QACzD,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAE5D,wBAAwB;QACxB,MAAM,GAAG,IAAI,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC;QAC5B,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC;QAC7B,MAAM,SAAS,GAAG,IAAI,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC;QACrC,MAAM,UAAU,GAAG,IAAI,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC;QAEtC,6DAA6D;QAC7D,wCAAwC;QACxC,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;YAC/B,SAAS,EAAE,UAAU;YACrB,MAAM,EAAE,CAAC;YACT,cAAc,EAAE,CAAC,SAAS,EAAE,UAAU,CAAC;SACxC,CAAC,CAAC;QAEH,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YACxC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;gBAC/C,SAAS,EAAE,UAAU;gBACrB,MAAM,EAAE,CAAC;gBACT,cAAc,EAAE,CAAC,SAAS,EAAE,UAAU,CAAC;aACxC,CAAC,CAAC;YACH,MAAM,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;YACjD,yBAAyB;YACzB,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YACtC,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;YAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;SACpD;IACH,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,oCAAoC,EAAE,KAAK,IAAI,EAAE;QAClD,kCAAkC,EAAE,CAAC;QACrC,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,iBAAiB,EAAC,CAAC,CAAC;QAC3D,yDAAyD;QACzD,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAE,GAAG,EAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,SAAS,CAAC,iBAAiB,CACvB,OAAO,CAAC,OAAO,CAAC,MAAM,CAAa,EACnC,CAAC,CAAC,gBAAgB,EAAE,CAAC,kBAAkB,CAAC,CAAC,CAAC;QAC9C,SAAS,CAAC,iBAAiB,CACvB,OAAO,CAAC,OAAO,CAAC,UAAU,CAAa,EACvC,CAAC,CAAC,gBAAgB,EAAE,CAAC,kBAAkB,CAAC,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2BAA2B,EAAE,KAAK,IAAI,EAAE;QACzC,gEAAgE;QAChE,iBAAiB;QACjB,EAAE;QACF,YAAY;QACZ,eAAe;QACf,6BAA6B;QAC7B,qBAAqB;QACrB,EAAE;QACF,2BAA2B;QAC3B,gCAAgC;QAChC,EAAE;QACF,kCAAkC;QAClC,8BAA8B;QAC9B,0DAA0D;QAC1D,yBAAyB;QACzB,sCAAsC;QACtC,qDAAqD;QACrD,2BAA2B;QAC3B,yBAAyB;QACzB,uBAAuB;QACvB,+CAA+C;QAC/C,4BAA4B;QAC5B,yBAAyB;QACzB,MAAM;QAEN,uBAAuB,EAAE,CAAC;QAE1B,MAAM,WAAW,GAAG,CAAC,CAAS,EAAE,CAAS,EAAE,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAElE,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,WAAW,EAAC,CAAC,CAAC;QACrD,yDAAyD;QACzD,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAE,GAAG,EAAC,CAAC,CAAC;QAC9D,SAAS,CAAC,iBAAiB,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAa,EAAE,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;QAC5E,SAAS,CAAC,iBAAiB,CACvB,OAAO,CAAC,OAAO,CAAC,UAAU,CAAa,EAAE,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC;IAC7D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,oCAAoC,EAAE,KAAK,IAAI,EAAE;QAClD,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,MAAM,EAAE,EAAE,EAAC,CAAC,CAAC;QAC/D,uCAAuC;QACvC,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QACzC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,EAAE,EAAE,CAAC,EAAE;YAC3B,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;SACrC;IACH,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qCAAqC,EAAE,KAAK,IAAI,EAAE;QACnD,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;QACjD,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACtC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gEAAgE,EAChE,KAAK,IAAI,EAAE;QACT,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACzE,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,kEAAkE;QAC9D,gBAAgB,EACpB,KAAK,IAAI,EAAE;QACT,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,YAAY,EAAE,CAAC,EAAC,CAAC,CAAC;QACzD,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACjD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,6BAA6B,EAAE,KAAK,IAAI,EAAE;QAC3C,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,SAAS,CAAC,EAAC,CAAC,CAAC;QACrD,MAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC;QAC5E,MAAM,OAAO,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,GAAG,EAAC,CAAC,CAAC;QAChD,MAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC;QAC5E,MAAM,MAAM,GACR,MAAM,CAAC,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAuB,CAAC;QAC3E,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE,MAAM,EAAC,CAAC,CAAC;QACpE,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAC5D,MAAM,CAAC,GAAG,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;QACvC,MAAM,CAAC,GAAG,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/B,MAAM,KAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,SAAS,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2CAA2C,EAAE,KAAK,IAAI,EAAE;QACzD,uBAAuB,EAAE,CAAC;QAC1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,gEAAgE;QAChE,4CAA4C;QAC5C,MAAM,QAAQ,GACV,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACnE,IAAI,WAAkB,CAAC;QACvB,IAAI;YACF,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;SAClC;QAAC,OAAO,GAAG,EAAE;YACZ,WAAW,GAAG,GAAG,CAAC;SACnB;QACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;aACtB,OAAO,CACJ,8DAA8D,CAAC,CAAC;QACxE,MAAM,QAAQ,CAAC;IACjB,CAAC,CAAC,CAAC;IAEH,MAAM,gBAAgB,GAAG,CAAC,GAAG,EAAE,IAAI,CAAC,CAAC;IACrC,KAAK,MAAM,eAAe,IAAI,gBAAgB,EAAE;QAC9C,MAAM,SAAS,GACX,kEAAkE;YAClE,mBAAmB,eAAe,EAAE,CAAC;QACzC,EAAE,CAAC,SAAS,EAAE,KAAK,IAAI,EAAE;YACvB,uBAAuB,EAAE,CAAC;YAC1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;YAC5D,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAC,CAAC,CAAC;YAC1E,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YACtC,MAAM,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;YACvC,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;YACjC,MAAM,SAAS,GAAG,OAAO,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;YAC9C,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;YACpC,+DAA+D;YAC/D,YAAY;YACZ,eAAe;YACf,qBAAqB;YACrB,kCAAkC;YAClC,8BAA8B;YAC9B,0DAA0D;YAC1D,yBAAyB;YACzB,sCAAsC;YACtC,4DAA4D;YAC5D,2BAA2B;YAC3B,yBAAyB;YACzB,uBAAuB;YACvB,+CAA+C;YAC/C,4BAA4B;YAC5B,yBAAyB;YACzB,MAAM;YACN,kBAAkB,CAAC,MAAkB,EAAE,CAAC,CAAC,EAAE,iBAAiB,CAAC,CAAC,CAAC;YAC/D,kBAAkB,CACd,SAAqB,EAAE,CAAC,iBAAiB,EAAE,iBAAiB,CAAC,CAAC,CAAC;QACrE,CAAC,CAAC,CAAC;KACJ;IAED,EAAE,CAAC,kEAAkE;QAC9D,oBAAoB,EACxB,KAAK,IAAI,EAAE;QACT,uBAAuB,EAAE,CAAC;QAC1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;YAC/C,SAAS,EAAE,UAAU;YACrB,MAAM,EAAE,CAAC;YACT,cAAc,EAAE,CAAC,KAAK,CAAC,MAAM,CAAC,KAAyB,CAAC,EAAE,OAAO,CAAC;SACnE,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACvC,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,SAAS,GAAG,OAAO,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;QAC9C,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACpC,kBAAkB,CAAC,MAAkB,EAAE,CAAC,CAAC,EAAE,iBAAiB,CAAC,CAAC,CAAC;IACjE,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,kEAAkE;QAC9D,+CAA+C,EACnD,KAAK,IAAI,EAAE;QACT,uBAAuB,EAAE,CAAC;QAC1B,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAE,OAAO,EAAE,CAAC,UAAU,CAAC,EAAC,CAAC,CAAC;QACzE,MAAM,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;QACpD,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;YAC/C,SAAS,EAAE,UAAU;YACrB,MAAM,EAAE,CAAC;YACT,eAAe,EAAE,GAAG;SACrB,CAAC,CAAC;QAEH,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACvC,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,SAAS,GAAG,OAAO,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;QAC9C,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACpC,kBAAkB,CAAC,MAAkB,EAAE,CAAC,CAAC,EAAE,iBAAiB,CAAC,CAAC,CAAC;QAC/D,kBAAkB,CACd,SAAqB,EAAE,CAAC,iBAAiB,EAAE,iBAAiB,CAAC,CAAC,CAAC;IACrE,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,mCAAmC,EAAE,KAAK,IAAI,EAAE;QACjD,4EAA4E;QAC5E,wCAAwC;QACxC,kEAAkE;QAClE,qBAAqB;QACrB,YAAY;QACZ,eAAe;QACf,qBAAqB;QACrB,EAAE;QACF,qBAAqB;QACrB,gBAAgB;QAChB,gBAAgB;QAChB,wBAAwB;QACxB,gBAAgB;QAChB,iBAAiB;QACjB,EAAE;QACF,6BAA6B;QAC7B,EAAE;QACF,oCAAoC;QACpC,kBAAkB;QAClB,iCAAiC;QACjC,oCAAoC;QACpC,sBAAsB;QACtB,6BAA6B;QAC7B,gDAAgD;QAChD,0CAA0C;QAC1C,0BAA0B;QAC1B,sBAAsB;QACtB,qCAAqC;QACrC,4BAA4B;QAC5B,EAAE;QACF,iCAAiC;QACjC,iDAAiD;QACjD,sCAAsC;QACtC,sEAAsE;QACtE,uEAAuE;QACvE,4CAA4C;QAC5C,gCAAgC;QAChC,wDAAwD;QACxD,yBAAyB;QACzB,MAAM;QAEN,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAG,EAAE,CAAC;QACpB,MAAM,eAAe,GAAG,GAAG,CAAC;QAC5B,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,4EAA4E;QAC5E,4EAA4E;QAC5E,qEAAqE;QACrE,MAAM,UAAU,GAAG,CAAC,CAAC;QACrB,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YACrC,KAAK,EAAE,UAAU;YACjB,iBAAiB,EAAE,MAAM;YACzB,oBAAoB,EAAE,MAAM;YAC5B,OAAO,EAAE,KAAK;YACd,eAAe,EAAE,IAAI;SACtB,CAAC,CAAC;QACH,MAAM,eAAe,GAAG,GAAG,CAAC,MAAM,CAAC,eAAe,CAAC;YACjD,KAAK,EAAE,GAAG,CAAC,MAAM,CAAC,KAAK,CACnB,EAAC,KAAK,EAAE,UAAU,EAAE,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC;SACpE,CAAC,CAAC;QACH,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,cAAc,EAAE,SAAS,CAAC,EAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GACR,eAAe,CAAC,KAAK,CAAC,SAAS,CAAC,KAAK,CAAC,KAAK,CAAC,CAAuB,CAAC;QACxE,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE,MAAM,EAAC,CAAC,CAAC;QACpE,KAAK,CAAC,OAAO,CAAC;YACZ,SAAS,EAAE,KAAK;YAChB,IAAI,EAAE,yBAAyB;YAC/B,OAAO,EAAE,CAAC,UAAU,CAAC;SACtB,CAAC,CAAC;QACH,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,IAAI,CAAC,CAAC,QAAQ,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,EAC3C,IAAI,CAAC,CAAC,QAAQ,EAAE,cAAc,EAAE,UAAU,CAAC,CAAC,EAAE;YAC5C,SAAS;YACT,MAAM,EAAE,CAAC;YACT,eAAe;SAChB,CAAC,CAAC;QACP,kBAAkB,CACd,OAAO,CAAC,OAAO,CAAC,MAAM,CAAa,EAAE,CAAC,kBAAkB,CAAC,CAAC,CAAC;QAC/D,kBAAkB,CACd,OAAO,CAAC,OAAO,CAAC,UAAU,CAAa,EAAE,CAAC,kBAAkB,CAAC,CAAC,CAAC;QACnE,kBAAkB,CAAC,OAAO,CAAC,OAAO,CAAC,KAAK,CAAa,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QAC9D,kBAAkB,CAAC,OAAO,CAAC,OAAO,CAAC,SAAS,CAAa,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;IACpE,CAAC,CAAC,CAAC;IAEH,mEAAmE;IAEnE,MAAM,aAAa,GAAe,CAAC,CAAC,KAAK,CAAC,EAAE,CAAC,UAAU,CAAC,CAAC,CAAC;IAC1D,gEAAgE;IAChE,KAAK,MAAM,OAAO,IAAI,aAAa,EAAE;QACnC,MAAM,SAAS,GAAG,wDAAwD;YACtE,GAAG,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,EAAE,CAAC;QACjC,EAAE,CAAC,SAAS,EAAE,KAAK,IAAI,EAAE;YACvB,kCAAkC,EAAE,CAAC;YACrC,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,yBAAyB,EAAE,OAAO,EAAC,CAAC,CAAC;YAClE,IAAI,YAAY,CAAC,OAAO,EAAE,CAAC,KAAK,CAAC,CAAC;gBAC9B,YAAY,CAAC,OAAO,EAAE,CAAC,UAAU,CAAC,CAAC,EAAE;gBACvC,MAAM,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;aACrD;iBAAM,IAAI,YAAY,CAAC,OAAO,EAAE,CAAC,KAAK,EAAE,UAAU,CAAC,CAAC,EAAE;gBACrD,MAAM,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;aAC5D;YACD,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAE,GAAG,EAAC,CAAC,CAAC;YAC9D,MAAM,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;YACvC,kBAAkB,CACd,MAAkB,EAAE,CAAC,kBAAkB,EAAE,kBAAkB,CAAC,CAAC,CAAC;YAClE,MAAM,SAAS,GAAG,OAAO,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;YAC9C,kBAAkB,CACd,SAAqB,EAAE,CAAC,kBAAkB,EAAE,kBAAkB,CAAC,CAAC,CAAC;YACrE,MAAM,GAAG,GAAG,OAAO,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;YACnC,kBAAkB,CAAC,GAAe,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAC5C,MAAM,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;YAC1C,kBAAkB,CAAC,MAAkB,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,CAAC,CAAC,CAAC;KACJ;IAED,EAAE,CAAC,wDAAwD;QACpD,4CAA4C,EAChD,KAAK,IAAI,EAAE;QACT,kCAAkC,EAAE,CAAC;QACrC,KAAK,CAAC,OAAO,CAAC;YACZ,SAAS,EAAE,KAAK;YAChB,IAAI,EAAE,yBAAyB;YAC/B,OAAO,EAAE,GAAG,CAAC,OAAO,CAAC,gBAAgB;SACtC,CAAC,CAAC;QACH,MAAM,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,kBAAkB,CAAC,CAAC,CAAC;QACjE,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAE,GAAG,EAAC,CAAC,CAAC;QAC9D,MAAM,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACvC,kBAAkB,CACd,MAAkB,EAAE,CAAC,kBAAkB,EAAE,kBAAkB,CAAC,CAAC,CAAC;QAClE,MAAM,eAAe,GAAG,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC;QAC5D,kBAAkB,CACd,eAA2B,EAAE,CAAC,IAAI,EAAE,kBAAkB,CAAC,CAAC,CAAC;IAC/D,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,wDAAwD;QACpD,mDAAmD,EACvD,KAAK,IAAI,EAAE;QACT,kCAAkC,EAAE,CAAC;QACrC,KAAK,CAAC,OAAO,CAAC;YACZ,SAAS,EAAE,KAAK;YAChB,IAAI,EAAE,yBAAyB;YAC/B,OAAO,EAAE,CAAC,GAAG,CAAC,OAAO,CAAC,gBAAgB,EAAE,KAAK,CAAC;SAC/C,CAAC,CAAC;QACH,MAAM,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,kBAAkB,EAAE,KAAK,CAAC,CAAC,CAAC;QACxE,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAE,GAAG,EAAC,CAAC,CAAC;QAC9D,MAAM,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACvC,kBAAkB,CACd,MAAkB,EAAE,CAAC,kBAAkB,EAAE,kBAAkB,CAAC,CAAC,CAAC;QAClE,MAAM,eAAe,GAAG,OAAO,CAAC,OAAO,CAAC,kBAAkB,CAAC,CAAC;QAC5D,kBAAkB,CACd,eAA2B,EAAE,CAAC,IAAI,EAAE,kBAAkB,CAAC,CAAC,CAAC;QAC7D,MAAM,GAAG,GAAG,OAAO,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QACnC,kBAAkB,CAAC,GAAe,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC9C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,8BAA8B,EAAE,KAAK,IAAI,EAAE;QAC5C,0EAA0E;QAC1E,QAAQ;QACR,YAAY;QACZ,eAAe;QACf,qBAAqB;QACrB,EAAE;QACF,iBAAiB;QACjB,kBAAkB;QAClB,EAAE;QACF,+DAA+D;QAC/D,+BAA+B;QAC/B,2DAA2D;QAC3D,+BAA+B;QAC/B,0DAA0D;QAC1D,wCAAwC;QACxC,4CAA4C;QAC5C,EAAE;QACF,8CAA8C;QAC9C,sCAAsC;QACtC,EAAE;QACF,4CAA4C;QAC5C,gEAAgE;QAChE,8BAA8B;QAC9B,+BAA+B;QAC/B,8CAA8C;QAC9C,gCAAgC;QAChC,4CAA4C;QAC5C,EAAE;QACF,yBAAyB;QACzB,8BAA8B;QAC9B,8BAA8B;QAC9B,EAAE;QACF,oBAAoB;QACpB,2BAA2B;QAC3B,gEAAgE;QAChE,8BAA8B;QAC9B,+BAA+B;QAC/B,8CAA8C;QAC9C,gCAAgC;QAChC,4CAA4C;QAC5C,EAAE;QACF,yBAAyB;QACzB,8BAA8B;QAC9B,8BAA8B;QAC9B,MAAM;QACN,MAAM,MAAM,GAAG,+BAA+B,EAAE,CAAC;QACjD,MAAM,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;QACzB,MAAM,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;QACzB,MAAM,SAAS,GAAG,IAAI,YAAY,CAAC,IAAI,CAAC,CAAC;QACzC,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QACrD,IAAI,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CACzB,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAE,GAAG,EAAC,CAAC,CAAC;QAC9D,IAAI,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACrC,kBAAkB,CAAC,MAAkB,EAAE,CAAC,MAAM,EAAE,kBAAkB,CAAC,CAAC,CAAC;QACrE,IAAI,SAAS,GAAG,OAAO,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;QAC5C,kBAAkB,CACd,SAAqB,EAAE,CAAC,kBAAkB,EAAE,kBAAkB,CAAC,CAAC,CAAC;QACrE,kBAAkB,CACd,MAAM,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,MAAM,CAAC,CAAC,UAAU,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACrE,kBAAkB,CACd,MAAM,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,MAAM,CAAC,CAAC,UAAU,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAErE,oDAAoD;QACpD,MAAM,CAAC,SAAS,GAAG,KAAK,CAAC;QACzB,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAErD,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CACrB,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAE,GAAG,EAAC,CAAC,CAAC;QAC9D,MAAM,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACjC,kBAAkB,CACd,MAAkB,EAAE,CAAC,kBAAkB,EAAE,kBAAkB,CAAC,CAAC,CAAC;QAClE,SAAS,GAAG,OAAO,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;QACxC,kBAAkB,CACd,SAAqB,EAAE,CAAC,kBAAkB,EAAE,kBAAkB,CAAC,CAAC,CAAC;QACrE,yEAAyE;QACzE,kBAAkB,CACd,MAAM,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,MAAM,CAAC,CAAC,UAAU,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACrE,iDAAiD;QACjD,kBAAkB,CACd,MAAM,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACpE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8CAA8C,EAAE,KAAK,IAAI,EAAE;QAC5D,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC;YACzB,KAAK,EAAE,CAAC;YACR,UAAU,EAAE,MAAM;YAClB,UAAU,EAAE,CAAC,CAAC,CAAC;YACf,iBAAiB,EAAE,MAAM;SAC1B,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC,CAAC;QACnE,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5B,MAAM,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5B,MAAM,kBAAkB,GAAmB,EAAE,CAAC;QAC9C,MAAM,kBAAkB,GAAmB,EAAE,CAAC;QAC9C,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE;YACtB,MAAM,EAAE,CAAC;YACT,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,EAAE;oBAChC,kBAAkB,CAAC,IAAI,CACnB,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,QAAQ,EAAkB,CAAC,CAAC;oBAChE,kBAAkB,CAAC,IAAI,CACnB,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,QAAQ,EAAkB,CAAC,CAAC;oBAChE,mEAAmE;oBACnE,uBAAuB;oBACvB,IAAI,KAAK,KAAK,CAAC,EAAE;wBACf,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,KAAK,CAAC;qBACnC;yBAAM,IAAI,KAAK,KAAK,CAAC,EAAE;wBACtB,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,IAAI,CAAC;qBAClC;oBACD,IAAI,KAAK,GAAG,CAAC,EAAE;wBACb,4DAA4D;wBAC5D,sCAAsC;wBACtC,2DAA2D;wBAC3D,MAAM,CAAC,QAAQ,CAAC,kBAAkB,CAAC,KAAK,CAAC,CAAC;6BAC9B,GAAG,CAAC,QAAQ,CAAC,kBAAkB,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC;6BAC5C,GAAG,EAAE;6BACL,GAAG,EAAE;6BACL,QAAQ,EAAE,CAAC,CAAC,CAAC,CAAC;6BACrB,eAAe,CAAC,CAAC,CAAC,CAAC;qBACzB;oBACD,mEAAmE;oBACnE,oDAAoD;oBACpD,sEAAsE;oBACtE,SAAS;oBACT,IAAI,KAAK,KAAK,CAAC,EAAE;wBACf,MAAM,CAAC,QAAQ,CAAC,kBAAkB,CAAC,KAAK,CAAC,CAAC;6BAC9B,GAAG,CAAC,QAAQ,CAAC,kBAAkB,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC;6BAC5C,GAAG,EAAE;6BACL,GAAG,EAAE;6BACL,QAAQ,EAAE,CAAC,CAAC,CAAC,CAAC;6BACrB,OAAO,CAAC,CAAC,CAAC,CAAC;qBACjB;yBAAM,IAAI,KAAK,GAAG,CAAC,EAAE;wBACpB,MAAM,CAAC,QAAQ,CAAC,kBAAkB,CAAC,KAAK,CAAC,CAAC;6BAC9B,GAAG,CAAC,QAAQ,CAAC,kBAAkB,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC;6BAC5C,GAAG,EAAE;6BACL,GAAG,EAAE;6BACL,QAAQ,EAAE,CAAC,CAAC,CAAC,CAAC;6BACrB,eAAe,CAAC,CAAC,CAAC,CAAC;qBACzB;gBACH,CAAC;aACF;SACF,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gBAAgB,EAAE,GAAG,EAAE;QACxB,kCAAkC,EAAE,CAAC;QACrC,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC;YACzB,SAAS,EAAE,KAAK;YAChB,IAAI,EAAE,yBAAyB;YAC/B,OAAO,EAAE,CAAC,KAAK,CAAC;SACjB,CAAC,CAAC,CAAC,YAAY,CAAC,oBAAoB,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gEAAgE,EAChE,KAAK,IAAI,EAAE;QACT,uBAAuB,CAAC,IAAI,CAAC,CAAC;QAE9B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACzE,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEnC,MAAM,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,EAAE,GAAG,IAAI,CAAC,CAAE,4CAA4C;QAC9D,MAAM,cAAc,GAAG,KAAK,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QACxD,MAAM,mBAAmB,GACrB,YAAY,CAAC,CAAC,GAAG,GAAG,CAAC,SAAS,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC;QAC9D,kBAAkB,CACd,cAAc,EAAE,QAAQ,CAAC,mBAAmB,EAAE,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACnE,MAAM,YAAY,GAAG,KAAK,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QACtD,MAAM,iBAAiB,GAAG,CAAC,GAAG,GAAG,CAAC,SAAS,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,CAAC;QAC3D,kBAAkB,CAAC,YAAY,EAAE,QAAQ,CAAC,iBAAiB,CAAC,CAAC,CAAC;IAChE,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,+DAA+D,EAC/D,KAAK,IAAI,EAAE;QACT,uBAAuB,EAAE,CAAC;QAE1B,sCAAsC;QACtC,MAAM,EAAE,GAAG,KAAK,CAAC;QACjB,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,IAAI,YAAY,CAAC,EAAE,CAAC,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QACjE,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACzE,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,eAAe,GAAG,KAAK,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QAEzD,MAAM,kBAAkB,GACpB,YAAY,CAAC,CAAC,GAAG,GAAG,CAAC,SAAS,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC;QAC9D,kBAAkB,CACd,eAAe,EAAE,QAAQ,CAAC,kBAAkB,EAAE,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACrE,CAAC,CAAC,CAAC;IAEN,yBAAyB;IACzB,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,kCAAkC;IAClC,kCAAkC;IAClC,yDAAyD;IACzD,sDAAsD;IACtD,kCAAkC;IAClC,yDAAyD;IACzD,sDAAsD;IACtD,kDAAkD;IAClD,EAAE;IACF,mEAAmE;IACnE,qEAAqE;IACrE,iCAAiC;IACjC,EAAE;IACF,uBAAuB;IACvB,yBAAyB;IACzB,yBAAyB;IACzB,gDAAgD;IAChD,yBAAyB;IACzB,MAAM;IACN,EAAE,CAAC,kCAAkC,EAAE,KAAK,IAAI,EAAE;QAChD,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC;aAClE,KAAK,CAAC,MAAM,CAAmB,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC;aAClE,KAAK,CAAC,MAAM,CAAmB,CAAC;QACzC,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,MAAM,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QACvE,MAAM,IAAI,GAAmC,EAAE,CAAC;QAChD,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,kBAAkB,CAAC;QAChD,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,mBAAmB,CAAC;QACjD,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAExC,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxB,MAAM,GAAG,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1B,MAAM,GAAG,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1B,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;IAC5E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;QACrE,qCAAqC,EAAE,CAAC;QAExC,MAAM,EAAE,GAAG,IAAI,CAAC;QAChB,cAAc,CAAC,OAAO,CAAC;YACrB,SAAS,EAAE,IAAI,YAAY,CAAC,EAAE,CAAC;YAC/B,IAAI,EAAE,CAAC,kBAAkB,EAAE,kBAAkB,CAAC;SAC/C,CAAC,CAAC;QACH,MAAM,gBAAgB,GAAG,cAAc,CAAC,gBAAgB,CAAC;QACzD,IAAI,gBAAgB,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QAClD,IAAI,gBAAgB,GAAG,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QAClD,MAAM,cAAc,CAAC,GAAG,CACpB,CAAC,OAAO,EAAE,OAAO,CAAC,EAAE,CAAC,QAAQ,EAAE,QAAQ,CAAC,EACxC,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAExC,MAAM,CAAC,cAAc,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC1D,gBAAgB,GAAG,cAAc,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QAC7D,gBAAgB,GAAG,cAAc,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;QAE7D,sCAAsC;QACtC,MAAM,mBAAmB,GACrB,YAAY,CAAC,CAAC,GAAG,GAAG,CAAC,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC;QAChE,kBAAkB,CACd,gBAAgB,EAAE,QAAQ,CAAC,mBAAmB,EAAE,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACtE,8DAA8D;QAC9D,WAAW;QACX,MAAM,mBAAmB,GACrB,YAAY,CAAC,CAAC,GAAG,GAAG,CAAC,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC;QAChE,kBAAkB,CACd,gBAAgB,EAAE,QAAQ,CAAC,mBAAmB,EAAE,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACxE,CAAC,CAAC,CAAC;IAEH,MAAM,oBAAoB,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;IAC3C,MAAM,qBAAqB,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;IAC5C,KAAK,MAAM,MAAM,IAAI,oBAAoB,EAAE;QACzC,KAAK,MAAM,OAAO,IAAI,qBAAqB,EAAE;YAC3C,MAAM,SAAS,GAAG,6CACd,MAAM,aAAa,OAAO,EAAE,CAAC;YACjC,EAAE,CAAC,SAAS,EAAE,KAAK,IAAI,EAAE;gBACvB,uBAAuB,EAAE,CAAC;gBAC1B,MAAM,cAAc,GAAW,EAAE,CAAC;gBAClC,MAAM,YAAY,GAAW,EAAE,CAAC;gBAChC,MAAM,gBAAgB,GAAa,EAAE,CAAC;gBACtC,MAAM,cAAc,GAAa,EAAE,CAAC;gBACpC,MAAM,iBAAiB,GAAa,EAAE,CAAC;gBACvC,MAAM,eAAe,GAAa,EAAE,CAAC;gBACrC,MAAM,cAAc,GAAa,EAAE,CAAC;gBACpC,MAAM,cAAc,GAAa,EAAE,CAAC;gBACpC,MAAM,kBAAkB,GAAuB;oBAC7C,YAAY,EAAE,KAAK,EAAE,IAAW,EAAE,EAAE;wBAClC,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;oBAC5B,CAAC;oBACD,UAAU,EAAE,KAAK,EAAE,IAAW,EAAE,EAAE;wBAChC,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;oBAC1B,CAAC;oBACD,YAAY,EAAE,KAAK,EAAE,KAAa,EAAE,IAAW,EAAE,EAAE;wBACjD,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC/B,CAAC;oBACD,UAAU,EAAE,KAAK,EAAE,KAAa,EAAE,IAAW,EAAE,EAAE;wBAC/C,cAAc,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;wBAC3B,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC;oBACpC,CAAC;oBACD,YAAY,EAAE,KAAK,EAAE,KAAa,EAAE,IAAW,EAAE,EAAE;wBACjD,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAChC,CAAC;oBACD,UAAU,EAAE,KAAK,EAAE,KAAa,EAAE,IAAW,EAAE,EAAE;wBAC/C,eAAe,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;wBAC5B,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC;oBACpC,CAAC;iBACF,CAAC;gBACF,MAAM,cAAc,GAAG,MAAM,CAAC,CAAC,CAAC,kBAAkB,CAAC,CAAC;oBACpB,IAAI,cAAc,CAAC,kBAAkB,CAAC,CAAC;gBACvE,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;gBAC5D,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;oBAC/B,SAAS,EAAE,CAAC;oBACZ,MAAM,EAAE,CAAC;oBACT,SAAS,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,cAAc;iBACvD,CAAC,CAAC;gBACH,MAAM,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;gBACzC,MAAM,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;gBACvC,MAAM,CAAC,gBAAgB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;gBACzC,MAAM,CAAC,cAAc,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;gBACvC,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;gBACtD,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;gBAEpD,mEAAmE;gBACnE,wEAAwE;gBACxE,4DAA4D;gBAC5D,MAAM,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;gBACzC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,cAAc,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;oBAC9C,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,cAAc,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;iBAC/D;gBACD,MAAM,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;gBACzC,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC;YAC5D,CAAC,CAAC,CAAC;SACJ;KACF;IAED,EAAE,CAAC,0BAA0B,EAAE,KAAK,IAAI,EAAE;QACxC,0EAA0E;QAC1E,EAAE;QACF,YAAY;QACZ,eAAe;QACf,qBAAqB;QACrB,EAAE;QACF,6BAA6B;QAC7B,0BAA0B;QAC1B,yEAAyE;QACzE,6DAA6D;QAC7D,MAAM;QACN,EAAE;QACF,uBAAuB;QACvB,uBAAuB;QACvB,EAAE;QACF,4DAA4D;QAC5D,EAAE;QACF,wCAAwC;QACxC,gCAAgC;QAChC,yBAAyB;QACzB,EAAE;QACF,MAAM;QACN,uBAAuB,CAAC,KAAK,EAAE,GAAG,CAAC,YAAY,CAAC,IAAI,CAAC,EAAC,EAAE,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC;QAEtE,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,yDAAyD;QACzD,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACzE,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,QAAQ,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,EAAE,CAAC,CAAC;QAChD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,KAAK,CAAC,CAAC;IACrD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0BAA0B,EAAE,KAAK,IAAI,EAAE;QACxC,0EAA0E;QAC1E,EAAE;QACF,YAAY;QACZ,eAAe;QACf,qBAAqB;QACrB,EAAE;QACF,6BAA6B;QAC7B,0BAA0B;QAC1B,yEAAyE;QACzE,qCAAqC;QACrC,MAAM;QACN,EAAE;QACF,uBAAuB;QACvB,uBAAuB;QACvB,EAAE;QACF,4DAA4D;QAC5D,EAAE;QACF,wCAAwC;QACxC,gCAAgC;QAChC,yBAAyB;QACzB,EAAE;QACF,MAAM;QACN,uBAAuB,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;QAEvC,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,yDAAyD;QACzD,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACzE,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,QAAQ,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,IAAI,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,IAAI,CAAC,CAAC;IACpD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qCAAqC,EAAE,KAAK,IAAI,EAAE;QACnD,uBAAuB,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;QACvC,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACrE,MAAM,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxB,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAChC,kBAAkB,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qCAAqC,EAAE,KAAK,IAAI,EAAE;QACnD,uBAAuB,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC;QACvC,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACrE,MAAM,CAAC,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1C,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAChC,kBAAkB,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;IAEH,MAAM,qBAAsB,SAAQ,GAAG,CAAC,cAAc;QACpD,YAAqB,cAAwB;YAC3C,KAAK,CAAC;gBACJ,YAAY,EAAE,KAAK,IAAI,EAAE;oBACvB,cAAc,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;gBACnC,CAAC;aACF,CAAC,CAAC;YALgB,mBAAc,GAAd,cAAc,CAAU;QAM7C,CAAC;KACF;IAED,EAAE,CAAC,uCAAuC,EAAE,KAAK,IAAI,EAAE;QACrD,uBAAuB,EAAE,CAAC;QAC1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;YAC/B,MAAM;YACN,SAAS;YACT,SAAS,EAAE,IAAI,qBAAqB,CAAC,cAAc,CAAC;SACrD,CAAC,CAAC;QACH,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACjD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC9C,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;QACvD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QACtD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;IACtD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,KAAK,IAAI,EAAE;QACtD,uBAAuB,EAAE,CAAC;QAC1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,eAAe,GAAG,GAAG,CAAC;QAC5B,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;YAC/B,MAAM;YACN,SAAS;YACT,eAAe;YACf,SAAS,EAAE,IAAI,qBAAqB,CAAC,cAAc,CAAC;SACrD,CAAC,CAAC;QACH,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACjD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC;aAC5B,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,eAAe,CAAC,CAAC,CAAC,CAAC;QAClE,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC9C,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;QACvD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QACrD,MAAM,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC,CAAC;IAClE,CAAC,CAAC,CAAC;IAEH,MAAM,gBAAiB,SAAQ,GAAG,CAAC,QAAQ;QAEzC,YAAY,aAAqB;YAC/B,KAAK,EAAE,CAAC;YACR,IAAI,CAAC,aAAa,GAAG,aAAa,CAAC;QACrC,CAAC;QAED,KAAK,CAAC,UAAU,CAAC,KAAa,EAAE,IAAqB;YACnD,IAAI,KAAK,KAAK,IAAI,CAAC,aAAa,GAAG,CAAC,EAAE;gBACpC,IAAI,CAAC,KAAK,CAAC,YAAY,GAAG,IAAI,CAAC;aAChC;QACH,CAAC;KACF;IAED,EAAE,CAAC,wDAAwD,EAAE,KAAK,IAAI,EAAE;QACtE,uBAAuB,CAAC,IAAI,CAAC,CAAC;QAC9B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,sEAAsE;QACtE,8BAA8B;QAC9B,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;YAC/C,SAAS,EAAE,UAAU;YACrB,MAAM,EAAE,EAAE;YACV,SAAS,EAAE,CAAC,IAAI,gBAAgB,CAAC,CAAC,CAAC,CAAC;SACrC,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACjD,CAAC,CAAC,CAAC;IAEH,MAAM,iBAAkB,SAAQ,GAAG,CAAC,QAAQ;QAE1C,YAAY,cAAsB;YAChC,KAAK,EAAE,CAAC;YACR,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;QACvC,CAAC;QAED,KAAK,CAAC,UAAU,CAAC,KAAa,EAAE,IAAW;YACzC,IAAI,KAAK,KAAK,IAAI,CAAC,cAAc,GAAG,CAAC,EAAE;gBACrC,IAAI,CAAC,KAAK,CAAC,YAAY,GAAG,IAAI,CAAC;aAChC;QACH,CAAC;KACF;IAED,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;QACrE,MAAM,eAAe,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QACzC,eAAe,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,UAAU,EAAE,CAAC,SAAS,CAAC,EAAC,CAAC,CAAC,CAAC;QACrE,mBAAmB;QACnB,MAAM,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACvC,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,eAAe,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QACtE,2EAA2E;QAC3E,wEAAwE;QACxE,wEAAwE;QACxE,QAAQ;QACR,MAAM,OAAO,GAAG,MAAM,eAAe,CAAC,GAAG,CACrC,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,CAAC,EAAE,MAAM,EAAE,EAAE,EAAE,SAAS,EAAE,CAAC,IAAI,iBAAiB,CAAC,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACjD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,iEAAiE,EACjE,KAAK,IAAI,EAAE;QACT,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAE5D,IAAI,aAAa,GAAG,CAAC,CAAC;QACtB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,IAAI,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;YAC7C,MAAM;YACN,SAAS,EAAE;gBACT,UAAU,EAAE,KAAK,EAAE,KAAa,EAAE,IAAqB,EAAE,EAAE;oBACzD,aAAa,EAAE,CAAC;oBAChB,IAAI,KAAK,KAAK,cAAc,EAAE;wBAC5B,KAAK,CAAC,YAAY,GAAG,IAAI,CAAC;qBAC3B;gBACH,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,CAAC,aAAa,CAAC,CAAC,OAAO,CAAC,cAAc,GAAG,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,cAAc,GAAG,CAAC,CAAC,CAAC;QAEhE,iEAAiE;QACjE,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACxD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACjD,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,oDAAoD,EAAE,KAAK,IAAI,EAAE;QAClE,MAAM,eAAe,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QACzC,eAAe,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,UAAU,EAAE,CAAC,SAAS,CAAC,EAAC,CAAC,CAAC,CAAC;QACrE,mBAAmB;QACnB,MAAM,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACvC,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,eAAe,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QACtE,2EAA2E;QAC3E,wEAAwE;QACxE,uEAAuE;QACvE,QAAQ;QACR,IAAI,OAAO,GAAG,MAAM,eAAe,CAAC,GAAG,CACnC,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,CAAC,EAAE,MAAM,EAAE,EAAE,EAAE,SAAS,EAAE,CAAC,IAAI,iBAAiB,CAAC,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAE/C,iDAAiD;QACjD,OAAO;YACH,MAAM,eAAe,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,CAAC,EAAE,MAAM,EAAE,EAAE,EAAC,CAAC,CAAC;QAC3E,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;IAClD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;QACrE,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QACpD,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GACT,GAAG,CAAC,MAAM;aACL,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,QAAQ,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnE,KAAK,CAAC,EAAE,CAAuB,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM;aACL,KAAK,CACF,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,SAAS,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACjE,KAAK,CAAC,EAAE,CAAuB,CAAC;QACzC,MAAM,KAAK,GACP,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QACvE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,CAAC,kBAAkB,EAAE,oBAAoB,CAAC,EAAE,SAAS,EAAE,MAAM,EAAC,CAAC,CAAC;QAE3E,MAAM,EAAE,GAAa,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,EAAE,GAAa,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAEpD,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,MAAM,cAAc,GAAG,KAAK,CAAC,OAAO,EAAE,CAAC;QACvC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,0EAA0E;QAC1E,4CAA4C;QAC5C,MAAM,2BAA2B,GAAG,CAAC,CAAC;QACtC,2EAA2E;QAC3E,gEAAgE;QAChE,MAAM,8BAA8B,GAAG,CAAC,CAAC;QACzC,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,CAAC,cAAc,CAAC,oBAAoB,CAAC;aACtC,OAAO,CACJ,eAAe,GAAG,2BAA2B;YAC7C,eAAe,GAAG,8BAA8B,CAAC,CAAC;QAC1D,MAAM,CAAC,cAAc,CAAC,oBAAoB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,WAAW,GAAG,WAAW,CAAC;aAC5B,OAAO,CACJ,eAAe,GAAG,2BAA2B;YAC7C,eAAe,GAAG,8BAA8B,CAAC,CAAC;IAC5D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;QACrE,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC;QACzD,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,MAAM,EAAC,CAAC,CAAC;QAE7D,MAAM,EAAE,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzB,MAAM,EAAE,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEzB,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,MAAM,cAAc,GAAG,KAAK,CAAC,OAAO,EAAE,CAAC;QACvC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,0EAA0E;QAC1E,4CAA4C;QAC5C,MAAM,2BAA2B,GAAG,CAAC,CAAC;QACtC,2EAA2E;QAC3E,gEAAgE;QAChE,MAAM,8BAA8B,GAAG,CAAC,CAAC;QACzC,MAAM,eAAe,GAAG,CAAC,CAAC;QAC1B,MAAM,CAAC,cAAc,CAAC,oBAAoB,CAAC;aACtC,OAAO,CACJ,eAAe,GAAG,2BAA2B;YAC7C,eAAe,GAAG,8BAA8B,CAAC,CAAC;QAC1D,MAAM,CAAC,cAAc,CAAC,oBAAoB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,WAAW,GAAG,WAAW,CAAC;aAC5B,OAAO,CACJ,eAAe,GAAG,2BAA2B;YAC7C,eAAe,GAAG,8BAA8B,CAAC,CAAC;IAC5D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;QACrE,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QACpD,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GACT,GAAG,CAAC,MAAM;aACL,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,QAAQ,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnE,KAAK,CAAC,EAAE,CAAuB,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM;aACL,KAAK,CACF,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,SAAS,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACjE,KAAK,CAAC,EAAE,CAAuB,CAAC;QACzC,MAAM,KAAK,GACP,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QACvE,MAAM,SAAS,GAAG,IAAI,GAAG,CAAC,aAAa,CAAC,IAAI,EAAE,GAAG,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,CAAC,kBAAkB,EAAE,oBAAoB,CAAC,EAAE,SAAS,EAAC,CAAC,CAAC;QAEnE,MAAM,EAAE,GAAa,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,EAAE,GAAa,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAEpD,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,MAAM,cAAc,GAAG,KAAK,CAAC,OAAO,EAAE,CAAC;QACvC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,0EAA0E;QAC1E,iBAAiB;QACjB,MAAM,CAAC,cAAc,CAAC,oBAAoB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,cAAc,CAAC,oBAAoB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,WAAW,GAAG,WAAW,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uDAAuD,EAAE,KAAK,IAAI,EAAE;QACrE,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC;QACzD,MAAM,SAAS,GAAG,IAAI,GAAG,CAAC,aAAa,CAAC,IAAI,EAAE,GAAG,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;QAChE,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAC,CAAC,CAAC;QAErD,MAAM,EAAE,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzB,MAAM,EAAE,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEzB,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACrC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,MAAM,cAAc,GAAG,KAAK,CAAC,OAAO,EAAE,CAAC;QACvC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,0DAA0D;QAC1D,MAAM,CAAC,cAAc,CAAC,oBAAoB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,cAAc,CAAC,oBAAoB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,WAAW,GAAG,WAAW,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,uBAAuB,EAAE,CAAC;QAC1B,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC;YACzB,SAAS,EAAE,KAAK;YAChB,IAAI,EAAE,EAAC,KAAK,EAAE,kBAAkB,EAAC;SAClC,CAAC,CAAC,CAAC,YAAY,CAAC,0CAA0C,CAAC,CAAC;IAC/D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gDAAgD,EAAE,GAAG,EAAE;QACxD,qCAAqC,EAAE,CAAC;QACxC,MAAM,CAAC,GAAG,EAAE,CAAC,cAAc,CAAC,OAAO,CAAC;YAClC,SAAS,EAAE,KAAK;YAChB,IAAI,EAAE,CAAC,kBAAkB,CAAC;SAC3B,CAAC,CAAC,CAAC,YAAY,CAAC,sDAAsD,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,uBAAuB,CAAC,IAAI,CAAC,CAAC;QAC9B,MAAM,UAAU,GACZ,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACnE,UAAU,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE;YACvB,MAAM,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC,SAAS,CAAC,iCAAiC,CAAC,CAAC;QACrE,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kCAAkC,EAAE,KAAK,IAAI,EAAE;QAChD,uBAAuB,EAAE,CAAC;QAC1B,MAAM,kBAAkB,GAAyB,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,GAAG,CAAC,CAAC;QACpE,KAAK,MAAM,SAAS,IAAI,kBAAkB,EAAE;YAC1C,IAAI,WAAkB,CAAC;YACvB,IAAI;gBACF,kCAAkC;gBAClC,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,SAAgB,EAAC,CAAC,CAAC;aACjE;YAAC,OAAO,GAAG,EAAE;gBACZ,WAAW,GAAG,GAAG,CAAC;aACnB;YACD,MAAM,CAAC,WAAW,CAAC,OAAO,CAAC;iBACtB,OAAO,CAAC,2DACL,SAAS,EAAE,CAAC,CAAC;SACtB;IACH,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,gDAAgD,EAAE,GAAG,EAAE;IAC3E,EAAE,CAAC,kDAAkD,EAAE,KAAK,IAAI,EAAE;QAChE,MAAM,WAAW,GACb,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;QAC1E,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC;QAC5C,MAAM,MAAM,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,GAAG,EAAC,CAAC,CAAC;QAE/C,uEAAuE;QACvE,yCAAyC;QACzC,MAAM,yBAAyB,GAAc,EAAE,CAAC;QAChD,MAAM,4BAA4B,GAC9B,CAAC,MAAuB,EAAE,MAAc,EAAE,EAAE;YAC1C,yBAAyB,CAAC,IAAI,CAAC,MAAM,CAAC,QAAmB,CAAC,CAAC;QAC7D,CAAC,CAAC;QACN,MAAM,CAAC,WAAW,CAAC,4BAA4B,CAAC,CAAC;QAEjD,MAAM,MAAM,GACR,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,CAAuB,CAAC;QAClE,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAC,CAAC,CAAC;QACpE,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxB,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExB,sEAAsE;QACtE,QAAQ;QACR,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,CAAC,EAAE,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;QACnD,MAAM,CAAC,yBAAyB,CAAC,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC;QAExD,iEAAiE;QACjE,oBAAoB;QACpB,KAAK,CAAC,QAAQ,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,CAAC,yBAAyB,CAAC,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,IAAI,EAAE,SAAS,CAAC,CAAC,CAAC;QAEnE,yEAAyE;QACzE,aAAa;QACb,KAAK,CAAC,OAAO,CAAC,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;QAClC,MAAM,CAAC,yBAAyB,CAAC,CAAC,OAAO,CAAC;YACxC,IAAI,EAAE,IAAI,EAAE,SAAS,EAAE,SAAS;SACjC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CACjB,8DAA8D,EAAE,GAAG,EAAE;IACnE,MAAM,SAAS,GAAG,CAAC,CAAC,CAAE,8CAA8C;IAEpE,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,SAAS,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;IACjE,IAAI,KAAsB,CAAC;IAC3B,IAAI,MAAc,CAAC;IACnB,IAAI,OAAe,CAAC;IAEpB,SAAS,uBAAuB,CAC5B,UAAkB,EAClB,iBAAsC,EACtC,eAAoC;QAEtC,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAC1B,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,iBAAiB,EAAC,CAAC,CAAC;QAC9D,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAC,CAAC,CAAC;QACxE,MAAM,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACvC,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;IAClC,CAAC;IAED,EAAE,CAAC,uBAAuB,EAAE,GAAG,EAAE;QAC/B,MAAM,WAAW,GAAG,CAAC,CAAC;QACtB,MAAM,SAAS,GAAG,EAAE,CAAC,CAAE,+CAA+C;QACtE,uBAAuB,CAAC,WAAW,CAAC,CAAC;QACrC,gBAAgB;QAChB,IAAI,GAAG,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,EAAC,SAAS,EAAC,CAAW,CAAC;QACvD,GAAG,CAAC,OAAO,EAAE,CAAC;QACd,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,eAAe;QACf,GAAG,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,EAAC,SAAS,EAAC,CAAW,CAAC;QACnD,GAAG,CAAC,OAAO,EAAE,CAAC;QACd,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,sBAAsB,EAAE,GAAG,EAAE;QAC9B,MAAM,WAAW,GAAG,CAAC,CAAC;QACtB,MAAM,SAAS,GAAG,CAAC,CAAC,CAAE,gDAAgD;QACtE,uBAAuB,CAAC,WAAW,CAAC,CAAC;QACrC,gBAAgB;QAChB,IAAI,GAAG,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,EAAC,SAAS,EAAC,CAAW,CAAC;QACvD,GAAG,CAAC,OAAO,EAAE,CAAC;QACd,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,eAAe;QACf,GAAG,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,EAAC,SAAS,EAAC,CAAW,CAAC;QACnD,GAAG,CAAC,OAAO,EAAE,CAAC;QACd,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;QAC3C,MAAM,WAAW,GAAG,CAAC,CAAC;QACtB,uBAAuB,CAAC,WAAW,CAAC,CAAC;QACrC,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,SAAS,GAAG,EAAE,CAAC,CAAE,+CAA+C;QACtE,gBAAgB;QAChB,IAAI,GAAG,GAAG,KAAK,CAAC,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAC,CAAW,CAAC;QACjE,GAAG,CAAC,OAAO,EAAE,CAAC;QACd,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,eAAe;QACf,GAAG,GAAG,KAAK,CAAC,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAC,CAAW,CAAC;QAC7D,GAAG,CAAC,OAAO,EAAE,CAAC;QACd,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kCAAkC,EAAE,GAAG,EAAE;QAC1C,MAAM,WAAW,GAAG,CAAC,CAAC;QACtB,uBAAuB,CAAC,WAAW,CAAC,CAAC;QACrC,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,SAAS,GAAG,CAAC,CAAC,CAAE,gDAAgD;QACtE,gBAAgB;QAChB,IAAI,GAAG,GAAG,KAAK,CAAC,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAC,CAAW,CAAC;QACjE,GAAG,CAAC,OAAO,EAAE,CAAC;QACd,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,eAAe;QACf,GAAG,GAAG,KAAK,CAAC,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAC,CAAW,CAAC;QAC7D,GAAG,CAAC,OAAO,EAAE,CAAC;QACd,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,oCAAoC,EAAE,GAAG,EAAE;QAC5C,MAAM,WAAW,GAAG,CAAC,CAAC;QACtB,uBAAuB,CAAC,WAAW,CAAC,CAAC;QACrC,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QACpE,MAAM,SAAS,GAAG,CAAC,CAAC,CAAE,gDAAgD;QACtE,gBAAgB;QAChB,IAAI,GAAG,GAAG,KAAK,CAAC,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAC,CAAa,CAAC;QACnE,GAAG,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC,CAAC;QACxC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,eAAe;QACf,GAAG,GAAG,KAAK,CAAC,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAC,CAAa,CAAC;QAC/D,GAAG,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC,CAAC;QACxC,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEP,qBAAqB,CAAC,iCAAiC,EAAE,GAAG,EAAE;IAC5D,MAAM,SAAS,GAAG,CAAC,CAAC,CAAG,8CAA8C;IACrE,MAAM,UAAU,GAAG,CAAC,CAAC,CAAE,gCAAgC;IAEvD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAChC,EAAC,KAAK,EAAE,CAAC,SAAS,CAAC,EAAE,IAAI,EAAE,aAAa,EAAE,KAAK,EAAE,SAAS,EAAC,CAAC,CAAC;IACjE,IAAI,KAAsB,CAAC;IAC3B,IAAI,MAAc,CAAC;IACnB,IAAI,OAAe,CAAC;IACpB,IAAI,SAAiB,CAAC;IACtB,IAAI,UAAkB,CAAC;IAEvB,SAAS,uBAAuB,CAC5B,OAAO,GAAG,KAAK,EACf,iBAAsC,EACtC,eAAoC;QAEtC,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAC1B,EAAC,KAAK,EAAE,CAAC,EAAE,OAAO,EAAE,iBAAiB,EAAE,MAAM,EAAE,iBAAiB,EAAC,CAAC,CAAC;QACvE,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,WAAW,CAAuB,CAAC;QAC9D,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,CAAC,WAAW,CAAC,EAAE,OAAO,EAAE,CAAC,MAAM,CAAC,EAAC,CAAC,CAAC;QACxE,MAAM,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACvC,OAAO,GAAG,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,SAAS,GAAG,KAAK,CAAC,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QAC3C,UAAU,GAAG,KAAK,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;IACtC,CAAC;IAED,EAAE,CAAC,sEAAsE,EACtE,KAAK,EAAE,IAAI,EAAE,EAAE;QACb,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,yDAAyD;QACzD,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACrE,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;YACrE,MAAM,aAAa,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YAC1C,IAAI,aAAa,GAAG,WAAW,EAAE;gBAC/B,IAAI,CAAC,IAAI,CACL,4CAA4C;oBAC5C,GAAG,aAAa,GAAG,WAAW,uBAAuB;oBACrD,GAAG,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;aAChC;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,2DAA2D;QACvD,0BAA0B,EAC9B,KAAK,EAAC,IAAI,EAAC,EAAE;QACX,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,MAAM,SAAS,GAAG,CAAC,CAAC,CAAE,qBAAqB;QAC3C,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACzD,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;YACzD,MAAM,aAAa,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YAC1C,IAAI,aAAa,GAAG,WAAW,EAAE;gBAC/B,IAAI,CAAC,IAAI,CACL,4CAA4C;oBAC5C,GAAG,aAAa,GAAG,WAAW,uBAAuB;oBACrD,GAAG,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;aAChC;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,0DAA0D,EAAE,KAAK,EAAC,IAAI,EAAC,EAAE;QAC1E,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QACpE,yDAAyD;QACzD,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACrE,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;YACrE,MAAM,aAAa,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YAC1C,IAAI,aAAa,GAAG,WAAW,EAAE;gBAC/B,IAAI,CAAC,IAAI,CACL,4CAA4C;oBAC5C,GAAG,aAAa,GAAG,WAAW,uBAAuB;oBACrD,GAAG,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;aAChC;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,6DAA6D,EAC7D,KAAK,EAAC,IAAI,EAAC,EAAE;QACX,uBAAuB,EAAE,CAAC;QAE1B,MAAM,eAAe,GAAG,GAAG,CAAC;QAC5B,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,yDAAyD;QACzD,MAAM,KAAK,CAAC,GAAG,CACX,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAC,CAAC,CAAC;QACzD,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,KAAK,CAAC,GAAG,CACX,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAC,CAAC,CAAC;YACzD,MAAM,aAAa,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YAC1C,IAAI,aAAa,GAAG,WAAW,EAAE;gBAC/B,IAAI,CAAC,IAAI,CACL,4CAA4C;oBAC5C,GAAG,aAAa,GAAG,WAAW,uBAAuB;oBACrD,GAAG,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;aAChC;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,4DAA4D,EAC5D,KAAK,EAAC,IAAI,EAAC,EAAE;QACX,uBAAuB,EAAE,CAAC;QAE1B,MAAM,cAAc,GAAqB,CAAC,SAAS,EAAE,UAAU,CAAC,CAAC;QACjE,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAC,CAAC,CAAC;QAC5D,yDAAyD;QACzD,MAAM,KAAK,CAAC,GAAG,CACX,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,cAAc,EAAC,CAAC,CAAC;QACzE,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,KAAK,CAAC,GAAG,CACX,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,cAAc,EAAC,CAAC,CAAC;YACxD,MAAM,aAAa,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YAC1C,IAAI,aAAa,GAAG,WAAW,EAAE;gBAC/B,IAAI,CAAC,IAAI,CACL,4CAA4C;oBAC5C,GAAG,aAAa,GAAG,WAAW,uBAAuB;oBACrD,GAAG,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;aAChC;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,uEAAuE,EACvE,KAAK,EAAC,IAAI,EAAC,EAAE;QACX,uBAAuB,EAAE,CAAC;QAE1B,MAAM,eAAe,GAAG,GAAG,CAAC;QAC5B,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QACpE,yDAAyD;QACzD,MAAM,KAAK,CAAC,GAAG,CACX,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAC,CAAC,CAAC;QACzD,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,KAAK,CAAC,GAAG,CACX,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAC,CAAC,CAAC;YACzD,MAAM,aAAa,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YAC1C,IAAI,aAAa,GAAG,WAAW,EAAE;gBAC/B,IAAI,CAAC,IAAI,CACL,4CAA4C;oBAC5C,GAAG,aAAa,GAAG,WAAW,uBAAuB;oBACrD,GAAG,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;aAChC;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,2DAA2D;QACvD,2BAA2B,EAC/B,KAAK,EAAC,IAAI,EAAC,EAAE;QACX,uBAAuB,EAAE,CAAC;QAE1B,MAAM,eAAe,GAAG,GAAG,CAAC;QAC5B,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QACpE,MAAM,SAAS,GAAG,CAAC,CAAC,CAAE,8BAA8B;QACpD,MAAM,aAAa,GAAG,CAAC,CAAC;QACxB,MAAM,KAAK,CAAC,GAAG,CACX,MAAM,EAAE,OAAO,EAAE,EAAC,SAAS,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAC,CAAC,CAAC;QAC9D,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,MAAM,EAAE,aAAa,EAAE,eAAe,EAAC,CAAC,CAAC;YACzD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;YAC9D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;YAClE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;YAC7D,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;YACjE,MAAM,aAAa,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YAC1C,IAAI,aAAa,GAAG,WAAW,EAAE;gBAC/B,IAAI,CAAC,IAAI,CACL,4CAA4C;oBAC5C,GAAG,aAAa,GAAG,WAAW,uBAAuB;oBACrD,GAAG,CAAC,GAAG,CAAC,iBAAiB,CAAC,CAAC;aAChC;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,oEAAoE,EACpE,KAAK,EAAC,IAAI,EAAC,EAAE;QACX,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QACpE,MAAM,eAAe,GAAG,GAAG,CAAC;QAE5B,iCAAiC;QACjC,MAAM,KAAK,CAAC,GAAG,CACX,MAAM,EAAE,OAAO,EACf,EAAC,SAAS,EAAE,UAAU,EAAE,MAAM,EAAE,CAAC,EAAE,eAAe,EAAC,CAAC,CAAC;QACzD,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,gCAAgC;QAChC,MAAM,WAAW,GAAG,CAAC,CAAC;QACtB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,EAAE,EAAE,CAAC,EAAE;YACpC,MAAM,YAAY,GAAa,EAAE,CAAC;YAClC,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;gBAC/B,SAAS,EAAE,UAAU;gBACrB,MAAM,EAAE,CAAC;gBACT,eAAe;gBACf,SAAS,EAAE;oBACT,UAAU,EAAE,KAAK,IAAI,EAAE;wBACrB,YAAY,CAAC,IAAI,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC;oBACzC,CAAC;iBACF;aACF,CAAC,CAAC;YACH,MAAM,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;YACvC,IAAI,MAAM,CAAC,YAAY,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;gBACrC,IAAI,CAAC,IAAI,CACL,oDAAoD;oBACpD,uCAAuC,YAAY,GAAG,CAAC,CAAC;aAC7D;YACD,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YACxC,IAAI,WAAW,GAAG,WAAW,EAAE;gBAC7B,IAAI,CAAC,IAAI,CACL,2BAA2B,WAAW,GAAG,WAAW,GAAG;oBACvD,8BAA8B,CAAC,GAAG,CAAC,OAAO,WAAW,GAAG;oBACxD,2BAA2B,CAAC,CAAC;aAClC;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,oEAAoE,EACpE,KAAK,EAAC,IAAI,EAAC,EAAE;QACX,uBAAuB,EAAE,CAAC;QAE1B,KAAK,CAAC,OAAO,CACT,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QACpE,MAAM,eAAe,GAAG,GAAG,CAAC;QAC5B,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,eAAe,GAAG,UAAU,GAAG,CAAC,CAAC,GAAG,eAAe,CAAC,CAAC;QAE3D,iCAAiC;QACjC,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;YAC/B,SAAS,EAAE,CAAC;YACZ,MAAM;YACN,eAAe;SAChB,CAAC,CAAC;QACH,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QAExC,gCAAgC;QAChC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,YAAY,GAAa,EAAE,CAAC;YAClC,MAAM,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,EAAE;gBAC/B,SAAS,EAAE,CAAC;gBACZ,MAAM;gBACN,eAAe;gBACf,SAAS,EAAE;oBACT,UAAU,EAAE,KAAK,EAAE,KAAa,EAAE,IAAU,EAAE,EAAE;wBAC9C,YAAY,CAAC,IAAI,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC;oBACzC,CAAC;iBACF;aACF,CAAC,CAAC;YACH,KAAK,IAAI,UAAU,GAAG,CAAC,EAAE,UAAU,GAAG,MAAM,EAAE,EAAE,UAAU,EAAE;gBAC1D,8DAA8D;gBAC9D,8DAA8D;gBAC9D,6DAA6D;gBAC7D,8DAA8D;gBAC9D,mEAAmE;gBACnE,6DAA6D;gBAC7D,8DAA8D;gBAC9D,kDAAkD;gBAClD,MAAM,UAAU,GAAG,eAAe,GAAG,UAAU,CAAC;gBAChD,MAAM,QAAQ,GAAG,eAAe,GAAG,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC;gBACpD,MAAM,mBAAmB,GACrB,YAAY,CAAC,KAAK,CAAC,UAAU,EAAE,QAAQ,GAAG,CAAC,CAAC,CAAC;gBACjD,IAAI,MAAM,CAAC,mBAAmB,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;oBAC5C,IAAI,CAAC,IAAI,CACL,2CAA2C,UAAU,GAAG,CAAC,GAAG;wBAC5D,MAAM,MAAM,0BAA0B;wBACtC,uCAAuC,mBAAmB,GAAG,CAAC,CAAC;iBACpE;aACF;YACD,MAAM,CAAC,YAAY,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,eAAe,GAAG,MAAM,CAAC,CAAC;YAC9D,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;YACxC,IAAI,WAAW,GAAG,WAAW,EAAE;gBAC7B,IAAI,CAAC,IAAI,CACL,2BAA2B,WAAW,GAAG,WAAW,GAAG;oBACvD,2CAA2C,CAAC,CAAC;aAClD;SACF;QACD,IAAI,EAAE,CAAC;IACT,CAAC,CAAC,CAAC;AACR,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,6BAA6B,EAAE,GAAG,EAAE;IAClD,SAAS,gBAAgB,CAAC,SAAiB;QACzC,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,MAAM,SAAS,GAAG,EAAE,CAAC;QACrB,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,SAAS,EAAE,UAAU,EAAE,CAAC,SAAS,CAAC,EAAE,UAAU,EAAE,MAAM,EAAC,CAAC,CAAC,CAAC;QACtE,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC;QACxC,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAC5D,OAAO,KAAK,CAAC;IACf,CAAC;IAED,EAAE,CAAC,mCAAmC,EAAE,KAAK,IAAI,EAAE;QACjD,MAAM,IAAI,GAAG,sBAAsB,CAAC;QACpC,MAAM,gBAAgB,GAAG;YACvB,CAAC;YACD,CAAC;YACD,IAAI,GAAG,CAAC;YACR,IAAI,GAAG,CAAC;YACR,CAAC;YACD,CAAC;SACF,CAAC;QACF,IAAI,OAAO,GAAG,CAAC,CAAC;QAChB,IAAI,QAAQ,GAAG,CAAC,CAAC;QACjB,KAAK,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,EAAE;YACnC,QAAQ,IAAI,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC;YACxC,OAAO,QAAQ,CAAC;QAClB,CAAC,CAAC,CAAC;QACH,IAAI,kBAAkB,GAAG,CAAC,CAAC;QAC3B,KAAK,CAAC,GAAG,EAAE,WAAW,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,IAAI,EAAE;YAC9C,kBAAkB,EAAE,CAAC;QACvB,CAAC,CAAC,CAAC;QAEH,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,WAAW,GAAG,EAAE,CAAC;QACvB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,GAAG,gBAAgB,CAAC,SAAS,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE;YACtC,MAAM;YACN,SAAS,EAAE,WAAW;YACtB,SAAS,EAAE;gBACT,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE;oBACrC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC9B,eAAe,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAC9B,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,yEAAyE;QACzE,uDAAuD;QACvD,MAAM,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qCAAqC,EAAE,KAAK,IAAI,EAAE;QACnD,MAAM,UAAU,GAAG,sBAAsB,CAAC;QAC1C,MAAM,gBAAgB,GAAG;YACvB,CAAC;YACD,CAAC;YACD,UAAU,GAAG,CAAC;YACd,UAAU,GAAG,CAAC;YACd,CAAC;YACD,UAAU,GAAG,CAAC;YACd,UAAU,GAAG,CAAC;YACd,CAAC;YACD,CAAC;SACF,CAAC;QACF,IAAI,OAAO,GAAG,CAAC,CAAC;QAChB,IAAI,QAAQ,GAAG,CAAC,CAAC;QACjB,KAAK,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,EAAE;YACnC,QAAQ,IAAI,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC;YACxC,OAAO,QAAQ,CAAC;QAClB,CAAC,CAAC,CAAC;QACH,IAAI,kBAAkB,GAAG,CAAC,CAAC;QAC3B,KAAK,CAAC,GAAG,EAAE,WAAW,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,IAAI,EAAE;YAC9C,kBAAkB,EAAE,CAAC;QACvB,CAAC,CAAC,CAAC;QAEH,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,WAAW,GAAG,EAAE,CAAC;QACvB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,GAAG,gBAAgB,CAAC,SAAS,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE;YACtC,MAAM;YACN,SAAS,EAAE,WAAW,GAAG,CAAC;YAC1B,SAAS,EAAE;gBACT,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE;oBACrC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC9B,eAAe,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAC9B,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,qEAAqE;QACrE,2EAA2E;QAC3E,6CAA6C;QAC7C,MAAM,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAClD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,KAAK,IAAI,EAAE;QAC1D,MAAM,UAAU,GAAG,CAAC,CAAC;QACrB,MAAM,gBAAgB,GAAG;YACvB,CAAC,EAAE,CAAC;YACJ,UAAU,GAAG,CAAC;YACd,CAAC,EAAE,UAAU,GAAG,CAAC;YACjB,UAAU,GAAG,CAAC;SACf,CAAC;QACF,IAAI,OAAO,GAAG,CAAC,CAAC;QAChB,IAAI,QAAQ,GAAG,CAAC,CAAC;QACjB,KAAK,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,EAAE;YACnC,QAAQ,IAAI,gBAAgB,CAAC,OAAO,EAAE,CAAC,CAAC;YACxC,OAAO,QAAQ,CAAC;QAClB,CAAC,CAAC,CAAC;QACH,IAAI,kBAAkB,GAAG,CAAC,CAAC;QAC3B,KAAK,CAAC,GAAG,EAAE,WAAW,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,IAAI,EAAE;YAC9C,kBAAkB,EAAE,CAAC;QACvB,CAAC,CAAC,CAAC;QAEH,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,WAAW,GAAG,EAAE,CAAC;QACvB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,GAAG,gBAAgB,CAAC,SAAS,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,eAAe,GAAa,EAAE,CAAC;QACrC,MAAM,iBAAiB,GAAa,EAAE,CAAC;QACvC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE;YACtC,MAAM;YACN,SAAS,EAAE,WAAW;YACtB,UAAU;YACV,SAAS,EAAE;gBACT,OAAO,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,EAAE;oBACrC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;oBAC9B,eAAe,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;gBAC9B,CAAC;aACF;SACF,CAAC,CAAC;QACH,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,yEAAyE;QACzE,4DAA4D;QAC5D,MAAM,CAAC,kBAAkB,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,CAAC,iBAAiB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yDAAyD,EAAE,KAAK,EAAC,IAAI,EAAC,EAAE;QACzE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,WAAW,GAAG,EAAE,CAAC;QACvB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,GAAG,gBAAgB,CAAC,SAAS,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,IAAI;YACF,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE;gBACtB,MAAM;gBACN,SAAS,EAAE,WAAW;gBACtB,UAAU,EAAE,OAAO;gBACnB,SAAS,EAAE,EAAC,OAAO,EAAE,KAAK,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,EAAE,GAAE,CAAC,EAAC;aAC1D,CAAC,CAAC;YACH,IAAI,CAAC,IAAI,CAAC,uBAAuB,CAAC,CAAC;SACpC;QAAC,WAAM;YACN,IAAI,EAAE,CAAC;SACR;IACH,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,6CAA6C,EAAE,KAAK,IAAI,EAAE;QAC3D,MAAM,qBAAqB,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC;QAClD,IAAI,OAAO,GAAG,CAAC,CAAC;QAChB,KAAK,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,EAAE,CAAC,qBAAqB,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC;QACxE,IAAI,kBAAkB,GAAG,CAAC,CAAC;QAC3B,KAAK,CAAC,GAAG,EAAE,WAAW,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,IAAI,EAAE;YAC9C,kBAAkB,EAAE,CAAC;QACvB,CAAC,CAAC,CAAC;QAEH,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,WAAW,GAAG,EAAE,CAAC;QACvB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,GAAG,gBAAgB,CAAC,SAAS,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,OAAO,GACT,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,SAAS,EAAE,CAAC,EAAE,UAAU,EAAE,OAAO,EAAC,CAAC,CAAC;QACzE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,8CAA8C;QAC9C,MAAM,CAAC,kBAAkB,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC;IACjE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uCAAuC,EAAE,KAAK,IAAI,EAAE;QACrD,IAAI,kBAAkB,GAAG,CAAC,CAAC;QAC3B,KAAK,CAAC,GAAG,EAAE,WAAW,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,IAAI,EAAE;YAC9C,kBAAkB,EAAE,CAAC;QACvB,CAAC,CAAC,CAAC;QAEH,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,WAAW,GAAG,EAAE,CAAC;QACvB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,GAAG,gBAAgB,CAAC,SAAS,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,SAAS,EAAE,WAAW,GAAG,EAAE,EAAE,UAAU,EAAE,OAAO,EAAC,CAAC,CAAC;QACxE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,MAAM,CAAC,kBAAkB,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;IAC7C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uCAAuC,EAAE,KAAK,IAAI,EAAE;QACrD,IAAI,kBAAkB,GAAG,CAAC,CAAC;QAC3B,KAAK,CAAC,GAAG,EAAE,WAAW,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,IAAI,EAAE;YAC9C,kBAAkB,EAAE,CAAC;QACvB,CAAC,CAAC,CAAC;QAEH,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,WAAW,GAAG,EAAE,CAAC;QACvB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,GAAG,gBAAgB,CAAC,SAAS,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAC3B,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,SAAS,EAAE,WAAW,GAAG,CAAC,EAAE,UAAU,EAAE,OAAO,EAAC,CAAC,CAAC;QACvE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QACpD,uEAAuE;QACvE,YAAY;QACZ,MAAM,CAAC,kBAAkB,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0DAA0D,EAAE,KAAK,IAAI,EAAE;QACxE,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,WAAW,GAAG,EAAE,CAAC;QACvB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC;QACjB,MAAM,KAAK,GAAG,gBAAgB,CAAC,SAAS,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1C,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,CAAC,CAAC,CAAC,CAAC;QAElC,MAAM,GAAG,GAAG,KAAK,CAAC,IAAI,EAAE,sBAAsB,CAAC,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC;QAClE,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,SAAS,EAAE,UAAU,EAAE,OAAO,EAAC,CAAC,CAAC;QAClE,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,gBAAgB,EAAE,CAAC;IACrC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,0BAA0B,EAAE,GAAG,EAAE;IACrD,+BAA+B;IAC/B,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,6BAA6B;IAC7B,gCAAgC;IAChC,uDAAuD;IACvD,4DAA4D;IAC5D,EAAE;IACF,iBAAiB;IACjB,gCAAgC;IAChC,gCAAgC;IAChC,EAAE;IACF,qBAAqB;IACrB,wCAAwC;IACxC,gBAAgB;IAChB,MAAM;IACN,EAAE,CAAC,6BAA6B,EAAE,KAAK,IAAI,EAAE;QAC3C,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;QAC9D,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,IAAI,IAAI,GAAG,MAAM,KAAK,CAAC,YAAY,CAAC,EAAE,EAAE,EAAE,CAAW,CAAC;QACtD,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAC9B,IAAI,GAAG,MAAM,KAAK,CAAC,YAAY,CAAC,EAAE,EAAE,EAAE,CAAW,CAAC;QAClD,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;QACjC,IAAI,GAAG,MAAM,KAAK,CAAC,YAAY,CAAC,EAAE,EAAE,EAAE,CAAW,CAAC;QAClD,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;IACrC,CAAC,CAAC,CAAC;IAEH,+BAA+B;IAC/B,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,kCAAkC;IAClC,kCAAkC;IAClC,4CAA4C;IAC5C,oDAAoD;IACpD,gCAAgC;IAChC,eAAe;IACf,2BAA2B;IAC3B,sCAAsC;IACtC,gCAAgC;IAChC,eAAe;IACf,4BAA4B;IAC5B,sCAAsC;IACtC,2EAA2E;IAC3E,oEAAoE;IACpE,iCAAiC;IACjC,EAAE;IACF,iBAAiB;IACjB,iCAAiC;IACjC,iCAAiC;IACjC,iCAAiC;IACjC,iCAAiC;IACjC,EAAE;IACF,qBAAqB;IACrB,0DAA0D;IAC1D,kBAAkB;IAClB,MAAM;IACN,EAAE,CAAC,oDAAoD,EAAE,KAAK,IAAI,EAAE;QAClE,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QACpD,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,WAAW,EAAE,CAAC,KAAK,CAAC,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;QAC5D,MAAM,OAAO,GACT,GAAG,CAAC,MAAM;aACL,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,QAAQ,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACnE,KAAK,CAAC,EAAE,CAAuB,CAAC;QACzC,MAAM,OAAO,GACT,GAAG,CAAC,MAAM;aACL,KAAK,CACF,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,SAAS,EAAE,iBAAiB,EAAE,OAAO,EAAC,CAAC;aACjE,KAAK,CAAC,EAAE,CAAuB,CAAC;QACzC,MAAM,KAAK,GACP,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,CAAC,OAAO,EAAE,OAAO,CAAC,EAAC,CAAC,CAAC;QACvE,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,CAAC,kBAAkB,EAAE,oBAAoB,CAAC,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE1E,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,IAAI,MAAM,GAAG,MAAM,KAAK,CAAC,YAAY,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAa,CAAC;QAC1E,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QACnC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;QACzC,MAAM,GAAG,MAAM,KAAK,CAAC,YAAY,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAa,CAAC;QACtE,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;QACtC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,UAAU,CAAC,CAAC;QAC1C,MAAM,GAAG,MAAM,KAAK,CAAC,YAAY,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAa,CAAC;QACtE,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,UAAU,CAAC,CAAC;QAC1C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,UAAU,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEH,+BAA+B;IAC/B,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,6BAA6B;IAC7B,gCAAgC;IAChC,4EAA4E;IAC5E,kEAAkE;IAClE,EAAE;IACF,gEAAgE;IAChE,qEAAqE;IACrE,EAAE;IACF,qBAAqB;IACrB,wCAAwC;IACxC,gBAAgB;IAChB,MAAM;IACN,EAAE,CAAC,6CAA6C,EAAE,KAAK,IAAI,EAAE;QAC3D,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC;YACzB,KAAK,EAAE,CAAC;YACR,UAAU,EAAE,CAAC,CAAC,CAAC;YACf,UAAU,EAAE,SAAS;YACrB,iBAAiB,EAAE,MAAM;SAC1B,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,yBAAyB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAEnE,MAAM,EAAE,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,EAAE,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3D,mBAAmB;QACnB,KAAK,CAAC,YAAY,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC;QAC3B,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,YAAY,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC;YAC9C,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE;gBACZ,IAAI,CAAC,KAAK,CAAC,EAAE;oBACX,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;iBACrC;qBAAM,IAAI,CAAC,KAAK,CAAC,EAAE;oBAClB,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;iBACrC;qBAAM;oBACL,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;iBACrC;YACH,CAAC,CAAC,CAAC;YACH,gCAAgC;YAChC,MAAM,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,mBAAmB,CAAC,WAAW,CAAC,CAAC;SAC9D;IACH,CAAC,CAAC,CAAC;IAEH,+BAA+B;IAC/B,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,6BAA6B;IAC7B,gCAAgC;IAChC,eAAe;IACf,uBAAuB;IACvB,4BAA4B;IAC5B,gCAAgC;IAChC,KAAK;IACL,iBAAiB;IACjB,8CAA8C;IAC9C,uBAAuB;IACvB,uBAAuB;IACvB,kBAAkB;IAClB,EAAE;IACF,gEAAgE;IAChE,mDAAmD;IACnD,EAAE;IACF,qBAAqB;IACrB,wCAAwC;IACxC,MAAM;IACN,EAAE,CAAC,yDAAyD,EAAE,KAAK,IAAI,EAAE;QACvE,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC;YACzB,KAAK,EAAE,CAAC;YACR,UAAU,EAAE,CAAC,CAAC,CAAC;YACf,UAAU,EAAE,SAAS;YACrB,iBAAiB,EAAE,MAAM;SAC1B,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,OAAO,CAAC;YACZ,IAAI,EAAE,+BAA+B;YACrC,SAAS,EAAE,KAAK;YAChB,OAAO,EAAE,CAAC,KAAK,CAAC;SACjB,CAAC,CAAC;QAEH,MAAM,EAAE,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,EAAE,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEzC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE;YAC1B,MAAM,CAAC,IAAI,EAAE,GAAG,CAAC,GAAG,MAAM,KAAK,CAAC,YAAY,CAAC,EAAE,EAAE,EAAE,CAAa,CAAC;YACjE,IAAI,CAAC,KAAK,CAAC,EAAE;gBACX,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;gBACpC,MAAM,CAAC,GAAG,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;aACpC;iBAAM,IAAI,CAAC,KAAK,CAAC,EAAE;gBAClB,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;gBACpC,MAAM,CAAC,GAAG,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;aACpC;iBAAM,IAAI,CAAC,KAAK,CAAC,EAAE;gBAClB,MAAM,CAAC,IAAI,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;gBACpC,MAAM,CAAC,GAAG,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;aACpC;SACF;IACH,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,sBAAsB,EAAE,GAAG,EAAE;IACjD,MAAM,WAAW,GAAG,CAAC,CAAC;IACtB,MAAM,SAAS,GAAG,CAAC,CAAC;IACpB,MAAM,UAAU,GAAG,CAAC,CAAC;IACrB,IAAI,KAAsB,CAAC;IAC3B,IAAI,CAAS,CAAC;IACd,IAAI,CAAS,CAAC;IACd,SAAS,SAAS;QAChB,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,SAAS,CAAC,EAAC,CAAC,CAAC;QACrD,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,KAAK,CAC1B,EAAC,KAAK,EAAE,UAAU,EAAE,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC;QACpE,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QACxD,KAAK,GAAG,IAAI,GAAG,CAAC,WAAW,CAAC,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE,MAAM,EAAC,CAAC,CAAC;IAChE,CAAC;IACD,SAAS,QAAQ;QACf,CAAC,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;QACnC,CAAC,GAAG,IAAI,CAAC,CAAC,WAAW,EAAE,UAAU,CAAC,CAAC,CAAC;IACtC,CAAC;IAED,EAAE,CAAC,gDAAgD,EAAE,GAAG,EAAE;QACxD,SAAS,EAAE,CAAC;QACZ,QAAQ,EAAE,CAAC;QAEX,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;aAC7B,YAAY,CAAC,6BAA6B,CAAC,CAAC;IACnD,CAAC,CAAC,CAAC;IAEH,MAAM,aAAa,GAAe,CAAC,IAAI,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;IAClD,MAAM,UAAU,GAAG,CAAC,IAAI,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC;IACjC,KAAK,MAAM,OAAO,IAAI,aAAa,EAAE;QACnC,KAAK,MAAM,SAAS,IAAI,UAAU,EAAE;YAClC,MAAM,SAAS,GACX,WAAW,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,eAAe,SAAS,EAAE,CAAC;YACjE,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;gBACjB,SAAS,EAAE,CAAC;gBACZ,QAAQ,EAAE,CAAC;gBACX,KAAK,CAAC,OAAO,CAAC,EAAC,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,kBAAkB,EAAE,OAAO,EAAC,CAAC,CAAC;gBACrE,MAAM,MAAM,GAAG,KAAK,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,SAAS,EAAC,CAAC,CAAC;gBACjD,IAAI,OAAO,IAAI,IAAI,EAAE;oBACnB,kBAAkB,CAAC,MAAgB,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;iBACjD;qBAAM;oBACL,MAAM,WAAW,GAAG,MAAkB,CAAC;oBACvC,MAAM,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;oBACtC,kBAAkB,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;oBAC9C,kBAAkB,CAAC,WAAW,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;iBAC/C;YACH,CAAC,CAAC,CAAC;SACJ;KACF;IAED,EAAE,CAAC,kCAAkC,EAAE,GAAG,EAAE;QAC1C,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC;QACzD,KAAK,CAAC,OAAO,CACT,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,EAAE,CAAC,KAAK,CAAC,EAAC,CAAC,CAAC;QAEpE,MAAM,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAG,iCAAiC;QAC1D,MAAM,EAAE,GAAG,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAE,iCAAiC;QAC1D,2BAA2B;QAC3B,GAAG,CAAC,OAAO,CAAC,KAAK,CAAC,QAAQ,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC;QACpD,MAAM,WAAW,GAAG,MAAM,EAAE,CAAC,UAAU,CAAC;QACxC,MAAM,QAAQ,GAAG,KAAK,CAAC,QAAQ,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAa,CAAC;QACpE,MAAM,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAK,gBAAgB;QACxD,MAAM,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC,CAAE,oBAAoB;QAC5D,MAAM,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC,CAAE,mBAAmB;QAC3D,GAAG,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC;QACtB,yBAAyB;QACzB,MAAM,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IACnD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,SAAS,EAAE,CAAC;QACZ,QAAQ,EAAE,CAAC;QACX,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;aAC7C,YAAY,CACT,2DAA2D,CAAC,CAAC;QACrE,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,SAAS,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;aAC9C,YAAY,CACT,4DAA4D,CAAC,CAAC;QACtE,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,SAAS,EAAE,IAAI,EAAC,CAAC,CAAC;aAChD,YAAY,CACT,+DAA+D,CAAC,CAAC;QACzE,kCAAkC;QAClC,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,SAAS,EAAE,GAAU,EAAC,CAAC,CAAC;aACtD,YAAY,CACT,2DAA2D,CAAC,CAAC;IACvE,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,QAAQ,CAAC,yCAAyC,EAAE,GAAG,EAAE;IACvD,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,CAAC;YAC3B,MAAM,EAAE;gBACN,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,UAAU,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC;gBACxC,2BAA2B;gBAC3B,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,MAAM,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC;gBAClE,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC;aAC7B;SACF,CAAC,CAAC;QAEH,KAAK,CAAC,SAAS,GAAG,KAAK,CAAC;QACxB,MAAM,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QACvC,6DAA6D;QAC7D,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAChD,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QACjD,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAEhD,KAAK,CAAC,SAAS,GAAG,IAAI,CAAC;QACvB,MAAM,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QACtC,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAChD,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QACjD,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IAClD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2DAA2D,EAAE,KAAK,IAAI,EAAE;QACzE,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CACL,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,MAAM,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC;QACvE,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC,CAAC;QACnE,KAAK,CAAC,SAAS,GAAG,KAAK,CAAC;QACxB,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC5D,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC5D,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC5D,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC5D,KAAK,CAAC,SAAS,GAAG,IAAI,CAAC;QACvB,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC3D,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC3D,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC3D,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IAC7D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0CAA0C,EAAE,KAAK,IAAI,EAAE;QACxD,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CACL,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,MAAM,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC;QACvE,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjD,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,KAAK,CAAC;QAClC,MAAM,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjD,KAAK,CAAC,SAAS,GAAG,KAAK,CAAC;QACxB,MAAM,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjD,KAAK,CAAC,SAAS,GAAG,IAAI,CAAC;QACvB,MAAM,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjD,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,SAAS,GAAG,IAAI,CAAC;QACjC,MAAM,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjD,KAAK,CAAC,SAAS,GAAG,KAAK,CAAC;QACxB,MAAM,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACnD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,qBAAqB,EAAE,GAAG,EAAE;IAChD,SAAS,qBAAqB;QAE5B,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QAC1C,MAAM,QAAQ,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC,KAAK,CAAC,MAAM,CACjD,CAAC;QACvB,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QAC1C,MAAM,MAAM,GACR,GAAG,CAAC,MAAM,CAAC,WAAW,CAAC,EAAC,IAAI,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC,KAAK,CAAC,CAAC,QAAQ,EAAE,MAAM,CAAC,CACzC,CAAC;QACvB,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,OAAO,EAAE,MAAM,EAAC,CAAC,CAAC;QAErE,OAAO,CAAC,KAAK,EAAE,EAAC,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,MAAM,EAAC,CAAC,CAAC;IACrD,CAAC;IAED,SAAS,qBAAqB;QAC5B,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC;YACzB,KAAK,EAAE,CAAC;YACR,UAAU,EAAE,CAAC,CAAC,CAAC;YACf,iBAAiB,EAAE,OAAO;YAC1B,OAAO,EAAE,KAAK;SACf,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC,CAAC;QAC7D,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC,CAAC;QAC7D,OAAO,KAAK,CAAC;IACf,CAAC;IAED,EAAE,CAAC,iCAAiC,EAAE,GAAG,EAAE;QACzC,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,GAAG,qBAAqB,EAAE,CAAC;QAChD,MAAM,MAAM,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,UAAU,CAAC,CAAC,IAAI,CAAW,CAAC;QACzE,kBAAkB,CAAC,OAAO,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,oCAAoC,EAAE,GAAG,EAAE;QAC5C,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,GAAG,qBAAqB,EAAE,CAAC;QAChD,MAAM,MAAM,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE;YACpC,MAAM,CAAC,UAAU,CAAC,CAAC,IAAI,EAAE,MAAM,CAAC,QAAQ,CAAC,CAAC,IAAI,EAAE,MAAM,CAAC,QAAQ,CAAC,CAAC,IAAI;SACtE,CAAa,CAAC;QACf,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjD,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjD,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACnD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,GAAG,qBAAqB,EAAE,CAAC;QAChD,MAAM,UAAU,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;QACxC,MAAM,UAAU,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;QACxC,MAAM,MAAM,GAAmB,EAAE,CAAC;QAClC,MAAM,CAAC,UAAU,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,CAAC,UAAU,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE;YACpC,MAAM,CAAC,UAAU,CAAC,CAAC,IAAI,EAAE,MAAM,CAAC,QAAQ,CAAC,CAAC,IAAI,EAAE,MAAM,CAAC,QAAQ,CAAC,CAAC,IAAI;SACtE,CAAa,CAAC;QACf,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjD,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjD,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACnD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4DAA4D,EAAE,GAAG,EAAE;QACpE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,GAAG,qBAAqB,EAAE,CAAC;QAChD,MAAM,UAAU,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;QACxC,MAAM,MAAM,GAAmB,EAAE,CAAC;QAClC,MAAM,CAAC,UAAU,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,CAAC;aACvD,YAAY,CAAC,mCAAmC,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2DAA2D,EAAE,GAAG,EAAE;QACnE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,GAAG,qBAAqB,EAAE,CAAC;QAChD,MAAM,MAAM,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,CAAC;aACvD,YAAY,CAAC,wDAAwD,CAAC,CAAC;IAC9E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wDAAwD,EAAE,GAAG,EAAE;QAChE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,GAAG,qBAAqB,EAAE,CAAC;QAChD,MAAM,MAAM,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,qBAAqB,GACvB,MAAM,CAAC,UAAU,CAAC,CAAC,IAAI,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,qBAAqB,CAAC,CAAC;aACrD,YAAY,CAAC,6CAA6C,CAAC,CAAC;QACjE,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE;YACjC,MAAM,CAAC,UAAU,CAAC,CAAC,IAAI,EAAE,qBAAqB;SAC/C,CAAC,CAAC,CAAC,YAAY,CAAC,6CAA6C,CAAC,CAAC;IAClE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qDAAqD,EAAE,GAAG,EAAE;QAC7D,MAAM,KAAK,GAAG,qBAAqB,EAAE,CAAC,CAAC,CAAC,CAAC;QACzC,MAAM,MAAM,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC,CAAC,YAAY,CAAC,aAAa,CAAC,CAAC;IACtE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;QAC3C,MAAM,KAAK,GAAG,qBAAqB,EAAE,CAAC;QACtC,MAAM,KAAK,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5B,MAAM,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,KAAK,EAAE;YAClC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,MAA6B,CAAC,IAAI;YAClD,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,MAA6B,CAAC,IAAI;YAClD,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,MAA6B,CAAC,IAAI;SACpD,CAAa,CAAC;QACf,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9C,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9C,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,KAAK,GAAG,qBAAqB,EAAE,CAAC;QACtC,MAAM,KAAK,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9B,MAAM,MAAM,GAAG,KAAK,CAAC,OAAO,CACT,KAAK,EACJ,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,MAA6B,CAAC,IAAI,CACxC,CAAC;QAC/B,kBAAkB,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,6CAA6C,EAAE,GAAG,EAAE;QACrD,MAAM,KAAK,GAAG,qBAAqB,EAAE,CAAC;QACtC,MAAM,MAAM,GAAmB,EAAE,CAAC;QAClC,MAAM,CAAE,KAAK,CAAC,KAAwB,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,MAAM,GAAG,KAAK,CAAC,OAAO,CACT,MAAM,EACL,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,MAA6B,CAAC,IAAI,CACxC,CAAC;QAC/B,kBAAkB,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Unit tests for training.ts\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {abs, mean, memory, mul, NamedTensorMap, ones, Scalar, scalar, SGDOptimizer, Tensor, tensor1d, tensor2d, tensor3d, test_util, util, zeros} from '@tensorflow/tfjs-core';\n\nimport * as K from '../backend/tfjs_backend';\nimport {CustomCallback, CustomCallbackArgs, DEFAULT_YIELD_EVERY_MS, Params} from '../base_callbacks';\nimport * as tfl from '../index';\nimport * as logs from '../logs';\nimport {Logs, UnresolvedLogs} from '../logs';\nimport {Regularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {pyListRepeat, stringsEqual, unique} from '../utils/generic_utils';\nimport {describeMathCPU, describeMathCPUAndGPU, describeMathGPU, expectTensorsClose} from '../utils/test_utils';\n\n// TODO(bileschi): Use external version of Layer.\nimport {Layer, SymbolicTensor} from './topology';\nimport {checkArrayLengths, collectMetrics, isDataArray, isDataDict, isDataTensor, standardizeInputData} from './training';\nimport {makeBatches, sliceArraysByIndices} from './training_tensors';\n\ndescribeMathCPU('isDataTensor', () => {\n  const x = tfc.tensor2d([[3.14]]);\n\n  it('Positive case', () => {\n    expect(isDataTensor(x)).toEqual(true);\n  });\n  it('Negative cases', () => {\n    expect(isDataTensor([x, x])).toEqual(false);\n    expect(isDataTensor({'Pie': x})).toEqual(false);\n    expect(isDataTensor({})).toEqual(false);\n  });\n});\n\ndescribeMathCPU('isDataArray', () => {\n  const x = tfc.tensor2d([[3.14]]);\n\n  it('Positive case', () => {\n    expect(isDataArray([x, x])).toEqual(true);\n    expect(isDataArray([])).toEqual(true);\n  });\n  it('Negative cases', () => {\n    expect(isDataArray(x)).toEqual(false);\n    expect(isDataArray({'Pie': x})).toEqual(false);\n    expect(isDataArray({})).toEqual(false);\n  });\n});\n\ndescribeMathCPU('isDataDict', () => {\n  const x = tfc.tensor2d([[3.14]]);\n  it('Positive case', () => {\n    expect(isDataDict({'Pie': x})).toEqual(true);\n    expect(isDataDict({})).toEqual(true);\n  });\n  it('Negative cases', () => {\n    expect(isDataDict(x)).toEqual(false);\n    expect(isDataDict([x, x])).toEqual(false);\n    expect(isDataDict([])).toEqual(false);\n  });\n});\n\ndescribeMathCPU('standardizeInputData', () => {\n  const getX = () => tfc.tensor2d([[42]]);\n  const getY = () => tfc.tensor2d([[21]]);\n\n  it('Singleton Tensor, Array of one name', () => {\n    const outputs = standardizeInputData(getX(), ['Foo']);\n    expect(outputs.length).toEqual(1);\n    expectTensorsClose(outputs[0], getX());\n  });\n  it('Array of one Tensor, Array of one name', () => {\n    const outputs = standardizeInputData([getX()], ['Foo']);\n    expect(outputs.length).toEqual(1);\n    expectTensorsClose(outputs[0], getX());\n  });\n  it('Array of two Tensors, Array of two names', () => {\n    const outputs = standardizeInputData([getX(), getY()], ['Foo', 'Bar']);\n    expect(outputs.length).toEqual(2);\n    expectTensorsClose(outputs[0], getX());\n    expectTensorsClose(outputs[1], getY());\n  });\n  it('Dict of two Tensors, Array of two names', () => {\n    const outputs =\n        standardizeInputData({'Foo': getX(), 'Bar': getY()}, ['Foo', 'Bar']);\n    expect(outputs.length).toEqual(2);\n    expectTensorsClose(outputs[0], getX());\n    expectTensorsClose(outputs[1], getY());\n  });\n  it('Unexpected data leads to exception: singleton Tensor', () => {\n    expect(() => standardizeInputData(getX(), []))\n        .toThrowError(/expected no data/);\n  });\n  it('Unexpected data leads to exception: Array of two Tensors', () => {\n    expect(() => standardizeInputData([getX(), getY()], []))\n        .toThrowError(/expected no data/);\n  });\n  it('Unexpected data leads to exception: Dict', () => {\n    expect(() => standardizeInputData({'Pie': getX()}, []))\n        .toThrowError(/expected no data/);\n  });\n  it('Length mismatch: 1 singleton Scalar vs two names', () => {\n    expect(() => standardizeInputData(getX(), ['Foo', 'Bar']))\n        .toThrowError(/expects 2 Tensor.* but only received one/);\n  });\n  it('Length mismatch: Array of 2 Scalars vs one name', () => {\n    expect(() => standardizeInputData([getX(), scalar(-42)], ['Foo']))\n        .toThrowError(/Expected to see 1 Tensor/);\n  });\n  it('Length mismatch: Dict of 1 Scalar vs 2 names', () => {\n    expect(() => standardizeInputData({'Foo': getX()}, ['Foo', 'Bar']))\n        .toThrowError(/No data provided for \\\"Bar\\\"/);\n  });\n});\n\ndescribeMathCPU('checkArrayLengths', () => {\n  it('Batch mismatch in inputs', () => {\n    const inputs = [zeros([2, 1]), zeros([3, 1])];\n    const targets = [zeros([2, 1]), zeros([2, 1])];\n    expect(() => checkArrayLengths(inputs, targets))\n        .toThrowError(/All input .* should have the same number of samples/);\n  });\n  it('Batch mismatch in targets', () => {\n    const inputs = [zeros([2, 1]), zeros([2, 1])];\n    const targets = [zeros([2, 1]), zeros([3, 1])];\n    expect(() => checkArrayLengths(inputs, targets))\n        .toThrowError(/All target .* should have the same number of samples/);\n  });\n  it('Batch mismatch between inputs and targets', () => {\n    const inputs = [zeros([2, 1]), zeros([2, 1])];\n    const targets = [zeros([3, 1]), zeros([3, 1])];\n    expect(() => checkArrayLengths(inputs, targets))\n        .toThrowError(\n            /Input Tensors should have the same number of samples as target/);\n  });\n});\n\ndescribeMathCPUAndGPU('collectMetrics', () => {\n  it('shortcut strings name', () => {\n    const metrics = 'mse';\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics(metrics, outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(1);\n    expect(collectedMetrics[0][0]).toEqual('mse');\n  });\n  it('metric function', () => {\n    const metrics = tfl.metrics.meanSquaredError;\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics(metrics, outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(1);\n    expect(collectedMetrics[0][0]).toEqual(metrics);\n  });\n  it('Array of shortcut string names', () => {\n    const metrics = ['mse', 'crossentropy'];\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics(metrics, outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(2);\n    expect(collectedMetrics[0][0]).toEqual('mse');\n    expect(collectedMetrics[0][1]).toEqual('crossentropy');\n  });\n  it('Array of metric functions', () => {\n    const metrics = [tfl.metrics.meanSquaredError, tfl.metrics.precision];\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics(metrics, outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(2);\n    expect(collectedMetrics[0][0]).toEqual(metrics[0]);\n    expect(collectedMetrics[0][1]).toEqual(metrics[1]);\n  });\n  it('Array of mixing shortcut string names and metric functions', () => {\n    const metrics = ['mse', tfl.metrics.precision];\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics(metrics, outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(2);\n    expect(collectedMetrics[0][0]).toEqual('mse');\n    expect(collectedMetrics[0][1]).toEqual(metrics[1]);\n  });\n  it('Dict of shortcut string names', () => {\n    const metrics = {'output': 'mse'};\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics(metrics, outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(1);\n    expect(collectedMetrics[0][0]).toEqual('mse');\n  });\n  it('Dict of metric functions', () => {\n    const metrics = {'output': tfl.metrics.meanSquaredError};\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics(metrics, outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(1);\n    expect(collectedMetrics[0][0]).toEqual(metrics['output']);\n  });\n  it('metrics null', () => {\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics(null, outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(0);\n  });\n  it('metrics is array, length = 0', () => {\n    const outputNames = ['output'];\n    const collectedMetrics = collectMetrics([], outputNames);\n    expect(collectedMetrics.length).toEqual(1);\n    expect(collectedMetrics[0].length).toEqual(0);\n  });\n  it('multiple output names', () => {\n    const metrics = ['mse'];\n    const outputNames = ['output1', 'output2'];\n    const collectedMetrics = collectMetrics(metrics, outputNames);\n    expect(collectedMetrics.length).toEqual(2);\n    expect(collectedMetrics[0].length).toEqual(1);\n    expect(collectedMetrics[0][0]).toEqual('mse');\n    expect(collectedMetrics[1].length).toEqual(1);\n    expect(collectedMetrics[1][0]).toEqual('mse');\n  });\n});\n\ndescribeMathCPUAndGPU('sliceArraysByIndices', () => {\n  it('Single 2D', () => {\n    const x = tensor2d([[1, 2], [3, 4], [5, 6]], [3, 2]);\n    const y = sliceArraysByIndices(x, tensor1d([0, 2])) as Tensor;\n    expectTensorsClose(y, tensor2d([[1, 2], [5, 6]], [2, 2]));\n  });\n  it('Array of two 2Ds', () => {\n    const xs = [\n      tensor2d([[1, 2], [3, 4], [5, 6]], [3, 2]),\n      tensor2d([[10, 20], [30, 40], [50, 60]], [3, 2])\n    ];\n    const ys = sliceArraysByIndices(xs, tensor1d([0, 2])) as Tensor[];\n    expect(ys.length).toEqual(2);\n    expectTensorsClose(ys[0], tensor2d([[1, 2], [5, 6]], [2, 2]));\n    expectTensorsClose(ys[1], tensor2d([[10, 20], [50, 60]], [2, 2]));\n  });\n  it('Array of two 3Ds', () => {\n    const xs = [\n      tensor3d([[[1]], [[2]], [[3]]], [3, 1, 1]),\n      tensor3d([[[10]], [[20]], [[30]]], [3, 1, 1]),\n    ];\n    const ys = sliceArraysByIndices(xs, tensor1d([0, 2])) as Tensor[];\n    expect(ys.length).toEqual(2);\n    expectTensorsClose(ys[0], tensor3d([[[1]], [[3]]], [2, 1, 1]));\n    expectTensorsClose(ys[1], tensor3d([[[10]], [[30]]], [2, 1, 1]));\n  });\n  it('null array input', () => {\n    expect(sliceArraysByIndices(null, tensor1d([0, 2]))).toBeNull();\n  });\n  it('casts indices automatically', () => {\n    const x = tensor2d([[1, 2], [3, 4], [5, 6]], [3, 2]);\n    const y =\n        sliceArraysByIndices(x, tensor1d([0.1, 2.0], 'float32')) as Tensor;\n    expectTensorsClose(y, tensor2d([[1, 2], [5, 6]], [2, 2]));\n  });\n});\n\ndescribe('makeBatches', () => {\n  it('divisible', () => {\n    expect(makeBatches(6, 3)).toEqual([[0, 3], [3, 6]]);\n  });\n\n  it('indivisible', () => {\n    expect(makeBatches(7, 3)).toEqual([[0, 3], [3, 6], [6, 7]]);\n    expect(makeBatches(2, 4)).toEqual([[0, 2]]);\n  });\n\n  it('empty size', () => {\n    expect(makeBatches(0, 4)).toEqual([]);\n  });\n});\n\ndescribeMathCPUAndGPU('LayersModel.predict', () => {\n  it('1 input, 1 output', () => {\n    const inputTensor = tfl.layers.input(\n        {shape: [3, 4], name: 'inputLayer1', dtype: 'float32'});\n    const layer = tfl.layers.reshape({targetShape: [2, 6]});\n    const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel(\n        {inputs: [inputTensor], outputs: [output], name: 'model1x1'});\n    const xs = ones([10, 3, 4]);\n    const ys = model.predict(xs, {batchSize: 4}) as Tensor;\n    expectTensorsClose(ys, ones([10, 2, 6]));\n  });\n\n  it('1D tensors as inputs', () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({units: 1, inputShape: [1]}));\n\n    const xs = ones([10]);  // A batch of 10.\n    // Do a burn-in call first.\n    tfc.dispose(model.predict(xs, {batchSize: 4}));\n    const numTensors0 = memory().numTensors;\n    const ys = model.predict(xs, {batchSize: 4}) as Tensor;\n    expect(ys.shape).toEqual([10, 1]);\n    ys.dispose();\n    // Assert no memory leak.\n    expect(memory().numTensors).toEqual(numTensors0);\n  });\n\n  it('1 input, 1 output, tensor as input argument', () => {\n    const inputTensor = tfl.layers.input(\n        {shape: [3, 4], name: 'inputLayer1', dtype: 'float32'});\n    const layer = tfl.layers.reshape({targetShape: [2, 6]});\n    const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel(\n        {inputs: [inputTensor], outputs: [output], name: 'model1x1'});\n    const xs = ones([10, 3, 4]);\n    const ys = model.predict(xs) as Tensor;\n    expectTensorsClose(ys, ones([10, 2, 6]));\n  });\n\n  it('1 input as Array, 1 output', () => {\n    const inputTensor = tfl.layers.input(\n        {shape: [3, 4], name: 'inputLayer1', dtype: 'float32'});\n    const layer = tfl.layers.reshape({targetShape: [2, 6]});\n    const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel(\n        {inputs: [inputTensor], outputs: [output], name: 'model1x1'});\n    const xs = ones([10, 3, 4]);\n    const ys = model.predict([xs], {batchSize: 4}) as Tensor;\n    expectTensorsClose(ys, ones([10, 2, 6]));\n  });\n\n  it('1 input, 2 outputs', () => {\n    const inputTensor = tfl.layers.input(\n        {shape: [3, 4], name: 'inputLayer2', dtype: 'float32'});\n    const layer1 = tfl.layers.reshape({targetShape: [2, 6]});\n    const layer2 = tfl.layers.flatten();\n    const output1 = layer1.apply(inputTensor) as tfl.SymbolicTensor;\n    const output2 = layer2.apply(output1) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel(\n        {inputs: [inputTensor], outputs: [output1, output2], name: 'model1x2'});\n    const xs = ones([10, 3, 4]);\n    const ys = model.predict(xs, {batchSize: 4}) as Tensor[];\n    expect(ys.length).toEqual(2);\n    expectTensorsClose(ys[0], ones([10, 2, 6]));\n    expectTensorsClose(ys[1], ones([10, 12]));\n  });\n\n  it('2 inputs, 2 outputs', () => {\n    const inputTensor1 = tfl.layers.input(\n        {shape: [3, 4], name: 'inputLayer3', dtype: 'float32'});\n    const inputTensor2 = tfl.layers.input(\n        {shape: [3, 3], name: 'inputLayer4', dtype: 'float32'});\n    const layer1 = tfl.layers.reshape({targetShape: [2, 6]});\n    const layer2 = tfl.layers.flatten();\n    const output1 = layer1.apply(inputTensor1) as tfl.SymbolicTensor;\n    const output2 = layer2.apply(inputTensor2) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel({\n      inputs: [inputTensor1, inputTensor2],\n      outputs: [output1, output2],\n      name: 'model2x2'\n    });\n    const xs1 = ones([10, 3, 4]);\n    const xs2 = ones([10, 3, 3]);\n    const ys = model.predict([xs1, xs2], {batchSize: 4}) as Tensor[];\n    expect(ys.length).toEqual(2);\n    expectTensorsClose(ys[0], ones([10, 2, 6]));\n    expectTensorsClose(ys[1], ones([10, 9]));\n  });\n\n  it('Incorrect number of inputs leads to exception: 1 vs 2', () => {\n    const inputTensor = tfl.layers.input(\n        {shape: [3, 4], name: 'inputLayer_inc_1', dtype: 'float32'});\n    const layer = tfl.layers.reshape({targetShape: [2, 6]});\n    const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel(\n        {inputs: [inputTensor], outputs: [output], name: 'model_inc_1x1'});\n    const xs1 = ones([10, 3, 4]);\n\n    expect(() => model.predict([\n      xs1, xs1\n    ])).toThrowError(/.*Expected.*1 Tensor.*got 2 Tensor.*/);\n  });\n\n  it('Incorrect number of inputs leads to exception: 2 vs 3', () => {\n    const inputTensor1 = tfl.layers.input(\n        {shape: [3, 4], name: 'inputLayer_inc_3', dtype: 'float32'});\n    const inputTensor2 = tfl.layers.input(\n        {shape: [3, 3], name: 'inputLayer_inc_4', dtype: 'float32'});\n    const layer1 = tfl.layers.reshape({targetShape: [2, 6]});\n    const layer2 = tfl.layers.flatten();\n    const output1 = layer1.apply(inputTensor1) as tfl.SymbolicTensor;\n    const output2 = layer2.apply(inputTensor2) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel({\n      inputs: [inputTensor1, inputTensor2],\n      outputs: [output1, output2],\n      name: 'model_inc_2x2'\n    });\n    const xs1 = ones([10, 3, 4]);\n\n    expect(() => model.predict([\n      xs1, xs1, xs1\n    ])).toThrowError(/.*Expected.*2 Tensor.*got 3 Tensor.*/);\n  });\n\n  it('Incorrect input shape leads to exception', () => {\n    const inputTensor = tfl.layers.input(\n        {shape: [3, 4], name: 'inputLayer_inc_1', dtype: 'float32'});\n    const layer = tfl.layers.reshape({targetShape: [2, 6]});\n    const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel(\n        {inputs: [inputTensor], outputs: [output], name: 'model_inc_1x1'});\n    const xs1 = ones([2, 4, 3]);\n\n    expect(() => model.predict(xs1))\n        .toThrowError(/.*expected.* shape \\[null,3,4\\].*but got.*\\[2,4,3\\]/);\n  });\n\n  it('Invalid batchSize value leads to Error', () => {\n    const model = tfl.sequential(\n        {layers: [tfl.layers.dense({units: 1, inputShape: [2]})]});\n    const xs = tfc.zeros([5, 2]);\n    expect(() => model.predict(xs, {batchSize: 0}))\n        .toThrowError(\n            /batchSize is required to be a positive integer, but got 0/);\n    expect(() => model.predict(xs, {batchSize: -2}))\n        .toThrowError(\n            /batchSize is required to be a positive integer, but got -2/);\n    expect(() => model.predict(xs, {batchSize: 3.14}))\n        .toThrowError(\n            /batchSize is required to be a positive integer, but got 3\\.14/);\n    // tslint:disable-next-line:no-any\n    expect(() => model.predict(xs, {batchSize: 'a' as any}))\n        .toThrowError(\n            /batchSize is required to be a positive integer, but got a/);\n  });\n});\n\ndescribeMathCPUAndGPU('LayersModel.fit', () => {\n  const inputSize = 4;   // Input vector size for model with one input.\n  const inputSize1 = 3;  // 1st input vector size for model with two inputs.\n  const inputSize2 = 4;  // 2nd input vector size for model with two inputs.\n  const numSamples = 5;  // Number of samples in a batch.\n\n  const inputTensor = tfl.layers.input(\n      {shape: [inputSize], name: 'inputLayer1', dtype: 'float32'});\n  const inputTensor1 = tfl.layers.input(\n      {shape: [inputSize1], name: 'inputLayer1of2', dtype: 'float32'});\n  const inputTensor2 = tfl.layers.input(\n      {shape: [inputSize2], name: 'inputLayer2of2', dtype: 'float32'});\n\n  // For model with one input.\n  let model: tfl.LayersModel;\n  let inputs: Tensor;\n  let targets: Tensor;\n\n  // For model with two inputs (and two outputs).\n  let twoOutputModel: tfl.LayersModel;\n  let inputs1: Tensor;\n  let inputs2: Tensor;\n  let targets1: Tensor;\n  let targets2: Tensor;\n\n  function createDenseModelAndData(\n      useBias = false,\n      kernelRegularizer?: string|Regularizer,\n      biasRegularizer?: string|Regularizer,\n      ): void {\n    const layer = tfl.layers.dense(\n        {units: 1, useBias, kernelInitializer: 'ones', kernelRegularizer});\n    const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n    model = new tfl.LayersModel({inputs: [inputTensor], outputs: [output]});\n    inputs = ones([numSamples, inputSize]);\n    targets = ones([numSamples, 1]);\n  }\n\n  function createDenseCategoricalModelAndData(useBias = false): void {\n    const layer =\n        tfl.layers.dense({units: 2, useBias, kernelInitializer: 'ones'});\n    const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n    model = new tfl.LayersModel({inputs: [inputTensor], outputs: [output]});\n    inputs = ones([numSamples, inputSize]);\n    targets = K.oneHot(ones([numSamples]), 2);\n  }\n\n  function createTwoLayerDenseModelAndData(useBias = false): [Layer, Layer] {\n    const layer1 =\n        tfl.layers.dense({units: 10, useBias, kernelInitializer: 'ones'});\n    const layer2 =\n        tfl.layers.dense({units: 1, useBias, kernelInitializer: 'ones'});\n    const output =\n        layer2.apply(layer1.apply(inputTensor)) as tfl.SymbolicTensor;\n    model = new tfl.LayersModel({inputs: [inputTensor], outputs: [output]});\n    inputs = ones([numSamples, inputSize]);\n    targets = ones([numSamples, 1]);\n    return [layer1, layer2];\n  }\n\n  function createDenseModelWithTwoOutputsAndData(): void {\n    const layer1 =\n        tfl.layers.dense({units: 1, useBias: false, kernelInitializer: 'ones'});\n    const layer2 =\n        tfl.layers.dense({units: 1, useBias: false, kernelInitializer: 'ones'});\n    const output1 = layer1.apply(inputTensor1) as tfl.SymbolicTensor;\n    const output2 = layer2.apply(inputTensor2) as tfl.SymbolicTensor;\n    twoOutputModel = new tfl.LayersModel(\n        {inputs: [inputTensor1, inputTensor2], outputs: [output1, output2]});\n    inputs1 = ones([numSamples, inputSize1]);\n    inputs2 = ones([numSamples, inputSize2]);\n    targets1 = ones([numSamples, 1]);\n    targets2 = ones([numSamples, 1]);\n  }\n\n  it('1 input, 1 output, dense, 1 weight, string optimizer, 1 batch',\n     async () => {\n       createDenseModelAndData();\n\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       // Use batchSize === numSamples to get exactly one batch.\n       const history =\n           await model.fit(inputs, targets, {batchSize: numSamples, epochs: 1});\n\n       expect(history.epoch).toEqual([0]);\n       const newWeightsValue = model.trainableWeights[0].read();\n\n       const lr = 0.01;  // This is the default learning rate of SGD.\n       const expectedValueArray =\n           pyListRepeat([1.0 - (inputSize - 1) * 2 * lr], inputSize);\n       expectTensorsClose(\n           newWeightsValue, tensor2d(expectedValueArray, [inputSize, 1]));\n     });\n\n  it('1D tensor as inputs, targets and validationData', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({units: 1, inputShape: [1]}));\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n\n    // Use 1D tensor shapes.\n    inputs = ones([numSamples]);\n    targets = ones([numSamples]);\n    const valInputs = ones([numSamples]);\n    const valTargets = ones([numSamples]);\n\n    // Do a burn-in run before checking memory to give any cached\n    // tensors a chance to be created first.\n    await model.fit(inputs, targets, {\n      batchSize: numSamples,\n      epochs: 2,\n      validationData: [valInputs, valTargets]\n    });\n\n    for (let i = 0; i < 2; ++i) {\n      const numTensors0 = memory().numTensors;\n      const history = await model.fit(inputs, targets, {\n        batchSize: numSamples,\n        epochs: 2,\n        validationData: [valInputs, valTargets]\n      });\n      expect(memory().numTensors).toEqual(numTensors0);\n      // Assert no memory leak.\n      expect(history.epoch).toEqual([0, 1]);\n      expect(history.history.loss.length).toEqual(2);\n      expect(history.history.val_loss.length).toEqual(2);\n    }\n  });\n\n  it('training with cosineProximity loss', async () => {\n    createDenseCategoricalModelAndData();\n    model.compile({optimizer: 'SGD', loss: 'cosineProximity'});\n    // Use batchSize === numSamples to get exactly one batch.\n    const history = await model.fit(\n        inputs, targets,\n        {batchSize: numSamples, epochs: 2, validationSplit: 0.2});\n    expect(history.epoch).toEqual([0, 1]);\n    expect(history.history.loss.length).toEqual(2);\n    expect(history.history.val_loss.length).toEqual(2);\n    test_util.expectArraysClose(\n        history.history['loss'] as number[],\n        [-0.70710688829422, -0.7077317237854004]);\n    test_util.expectArraysClose(\n        history.history['val_loss'] as number[],\n        [-0.70710688829422, -0.7077317237854004]);\n  });\n\n  it('training with custom loss', async () => {\n    // Use the following Python code snippet to get reference values\n    // for assertion:\n    //\n    // ```python\n    // import keras\n    // import keras.backend as K;\n    // import numpy as np\n    //\n    // def abs_diff_loss(x, y):\n    //   return K.mean(K.abs(x - y))\n    //\n    // input1 = keras.Input(shape=[4])\n    // layer = keras.layers.Dense(\n    //     units=1, use_bias=False, kernel_initializer='ones')\n    // output = layer(input1)\n    // model = keras.Model(input1, output)\n    // model.compile(optimizer='SGD', loss=abs_diff_loss)\n    // inputs = np.ones([5, 4])\n    // targets = np.ones([5])\n    // history = model.fit(\n    //     inputs, targets, batch_size=5, epochs=2,\n    //     validation_split=0.2)\n    // print(history.history)\n    // ```\n\n    createDenseModelAndData();\n\n    const absDiffLoss = (x: Tensor, y: Tensor) => mean(abs(x.sub(y)));\n\n    model.compile({optimizer: 'SGD', loss: absDiffLoss});\n    // Use batchSize === numSamples to get exactly one batch.\n    const history = await model.fit(\n        inputs, targets,\n        {batchSize: numSamples, epochs: 2, validationSplit: 0.2});\n    test_util.expectArraysClose(history.history['loss'] as number[], [3, 2.96]);\n    test_util.expectArraysClose(\n        history.history['val_loss'] as number[], [2.96, 2.92]);\n  });\n\n  it('Using only x and y input arguments', async () => {\n    createDenseModelAndData();\n\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    const history = await model.fit(inputs, targets, {epochs: 10});\n    // 100 is the default number of epochs.\n    expect(history.epoch.length).toEqual(10);\n    for (let i = 0; i < 10; ++i) {\n      expect(history.epoch[i]).toEqual(i);\n    }\n  });\n\n  it('Default LayersModel.fit epochs is 1', async () => {\n    createDenseModelAndData();\n\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    const history = await model.fit(inputs, targets);\n    expect(history.epoch.length).toEqual(1);\n    expect(history.epoch[0]).toEqual(0);\n  });\n\n  it('1 input, 1 output, dense, 1 weight, string optimizer, 2 epochs',\n     async () => {\n       createDenseModelAndData();\n\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       const history =\n           await model.fit(inputs, targets, {batchSize: numSamples, epochs: 2});\n       expect(history.epoch).toEqual([0, 1]);\n     });\n\n  it('1 input, 1 output, dense, 1 weight, string optimizer, 2 epochs, ' +\n         '1 initialEpoch',\n     async () => {\n       createDenseModelAndData();\n\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       const history = await model.fit(\n           inputs, targets,\n           {batchSize: numSamples, epochs: 2, initialEpoch: 1});\n       expect(history.epoch).toEqual([1]);\n       expect(history.history.loss.length).toEqual(1);\n     });\n\n  it('Training with Dropout layer', async () => {\n    const inputSize = 2;\n    const batchSize = 4;\n    const input = tfl.layers.input({shape: [inputSize]});\n    const dense1 =\n        tfl.layers.dense({units: 2, kernelInitializer: 'ones', useBias: false});\n    const dropout = tfl.layers.dropout({rate: 0.5});\n    const dense2 =\n        tfl.layers.dense({units: 1, kernelInitializer: 'ones', useBias: false});\n    const output =\n        dense2.apply(dropout.apply(dense1.apply(input))) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel({inputs: input, outputs: output});\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n    const x = ones([batchSize, inputSize]);\n    const y = ones([batchSize, 1]);\n    await model.fit(x, y, {batchSize, epochs: 1});\n  });\n\n  it('Calling fit twice in a row leads to Error', async () => {\n    createDenseModelAndData();\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    // Do not use `await` in the following `model.fit` call, so that\n    // the two model.fit() calls may interleave.\n    const firstFit =\n        model.fit(inputs, targets, {batchSize: numSamples, epochs: 8});\n    let errorCaught: Error;\n    try {\n      await model.fit(inputs, targets);\n    } catch (err) {\n      errorCaught = err;\n    }\n    expect(errorCaught.message)\n        .toEqual(\n            'Cannot start training because another fit() call is ongoing.');\n    await firstFit;\n  });\n\n  const validationSplits = [0.2, 0.01];\n  for (const validationSplit of validationSplits) {\n    const testTitle =\n        '1 input, 1 output, dense, 1 weight, string optimizer, 2 epochs, ' +\n        `validationSplit=${validationSplit}`;\n    it(testTitle, async () => {\n      createDenseModelAndData();\n      model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n      const history = await model.fit(\n          inputs, targets, {batchSize: numSamples, epochs: 2, validationSplit});\n      expect(history.epoch).toEqual([0, 1]);\n      const losses = history.history['loss'];\n      expect(losses.length).toEqual(2);\n      const valLosses = history.history['val_loss'];\n      expect(valLosses.length).toEqual(2);\n      // Reference values of the losses can be obtained from PyKeras:\n      // ```python\n      // import keras\n      // import numpy as np\n      // input1 = keras.Input(shape=[4])\n      // layer = keras.layers.Dense(\n      //     units=1, use_bias=False, kernel_initializer='ones')\n      // output = layer(input1)\n      // model = keras.Model(input1, output)\n      // model.compile(optimizer='SGD', loss='mean_squared_error')\n      // inputs = np.ones([5, 4])\n      // targets = np.ones([5])\n      // history = model.fit(\n      //     inputs, targets, batch_size=5, epochs=2,\n      //     validation_split=0.2)\n      // print(history.history)\n      // ```\n      expectTensorsClose(losses as number[], [9, 7.617599964141846]);\n      expectTensorsClose(\n          valLosses as number[], [7.617599964141846, 6.447536945343018]);\n    });\n  }\n\n  it('1 input, 1 output, dense, 1 weight, string optimizer, 2 epochs, ' +\n         'use validationData',\n     async () => {\n       createDenseModelAndData();\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       const history = await model.fit(inputs, targets, {\n         batchSize: numSamples,\n         epochs: 2,\n         validationData: [zeros(inputs.shape as [number, number]), targets]\n       });\n       expect(history.epoch).toEqual([0, 1]);\n       const losses = history.history['loss'];\n       expect(losses.length).toEqual(2);\n       const valLosses = history.history['val_loss'];\n       expect(valLosses.length).toEqual(2);\n       expectTensorsClose(losses as number[], [9, 7.617599964141846]);\n     });\n\n  it('1 input, 1 output, dense, 1 weight, string optimizer, 2 epochs, ' +\n         'validationSplit = 0.2, with additional metric',\n     async () => {\n       createDenseModelAndData();\n       model.compile(\n           {optimizer: 'SGD', loss: 'meanSquaredError', metrics: ['accuracy']});\n       expect(model.metricsNames).toEqual(['loss', 'acc']);\n       const history = await model.fit(inputs, targets, {\n         batchSize: numSamples,\n         epochs: 2,\n         validationSplit: 0.2,\n       });\n\n       expect(history.epoch).toEqual([0, 1]);\n       const losses = history.history['loss'];\n       expect(losses.length).toEqual(2);\n       const valLosses = history.history['val_loss'];\n       expect(valLosses.length).toEqual(2);\n       expectTensorsClose(losses as number[], [9, 7.617599964141846]);\n       expectTensorsClose(\n           valLosses as number[], [7.617599964141846, 6.447536945343018]);\n     });\n\n  it('Return sequences; Fit with metric', async () => {\n    // The golden values for history used in the assertion below can be obtained\n    // with the following Python Keras code.\n    // Ran with Python Keras verion 2.1.2 and TensorFlow (CPU) version\n    // 1.7.0-dev20180226.\n    // ```python\n    // import keras\n    // import numpy as np\n    //\n    // sequenceLength = 3\n    // inputSize = 4\n    // dataSize = 16\n    // validationSplit = 0.5\n    // batchSize = 3\n    // outputSize = 2\n    //\n    // model = keras.Sequential()\n    //\n    // model.add(keras.layers.SimpleRNN(\n    //     outputSize,\n    //     kernel_initializer='ones',\n    //     recurrent_initializer='ones',\n    //     use_bias=False,\n    //     return_sequences=True,\n    //     input_shape=[sequenceLength, inputSize]))\n    // model.add(keras.layers.TimeDistributed(\n    //     keras.layers.Dense(\n    //         outputSize,\n    //         kernel_initializer='ones',\n    //         use_bias=False)))\n    //\n    // model.compile(optimizer='sgd',\n    //               loss='categorical_crossentropy',\n    //               metrics=['accuracy'])\n    // history = model.fit(np.ones([dataSize, sequenceLength, inputSize]),\n    //                     np.ones([dataSize, sequenceLength, outputSize]),\n    //                     batch_size=batchSize,\n    //                     epochs=2,\n    //                     validation_split=validationSplit)\n    // print(history.history)\n    // ```\n\n    const sequenceLength = 3;\n    const inputSize = 4;\n    const dataSize = 16;\n    const validationSplit = 0.5;\n    const batchSize = 3;\n    // So there are 8 examples for train and validation, respectivly. The actual\n    // batches during training and validation will be 3, 3 and 2. This tests the\n    // correct averaging of the loss values happens without broadcasting.\n    const outputSize = 2;\n    const simpleRNN = tfl.layers.simpleRNN({\n      units: outputSize,\n      kernelInitializer: 'ones',\n      recurrentInitializer: 'ones',\n      useBias: false,\n      returnSequences: true,\n    });\n    const timeDistributed = tfl.layers.timeDistributed({\n      layer: tfl.layers.dense(\n          {units: outputSize, kernelInitializer: 'ones', useBias: false})\n    });\n    const input = tfl.layers.input({shape: [sequenceLength, inputSize]});\n    const output =\n        timeDistributed.apply(simpleRNN.apply(input)) as tfl.SymbolicTensor;\n    const model = new tfl.LayersModel({inputs: input, outputs: output});\n    model.compile({\n      optimizer: 'sgd',\n      loss: 'categoricalCrossentropy',\n      metrics: ['accuracy'],\n    });\n    const history = await model.fit(\n        ones([dataSize, sequenceLength, inputSize]),\n        ones([dataSize, sequenceLength, outputSize]), {\n          batchSize,\n          epochs: 1,\n          validationSplit,\n        });\n    expectTensorsClose(\n        history.history['loss'] as number[], [1.3862943649291992]);\n    expectTensorsClose(\n        history.history['val_loss'] as number[], [1.3862943649291992]);\n    expectTensorsClose(history.history['acc'] as number[], [1.0]);\n    expectTensorsClose(history.history['val_acc'] as number[], [1.0]);\n  });\n\n  // TODO(cais): Test metric as a \"dict\", for models with >1 outputs.\n\n  const metricsToTest: string[][] = [['acc'], ['accuracy']];\n  // TODO(cais): Add 'acc', 'accuracy' and assertion acc_1, acc_2.\n  for (const metrics of metricsToTest) {\n    const testTitle = `categoricalCrossentropy model, validationSplit = 0.2, ` +\n        `${JSON.stringify(metrics)}`;\n    it(testTitle, async () => {\n      createDenseCategoricalModelAndData();\n      model.compile(\n          {optimizer: 'SGD', loss: 'categoricalCrossentropy', metrics});\n      if (stringsEqual(metrics, ['acc']) ||\n          stringsEqual(metrics, ['accuracy'])) {\n        expect(model.metricsNames).toEqual(['loss', 'acc']);\n      } else if (stringsEqual(metrics, ['acc', 'accuracy'])) {\n        expect(model.metricsNames).toEqual(['loss', 'acc', 'acc']);\n      }\n      const history = await model.fit(\n          inputs, targets,\n          {batchSize: numSamples, epochs: 2, validationSplit: 0.2});\n      const losses = history.history['loss'];\n      expectTensorsClose(\n          losses as number[], [0.6931471824645996, 0.6918979287147522]);\n      const valLosses = history.history['val_loss'];\n      expectTensorsClose(\n          valLosses as number[], [0.6918979287147522, 0.6906517744064331]);\n      const acc = history.history['acc'];\n      expectTensorsClose(acc as number[], [0, 1]);\n      const valAcc = history.history['val_acc'];\n      expectTensorsClose(valAcc as number[], [1, 1]);\n    });\n  }\n\n  it('categoricalCrossentropy model, validationSplit = 0.2, ' +\n         'tf.metrics.meanSquareError metric function',\n     async () => {\n       createDenseCategoricalModelAndData();\n       model.compile({\n         optimizer: 'SGD',\n         loss: 'categoricalCrossentropy',\n         metrics: tfl.metrics.meanSquaredError\n       });\n       expect(model.metricsNames).toEqual(['loss', 'meanSquaredError']);\n       const history = await model.fit(\n           inputs, targets,\n           {batchSize: numSamples, epochs: 2, validationSplit: 0.2});\n       const losses = history.history['loss'];\n       expectTensorsClose(\n           losses as number[], [0.6931471824645996, 0.6918979287147522]);\n       const meanSquareError = history.history['meanSquaredError'];\n       expectTensorsClose(\n           meanSquareError as number[], [12.5, 12.495024681091309]);\n     });\n\n  it('categoricalCrossentropy model, validationSplit = 0.2, ' +\n         'tf.metrics.meanSquareError metric function && acc',\n     async () => {\n       createDenseCategoricalModelAndData();\n       model.compile({\n         optimizer: 'SGD',\n         loss: 'categoricalCrossentropy',\n         metrics: [tfl.metrics.meanSquaredError, 'acc']\n       });\n       expect(model.metricsNames).toEqual(['loss', 'meanSquaredError', 'acc']);\n       const history = await model.fit(\n           inputs, targets,\n           {batchSize: numSamples, epochs: 2, validationSplit: 0.2});\n       const losses = history.history['loss'];\n       expectTensorsClose(\n           losses as number[], [0.6931471824645996, 0.6918979287147522]);\n       const meanSquareError = history.history['meanSquaredError'];\n       expectTensorsClose(\n           meanSquareError as number[], [12.5, 12.495024681091309]);\n       const acc = history.history['acc'];\n       expectTensorsClose(acc as number[], [0, 1]);\n     });\n\n  it('Two layers, freeze one layer', async () => {\n    // The golden values used below can be obtained with the following PyKeras\n    // code.\n    // ```python\n    // import keras\n    // import numpy as np\n    //\n    // input_size = 4\n    // num_samples = 5\n    //\n    // input_tensor = keras.Input([input_size], name='inputLayer1')\n    // layer1 = keras.layers.Dense(\n    //     units=10, use_bias=False, kernel_initializer='ones')\n    // layer2 = keras.layers.Dense(\n    //     units=1, use_bias=False, kernel_initializer='ones')\n    // output = layer2(layer1(input_tensor))\n    // model = keras.Model(input_tensor, output)\n    //\n    // inputs = np.ones([num_samples, input_size])\n    // targets = np.ones([num_samples, 1])\n    //\n    // optimizer = keras.optimizers.SGD(lr=1e-2)\n    // model.compile(optimizer=optimizer, loss='mean_squared_error')\n    // history = model.fit(inputs,\n    //                     targets,\n    //                     batch_size=num_samples,\n    //                     epochs=2,\n    //                     validation_split=0.2)\n    //\n    // print(history.history)\n    // print(layer1.get_weights())\n    // print(layer2.get_weights())\n    //\n    // # Freeze layer 1.\n    // layer1.trainable = False\n    // model.compile(optimizer=optimizer, loss='mean_squared_error')\n    // history = model.fit(inputs,\n    //                     targets,\n    //                     batch_size=num_samples,\n    //                     epochs=2,\n    //                     validation_split=0.2)\n    //\n    // print(history.history)\n    // print(layer1.get_weights())\n    // print(layer2.get_weights())\n    // ```\n    const layers = createTwoLayerDenseModelAndData();\n    const layer1 = layers[0];\n    const layer2 = layers[1];\n    const optimizer = new SGDOptimizer(1e-2);\n    model.compile({optimizer, loss: 'meanSquaredError'});\n    let history = await model.fit(\n        inputs, targets,\n        {batchSize: numSamples, epochs: 2, validationSplit: 0.2});\n    let losses = history.history['loss'];\n    expectTensorsClose(losses as number[], [1521.0, 386.35842895507812]);\n    let valLosses = history.history['val_loss'];\n    expectTensorsClose(\n        valLosses as number[], [386.35848999023438, 1808.7342529296875]);\n    expectTensorsClose(\n        layer1.getWeights()[0], mul(scalar(-0.61341441), ones([4, 10])));\n    expectTensorsClose(\n        layer2.getWeights()[0], mul(scalar(-1.77405429), ones([10, 1])));\n\n    // Freeze the 1st layer and compile the model again.\n    layer1.trainable = false;\n    model.compile({optimizer, loss: 'meanSquaredError'});\n\n    history = await model.fit(\n        inputs, targets,\n        {batchSize: numSamples, epochs: 2, validationSplit: 0.2});\n    losses = history.history['loss'];\n    expectTensorsClose(\n        losses as number[], [1808.7342529296875, 75.336509704589844]);\n    valLosses = history.history['val_loss'];\n    expectTensorsClose(\n        valLosses as number[], [75.336524963378906, 3.1378798484802246]);\n    // Expect no change in the value of layer1's kernel, due to the freezing.\n    expectTensorsClose(\n        layer1.getWeights()[0], mul(scalar(-0.61341441), ones([4, 10])));\n    // Expect change in the value of layer2's kernel.\n    expectTensorsClose(\n        layer2.getWeights()[0], mul(scalar(-0.11295), ones([10, 1])));\n  });\n\n  it('Setting trainable of layer from fit callback', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({\n      units: 3,\n      activation: 'relu',\n      inputShape: [4],\n      kernelInitializer: 'ones'\n    }));\n    model.add(tfl.layers.dense({units: 1, kernelInitializer: 'ones'}));\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    expect(model.trainableWeights.length).toEqual(4);\n    const xs = tfc.ones([5, 4]);\n    const ys = tfc.ones([5, 1]);\n    const layer1KernelValues: Float32Array[] = [];\n    const layer2KernelValues: Float32Array[] = [];\n    await model.fit(xs, ys, {\n      epochs: 3,\n      callbacks: {\n        onEpochEnd: async (epoch, logs) => {\n          layer1KernelValues.push(\n              model.layers[0].getWeights()[0].dataSync() as Float32Array);\n          layer2KernelValues.push(\n              model.layers[1].getWeights()[0].dataSync() as Float32Array);\n          // Freeze the first dense layer after the 2nd epoch and unfreeze it\n          // after the 3rd epoch.\n          if (epoch === 1) {\n            model.layers[0].trainable = false;\n          } else if (epoch === 2) {\n            model.layers[0].trainable = true;\n          }\n          if (epoch > 0) {\n            // The 2nd dense layer is never frozen. So its kernel should\n            // be updated in every training epoch.\n            // TODO(cais): Use `expectArraysNotClose()` when available.\n            expect(tensor1d(layer2KernelValues[epoch])\n                       .sub(tensor1d(layer2KernelValues[epoch - 1]))\n                       .abs()\n                       .max()\n                       .dataSync()[0])\n                .toBeGreaterThan(0);\n          }\n          // The 1st dense layer is frozen after the 2nd epoch (epoch === 1),\n          // and is then unfrozen after the 3rd (epoch === 2).\n          // So its kernel value should not change between epoch === 1 and epoch\n          // === 2.\n          if (epoch === 2) {\n            expect(tensor1d(layer1KernelValues[epoch])\n                       .sub(tensor1d(layer1KernelValues[epoch - 1]))\n                       .abs()\n                       .max()\n                       .dataSync()[0])\n                .toEqual(0);\n          } else if (epoch > 0) {\n            expect(tensor1d(layer1KernelValues[epoch])\n                       .sub(tensor1d(layer1KernelValues[epoch - 1]))\n                       .abs()\n                       .max()\n                       .dataSync()[0])\n                .toBeGreaterThan(0);\n          }\n        }\n      }\n    });\n  });\n\n  it('Unknown metric', () => {\n    createDenseCategoricalModelAndData();\n    expect(() => model.compile({\n      optimizer: 'SGD',\n      loss: 'categoricalCrossentropy',\n      metrics: ['foo']\n    })).toThrowError(/Unknown metric foo/);\n  });\n\n  it('1 input, 1 output, dense, 2 weights, string optimizer, 1 batch',\n     async () => {\n       createDenseModelAndData(true);\n\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       const history =\n           await model.fit(inputs, targets, {batchSize: numSamples, epochs: 1});\n       expect(history.epoch).toEqual([0]);\n\n       expect(model.trainableWeights.length).toEqual(2);\n       const lr = 0.01;  // This is the default learning rate of SGD.\n       const newKernelValue = model.trainableWeights[0].read();\n       const expectedKernelArray =\n           pyListRepeat([1.0 - (inputSize - 1) * 2 * lr], inputSize);\n       expectTensorsClose(\n           newKernelValue, tensor2d(expectedKernelArray, [inputSize, 1]));\n       const newBiasValue = model.trainableWeights[1].read();\n       const expectedBiasArray = [0.0 - (inputSize - 1) * 2 * lr];\n       expectTensorsClose(newBiasValue, tensor1d(expectedBiasArray));\n     });\n\n  it('1 input, 1 output, dense, 1 weight, optimizer object, 1 batch',\n     async () => {\n       createDenseModelAndData();\n\n       // Use a custom learning rate for SGD.\n       const lr = 0.025;\n       model.compile(\n           {optimizer: new SGDOptimizer(lr), loss: 'meanSquaredError'});\n       const history =\n           await model.fit(inputs, targets, {batchSize: numSamples, epochs: 1});\n       expect(history.epoch).toEqual([0]);\n       const newWeightsValue = model.trainableWeights[0].read();\n\n       const expectedValueArray =\n           pyListRepeat([1.0 - (inputSize - 1) * 2 * lr], inputSize);\n       expectTensorsClose(\n           newWeightsValue, tensor2d(expectedValueArray, [inputSize, 1]));\n     });\n\n  // Reference Python code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // input1 = keras.Input(shape=[2])\n  // output1 = keras.layers.Dense(1,\n  //                             kernel_initializer='ones',\n  //                             use_bias=False)(input1)\n  // output2 = keras.layers.Dense(1,\n  //                             kernel_initializer='ones',\n  //                             use_bias=False)(input1)\n  // model = keras.Model(input1, [output1, output2])\n  //\n  // model.compile(loss={model.output_names[0]: 'mean_squared_error',\n  //                     model.output_names[1]: 'mean_absolute_error'},\n  //               optimizer='sgd')\n  //\n  // xs = np.ones([2, 2])\n  // ys1 = np.zeros([2, 1])\n  // ys2 = np.zeros([2, 1])\n  // history = model.fit(xs, [ys1, ys2], epochs=1)\n  // print(history.history)\n  // ```\n  it('2 outputs, losses by output name', async () => {\n    const input1 = tfl.input({shape: [2]});\n    const output1 =\n        tfl.layers.dense({units: 1, kernelInitializer: 'ones', useBias: false})\n            .apply(input1) as SymbolicTensor;\n    const output2 =\n        tfl.layers.dense({units: 1, kernelInitializer: 'ones', useBias: false})\n            .apply(input1) as SymbolicTensor;\n    const model = tfl.model({inputs: input1, outputs: [output1, output2]});\n    const loss: {[outputName: string]: string} = {};\n    loss[model.outputNames[0]] = 'meanSquaredError';\n    loss[model.outputNames[1]] = 'meanAbsoluteError';\n    model.compile({loss, optimizer: 'sgd'});\n\n    const xs = ones([2, 2]);\n    const ys1 = zeros([2, 1]);\n    const ys2 = zeros([2, 1]);\n    const history = await model.fit(xs, [ys1, ys2], {epochs: 1});\n    expect(history.history.loss[0]).toBeCloseTo(6);\n    expect(history.history[`${model.outputNames[0]}_loss`][0]).toBeCloseTo(4);\n    expect(history.history[`${model.outputNames[1]}_loss`][0]).toBeCloseTo(2);\n  });\n\n  it('2 inputs, 2 outputs, dense, optimizer object, 1 batch', async () => {\n    createDenseModelWithTwoOutputsAndData();\n\n    const lr = 0.01;\n    twoOutputModel.compile({\n      optimizer: new SGDOptimizer(lr),\n      loss: ['meanSquaredError', 'meanSquaredError']\n    });\n    const trainableWeights = twoOutputModel.trainableWeights;\n    let newWeightsValue1 = trainableWeights[0].read();\n    let newWeightsValue2 = trainableWeights[1].read();\n    await twoOutputModel.fit(\n        [inputs1, inputs2], [targets1, targets2],\n        {batchSize: numSamples, epochs: 1});\n\n    expect(twoOutputModel.trainableWeights.length).toEqual(2);\n    newWeightsValue1 = twoOutputModel.trainableWeights[0].read();\n    newWeightsValue2 = twoOutputModel.trainableWeights[1].read();\n\n    // Check the weight updates to layer1.\n    const expectedValueArray1 =\n        pyListRepeat([1.0 - (inputSize1 - 1) * 2 * lr], inputSize1);\n    expectTensorsClose(\n        newWeightsValue1, tensor2d(expectedValueArray1, [inputSize1, 1]));\n    // Check the weight updates to layer2 (different from those to\n    // layer1).\n    const expectedValueArray2 =\n        pyListRepeat([1.0 - (inputSize2 - 1) * 2 * lr], inputSize2);\n    expectTensorsClose(\n        newWeightsValue2, tensor2d(expectedValueArray2, [inputSize2, 1]));\n  });\n\n  const isCustomCallbackArgs = [false, true];\n  const isCustomCallbackArray = [false, true];\n  for (const isArgs of isCustomCallbackArgs) {\n    for (const isArray of isCustomCallbackArray) {\n      const testTitle = `Fit with custom callback object: isConfig=${\n          isArgs}, isArray=${isArray}`;\n      it(testTitle, async () => {\n        createDenseModelAndData();\n        const trainBeginLogs: Logs[] = [];\n        const trainEndLogs: Logs[] = [];\n        const epochBeginEpochs: number[] = [];\n        const epochEndEpochs: number[] = [];\n        const batchBeginBatches: number[] = [];\n        const batchEndBatches: number[] = [];\n        const batchEndLosses: number[] = [];\n        const epochEndLosses: number[] = [];\n        const customCallbackArgs: CustomCallbackArgs = {\n          onTrainBegin: async (logs?: Logs) => {\n            trainBeginLogs.push(logs);\n          },\n          onTrainEnd: async (logs?: Logs) => {\n            trainEndLogs.push(logs);\n          },\n          onEpochBegin: async (epoch: number, logs?: Logs) => {\n            epochBeginEpochs.push(epoch);\n          },\n          onEpochEnd: async (epoch: number, logs?: Logs) => {\n            epochEndEpochs.push(epoch);\n            epochEndLosses.push(logs['loss']);\n          },\n          onBatchBegin: async (batch: number, logs?: Logs) => {\n            batchBeginBatches.push(batch);\n          },\n          onBatchEnd: async (batch: number, logs?: Logs) => {\n            batchEndBatches.push(batch);\n            batchEndLosses.push(logs['loss']);\n          }\n        };\n        const customCallback = isArgs ? customCallbackArgs :\n                                        new CustomCallback(customCallbackArgs);\n        model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n        await model.fit(inputs, targets, {\n          batchSize: 2,\n          epochs: 2,\n          callbacks: isArray ? [customCallback] : customCallback,\n        });\n        expect(trainBeginLogs.length).toEqual(1);\n        expect(trainEndLogs.length).toEqual(1);\n        expect(epochBeginEpochs).toEqual([0, 1]);\n        expect(epochEndEpochs).toEqual([0, 1]);\n        expect(batchBeginBatches).toEqual([0, 1, 2, 0, 1, 2]);\n        expect(batchEndBatches).toEqual([0, 1, 2, 0, 1, 2]);\n\n        // The optimization problem is a convex one (a single Dense layer),\n        // the learning rate low (default 0.01 for SGD). So it should be fine to\n        // assert monotonic assert monotonic decrease in loss value.\n        expect(batchEndLosses.length).toEqual(6);\n        for (let i = 1; i < batchEndLosses.length; ++i) {\n          expect(batchEndLosses[i]).toBeLessThan(batchEndLosses[i - 1]);\n        }\n        expect(epochEndLosses.length).toEqual(2);\n        expect(epochEndLosses[1]).toBeLessThan(epochEndLosses[0]);\n      });\n    }\n  }\n\n  it('Using custom regularizer', async () => {\n    // The golden values used for assertion can be obtained with PyKeras code:\n    //\n    // ```python\n    // import keras\n    // import numpy as np\n    //\n    // model = keras.Sequential([\n    //     keras.layers.Dense(\n    //         1, kernel_initializer='ones', use_bias=False, input_shape=[4],\n    //         kernel_regularizer=keras.regularizers.l1_l2(1, 1))\n    // ]);\n    //\n    // xs = np.ones([5, 4])\n    // ys = np.ones([5, 1])\n    //\n    // model.compile(optimizer='sgd', loss='mean_squared_error')\n    //\n    // history = model.fit(xs, ys, epochs=2)\n    // print(model.get_weights()[0])\n    // print(history.history)\n    //\n    // ```\n    createDenseModelAndData(false, tfl.regularizers.l1l2({l1: 1, l2: 1}));\n\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    // Use batchSize === numSamples to get exactly one batch.\n    const history =\n        await model.fit(inputs, targets, {batchSize: numSamples, epochs: 2});\n    expectTensorsClose(\n        model.layers[1].getWeights()[0],\n        tensor2d([0.829, 0.829, 0.829, 0.829], [4, 1]));\n    expect(history.history.loss.length).toEqual(2);\n    expect(history.history.loss[0]).toBeCloseTo(17);\n    expect(history.history.loss[1]).toBeCloseTo(13.92);\n  });\n\n  it('Using string regularizer', async () => {\n    // The golden values used for assertion can be obtained with PyKeras code:\n    //\n    // ```python\n    // import keras\n    // import numpy as np\n    //\n    // model = keras.Sequential([\n    //     keras.layers.Dense(\n    //         1, kernel_initializer='ones', use_bias=False, input_shape=[4],\n    //         kernel_regularizer='l1l2')\n    // ]);\n    //\n    // xs = np.ones([5, 4])\n    // ys = np.ones([5, 1])\n    //\n    // model.compile(optimizer='sgd', loss='mean_squared_error')\n    //\n    // history = model.fit(xs, ys, epochs=2)\n    // print(model.get_weights()[0])\n    // print(history.history)\n    //\n    // ```\n    createDenseModelAndData(false, 'l1l2');\n\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    // Use batchSize === numSamples to get exactly one batch.\n    const history =\n        await model.fit(inputs, targets, {batchSize: numSamples, epochs: 2});\n    expectTensorsClose(\n        model.layers[1].getWeights()[0],\n        tensor2d([0.884, 0.884, 0.884, 0.884], [4, 1]));\n    expect(history.history.loss.length).toEqual(2);\n    expect(history.history.loss[0]).toBeCloseTo(9.08);\n    expect(history.history.loss[1]).toBeCloseTo(7.68);\n  });\n\n  it('and then set weights to new weights', async () => {\n    createDenseModelAndData(false, 'l1l2');\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    await model.fit(inputs, targets, {batchSize: numSamples, epochs: 2});\n    const w = zeros([4, 1]);\n    model.layers[1].setWeights([w]);\n    expectTensorsClose(model.layers[1].getWeights()[0], w);\n  });\n\n  it('and then set weights to own weights', async () => {\n    createDenseModelAndData(false, 'l1l2');\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    await model.fit(inputs, targets, {batchSize: numSamples, epochs: 2});\n    const w = model.layers[1].getWeights()[0];\n    model.layers[1].setWeights([w]);\n    expectTensorsClose(model.layers[1].getWeights()[0], w);\n  });\n\n  class CustomCallbackForTest extends tfl.CustomCallback {\n    constructor(readonly recordedParams: Params[]) {\n      super({\n        onTrainBegin: async () => {\n          recordedParams.push(this.params);\n        }\n      });\n    }\n  }\n\n  it('Custom callback params: no validation', async () => {\n    createDenseModelAndData();\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    const recordedParams: Params[] = [];\n    const epochs = 3;\n    const batchSize = 2;\n    await model.fit(inputs, targets, {\n      epochs,\n      batchSize,\n      callbacks: new CustomCallbackForTest(recordedParams)\n    });\n    expect(recordedParams[0].epochs).toEqual(epochs);\n    expect(recordedParams[0].initialEpoch).toEqual(0);\n    expect(recordedParams[0].samples).toEqual(inputs.shape[0]);\n    expect(recordedParams[0].steps).toEqual(null);\n    expect(recordedParams[0].batchSize).toEqual(batchSize);\n    expect(recordedParams[0].doValidation).toEqual(false);\n    expect(recordedParams[0].metrics).toEqual(['loss']);\n  });\n\n  it('Custom callback params: has validation', async () => {\n    createDenseModelAndData();\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    const recordedParams: Params[] = [];\n    const epochs = 3;\n    const batchSize = 2;\n    const validationSplit = 0.2;\n    await model.fit(inputs, targets, {\n      epochs,\n      batchSize,\n      validationSplit,\n      callbacks: new CustomCallbackForTest(recordedParams)\n    });\n    expect(recordedParams[0].epochs).toEqual(epochs);\n    expect(recordedParams[0].initialEpoch).toEqual(0);\n    expect(recordedParams[0].samples)\n        .toEqual(Math.round(inputs.shape[0] * (1 - validationSplit)));\n    expect(recordedParams[0].steps).toEqual(null);\n    expect(recordedParams[0].batchSize).toEqual(batchSize);\n    expect(recordedParams[0].doValidation).toEqual(true);\n    expect(recordedParams[0].metrics).toEqual(['loss', 'val_loss']);\n  });\n\n  class StopAfterNEpochs extends tfl.Callback {\n    private readonly epochsToTrain: number;\n    constructor(epochsToTrain: number) {\n      super();\n      this.epochsToTrain = epochsToTrain;\n    }\n\n    async onEpochEnd(epoch: number, logs?: UnresolvedLogs) {\n      if (epoch === this.epochsToTrain - 1) {\n        this.model.stopTraining = true;\n      }\n    }\n  }\n\n  it('Stop training at the end of an epoch: Functional model', async () => {\n    createDenseModelAndData(true);\n    model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    // Order 10 epochs of training, but the training should stop after two\n    // epochs due to the callback.\n    const history = await model.fit(inputs, targets, {\n      batchSize: numSamples,\n      epochs: 10,\n      callbacks: [new StopAfterNEpochs(2)]\n    });\n    expect(history.history.loss.length).toEqual(2);\n  });\n\n  class StopAfterNBatches extends tfl.Callback {\n    private readonly batchesToTrain: number;\n    constructor(batchesToTrain: number) {\n      super();\n      this.batchesToTrain = batchesToTrain;\n    }\n\n    async onBatchEnd(batch: number, logs?: Logs) {\n      if (batch === this.batchesToTrain - 1) {\n        this.model.stopTraining = true;\n      }\n    }\n  }\n\n  it('Stop training at the end of a batch: Sequential model', async () => {\n    const sequentialModel = tfl.sequential();\n    sequentialModel.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'ones', inputShape: [inputSize]}));\n    // numSamples is 5.\n    inputs = ones([numSamples, inputSize]);\n    targets = ones([numSamples, 1]);\n    sequentialModel.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    // Order 10 epochs of training, but the training should stop after only one\n    // epochs due to the callback that orders the training to stop after two\n    // batches. The first epoch should have five batches  due to a batchSize\n    // of 1.\n    const history = await sequentialModel.fit(\n        inputs, targets,\n        {batchSize: 1, epochs: 10, callbacks: [new StopAfterNBatches(2)]});\n    expect(history.history.loss.length).toEqual(1);\n  });\n\n  it('Stop LayersModel.fit() using non-class object callback function',\n     async () => {\n       createDenseModelAndData();\n\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n\n       let numEpochsDone = 0;\n       const epochs = 8;\n       const stopAfterEpoch = 3;\n       let history = await model.fit(inputs, targets, {\n         epochs,\n         callbacks: {\n           onEpochEnd: async (epoch: number, logs?: UnresolvedLogs) => {\n             numEpochsDone++;\n             if (epoch === stopAfterEpoch) {\n               model.stopTraining = true;\n             }\n           }\n         }\n       });\n       expect(numEpochsDone).toEqual(stopAfterEpoch + 1);\n       expect(history.history.loss.length).toEqual(stopAfterEpoch + 1);\n\n       // Check that model.fit can still be called after force stopping.\n       history = await model.fit(inputs, targets, {epochs: 2});\n       expect(history.history.loss.length).toEqual(2);\n     });\n\n  it('Stop training resets at start of LayersModel.fit()', async () => {\n    const sequentialModel = tfl.sequential();\n    sequentialModel.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'ones', inputShape: [inputSize]}));\n    // numSamples is 5.\n    inputs = ones([numSamples, inputSize]);\n    targets = ones([numSamples, 1]);\n    sequentialModel.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n    // Order 10 epochs of training, but the training should stop after only one\n    // epochs due to the callback that orders the training to stop after two\n    // batches. The first epoch should have five batches due to a batchSize\n    // of 1.\n    let history = await sequentialModel.fit(\n        inputs, targets,\n        {batchSize: 1, epochs: 10, callbacks: [new StopAfterNBatches(2)]});\n    expect(history.history.loss.length).toEqual(1);\n\n    // Running fit again should now run to completion\n    history =\n        await sequentialModel.fit(inputs, targets, {batchSize: 1, epochs: 10});\n    expect(history.history.loss.length).toEqual(10);\n  });\n\n  it('Model.dispose() cleans up owned optimizer: Functional', async () => {\n    const input1 = tfl.input({shape: [2]});\n    const input2 = tfl.input({shape: [2]});\n    const y1 = tfl.layers.add().apply([input1, input2]);\n    const y2 = tfl.layers.concatenate().apply([input1, input2]);\n    const output1 =\n        tfl.layers\n            .dense({units: 1, activation: 'linear', kernelInitializer: 'zeros'})\n            .apply(y1) as tfl.SymbolicTensor;\n    const output2 =\n        tfl.layers\n            .dense(\n                {units: 1, activation: 'sigmoid', kernelInitializer: 'zeros'})\n            .apply(y2) as tfl.SymbolicTensor;\n    const model =\n        tfl.model({inputs: [input1, input2], outputs: [output1, output2]});\n    model.compile(\n        {loss: ['meanSquaredError', 'binaryCrossentropy'], optimizer: 'adam'});\n\n    const xs: Tensor[] = [zeros([4, 2]), zeros([4, 2])];\n    const ys: Tensor[] = [zeros([4, 1]), zeros([4, 1])];\n\n    await model.fit(xs, ys, {epochs: 1});\n    const numTensors1 = memory().numTensors;\n\n    const disposalResult = model.dispose();\n    const numTensors2 = memory().numTensors;\n    // The optimizerNumGlobalVariables comes from the intrinsic weights of the\n    // ADAM optimizer, e.g., accBeta1, accBeta2.\n    const optimizerNumGlobalVariables = 2;\n    // The optimizerNumVariablesPerWeight comes from accumulatedFirstMoment and\n    // accumulatedSecondMoment, which are computed per model weight.\n    const optimizerNumVariablesPerWeight = 2;\n    const numModelWeights = 4;\n    expect(disposalResult.numDisposedVariables)\n        .toEqual(\n            numModelWeights + optimizerNumGlobalVariables +\n            numModelWeights * optimizerNumVariablesPerWeight);\n    expect(disposalResult.refCountAfterDispose).toEqual(0);\n    expect(numTensors1 - numTensors2)\n        .toEqual(\n            numModelWeights + optimizerNumGlobalVariables +\n            numModelWeights * optimizerNumVariablesPerWeight);\n  });\n\n  it('Model.dispose() cleans up owned optimizer: Sequential', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({units: 1, inputShape: [2]}));\n    model.compile({loss: 'meanSquaredError', optimizer: 'adam'});\n\n    const xs = zeros([4, 2]);\n    const ys = zeros([4, 1]);\n\n    await model.fit(xs, ys, {epochs: 1});\n    const numTensors1 = memory().numTensors;\n\n    const disposalResult = model.dispose();\n    const numTensors2 = memory().numTensors;\n\n    // The optimizerNumGlobalVariables comes from the intrinsic weights of the\n    // ADAM optimizer, e.g., accBeta1, accBeta2.\n    const optimizerNumGlobalVariables = 2;\n    // The optimizerNumVariablesPerWeight comes from accumulatedFirstMoment and\n    // accumulatedSecondMoment, which are computed per model weight.\n    const optimizerNumVariablesPerWeight = 2;\n    const numModelWeights = 2;\n    expect(disposalResult.numDisposedVariables)\n        .toEqual(\n            numModelWeights + optimizerNumGlobalVariables +\n            numModelWeights * optimizerNumVariablesPerWeight);\n    expect(disposalResult.refCountAfterDispose).toEqual(0);\n    expect(numTensors1 - numTensors2)\n        .toEqual(\n            numModelWeights + optimizerNumGlobalVariables +\n            numModelWeights * optimizerNumVariablesPerWeight);\n  });\n\n  it('Model.dispose() skips non-owned optimizer: Functional', async () => {\n    const input1 = tfl.input({shape: [2]});\n    const input2 = tfl.input({shape: [2]});\n    const y1 = tfl.layers.add().apply([input1, input2]);\n    const y2 = tfl.layers.concatenate().apply([input1, input2]);\n    const output1 =\n        tfl.layers\n            .dense({units: 1, activation: 'linear', kernelInitializer: 'zeros'})\n            .apply(y1) as tfl.SymbolicTensor;\n    const output2 =\n        tfl.layers\n            .dense(\n                {units: 1, activation: 'sigmoid', kernelInitializer: 'zeros'})\n            .apply(y2) as tfl.SymbolicTensor;\n    const model =\n        tfl.model({inputs: [input1, input2], outputs: [output1, output2]});\n    const optimizer = new tfc.AdamOptimizer(1e-3, 0.9, 0.999, 1e-6);\n    model.compile(\n        {loss: ['meanSquaredError', 'binaryCrossentropy'], optimizer});\n\n    const xs: Tensor[] = [zeros([4, 2]), zeros([4, 2])];\n    const ys: Tensor[] = [zeros([4, 1]), zeros([4, 1])];\n\n    await model.fit(xs, ys, {epochs: 1});\n    const numTensors1 = memory().numTensors;\n\n    const disposalResult = model.dispose();\n    const numTensors2 = memory().numTensors;\n    // Only the weights of the model (not including the optimizer) should have\n    // been disposed.\n    expect(disposalResult.numDisposedVariables).toEqual(4);\n    expect(disposalResult.refCountAfterDispose).toEqual(0);\n    expect(numTensors1 - numTensors2).toEqual(4);\n  });\n\n  it('Model.dispose() skips non-owned optimizer: Sequential', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({units: 1, inputShape: [2]}));\n    const optimizer = new tfc.AdamOptimizer(1e-3, 0.9, 0.999, 1e-6);\n    model.compile({loss: 'meanSquaredError', optimizer});\n\n    const xs = zeros([4, 2]);\n    const ys = zeros([4, 1]);\n\n    await model.fit(xs, ys, {epochs: 1});\n    const numTensors1 = memory().numTensors;\n\n    const disposalResult = model.dispose();\n    const numTensors2 = memory().numTensors;\n\n    // Only the Model's own weights should have been disposed.\n    expect(disposalResult.numDisposedVariables).toEqual(2);\n    expect(disposalResult.refCountAfterDispose).toEqual(0);\n    expect(numTensors1 - numTensors2).toEqual(2);\n  });\n\n  it('Invalid dict loss: nonexistent output name', () => {\n    createDenseModelAndData();\n    expect(() => model.compile({\n      optimizer: 'SGD',\n      loss: {'Foo': 'meanSquaredError'}\n    })).toThrowError(/Unknown entry in loss dictionary:.*Foo.*/);\n  });\n\n  it('Invalid Array loss: missing loss for an output', () => {\n    createDenseModelWithTwoOutputsAndData();\n    expect(() => twoOutputModel.compile({\n      optimizer: 'SGD',\n      loss: ['meanSquaredError']\n    })).toThrowError(/should have one entry per model output.*has 2 output/);\n  });\n\n  it('Calling fit without compile leads to error', () => {\n    createDenseModelAndData(true);\n    const fitPromise =\n        model.fit(inputs, targets, {batchSize: numSamples, epochs: 1});\n    fitPromise.catch(error => {\n      expect(error.message).toContain('You must compile a model before');\n    });\n  });\n\n  it('Invalid batchSize leads to Error', async () => {\n    createDenseModelAndData();\n    const badBatchSizeValues: Array<number|string> = [0, -1, 3.14, 'a'];\n    for (const batchSize of badBatchSizeValues) {\n      let errorCaught: Error;\n      try {\n        // tslint:disable-next-line:no-any\n        await model.fit(inputs, targets, {batchSize: batchSize as any});\n      } catch (err) {\n        errorCaught = err;\n      }\n      expect(errorCaught.message)\n          .toEqual(`batchSize is required to be a positive integer, but got ${\n              batchSize}`);\n    }\n  });\n});\n\ndescribeMathCPUAndGPU('LayersModel.fit with training-sensitive layers', () => {\n  it('Correct training arg during fit/evaluate/predict', async () => {\n    const inputTensor =\n        tfl.layers.input({shape: [1], name: 'inputLayer1', dtype: 'float32'});\n    const layer1 = tfl.layers.dense({units: 1});\n    const layer2 = tfl.layers.dropout({rate: 0.5});\n\n    // Hook the dropout layer to observe the training arg values during the\n    // fit(), evaluate() and predict() calls.\n    const dropoutLayerTrainingFlags: boolean[] = [];\n    const recordDropoutTrainingArgHook =\n        (inputs: Tensor|Tensor[], kwargs: Kwargs) => {\n          dropoutLayerTrainingFlags.push(kwargs.training as boolean);\n        };\n    layer2.setCallHook(recordDropoutTrainingArgHook);\n\n    const output =\n        layer2.apply(layer1.apply(inputTensor)) as tfl.SymbolicTensor;\n    const model =\n        new tfl.LayersModel({inputs: [inputTensor], outputs: [output]});\n    model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n    const xs = ones([4, 1]);\n    const ys = ones([4, 1]);\n\n    // 1. Call fit: Dropout layer should be called twice, with training as\n    // true.\n    await model.fit(xs, ys, {epochs: 2, batchSize: 4});\n    expect(dropoutLayerTrainingFlags).toEqual([true, true]);\n\n    // 2. Call evaluate, Dropout layer should be called once, without\n    // training defined.\n    model.evaluate(xs, ys, {batchSize: 4});\n    expect(dropoutLayerTrainingFlags).toEqual([true, true, undefined]);\n\n    // 3. Call predict, Dropout layer should be called once, without training\n    //   defined.\n    model.predict(xs, {batchSize: 4});\n    expect(dropoutLayerTrainingFlags).toEqual([\n      true, true, undefined, undefined\n    ]);\n  });\n});\n\ndescribeMathCPUAndGPU(\n    'LayersModel.predict and LayersModel.evaluate: No memory leak', () => {\n      const inputSize = 4;  // Input vector size for model with one input.\n\n      const inputTensor = tfl.layers.input(\n          {shape: [inputSize], name: 'inputLayer1', dtype: 'float32'});\n      let model: tfl.LayersModel;\n      let inputs: Tensor;\n      let targets: Tensor;\n\n      function createDenseModelAndData(\n          numSamples: number,\n          kernelRegularizer?: string|Regularizer,\n          biasRegularizer?: string|Regularizer,\n          ): void {\n        const layer = tfl.layers.dense(\n            {units: 1, kernelInitializer: 'ones', kernelRegularizer});\n        const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n        model = new tfl.LayersModel({inputs: [inputTensor], outputs: [output]});\n        inputs = ones([numSamples, inputSize]);\n        targets = ones([numSamples, 1]);\n      }\n\n      it('predict: Single batch', () => {\n        const numExamples = 5;\n        const batchSize = 32;  // batchSize >= numExamples ==> a single batch.\n        createDenseModelAndData(numExamples);\n        // Burn-in call.\n        let out = model.predict(inputs, {batchSize}) as Tensor;\n        out.dispose();\n        const numTensors0 = memory().numTensors;\n\n        // Actual call.\n        out = model.predict(inputs, {batchSize}) as Tensor;\n        out.dispose();\n        const numTensors1 = memory().numTensors;\n        expect(numTensors1).toEqual(numTensors0);\n      });\n\n      it('predict: Two batches', () => {\n        const numExamples = 5;\n        const batchSize = 3;  // batchSize < numExamples ==> multiple batches.\n        createDenseModelAndData(numExamples);\n        // Burn-in call.\n        let out = model.predict(inputs, {batchSize}) as Tensor;\n        out.dispose();\n        const numTensors0 = memory().numTensors;\n\n        // Actual call.\n        out = model.predict(inputs, {batchSize}) as Tensor;\n        out.dispose();\n        const numTensors1 = memory().numTensors;\n        expect(numTensors1).toEqual(numTensors0);\n      });\n\n      it('evaluate: Single batch, no metric', () => {\n        const numExamples = 5;\n        createDenseModelAndData(numExamples);\n        model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n        const batchSize = 32;  // batchSize >= numExamples ==> a single batch.\n        // Burn-in call.\n        let out = model.evaluate(inputs, targets, {batchSize}) as Tensor;\n        out.dispose();\n        const numTensors0 = memory().numTensors;\n\n        // Actual call.\n        out = model.evaluate(inputs, targets, {batchSize}) as Tensor;\n        out.dispose();\n        const numTensors1 = memory().numTensors;\n        expect(numTensors1).toEqual(numTensors0);\n      });\n\n      it('evaluate: Two batches, no metric', () => {\n        const numExamples = 5;\n        createDenseModelAndData(numExamples);\n        model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n        const batchSize = 3;  // batchSize < numExamples ==> multiple batches.\n        // Burn-in call.\n        let out = model.evaluate(inputs, targets, {batchSize}) as Tensor;\n        out.dispose();\n        const numTensors0 = memory().numTensors;\n\n        // Actual call.\n        out = model.evaluate(inputs, targets, {batchSize}) as Tensor;\n        out.dispose();\n        const numTensors1 = memory().numTensors;\n        expect(numTensors1).toEqual(numTensors0);\n      });\n\n      it('evaluate: Two batches, with metric', () => {\n        const numExamples = 5;\n        createDenseModelAndData(numExamples);\n        model.compile(\n            {optimizer: 'SGD', loss: 'meanSquaredError', metrics: ['mae']});\n        const batchSize = 3;  // batchSize < numExamples ==> multiple batches.\n        // Burn-in call.\n        let out = model.evaluate(inputs, targets, {batchSize}) as Tensor[];\n        out.forEach(tensor => tensor.dispose());\n        const numTensors0 = memory().numTensors;\n\n        // Actual call.\n        out = model.evaluate(inputs, targets, {batchSize}) as Tensor[];\n        out.forEach(tensor => tensor.dispose());\n        const numTensors1 = memory().numTensors;\n        expect(numTensors1).toEqual(numTensors0);\n      });\n    });\n\ndescribeMathCPUAndGPU('LayersModel.fit: No memory leak', () => {\n  const inputSize = 4;   // Input vector size for model with one input.\n  const numSamples = 5;  // Number of samples in a batch.\n\n  const inputTensor = tfl.layers.input(\n      {shape: [inputSize], name: 'inputLayer1', dtype: 'float32'});\n  let model: tfl.LayersModel;\n  let inputs: Tensor;\n  let targets: Tensor;\n  let valInputs: Tensor;\n  let valTargets: Tensor;\n\n  function createDenseModelAndData(\n      useBias = false,\n      kernelRegularizer?: string|Regularizer,\n      biasRegularizer?: string|Regularizer,\n      ): void {\n    const layer = tfl.layers.dense(\n        {units: 1, useBias, kernelInitializer: 'ones', kernelRegularizer});\n    const output = layer.apply(inputTensor) as tfl.SymbolicTensor;\n    model = new tfl.LayersModel({inputs: [inputTensor], outputs: [output]});\n    inputs = ones([numSamples, inputSize]);\n    targets = ones([numSamples, 1]);\n    valInputs = zeros([numSamples, inputSize]);\n    valTargets = zeros([numSamples, 1]);\n  }\n\n  it('Repeated fit calls leads to no memory leak: no validation or metrics',\n     async (done) => {\n       createDenseModelAndData();\n\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       // Use batchSize === numSamples to get exactly one batch.\n       await model.fit(inputs, targets, {batchSize: numSamples, epochs: 1});\n       const numTensors0 = memory().numTensors;\n       for (let i = 0; i < 2; ++i) {\n         await model.fit(inputs, targets, {batchSize: numSamples, epochs: 1});\n         const numTensorsNow = memory().numTensors;\n         if (numTensorsNow > numTensors0) {\n           done.fail(\n               `Memory leak detected during fit(): Leaked ` +\n               `${numTensorsNow - numTensors0} tensor(s) after the ` +\n               `${i + 1}-th fit() call.`);\n         }\n       }\n       done();\n     });\n\n  it('Repeated fit calls leads to no memory leak: batchSize=1, ' +\n         'no validation or metrics',\n     async done => {\n       createDenseModelAndData();\n\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       const batchSize = 1;  // Use batchSize = 1.\n       await model.fit(inputs, targets, {batchSize, epochs: 1});\n       const numTensors0 = memory().numTensors;\n       for (let i = 0; i < 2; ++i) {\n         await model.fit(inputs, targets, {batchSize, epochs: 1});\n         const numTensorsNow = memory().numTensors;\n         if (numTensorsNow > numTensors0) {\n           done.fail(\n               `Memory leak detected during fit(): Leaked ` +\n               `${numTensorsNow - numTensors0} tensor(s) after the ` +\n               `${i + 1}-th fit() call.`);\n         }\n       }\n       done();\n     });\n\n  it('Repeated fit calls leads to no memory leak: with metrics', async done => {\n    createDenseModelAndData();\n\n    model.compile(\n        {optimizer: 'SGD', loss: 'meanSquaredError', metrics: ['mse']});\n    // Use batchSize === numSamples to get exactly one batch.\n    await model.fit(inputs, targets, {batchSize: numSamples, epochs: 1});\n    const numTensors0 = memory().numTensors;\n    for (let i = 0; i < 2; ++i) {\n      await model.fit(inputs, targets, {batchSize: numSamples, epochs: 1});\n      const numTensorsNow = memory().numTensors;\n      if (numTensorsNow > numTensors0) {\n        done.fail(\n            `Memory leak detected during fit(): Leaked ` +\n            `${numTensorsNow - numTensors0} tensor(s) after the ` +\n            `${i + 1}-th fit() call.`);\n      }\n    }\n    done();\n  });\n\n  it('Repeated fit calls leads to no memory leak: validationSplit',\n     async done => {\n       createDenseModelAndData();\n\n       const validationSplit = 0.4;\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       // Use batchSize === numSamples to get exactly one batch.\n       await model.fit(\n           inputs, targets,\n           {batchSize: numSamples, epochs: 1, validationSplit});\n       const numTensors0 = memory().numTensors;\n       for (let i = 0; i < 2; ++i) {\n         await model.fit(\n             inputs, targets,\n             {batchSize: numSamples, epochs: 1, validationSplit});\n         const numTensorsNow = memory().numTensors;\n         if (numTensorsNow > numTensors0) {\n           done.fail(\n               `Memory leak detected during fit(): Leaked ` +\n               `${numTensorsNow - numTensors0} tensor(s) after the ` +\n               `${i + 1}-th fit() call.`);\n         }\n       }\n       done();\n     });\n\n  it('Repeated fit calls leads to no memory leak: validationData',\n     async done => {\n       createDenseModelAndData();\n\n       const validationData: [Tensor, Tensor] = [valInputs, valTargets];\n       model.compile({optimizer: 'SGD', loss: 'meanSquaredError'});\n       // Use batchSize === numSamples to get exactly one batch.\n       await model.fit(\n           inputs, targets, {batchSize: numSamples, epochs: 1, validationData});\n       const numTensors0 = memory().numTensors;\n       for (let i = 0; i < 2; ++i) {\n         await model.fit(\n             inputs, targets,\n             {batchSize: numSamples, epochs: 1, validationData});\n         const numTensorsNow = memory().numTensors;\n         if (numTensorsNow > numTensors0) {\n           done.fail(\n               `Memory leak detected during fit(): Leaked ` +\n               `${numTensorsNow - numTensors0} tensor(s) after the ` +\n               `${i + 1}-th fit() call.`);\n         }\n       }\n       done();\n     });\n\n  it('Repeated fit calls leads to no memory leak: metrics & validationSplit',\n     async done => {\n       createDenseModelAndData();\n\n       const validationSplit = 0.4;\n       model.compile(\n           {optimizer: 'SGD', loss: 'meanSquaredError', metrics: ['mse']});\n       // Use batchSize === numSamples to get exactly one batch.\n       await model.fit(\n           inputs, targets,\n           {batchSize: numSamples, epochs: 1, validationSplit});\n       const numTensors0 = memory().numTensors;\n       for (let i = 0; i < 2; ++i) {\n         await model.fit(\n             inputs, targets,\n             {batchSize: numSamples, epochs: 1, validationSplit});\n         const numTensorsNow = memory().numTensors;\n         if (numTensorsNow > numTensors0) {\n           done.fail(\n               `Memory leak detected during fit(): Leaked ` +\n               `${numTensorsNow - numTensors0} tensor(s) after the ` +\n               `${i + 1}-th fit() call.`);\n         }\n       }\n       done();\n     });\n\n  it('Repeated fit calls leads to no memory leak: batchSize=2, ' +\n         'metrics & validationSplit',\n     async done => {\n       createDenseModelAndData();\n\n       const validationSplit = 0.4;\n       model.compile(\n           {optimizer: 'SGD', loss: 'meanSquaredError', metrics: ['mse']});\n       const batchSize = 2;  // Use batchSize < numSamples.\n       const epochsPerIter = 2;\n       await model.fit(\n           inputs, targets, {batchSize, epochs: 1, validationSplit});\n       const numTensors0 = memory().numTensors;\n       for (let i = 0; i < 2; ++i) {\n         const history = await model.fit(\n             inputs, targets,\n             {batchSize, epochs: epochsPerIter, validationSplit});\n         expect(history.history['loss'].length).toEqual(epochsPerIter);\n         expect(history.history['val_loss'].length).toEqual(epochsPerIter);\n         expect(history.history['mse'].length).toEqual(epochsPerIter);\n         expect(history.history['val_mse'].length).toEqual(epochsPerIter);\n         const numTensorsNow = memory().numTensors;\n         if (numTensorsNow > numTensors0) {\n           done.fail(\n               `Memory leak detected during fit(): Leaked ` +\n               `${numTensorsNow - numTensors0} tensor(s) after the ` +\n               `${i + 1}-th fit() call.`);\n         }\n       }\n       done();\n     });\n\n  it('Fit with onEpochEnd callback: no memory leak: validation & metrics',\n     async done => {\n       createDenseModelAndData();\n\n       model.compile(\n           {optimizer: 'SGD', loss: 'meanSquaredError', metrics: ['mse']});\n       const validationSplit = 0.4;\n\n       // First, perform a burn-in call.\n       await model.fit(\n           inputs, targets,\n           {batchSize: numSamples, epochs: 1, validationSplit});\n       const numTensors0 = memory().numTensors;\n\n       // Perform actual testing calls.\n       const numFitCalls = 2;\n       for (let n = 0; n < numFitCalls; ++n) {\n         const tensorCounts: number[] = [];\n         await model.fit(inputs, targets, {\n           batchSize: numSamples,\n           epochs: 4,\n           validationSplit,\n           callbacks: {\n             onEpochEnd: async () => {\n               tensorCounts.push(memory().numTensors);\n             }\n           }\n         });\n         expect(tensorCounts.length).toEqual(4);\n         if (unique(tensorCounts).length !== 1) {\n           done.fail(\n               `Detected WebGL memory leak during fit() call with ` +\n               `onEpochEnd callback: tensor counts: ${tensorCounts}.`);\n         }\n         const numTensors1 = memory().numTensors;\n         if (numTensors1 > numTensors0) {\n           done.fail(\n               `Detected memory leak of ${numTensors1 - numTensors0} ` +\n               `tensor(s) after fit() call ${n + 1} of ${numFitCalls} ` +\n               `with onEpochEnd callback.`);\n         }\n       }\n       done();\n     });\n\n  it('Fit with onBatchEnd callback: no memory leak: validation & metrics',\n     async done => {\n       createDenseModelAndData();\n\n       model.compile(\n           {optimizer: 'SGD', loss: 'meanSquaredError', metrics: ['mse']});\n       const validationSplit = 0.4;\n       const epochs = 3;\n       const batchesPerEpoch = numSamples * (1 - validationSplit);\n\n       // First, perform a burn-in call.\n       await model.fit(inputs, targets, {\n         batchSize: 1,\n         epochs,\n         validationSplit,\n       });\n       const numTensors0 = memory().numTensors;\n\n       // Perform actual testing calls.\n       for (let n = 0; n < 2; ++n) {\n         const tensorCounts: number[] = [];\n         await model.fit(inputs, targets, {\n           batchSize: 1,\n           epochs,\n           validationSplit,\n           callbacks: {\n             onBatchEnd: async (batch: number, logs: Logs) => {\n               tensorCounts.push(memory().numTensors);\n             }\n           }\n         });\n         for (let epochIndex = 0; epochIndex < epochs; ++epochIndex) {\n           // Get the tensor counts within an epoch (i.e., from the first\n           // batch till the penultimate one.) Assert that the counts are\n           // constant, i.e., no increase in the tensor count within the\n           // epoch. N.B.: Even though the tensor count is expected to be\n           // constant across batches, across epochs, the count will increase,\n           // due to the per-epoch loss and metric values stored for the\n           // returned history object, which are currently downloaded via\n           // data() calls only at the end of the fit() call.\n           const beginBatch = batchesPerEpoch * epochIndex;\n           const endBatch = batchesPerEpoch * (epochIndex + 1);\n           const inEpochTensorCounts =\n               tensorCounts.slice(beginBatch, endBatch - 1);\n           if (unique(inEpochTensorCounts).length !== 1) {\n             done.fail(\n                 `Detected WebGL memory leak within epoch ${epochIndex + 1} ` +\n                 `of ${epochs} of the fit() call with ` +\n                 `onBatchEnd callback: tensor counts: ${inEpochTensorCounts}.`);\n           }\n         }\n         expect(tensorCounts.length).toEqual(batchesPerEpoch * epochs);\n         const numTensors1 = memory().numTensors;\n         if (numTensors1 > numTensors0) {\n           done.fail(\n               `Detected memory leak of ${numTensors1 - numTensors0} ` +\n               `tensor(s) after fit() call with callback.`);\n         }\n       }\n       done();\n     });\n});\n\ndescribeMathGPU('LayersModel.fit: yieldEvery', () => {\n  function createDummyModel(inputSize: number): tfl.LayersModel {\n    const model = tfl.sequential();\n    const layerSize = 10;\n    model.add(tfl.layers.dense(\n        {units: layerSize, inputShape: [inputSize], activation: 'relu'}));\n    model.add(tfl.layers.dense({units: 1}));\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n    return model;\n  }\n\n  it('auto: 1 batch per epoch; 5 epochs', async () => {\n    const wait = DEFAULT_YIELD_EVERY_MS;\n    const timeBetweenCalls = [\n      0,\n      1,\n      wait + 1,  // Should call.\n      wait + 1,  // Should call.\n      1,\n      1,\n    ];\n    let counter = 0;\n    let prevTime = 0;\n    spyOn(util, 'now').and.callFake(() => {\n      prevTime += timeBetweenCalls[counter++];\n      return prevTime;\n    });\n    let nextFrameCallCount = 0;\n    spyOn(tfc, 'nextFrame').and.callFake(async () => {\n      nextFrameCallCount++;\n    });\n\n    const inputSize = 2;\n    const numExamples = 10;\n    const epochs = 5;\n    const model = createDummyModel(inputSize);\n    const xs = ones([numExamples, inputSize]);\n    const ys = ones([numExamples, 1]);\n    const onYieldEpochIds: number[] = [];\n    const onYieldBatchesIds: number[] = [];\n    const history = await model.fit(xs, ys, {\n      epochs,\n      batchSize: numExamples,\n      callbacks: {\n        onYield: async (epoch, batch, _logs) => {\n          onYieldBatchesIds.push(batch);\n          onYieldEpochIds.push(epoch);\n        }\n      }\n    });\n    expect(history.history.loss.length).toEqual(epochs);\n    // There are 5 batches in total (1 batch per epoch). We expect next frame\n    // to be called twice, after epoch 1 and after epoch 2.\n    expect(nextFrameCallCount).toBe(2);\n    expect(onYieldEpochIds).toEqual([1, 2]);\n    expect(onYieldBatchesIds).toEqual([0, 0]);\n  });\n\n  it('auto: 2 batches per epoch; 4 epochs', async () => {\n    const yieldEvery = DEFAULT_YIELD_EVERY_MS;\n    const timeBetweenCalls = [\n      0,\n      1,\n      yieldEvery + 1,  // Should call.\n      yieldEvery + 1,  // Should call.\n      1,\n      yieldEvery + 1,  // SHould call.\n      yieldEvery + 1,  // Should call.\n      1,\n      1,\n    ];\n    let counter = 0;\n    let prevTime = 0;\n    spyOn(util, 'now').and.callFake(() => {\n      prevTime += timeBetweenCalls[counter++];\n      return prevTime;\n    });\n    let nextFrameCallCount = 0;\n    spyOn(tfc, 'nextFrame').and.callFake(async () => {\n      nextFrameCallCount++;\n    });\n\n    const inputSize = 2;\n    const numExamples = 10;\n    const epochs = 4;\n    const model = createDummyModel(inputSize);\n    const xs = ones([numExamples, inputSize]);\n    const ys = ones([numExamples, 1]);\n    const onYieldEpochIds: number[] = [];\n    const onYieldBatchesIds: number[] = [];\n    const history = await model.fit(xs, ys, {\n      epochs,\n      batchSize: numExamples / 2,\n      callbacks: {\n        onYield: async (epoch, batch, _logs) => {\n          onYieldBatchesIds.push(batch);\n          onYieldEpochIds.push(epoch);\n        }\n      }\n    });\n    expect(history.history.loss.length).toEqual(epochs);\n    // There are 8 batches in total (2 batches per epoch). We expect next\n    // frame to be called 3 times, after (epoch 0, batch 1), (epoch 1, batch 0)\n    // (epoch 2, batch 0) and (epoch 2, batch 1).\n    expect(nextFrameCallCount).toBe(4);\n    expect(onYieldEpochIds).toEqual([0, 1, 2, 2]);\n    expect(onYieldBatchesIds).toEqual([1, 0, 0, 1]);\n  });\n\n  it('yieldEvery: 5, 1 batch per epoch; 5 epochs', async () => {\n    const yieldEvery = 5;\n    const timeBetweenCalls = [\n      0, 1,\n      yieldEvery + 1,     // Should call.\n      1, yieldEvery + 1,  // Should call.\n      yieldEvery + 1,     // Should call.\n    ];\n    let counter = 0;\n    let prevTime = 0;\n    spyOn(util, 'now').and.callFake(() => {\n      prevTime += timeBetweenCalls[counter++];\n      return prevTime;\n    });\n    let nextFrameCallCount = 0;\n    spyOn(tfc, 'nextFrame').and.callFake(async () => {\n      nextFrameCallCount++;\n    });\n\n    const inputSize = 2;\n    const numExamples = 10;\n    const epochs = 5;\n    const model = createDummyModel(inputSize);\n    const xs = ones([numExamples, inputSize]);\n    const ys = ones([numExamples, 1]);\n    const onYieldEpochIds: number[] = [];\n    const onYieldBatchesIds: number[] = [];\n    const history = await model.fit(xs, ys, {\n      epochs,\n      batchSize: numExamples,\n      yieldEvery,\n      callbacks: {\n        onYield: async (epoch, batch, _logs) => {\n          onYieldBatchesIds.push(batch);\n          onYieldEpochIds.push(epoch);\n        }\n      }\n    });\n    expect(history.history.loss.length).toEqual(epochs);\n    // There are 5 batches in total (1 batch per epoch). We expect next frame\n    // to be called 3 times, after epoch 1, epoch 3 and epoch 4.\n    expect(nextFrameCallCount).toBe(3);\n    expect(onYieldEpochIds).toEqual([1, 3, 4]);\n    expect(onYieldBatchesIds).toEqual([0, 0, 0]);\n  });\n\n  it('fails when onYield is provided, but yieldEvery is never', async done => {\n    const inputSize = 2;\n    const numExamples = 10;\n    const epochs = 5;\n    const model = createDummyModel(inputSize);\n    const xs = ones([numExamples, inputSize]);\n    const ys = ones([numExamples, 1]);\n    try {\n      await model.fit(xs, ys, {\n        epochs,\n        batchSize: numExamples,\n        yieldEvery: 'never',\n        callbacks: {onYield: async (_epoch, _batch, _logs) => {}}\n      });\n      done.fail('Model.fit should fail');\n    } catch {\n      done();\n    }\n  });\n\n  it('batch: uneven 9 batches per epoch; 2 epochs', async () => {\n    const presetBatchTimestamps = [0, 2, 4, 6, 8, 10];\n    let counter = 0;\n    spyOn(util, 'now').and.callFake(() => presetBatchTimestamps[counter++]);\n    let nextFrameCallCount = 0;\n    spyOn(tfc, 'nextFrame').and.callFake(async () => {\n      nextFrameCallCount++;\n    });\n\n    const inputSize = 1;\n    const numExamples = 10;\n    const epochs = 2;\n    const model = createDummyModel(inputSize);\n    const xs = ones([numExamples, inputSize]);\n    const ys = ones([numExamples, 1]);\n    const history =\n        await model.fit(xs, ys, {epochs, batchSize: 4, yieldEvery: 'batch'});\n    expect(history.history.loss.length).toEqual(epochs);\n    // There are `ceil(10 / 4)` batches per epoch.\n    expect(nextFrameCallCount).toEqual(Math.ceil(10 / 4) * epochs);\n  });\n\n  it('epoch: 10 batches per epoch; 2 epochs', async () => {\n    let nextFrameCallCount = 0;\n    spyOn(tfc, 'nextFrame').and.callFake(async () => {\n      nextFrameCallCount++;\n    });\n\n    const inputSize = 5;\n    const numExamples = 10;\n    const epochs = 2;\n    const model = createDummyModel(inputSize);\n    const xs = ones([numExamples, inputSize]);\n    const ys = ones([numExamples, 1]);\n    const history = await model.fit(\n        xs, ys, {epochs, batchSize: numExamples / 10, yieldEvery: 'epoch'});\n    expect(history.history.loss.length).toEqual(epochs);\n    expect(nextFrameCallCount).toEqual(epochs);\n  });\n\n  it('never: 2 batches per epoch; 20 epochs', async () => {\n    let nextFrameCallCount = 0;\n    spyOn(tfc, 'nextFrame').and.callFake(async () => {\n      nextFrameCallCount++;\n    });\n\n    const inputSize = 5;\n    const numExamples = 10;\n    const epochs = 4;\n    const model = createDummyModel(inputSize);\n    const xs = ones([numExamples, inputSize]);\n    const ys = ones([numExamples, 1]);\n    const history = await model.fit(\n        xs, ys, {epochs, batchSize: numExamples / 2, yieldEvery: 'never'});\n    expect(history.history.loss.length).toEqual(epochs);\n    // Due to yieldEvery = 'never', no `await nextFrame()` call should have\n    // happened.\n    expect(nextFrameCallCount).toEqual(0);\n  });\n\n  it('resolveScalarInLogs is not called if no custom callbacks', async () => {\n    const inputSize = 1;\n    const numExamples = 10;\n    const batchSize = 2;\n    const epochs = 2;\n    const model = createDummyModel(inputSize);\n    const xs = ones([numExamples, inputSize]);\n    const ys = ones([numExamples, 1]);\n\n    const spy = spyOn(logs, 'resolveScalarsInLogs').and.callThrough();\n    await model.fit(xs, ys, {epochs, batchSize, yieldEvery: 'never'});\n    expect(spy).not.toHaveBeenCalled();\n  });\n});\n\ndescribeMathCPUAndGPU('LayersModel.trainOnBatch', () => {\n  // Reference Python Keras code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.Dense(\n  //     1, input_shape=[3], kernel_initializer='zeros'))\n  // model.compile(loss='mean_squared_error', optimizer='sgd')\n  //\n  // batch_size = 4\n  // xs = np.ones([batch_size, 3])\n  // ys = np.ones([batch_size, 1])\n  //\n  // for _ in range(3):\n  //   loss = model.train_on_batch(xs, ys)\n  //   print(loss)\n  // ```\n  it('Sequential MLP: correctness', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense(\n        {units: 1, inputShape: [3], kernelInitializer: 'zeros'}));\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const batchSize = 4;\n    const xs = tfc.ones([batchSize, 3]);\n    const ys = tfc.ones([batchSize, 1]);\n    let loss = await model.trainOnBatch(xs, ys) as number;\n    expect(loss).toBeCloseTo(1.0);\n    loss = await model.trainOnBatch(xs, ys) as number;\n    expect(loss).toBeCloseTo(0.8464);\n    loss = await model.trainOnBatch(xs, ys) as number;\n    expect(loss).toBeCloseTo(0.716393);\n  });\n\n  // Reference Python Keras code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // input1 = keras.Input(shape=[2])\n  // input2 = keras.Input(shape=[2])\n  // y1 = keras.layers.Add()([input1, input2])\n  // y2 = keras.layers.Concatenate()([input1, input2])\n  // output1 = keras.layers.Dense(\n  //     units=1,\n  //     activation='linear',\n  //     kernel_initializer='zeros')(y1)\n  // output2 = keras.layers.Dense(\n  //     units=1,\n  //     activation='sigmoid',\n  //     kernel_initializer='zeros')(y2)\n  // model = keras.Model(inputs=[input1, input2], outputs=[output1, output2])\n  // model.compile(loss=['mean_squared_error', 'binary_crossentropy'],\n  //               optimizer='sgd')\n  //\n  // batch_size = 4\n  // xs1 = np.ones([batch_size, 2])\n  // xs2 = np.ones([batch_size, 2])\n  // ys1 = np.ones([batch_size, 1])\n  // ys2 = np.ones([batch_size, 1])\n  //\n  // for _ in range(3):\n  //   losses = model.train_on_batch([xs1, xs2], [ys1, ys2])\n  //   print(losses)\n  // ```\n  it('Functional two inputs and two outputs: correctness', async () => {\n    const input1 = tfl.input({shape: [2]});\n    const input2 = tfl.input({shape: [2]});\n    const y1 = tfl.layers.add().apply([input1, input2]);\n    const y2 = tfl.layers.concatenate().apply([input1, input2]);\n    const output1 =\n        tfl.layers\n            .dense({units: 1, activation: 'linear', kernelInitializer: 'zeros'})\n            .apply(y1) as tfl.SymbolicTensor;\n    const output2 =\n        tfl.layers\n            .dense(\n                {units: 1, activation: 'sigmoid', kernelInitializer: 'zeros'})\n            .apply(y2) as tfl.SymbolicTensor;\n    const model =\n        tfl.model({inputs: [input1, input2], outputs: [output1, output2]});\n    model.compile(\n        {loss: ['meanSquaredError', 'binaryCrossentropy'], optimizer: 'sgd'});\n\n    const batchSize = 4;\n    const xs1 = tfc.ones([batchSize, 2]);\n    const xs2 = tfc.ones([batchSize, 2]);\n    const ys1 = tfc.ones([batchSize, 1]);\n    const ys2 = tfc.ones([batchSize, 1]);\n    let losses = await model.trainOnBatch([xs1, xs2], [ys1, ys2]) as number[];\n    expect(losses.length).toEqual(3);\n    expect(losses[0]).toBeCloseTo(1.6931472);\n    expect(losses[1]).toBeCloseTo(1.0);\n    expect(losses[2]).toBeCloseTo(0.6931472);\n    losses = await model.trainOnBatch([xs1, xs2], [ys1, ys2]) as number[];\n    expect(losses.length).toEqual(3);\n    expect(losses[0]).toBeCloseTo(1.3531253);\n    expect(losses[1]).toBeCloseTo(0.6724);\n    expect(losses[2]).toBeCloseTo(0.68072534);\n    losses = await model.trainOnBatch([xs1, xs2], [ys1, ys2]) as number[];\n    expect(losses.length).toEqual(3);\n    expect(losses[0]).toBeCloseTo(1.1207337);\n    expect(losses[1]).toBeCloseTo(0.45212176);\n    expect(losses[2]).toBeCloseTo(0.66861194);\n  });\n\n  // Reference Python Keras code.\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.Dense(\n  //     3, input_shape=[2], activation='softmax', kernel_initializer='ones'))\n  // model.compile(loss='categorical_crossentropy', optimizer='sgd')\n  //\n  // xs = np.array([[0.5, 0.5], [1, 1], [0, 1]], dtype=np.float32)\n  // ys = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=np.float32)\n  //\n  // for _ in range(3):\n  //   loss = model.train_on_batch(xs, ys)\n  //   print(loss)\n  // ```\n  it('Categorical: Correctness and no memory leak', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({\n      units: 3,\n      inputShape: [2],\n      activation: 'softmax',\n      kernelInitializer: 'ones'\n    }));\n    model.compile({loss: 'categoricalCrossentropy', optimizer: 'sgd'});\n\n    const xs = tfc.tensor2d([[0.5, 0.5], [1, 1], [0, 1]]);\n    const ys = tfc.tensor2d([[1, 0, 0], [0, 1, 0], [0, 0, 1]]);\n    // Perform burn-in.\n    model.trainOnBatch(xs, ys);\n    const numTensors0 = memory().numTensors;\n    for (let i = 0; i < 3; ++i) {\n      const loss = await model.trainOnBatch(xs, ys);\n      tfc.tidy(() => {\n        if (i === 0) {\n          expect(loss).toBeCloseTo(1.0986123);\n        } else if (i === 1) {\n          expect(loss).toBeCloseTo(1.0978721);\n        } else {\n          expect(loss).toBeCloseTo(1.0971345);\n        }\n      });\n      // Assert no tensor memory leak.\n      expect(memory().numTensors).toBeLessThanOrEqual(numTensors0);\n    }\n  });\n\n  // Reference Python Keras code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.Dense(\n  //     units=3,\n  //     input_shape=[2],\n  //     activation='softmax',\n  //     kernel_initializer='ones'\n  // ))\n  // model.compile(\n  //     loss='sparse_categorical_crossentropy',\n  //     optimizer='sgd',\n  //     metrics=['acc'])\n  // model.summary()\n  //\n  // xs = np.array([[0, 0.5], [0.5, 1], [0, 1]], dtype=np.float32)\n  // ys = np.array([[2], [1], [0]], dtype=np.float32)\n  //\n  // for _ in range(3):\n  //   print(model.train_on_batch(xs, ys))\n  // ```\n  it('Sparse categorical: w/ metrics: correctness and no leak', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({\n      units: 3,\n      inputShape: [2],\n      activation: 'softmax',\n      kernelInitializer: 'ones'\n    }));\n    model.compile({\n      loss: 'sparseCategoricalCrossentropy',\n      optimizer: 'sgd',\n      metrics: ['acc']\n    });\n\n    const xs = tfc.tensor2d([[0, 0.5], [0.5, 1], [0, 1]]);\n    const ys = tfc.tensor2d([[2], [1], [0]]);\n\n    for (let i = 0; i < 3; ++i) {\n      const [loss, acc] = await model.trainOnBatch(xs, ys) as number[];\n      if (i === 0) {\n        expect(loss).toBeCloseTo(1.0986123);\n        expect(acc).toBeCloseTo(0.3333333);\n      } else if (i === 1) {\n        expect(loss).toBeCloseTo(1.0982422);\n        expect(acc).toBeCloseTo(0.6666667);\n      } else if (i === 2) {\n        expect(loss).toBeCloseTo(1.0978734);\n        expect(acc).toBeCloseTo(0.6666667);\n      }\n    }\n  });\n});\n\ndescribeMathCPUAndGPU('LayersModel.evaluate', () => {\n  const numExamples = 8;\n  const inputSize = 2;\n  const outputSize = 1;\n  let model: tfl.LayersModel;\n  let x: Tensor;\n  let y: Tensor;\n  function prepModel() {\n    const input = tfl.layers.input({shape: [inputSize]});\n    const dense = tfl.layers.dense(\n        {units: outputSize, kernelInitializer: 'ones', useBias: false});\n    const output = dense.apply(input) as tfl.SymbolicTensor;\n    model = new tfl.LayersModel({inputs: input, outputs: output});\n  }\n  function prepData() {\n    x = ones([numExamples, inputSize]);\n    y = ones([numExamples, outputSize]);\n  }\n\n  it('Calling evaluate before compile leads to error', () => {\n    prepModel();\n    prepData();\n\n    expect(() => model.evaluate(x, y))\n        .toThrowError(/must compile a model before/);\n  });\n\n  const metricsValues: string[][] = [null, ['mse']];\n  const batchSizes = [null, 4, 16];\n  for (const metrics of metricsValues) {\n    for (const batchSize of batchSizes) {\n      const testTitle =\n          `metrics=${JSON.stringify(metrics)}, batchSize=${batchSize}`;\n      it(testTitle, () => {\n        prepModel();\n        prepData();\n        model.compile({optimizer: 'sgd', loss: 'meanSquaredError', metrics});\n        const losses = model.evaluate(x, y, {batchSize});\n        if (metrics == null) {\n          expectTensorsClose(losses as Scalar, scalar(1));\n        } else {\n          const lossesArray = losses as Scalar[];\n          expect(lossesArray.length).toEqual(2);\n          expectTensorsClose(lossesArray[0], scalar(1));\n          expectTensorsClose(lossesArray[1], scalar(1));\n        }\n      });\n    }\n  }\n\n  it('1D tensors as inputs and targets', () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({units: 1, inputShape: [1]}));\n    model.compile(\n        {loss: 'meanSquaredError', optimizer: 'sgd', metrics: ['acc']});\n\n    const xs = ones([10]);   // A batch of 10, as a 1D tensor.\n    const ys = zeros([10]);  // A batch of 10, as a 1D tensor.\n    // Do a burn-in call first.\n    tfc.dispose(model.evaluate(xs, ys, {batchSize: 4}));\n    const numTensors0 = memory().numTensors;\n    const evalOuts = model.evaluate(xs, ys, {batchSize: 4}) as Tensor[];\n    expect(evalOuts.length).toEqual(2);     // Loss and acc.\n    expect(evalOuts[0].shape).toEqual([]);  // Loss as a scalar.\n    expect(evalOuts[1].shape).toEqual([]);  // Acc as a scalar.\n    tfc.dispose(evalOuts);\n    // Assert no memory leak.\n    expect(memory().numTensors).toEqual(numTensors0);\n  });\n\n  it('Invalid batchSize value leads to Error', () => {\n    prepModel();\n    prepData();\n    expect(() => model.evaluate(x, y, {batchSize: 0}))\n        .toThrowError(\n            /batchSize is required to be a positive integer, but got 0/);\n    expect(() => model.evaluate(x, y, {batchSize: -2}))\n        .toThrowError(\n            /batchSize is required to be a positive integer, but got -2/);\n    expect(() => model.evaluate(x, y, {batchSize: 3.14}))\n        .toThrowError(\n            /batchSize is required to be a positive integer, but got 3\\.14/);\n    // tslint:disable-next-line:no-any\n    expect(() => model.evaluate(x, y, {batchSize: 'a' as any}))\n        .toThrowError(\n            /batchSize is required to be a positive integer, but got a/);\n  });\n});\n\ndescribe('LayersModel trainable setter and getter', () => {\n  it('Setting trainable does not affect Layers', () => {\n    const model = tfl.sequential({\n      layers: [\n        tfl.layers.flatten({inputShape: [2, 5]}),\n        // Initially non-trainable.\n        tfl.layers.dense({units: 3, activation: 'relu', trainable: false}),\n        tfl.layers.dense({units: 1}),\n      ]\n    });\n\n    model.trainable = false;\n    expect(model.trainable).toEqual(false);\n    // The trainable property of the layers should be unaffected.\n    expect(model.layers[0].trainable).toEqual(true);\n    expect(model.layers[1].trainable).toEqual(false);\n    expect(model.layers[2].trainable).toEqual(true);\n\n    model.trainable = true;\n    expect(model.trainable).toEqual(true);\n    expect(model.layers[0].trainable).toEqual(true);\n    expect(model.layers[1].trainable).toEqual(false);\n    expect(model.layers[2].trainable).toEqual(true);\n  });\n\n  it('Setting trainable of model sets trainable bit of Variable', async () => {\n    const model = tfl.sequential();\n    model.add(\n        tfl.layers.dense({units: 3, activation: 'relu', inputShape: [4]}));\n    model.add(tfl.layers.dense({units: 1, kernelInitializer: 'ones'}));\n    model.trainable = false;\n    expect(model.layers[0].weights[0].trainable).toEqual(false);\n    expect(model.layers[0].weights[1].trainable).toEqual(false);\n    expect(model.layers[1].weights[0].trainable).toEqual(false);\n    expect(model.layers[1].weights[1].trainable).toEqual(false);\n    model.trainable = true;\n    expect(model.layers[0].weights[0].trainable).toEqual(true);\n    expect(model.layers[0].weights[1].trainable).toEqual(true);\n    expect(model.layers[1].weights[0].trainable).toEqual(true);\n    expect(model.layers[1].weights[1].trainable).toEqual(true);\n  });\n\n  it('model.trainable respects layer.trainable', async () => {\n    const model = tfl.sequential();\n    model.add(\n        tfl.layers.dense({units: 3, activation: 'relu', inputShape: [4]}));\n    model.add(tfl.layers.dense({units: 1}));\n    expect(model.trainableWeights.length).toEqual(4);\n    model.layers[0].trainable = false;\n    expect(model.trainableWeights.length).toEqual(2);\n    model.trainable = false;\n    expect(model.trainableWeights.length).toEqual(0);\n    model.trainable = true;\n    expect(model.trainableWeights.length).toEqual(2);\n    model.layers[0].trainable = true;\n    expect(model.trainableWeights.length).toEqual(4);\n    model.trainable = false;\n    expect(model.trainableWeights.length).toEqual(0);\n  });\n});\n\ndescribeMathCPUAndGPU('LayersModel.execute', () => {\n  function createFunctionalModel():\n      [tfl.LayersModel, {[name: string]: tfl.SymbolicTensor}] {\n    const input1 = tfl.input({shape: [2, 3]});\n    const reshape1 = tfl.layers.reshape({targetShape: [3, 2]}).apply(input1) as\n        tfl.SymbolicTensor;\n    const input2 = tfl.input({shape: [3, 4]});\n    const concat =\n        tfl.layers.concatenate({axis: -1}).apply([reshape1, input2]) as\n        tfl.SymbolicTensor;\n    const model = tfl.model({inputs: [input1, input2], outputs: concat});\n\n    return [model, {input1, reshape1, input2, concat}];\n  }\n\n  function createSequentialModel(): tfl.Sequential {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({\n      units: 6,\n      inputShape: [4],\n      kernelInitializer: 'zeros',\n      useBias: false\n    }));\n    model.add(tfl.layers.dense(\n        {units: 3, kernelInitializer: 'zeros', useBias: false}));\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'zeros', useBias: false}));\n    return model;\n  }\n\n  it('Functional model: single output', () => {\n    const [model, layers] = createFunctionalModel();\n    const inputs = [zeros([1, 2, 3]), zeros([1, 3, 4])];\n    const outputs = model.execute(inputs, layers['reshape1'].name) as Tensor;\n    expectTensorsClose(outputs, zeros([1, 3, 2]));\n  });\n\n  it('Functional model: multiple outputs', () => {\n    const [model, layers] = createFunctionalModel();\n    const inputs = [zeros([1, 2, 3]), zeros([1, 3, 4])];\n    const outputs = model.execute(inputs, [\n      layers['reshape1'].name, layers['concat'].name, layers['input2'].name\n    ]) as Tensor[];\n    expectTensorsClose(outputs[0], zeros([1, 3, 2]));\n    expectTensorsClose(outputs[1], zeros([1, 3, 6]));\n    expectTensorsClose(outputs[2], zeros([1, 3, 4]));\n  });\n\n  it('Functional model: Dictionary of inputs', () => {\n    const [model, layers] = createFunctionalModel();\n    const inputName1 = model.inputs[0].name;\n    const inputName2 = model.inputs[1].name;\n    const inputs: NamedTensorMap = {};\n    inputs[inputName1] = zeros([1, 2, 3]);\n    inputs[inputName2] = zeros([1, 3, 4]);\n    const outputs = model.execute(inputs, [\n      layers['reshape1'].name, layers['concat'].name, layers['input2'].name\n    ]) as Tensor[];\n    expectTensorsClose(outputs[0], zeros([1, 3, 2]));\n    expectTensorsClose(outputs[1], zeros([1, 3, 6]));\n    expectTensorsClose(outputs[2], zeros([1, 3, 4]));\n  });\n\n  it('Functional model: missing input in dictionary throws Error', () => {\n    const [model, layers] = createFunctionalModel();\n    const inputName2 = model.inputs[1].name;\n    const inputs: NamedTensorMap = {};\n    inputs[inputName2] = zeros([1, 3, 4]);\n    expect(() => model.execute(inputs, layers['reshape1'].name))\n        .toThrowError(/No value is provided for .* input/);\n  });\n\n  it('Functional model: Incorrect number of inputs throws Error', () => {\n    const [model, layers] = createFunctionalModel();\n    const inputs = [zeros([1, 2, 3])];\n    expect(() => model.execute(inputs, layers['reshape1'].name))\n        .toThrowError(/The number of inputs provided \\(1\\) does not match .*2/);\n  });\n\n  it('Functional model: nonexistent tensor name throws Error', () => {\n    const [model, layers] = createFunctionalModel();\n    const inputs = [zeros([1, 2, 3]), zeros([1, 3, 4])];\n    const nonexistentTensorName =\n        layers['reshape1'].name + Math.random().toFixed(4);\n    expect(() => model.execute(inputs, nonexistentTensorName))\n        .toThrowError(/Cannot find SymbolicTensors for output name/);\n    expect(() => model.execute(inputs, [\n      layers['reshape1'].name, nonexistentTensorName\n    ])).toThrowError(/Cannot find SymbolicTensors for output name/);\n  });\n\n  it('Functional model: empty outputs string throws Error', () => {\n    const model = createFunctionalModel()[0];\n    const inputs = [zeros([1, 2, 3]), zeros([1, 3, 4])];\n    expect(() => model.execute(inputs, [])).toThrowError(/empty Array/);\n  });\n\n  it('Sequential model: singleton input', () => {\n    const model = createSequentialModel();\n    const input = zeros([2, 4]);\n    const outputs = model.execute(input, [\n      (model.layers[2].output as tfl.SymbolicTensor).name,\n      (model.layers[1].output as tfl.SymbolicTensor).name,\n      (model.layers[0].output as tfl.SymbolicTensor).name,\n    ]) as Tensor[];\n    expectTensorsClose(outputs[0], zeros([2, 1]));\n    expectTensorsClose(outputs[1], zeros([2, 3]));\n    expectTensorsClose(outputs[2], zeros([2, 6]));\n  });\n\n  it('Sequential model: length-1 Array input', () => {\n    const model = createSequentialModel();\n    const input = [zeros([2, 4])];\n    const output = model.execute(\n                       input,\n                       (model.layers[1].output as tfl.SymbolicTensor).name,\n                       ) as Tensor;\n    expectTensorsClose(output, zeros([2, 3]));\n  });\n\n  it('Sequential model: length-1 dictionary input', () => {\n    const model = createSequentialModel();\n    const inputs: NamedTensorMap = {};\n    inputs[(model.input as SymbolicTensor).name] = zeros([2, 4]);\n    const output = model.execute(\n                       inputs,\n                       (model.layers[1].output as tfl.SymbolicTensor).name,\n                       ) as Tensor;\n    expectTensorsClose(output, zeros([2, 3]));\n  });\n});\n"]}