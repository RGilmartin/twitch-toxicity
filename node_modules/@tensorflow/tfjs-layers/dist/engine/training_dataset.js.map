{"version":3,"file":"training_dataset.js","sourceRoot":"","sources":["../../src/engine/training_dataset.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;AAEH;;GAEG;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAC,MAAM,EAAC,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAe,kBAAkB,EAAsD,oBAAoB,EAAoB,MAAM,mBAAmB,CAAC;AAChK,OAAO,EAAC,mBAAmB,EAAE,UAAU,EAAC,MAAM,WAAW,CAAC;AAC1D,OAAO,EAAC,oBAAoB,EAAiB,MAAM,SAAS,CAAC;AAE7D,OAAO,EAAC,gBAAgB,EAAE,MAAM,EAAC,MAAM,wBAAwB,CAAC;AAGhE,OAAO,EAA8B,uBAAuB,EAAE,kBAAkB,EAAC,MAAM,kBAAkB,CAAC;AAiK1G,0DAA0D;AAC1D,MAAM,6BAA6B,GAAG,EAAE,CAAC;AAEzC;;;;;;;;;;;;;GAaG;AACH,SAAS,6BAA6B;AAClC,6DAA6D;AAC7D,eAAe;AACf,kCAAkC;AAClC,KAAU,EAAE,WAAe;IAC7B,IAAI,EAAsB,CAAC;IAC3B,IAAI,EAAsB,CAAC;IAE3B,MAAM,cAAc,GAAG,WAAgC,CAAC;IACxD,EAAE,GAAG,cAAc,CAAC,IAAI,CAAC,CAAC;IAC1B,EAAE,GAAG,cAAc,CAAC,IAAI,CAAC,CAAC;IAC1B,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,EAAE,IAAI,IAAI,IAAI,EAAE,IAAI,IAAI,EACxB,GAAG,EAAE,CAAC,8DAA8D;QAChE,4DAA4D;QAC5D,8DAA8D;QAC9D,4DAA4D;QAC5D,GAAG,WAAW,EAAE,CAAC,CAAC;IAE1B,MAAM,WAAW,GACb,yBAAyB,CAAC,OAAO,EAAE,KAAK,CAAC,UAAU,EAAE,EAAE,CAAC,CAAC;IAC7D,MAAM,WAAW,GACb,yBAAyB,CAAC,QAAQ,EAAE,KAAK,CAAC,WAAW,EAAE,EAAE,CAAC,CAAC;IAE/D,MAAM,SAAS,GAAW,WAAW,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;IAElD,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,WAAW,CAAC,MAAM,KAAK,KAAK,CAAC,MAAM,CAAC,MAAM,EAC1C,GAAG,EAAE,CAAC,mBAAmB,KAAK,CAAC,MAAM,CAAC,MAAM,2BAA2B;QACnE,YAAY,WAAW,CAAC,MAAM,kCAAkC;QAChE,GAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC;IAEhD,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,WAAW,CAAC,MAAM,KAAK,KAAK,CAAC,OAAO,CAAC,MAAM,EAC3C,GAAG,EAAE,CACD,mBAAmB,KAAK,CAAC,OAAO,CAAC,MAAM,4BAA4B;QACnE,YAAY,WAAW,CAAC,MAAM,oCAAoC;QAClE,GAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;IAEjD,KAAK,IAAI,MAAM,GAAG,CAAC,EAAE,MAAM,GAAG,WAAW,CAAC,MAAM,EAAE,MAAM,EAAE,EAAE;QAC1D,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,WAAW,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,SAAS,EAC1C,GAAG,EAAE,CAAC,6BAA6B;YAC/B,GAAG,KAAK,CAAC,UAAU,CAAC,MAAM,CAAC,QACrB,WAAW,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI;YACtC,aAAa,SAAS,mBAAmB,KAAK,CAAC,UAAU,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;KAC1E;IAED,KAAK,IAAI,MAAM,GAAG,CAAC,EAAE,MAAM,GAAG,WAAW,CAAC,MAAM,EAAE,MAAM,EAAE,EAAE;QAC1D,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,WAAW,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,SAAS,EAC1C,GAAG,EAAE,CAAC,8BAA8B;YAChC,GAAG,KAAK,CAAC,WAAW,CAAC,MAAM,CAAC,QACtB,WAAW,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI;YACtC,aAAa,SAAS,mBAAmB,KAAK,CAAC,UAAU,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;KAC1E;IAED,OAAO,EAAC,EAAE,EAAE,WAAW,EAAE,EAAE,EAAE,WAAW,EAAC,CAAC;AAC5C,CAAC;AAED,SAAS,yBAAyB,CAC9B,aAAqB,EAAE,KAAe,EAAE,MAA0B;IACpE,IAAI,MAAM,YAAY,GAAG,CAAC,MAAM,EAAE;QAChC,OAAO,CAAC,MAAM,CAAC,CAAC;KACjB;SAAM,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;QAChC,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,MAAM,CAAC,MAAM,KAAK,KAAK,CAAC,MAAM,EAC9B,GAAG,EAAE,CAAC,wBAAwB,MAAM,CAAC,MAAM,0BACvC,KAAK,CAAC,MAAM,iBAAiB,aAAa,SAAS,KAAK,GAAG,CAAC,CAAC;QACrE,OAAO,MAAM,CAAC;KACf;SAAM;QACL,MAAM,MAAM,GAAiB,EAAE,CAAC;QAChC,kDAAkD;QAClD,KAAK,MAAM,IAAI,IAAI,KAAK,EAAE;YACxB,IAAI,MAAM,CAAC,IAAI,CAAC,IAAI,IAAI,EAAE;gBACxB,MAAM,IAAI,UAAU,CAChB,+DAA+D;oBAC/D,GAAG,aAAa,SAAS,IAAI,IAAI,CAAC,CAAC;aACxC;YACD,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;SAC3B;QACD,OAAO,MAAM,CAAC;KACf;AACH,CAAC;AAED,SAAS,+BAA+B,CACpC,IAIiC;IAEnC,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;QACrB,MAAM,IAAI,mBAAmB,CACzB,wDAAwD,CAAC,CAAC;KAC/D;IACD,OAAO,EAAC,EAAE,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC,CAAC,EAAC,CAAC;AACpC,CAAC;AAED,MAAM,CAAC,KAAK,UAAU,UAAU;AAC5B,6DAA6D;AAC7D,eAAe;AACf,kCAAkC;AAClC,KAAU,EAAE,OAAmB,EAC/B,IAA4B;IAC9B,MAAM,kBAAkB,GAAG,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC;IACxD,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,KAAK,CAAC,SAAS,IAAI,IAAI,EACvB,GAAG,EAAE,CAAC,wDAAwD;QAC1D,0CAA0C,CAAC,CAAC;IAEpD,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,IAAI,IAAI,IAAI,EACZ,GAAG,EAAE,CAAC,2DAA2D;QAC7D,sCAAsC,CAAC,CAAC;IAChD,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,IAAI,CAAC,MAAM,IAAI,IAAI,IAAI,IAAI,CAAC,MAAM,GAAG,CAAC,IAAI,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,MAAM,CAAC,EACvE,GAAG,EAAE,CAAC,+DAA+D;QACjE,oBAAoB,IAAI,CAAC,MAAM,EAAE,CAAC,CAAC;IAC3C,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,CAAC,kBAAkB;QACf,CAAC,IAAI,CAAC,eAAe,GAAG,CAAC,IAAI,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC,EACxE,GAAG,EAAE,CAAC,+DAA+D;QACjE,0CAA0C,IAAI,CAAC,eAAe,EAAE,CAAC,CAAC;IAC1E,GAAG,CAAC,IAAI,CAAC,MAAM;IACX,kCAAkC;IACjC,IAAY,CAAC,iBAAiB,CAAC,IAAI,IAAI,EACxC,GAAG,EAAE,CAAC,wDAAwD;QAC1D,6BAA6B,CAAC,CAAC;IAEvC,IAAI,KAAK,CAAC,UAAU,EAAE;QACpB,MAAM,IAAI,KAAK,CACX,8DAA8D,CAAC,CAAC;KACrE;IACD,KAAK,CAAC,UAAU,GAAG,IAAI,CAAC;IAExB,IAAI;QACF,MAAM,YAAY,GAAG,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC;QACjD,IAAI,KAA8B,CAAC;QACnC,IAAI,KAA8B,CAAC;QACnC,IAAI,YAAY,EAAE;YAChB,IAAI,eAAe,CAAC,IAAI,CAAC,cAAc,CAAC,EAAE;gBACxC,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,IAAI,CAAC,iBAAiB,IAAI,IAAI;oBAC1B,CAAC,IAAI,CAAC,iBAAiB,GAAG,CAAC;wBAC1B,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC,EAC9C,GAAG,EAAE,CAAC,kDAAkD;oBACpD,2DAA2D;oBAC3D,+BAA+B;oBAC/B,WAAW,IAAI,CAAC,iBAAiB,EAAE,CAAC,CAAC;aAC9C;iBAAM;gBACL,MAAM,cAAc,GAAG,+BAA+B,CAClD,IAAI,CAAC,cAKJ,CAAC,CAAC;gBACP,KAAK,GAAG,cAAc,CAAC,EAAE,CAAC;gBAC1B,KAAK,GAAG,cAAc,CAAC,EAAE,CAAC;aAC3B;SACF;QAED,MAAM,aAAa,GAAG,KAAK,CAAC,iBAAiB,EAAE,CAAC;QAChD,MAAM,SAAS,GAAG,KAAK,CAAC,sBAAsB,EAAc,CAAC;QAE7D,IAAI,eAAyB,CAAC;QAC9B,IAAI,YAAY,EAAE;YAChB,eAAe;gBACX,SAAS,CAAC,KAAK,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC;SAC9D;aAAM;YACL,eAAe,GAAG,SAAS,CAAC,KAAK,EAAE,CAAC;SACrC;QAED,MAAM,SAAS,GAAG,oBAAoB,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;QACxE,MAAM,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;QACxD,MAAM,EAAC,YAAY,EAAE,OAAO,EAAC,GAAG,kBAAkB,CAC9C,SAAS,EAAE,OAAO,EAAE,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,IAAI,EAC3C,gBAAgB,CAAC,OAAO,EAAE,IAAI,CAAC,EAC/B,IAAI,EAAG,+CAA+C;QACtD,YAAY,EAAE,eAAe,CAAC,CAAC;QACnC,YAAY,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC;QAC7B,KAAK,CAAC,OAAO,GAAG,OAAO,CAAC;QAExB,MAAM,YAAY,CAAC,YAAY,EAAE,CAAC;QAClC,KAAK,CAAC,aAAa,GAAG,KAAK,CAAC;QAC5B,IAAI,KAAK,GAAG,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC;QAE9D,IAAI,YAAY,GAAG,MAAM,OAAO,CAAC,QAAQ,EAAE,CAAC;QAC5C,OAAO,KAAK,GAAG,IAAI,CAAC,MAAM,EAAE;YAC1B,MAAM,SAAS,GAAmB,EAAE,CAAC;YACrC,MAAM,YAAY,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC;YACvC,IAAI,SAAS,GAAG,CAAC,CAAC;YAClB,IAAI,UAAU,GAAG,CAAC,CAAC;YACnB,IAAI,CAAC,kBAAkB,EAAE;gBACvB,YAAY,GAAG,MAAM,OAAO,CAAC,QAAQ,EAAE,CAAC;aACzC;YACD,OAAO,kBAAkB,CAAC,CAAC,CAAC,SAAS,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,IAAI,EAAE;gBACnE,MAAM,WAAW,GAAG,MAAM,YAAY,CAAC,IAAI,EAAE,CAAC;gBAE9C,+DAA+D;gBAC/D,wCAAwC;gBACxC,IAAI,kBAAkB,IAAI,WAAW,CAAC,IAAI,EAAE;oBAC1C,OAAO,CAAC,IAAI,CACR,oCAAoC;wBACpC,GAAG,IAAI,CAAC,eAAe,IAAI;wBAC3B,kDAAkD;wBAClD,GAAG,SAAS,YAAY;wBACxB,6CAA6C;wBAC7C,2DAA2D;wBAC3D,yBAAyB;wBACzB,GAAG,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,MAAM,aAAa;wBAClD,0DAA0D;wBAC1D,eAAe,CAAC,CAAC;oBACrB,MAAM;iBACP;gBAED,IAAI,WAAW,CAAC,KAAK,IAAI,IAAI,EAAE;oBAC7B,MAAM,EAAC,EAAE,EAAE,EAAE,EAAC,GACV,6BAA6B,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,CAAC,CAAC;oBAC5D,MAAM,SAAS,GAAmB,EAAE,CAAC;oBACrC,SAAS,CAAC,OAAO,CAAC,GAAG,UAAU,CAAC;oBAChC,SAAS,CAAC,MAAM,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;oBAEnC,MAAM,YAAY,CAAC,YAAY,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC;oBAEvD,MAAM,aAAa,GAAiB,EAAE,CAAC;oBACvC,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;wBAC5B,MAAM,oBAAoB,GACtB,uBAAuB,CAAC,IAAI,CAAC,WAAW,EAAE,KAAK,CAAC,WAAW,CAAC,CAAC;wBACjE,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,oBAAoB,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;4BACpD,aAAa,CAAC,IAAI,CAAC,MAAM,kBAAkB,CACvC,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,oBAAoB,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;yBAC5C;qBACF;oBAED,kBAAkB;oBAClB,MAAM,GAAG,GAAG,EAAE,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;oBAChD,MAAM,IAAI,GAAG,aAAa,CAAC,GAAG,CAAC,CAAC;oBAChC,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC;oBACjB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;wBACzC,MAAM,KAAK,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;wBAC3B,MAAM,GAAG,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;wBACpB,SAAS,CAAC,KAAK,CAAC,GAAG,GAAG,CAAC;wBACvB,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;qBACf;oBAED,MAAM,YAAY,CAAC,UAAU,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC;oBACrD,oBAAoB,CAAC,SAAS,CAAC,CAAC;oBAEhC,UAAU,EAAE,CAAC;oBACb,SAAS,EAAE,CAAC;iBACb;gBAED,IAAI,kBAAkB,CAAC,CAAC,CAAC,SAAS,IAAI,IAAI,CAAC,eAAe,CAAC,CAAC;oBACnC,WAAW,CAAC,IAAI,EAAE;oBACzC,sCAAsC;oBACtC,IAAI,YAAY,EAAE;wBAChB,IAAI,OAAqB,CAAC;wBAC1B,IAAI,eAAe,CAAC,IAAI,CAAC,cAAc,CAAC,EAAE;4BACxC,OAAO,GAAG,MAAM,CAAC,MAAM,KAAK,CAAC,eAAe,CACxC,IAAI,CAAC,cAAc,EAAE,EAAC,OAAO,EAAE,IAAI,CAAC,iBAAiB,EAAC,CAAC,CAAC,CAAC;yBAC9D;6BAAM;4BACL,OAAO,GAAG,MAAM,CAAC,KAAK,CAAC,QAAQ,CAAC,KAAK,EAAE,KAAK,EAAE;gCAC5C,SAAS,EAAE,IAAI,CAAC,mBAAmB,IAAI,IAAI,CAAC,CAAC;oCACzC,6BAA6B,CAAC,CAAC;oCAC/B,IAAI,CAAC,mBAAmB;gCAC5B,OAAO,EAAE,CAAC;6BACX,CAAC,CAAC,CAAC;yBACL;wBACD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,YAAY,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;4BAClD,SAAS,CAAC,OAAO,KAAK,CAAC,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;yBACxD;qBACF;oBACD,mEAAmE;oBACnE,gEAAgE;oBAChE,wDAAwD;oBACxD,mEAAmE;oBACnE,8DAA8D;oBAC9D,MAAM;iBACP;gBAED,IAAI,KAAK,CAAC,aAAa,EAAE;oBACvB,MAAM;iBACP;aACF;YACD,MAAM,YAAY,CAAC,UAAU,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;YAChD,KAAK,EAAE,CAAC;YACR,IAAI,KAAK,CAAC,aAAa,EAAE;gBACvB,MAAM;aACP;SACF;QACD,MAAM,YAAY,CAAC,UAAU,EAAE,CAAC;QAChC,MAAM,KAAK,CAAC,OAAO,CAAC,QAAQ,EAAE,CAAC;QAC/B,OAAO,KAAK,CAAC,OAAO,CAAC;KACtB;YAAS;QACR,KAAK,CAAC,UAAU,GAAG,KAAK,CAAC;KAC1B;AACH,CAAC;AAED,2EAA2E;AAC3E,SAAS,gBAAgB,CACrB,OAAmB,EAAE,IAA4B;IACnD,iDAAiD;IACjD,IAAI,aAAa,GAAW,IAAI,CAAC;IACjC,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,EAAE;QAChC,aAAa,GAAG,IAAI,CAAC,eAAe,CAAC;KACtC;SAAM,IAAI,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;QACxC,aAAa,GAAG,OAAO,CAAC,IAAI,CAAC;KAC9B;IACD,OAAO,aAAa,CAAC;AACvB,CAAC;AAED,yEAAyE;AACzE,WAAW;AACX,SAAS,eAAe,CACpB,OAIU;IACZ,OAAO,CAAC,OAAQ,OAAsB,CAAC,QAAQ,KAAK,UAAU,CAAC,CAAC;AAClE,CAAC;AAED,2EAA2E;AAC3E,WAAW;AACX,SAAS,oBAAoB,CAAI,QACe;IAC9C,OAAO,CAAC,OAAQ,QAA4B,CAAC,IAAI,KAAK,UAAU,CAAC,CAAC;AACpE,CAAC;AAED,MAAM,CAAC,KAAK,UAAU,eAAe;AACjC,6DAA6D;AAC7D,eAAe;AACf,kCAAkC;AAClC,KAAU,EAAE,OAAmC,EAC/C,IAA8B;IAChC,IAAI,GAAG,IAAI,IAAI,EAAE,CAAC;IAClB,MAAM,UAAU,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC;IACxC,MAAM,CAAC,GAAG,KAAK,CAAC,YAAY,CAAC;IAC7B,IAAI,IAAI,GAAiB,EAAE,CAAC;IAC5B,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE;QACpB,MAAM,IAAI,mBAAmB,CAAC,sCAAsC,CAAC,CAAC;KACvE;IAED,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,CAAC,UAAU,IAAI,CAAC,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,EACnE,GAAG,EAAE,CAAC,4DAA4D;QAC9D,YAAY,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;IACpD,MAAM,YAAY,GAAG,oBAAoB,CAAC,OAAO,CAAC,CAAC,CAAC;QAChD,OAA0B,CAAA,CAAC;QAC3B,MAAO,OAAsB,CAAC,QAAQ,EAAE,CAAC;IAC7C,6DAA6D;IAC7D,IAAI,WAAW,GAAG,CAAC,CAAC;IACpB,IAAI,KAAK,GAAG,CAAC,CAAC;IAEd,OAAO,UAAU,CAAC,CAAC,CAAC,KAAK,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,EAAE;QAC/C,MAAM,WAAW,GAAG,MAAM,YAAY,CAAC,IAAI,EAAE,CAAC;QAC9C,IAAI,GAAG,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE;YACnB,IAAI,WAAW,CAAC,KAAK,EAAE;gBACrB,kDAAkD;gBAClD,+DAA+D;gBAC/D,MAAM,EAAC,EAAE,EAAE,EAAE,EAAC,GACV,6BAA6B,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,CAAC,CAAC;gBAC5D,MAAM,OAAO,GAAG,EAAE,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC;gBAC9B,MAAM,SAAS,GAAG,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC;gBAC7C,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;gBAErB,IAAI,KAAK,KAAK,CAAC,EAAE;oBACf,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;wBACzC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;qBACtB;iBACF;gBAED,MAAM,SAAS,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;gBACtC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;oBACzC,MAAM,QAAQ,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;oBAC9B,MAAM,SAAS,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,CAAC,CAAC;wBACH,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,SAAS,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC;oBACnE,IAAI,KAAK,GAAG,CAAC,EAAE;wBACb,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;qBACxB;iBACF;gBACD,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;gBACvB,WAAW,IAAI,SAAS,CAAC;gBAEzB,EAAE,KAAK,CAAC;aACT;YACD,OAAO,IAAI,CAAC;QACd,CAAC,CAAC,CAAC;QAEH,IAAI,WAAW,CAAC,IAAI,EAAE;YACpB,IAAI,UAAU,EAAE;gBACd,OAAO,CAAC,IAAI,CACR,kEAAkE;oBAClE,8CAA8C;oBAC9C,0CAA0C;oBAC1C,0BAA0B,IAAI,CAAC,OAAO,aAAa;oBACnD,0DAA0D;oBAC1D,eAAe,CAAC,CAAC;aACtB;YACD,MAAM;SACP;KACF;IAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;QACpC,MAAM,SAAS,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;QAC1B,IAAI,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC;QACxC,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;KACxB;IAED,OAAO,gBAAgB,CAAC,IAAI,CAAC,CAAC;AAChC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using TensorFlow.js datasets.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {scalar} from '@tensorflow/tfjs-core';\nimport {BaseCallback, configureCallbacks, CustomCallbackArgs, History, ModelLoggingVerbosity, standardizeCallbacks, YieldEveryOptions} from '../base_callbacks';\nimport {NotImplementedError, ValueError} from '../errors';\nimport {disposeTensorsInLogs, UnresolvedLogs} from '../logs';\nimport {TensorOrArrayOrMap} from '../types';\nimport {singletonOrArray, toList} from '../utils/generic_utils';\n\nimport {Dataset, LazyIterator} from './dataset_stub';\nimport {ClassWeight, ClassWeightMap, standardizeClassWeights, standardizeWeights} from './training_utils';\n\n/**\n * Interface for configuring model training based on a dataset object.\n */\nexport interface ModelFitDatasetArgs<T> {\n  /**\n   * (Optional) Total number of steps (batches of samples) before\n   * declaring one epoch finished and starting the next epoch. It should\n   * typically be equal to the number of samples of your dataset divided by\n   * the batch size, so that `fitDataset`() call can utilize the entire dataset.\n   * If it is not provided, use `done` return value in `iterator.next()` as\n   * signal to finish an epoch.\n   */\n  batchesPerEpoch?: number;\n\n  /**\n   * Integer number of times to iterate over the training dataset.\n   */\n  epochs: number;\n\n  /**\n   * Verbosity level.\n   *\n   * Expected to be 0, 1, or 2. Default: 1.\n   *\n   * 0 - No printed message during fit() call.\n   * 1 - In Node.js (tfjs-node), prints the progress bar, together with\n   *     real-time updates of loss and metric values and training speed.\n   *     In the browser: no action. This is the default.\n   * 2 - Not implemented yet.\n   */\n  verbose?: ModelLoggingVerbosity;\n\n  /**\n   * List of callbacks to be called during training.\n   * Can have one or more of the following callbacks:\n   *   - `onTrainBegin(logs)`: called when training starts.\n   *   - `onTrainEnd(logs)`: called when training ends.\n   *   - `onEpochBegin(epoch, logs)`: called at the start of every epoch.\n   *   - `onEpochEnd(epoch, logs)`: called at the end of every epoch.\n   *   - `onBatchBegin(batch, logs)`: called at the start of every batch.\n   *   - `onBatchEnd(batch, logs)`: called at the end of every batch.\n   *   - `onYield(epoch, batch, logs)`: called every `yieldEvery` milliseconds\n   *      with the current epoch, batch and logs. The logs are the same\n   *      as in `onBatchEnd()`. Note that `onYield` can skip batches or\n   *      epochs. See also docs for `yieldEvery` below.\n   */\n  callbacks?: BaseCallback[]|CustomCallbackArgs|CustomCallbackArgs[];\n\n  /**\n   * Data on which to evaluate the loss and any model\n   * metrics at the end of each epoch. The model will not be trained on this\n   * data. This could be any of the following:\n   *\n   *   - An array `[xVal, yVal]`, where the two values may be `tf.Tensor`,\n   *     an array of Tensors, or a map of string to Tensor.\n   *   - Similarly, an array ` [xVal, yVal, valSampleWeights]`\n   *     (not implemented yet).\n   *   - a `Dataset` object with elements of the form `{xs: xVal, ys: yVal}`,\n   *     where `xs` and `ys` are the feature and label tensors, respectively.\n   *\n   * If `validationData` is an Array of Tensor objects, each `tf.Tensor` will be\n   * sliced into batches during validation, using the parameter\n   * `validationBatchSize` (which defaults to 32). The entirety of the\n   * `tf.Tensor` objects will be used in the validation.\n   *\n   * If `validationData` is a dataset object, and the `validationBatches`\n   * parameter is specified, the validation will use `validationBatches` batches\n   * drawn from the dataset object. If `validationBatches` parameter is not\n   * specified, the validation will stop when the dataset is exhausted.\n   *\n   * The model will not be trained on this data.\n   */\n  validationData?: [\n    TensorOrArrayOrMap, TensorOrArrayOrMap\n  ]|[TensorOrArrayOrMap, TensorOrArrayOrMap, TensorOrArrayOrMap]|Dataset<T>;\n\n  /**\n   * Optional batch size for validation.\n   *\n   * Used only if `validationData` is an array of `tf.Tensor` objects, i.e., not\n   * a dataset object.\n   *\n   * If not specified, its value defaults to 32.\n   */\n  validationBatchSize?: number;\n\n  /**\n   * (Optional) Only relevant if `validationData` is specified and is a dataset\n   * object.\n   *\n   * Total number of batches of samples to draw from `validationData` for\n   * validation purpose before stopping at the end of every epoch. If not\n   * specified, `evaluateDataset` will use `iterator.next().done` as signal to\n   * stop validation.\n   */\n  validationBatches?: number;\n\n  /**\n   * Configures the frequency of yielding the main thread to other tasks.\n   *\n   * In the browser environment, yielding the main thread can improve the\n   * responsiveness of the page during training. In the Node.js environment,\n   * it can ensure tasks queued in the event loop can be handled in a timely\n   * manner.\n   *\n   * The value can be one of the following:\n   *   - `'auto'`: The yielding happens at a certain frame rate (currently set\n   *               at 125ms). This is the default.\n   *   - `'batch'`: yield every batch.\n   *   - `'epoch'`: yield every epoch.\n   *   - a `number`: Will yield every `number` milliseconds.\n   *   - `'never'`: never yield. (But yielding can still happen through `await\n   *      nextFrame()` calls in custom callbacks.)\n   */\n  yieldEvery?: YieldEveryOptions;\n\n  /**\n   * Epoch at which to start training (useful for resuming a previous training\n   * run). When this is used, `epochs` is the index of the \"final epoch\".\n   * The model is not trained for a number of iterations given by `epochs`,\n   * but merely until the epoch of index `epochs` is reached.\n   */\n  initialEpoch?: number;\n\n  /**\n   * Optional object mapping class indices (integers) to\n   * a weight (float) to apply to the model's loss for the samples from this\n   * class during training. This can be useful to tell the model to \"pay more\n   * attention\" to samples from an under-represented class.\n   *\n   * If the model has multiple outputs, a class weight can be specified for\n   * each of the outputs by setting this field an array of weight object\n   * or a object that maps model output names (e.g., `model.outputNames[0]`)\n   * to weight objects.\n   */\n  classWeight?: ClassWeight|ClassWeight[]|ClassWeightMap;\n}\n\nexport interface FitDatasetElement {\n  xs: TensorOrArrayOrMap;\n  ys: TensorOrArrayOrMap;\n}\n\n/**\n * Interface for configuring model evaluation based on a dataset object.\n */\nexport interface ModelEvaluateDatasetArgs {\n  /**\n   * Number of batches to draw from the dataset object before ending the\n   * evaluation.\n   */\n  batches?: number;\n\n  /**\n   * Verbosity mode.\n   */\n  verbose?: ModelLoggingVerbosity;\n}\n\n// Default batch size used during tensor-based validation.\nconst DEFAULT_VALIDATION_BATCH_SIZE = 32;\n\n/**\n * Standardize the output of a dataset iterator for use by\n * LayersModel.fitDataset().\n *\n * @param model: A `tf.LayersModel` object.\n * @param iteratorOut The output of a dataset iterator. It is required to be\n *   an object of the form `{xs: TensorOrArrayOrMap, ys:\n * TensorOrArrayOrMap}`, where `TensorOrArrayOrMap` is a single `tf.Tensor`,\n * a `tf.Tensor[]`, or a flat map from string names to `tf.Tensor`s.\n * @returns A flat array of `tf.Tensor` objects: the input `tf.Tensor`s\n *   followed by the target `tf.Tensor`s.  When `tf.Tensor`s are provided\n *   as a map, the order in the resulting array is taken from the `inputNames`\n *   and `outputNames` of the model.\n */\nfunction standardizeDataIteratorOutput(\n    // Type `model` as `any` here to avoid circular dependency w/\n    // training.ts.\n    // tslint:disable-next-line:no-any\n    model: any, iteratorOut: {}): {xs: tfc.Tensor[], ys: tfc.Tensor[]} {\n  let xs: TensorOrArrayOrMap;\n  let ys: TensorOrArrayOrMap;\n\n  const iteratorOutObj = iteratorOut as FitDatasetElement;\n  xs = iteratorOutObj['xs'];\n  ys = iteratorOutObj['ys'];\n  tfc.util.assert(\n      xs != null && ys != null,\n      () => 'A Dataset iterator for fitDataset() is expected to generate ' +\n          'objects of the form `{xs: xVal, ys: yVal}`, where the two ' +\n          'values may be `tf.Tensor`, an array of Tensors, or a map of ' +\n          'string to Tensor.  The provided Dataset instead generates ' +\n          `${iteratorOut}`);\n\n  const flattenedXs: tfc.Tensor[] =\n      flattenTensorOrArrayOrMap('input', model.inputNames, xs);\n  const flattenedYs: tfc.Tensor[] =\n      flattenTensorOrArrayOrMap('output', model.outputNames, ys);\n\n  const batchSize: number = flattenedXs[0].shape[0];\n\n  tfc.util.assert(\n      flattenedXs.length === model.inputs.length,\n      () => `LayersModel has ${model.inputs.length} inputs, but the dataset ` +\n          `provides ${flattenedXs.length} inputs.  (Expected input keys: ` +\n          `${JSON.stringify(model.inputNames)})`);\n\n  tfc.util.assert(\n      flattenedYs.length === model.outputs.length,\n      () =>\n          `LayersModel has ${model.outputs.length} outputs, but the dataset ` +\n          `provides ${flattenedYs.length} outputs.  (Expected output keys: ` +\n          `${JSON.stringify(model.outputNames)})`);\n\n  for (let xIndex = 0; xIndex < flattenedXs.length; xIndex++) {\n    tfc.util.assert(\n        flattenedXs[xIndex].shape[0] === batchSize,\n        () => `Batch size mismatch: input ` +\n            `${model.inputNames[xIndex]} has ${\n                  flattenedXs[xIndex].shape[0]}; ` +\n            `expected  ${batchSize} based on input ${model.inputNames[0]}.`);\n  }\n\n  for (let yIndex = 0; yIndex < flattenedYs.length; yIndex++) {\n    tfc.util.assert(\n        flattenedYs[yIndex].shape[0] === batchSize,\n        () => `Batch size mismatch: output ` +\n            `${model.outputNames[yIndex]} has ${\n                  flattenedYs[yIndex].shape[0]}; ` +\n            `expected  ${batchSize} based on input ${model.inputNames[0]}.`);\n  }\n\n  return {xs: flattenedXs, ys: flattenedYs};\n}\n\nfunction flattenTensorOrArrayOrMap(\n    inputOrOutput: string, names: string[], values: TensorOrArrayOrMap) {\n  if (values instanceof tfc.Tensor) {\n    return [values];\n  } else if (Array.isArray(values)) {\n    tfc.util.assert(\n        values.length === names.length,\n        () => `Received an array of ${values.length} Tensors, but expected ${\n            names.length} to match the ${inputOrOutput} keys ${names}.`);\n    return values;\n  } else {\n    const result: tfc.Tensor[] = [];\n    // Check that all the required keys are available.\n    for (const name of names) {\n      if (values[name] == null) {\n        throw new ValueError(\n            `The feature data generated by the dataset lacks the required ` +\n            `${inputOrOutput} key '${name}'.`);\n      }\n      result.push(values[name]);\n    }\n    return result;\n  }\n}\n\nfunction standardizeTensorValidationData<T>(\n    data:\n        [\n          tfc.Tensor|tfc.Tensor[], tfc.Tensor|tfc.Tensor[]\n        ]|[tfc.Tensor | tfc.Tensor[], tfc.Tensor | tfc.Tensor[],\n           tfc.Tensor | tfc.Tensor[]]):\n    {xs: tfc.Tensor|tfc.Tensor[], ys: tfc.Tensor|tfc.Tensor[]} {\n  if (data.length === 3) {\n    throw new NotImplementedError(\n        'Validation with sample weights is not implemented yet.');\n  }\n  return {xs: data[0], ys: data[1]};\n}\n\nexport async function fitDataset<T>(\n    // Type `model` as `any` here to avoid circular dependency w/\n    // training.ts.\n    // tslint:disable-next-line:no-any\n    model: any, dataset: Dataset<T>,\n    args: ModelFitDatasetArgs<T>): Promise<History> {\n  const hasBatchesPerEpoch = args.batchesPerEpoch != null;\n  tfc.util.assert(\n      model.optimizer != null,\n      () => 'You must compile a model before training/testing. Use ' +\n          'LayersModel.compile(modelCompileConfig).');\n\n  tfc.util.assert(\n      args != null,\n      () => `For fitDataset(), the 2nd argument (config) is required, ` +\n          `but it is not provided in this call.`);\n  tfc.util.assert(\n      args.epochs != null && args.epochs > 0 && Number.isInteger(args.epochs),\n      () => `For fitDataset(), config.epochs is expected to be a positive ` +\n          `integer, but got ${args.epochs}`);\n  tfc.util.assert(\n      !hasBatchesPerEpoch ||\n          (args.batchesPerEpoch > 0 && Number.isInteger(args.batchesPerEpoch)),\n      () => `For fitDataset(), config.batchesPerEpoch is expected to be a ` +\n          `positive integer if specified, but got ${args.batchesPerEpoch}`);\n  tfc.util.assert(\n      // tslint:disable-next-line:no-any\n      (args as any)['validationSplit'] == null,\n      () => '`validationSplit` is not supported by `fitDataset()`. ' +\n          'Use validationData instead.');\n\n  if (model.isTraining) {\n    throw new Error(\n        'Cannot start training because another fit() call is ongoing.');\n  }\n  model.isTraining = true;\n\n  try {\n    const doValidation = args.validationData != null;\n    let valXs: tfc.Tensor|tfc.Tensor[];\n    let valYs: tfc.Tensor|tfc.Tensor[];\n    if (doValidation) {\n      if (isDatasetObject(args.validationData)) {\n        tfc.util.assert(\n            args.validationBatches == null ||\n                (args.validationBatches > 0 &&\n                 Number.isInteger(args.validationBatches)),\n            () => `For fitDataset() with dataset-based validation, ` +\n                `config.validationBatches is expected not to be provided, ` +\n                `or to be a positive integer, ` +\n                `but got ${args.validationBatches}`);\n      } else {\n        const validationData = standardizeTensorValidationData(\n            args.validationData as\n                    [tfc.Tensor | tfc.Tensor[], tfc.Tensor | tfc.Tensor[]] |\n            [\n              tfc.Tensor | tfc.Tensor[], tfc.Tensor | tfc.Tensor[],\n              tfc.Tensor | tfc.Tensor[]\n            ]);\n        valXs = validationData.xs;\n        valYs = validationData.ys;\n      }\n    }\n\n    const trainFunction = model.makeTrainFunction();\n    const outLabels = model.getDedupedMetricsNames() as string[];\n\n    let callbackMetrics: string[];\n    if (doValidation) {\n      callbackMetrics =\n          outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n    } else {\n      callbackMetrics = outLabels.slice();\n    }\n\n    const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n    const verbose = args.verbose == null ? 1 : args.verbose;\n    const {callbackList, history} = configureCallbacks(\n        callbacks, verbose, args.epochs, null, null,\n        getStepsPerEpoch(dataset, args),\n        null,  // Batch size determined by the dataset itself.\n        doValidation, callbackMetrics);\n    callbackList.setModel(model);\n    model.history = history;\n\n    await callbackList.onTrainBegin();\n    model.stopTraining_ = false;\n    let epoch = args.initialEpoch == null ? 0 : args.initialEpoch;\n\n    let dataIterator = await dataset.iterator();\n    while (epoch < args.epochs) {\n      const epochLogs: UnresolvedLogs = {};\n      await callbackList.onEpochBegin(epoch);\n      let stepsDone = 0;\n      let batchIndex = 0;\n      if (!hasBatchesPerEpoch) {\n        dataIterator = await dataset.iterator();\n      }\n      while (hasBatchesPerEpoch ? stepsDone < args.batchesPerEpoch : true) {\n        const iteratorOut = await dataIterator.next();\n\n        // If `batchesPerEpoch` is specified, the dataset should not be\n        // exhausted until all epoches are done.\n        if (hasBatchesPerEpoch && iteratorOut.done) {\n          console.warn(\n              'You provided `batchesPerEpoch` as ' +\n              `${args.batchesPerEpoch}, ` +\n              'but your dataset iterator ran out of data after ' +\n              `${stepsDone} batches; ` +\n              'interrupting training. Make sure that your ' +\n              'dataset can generate at least `batchesPerEpoch * epochs` ' +\n              'batches (in this case, ' +\n              `${args.batchesPerEpoch * args.epochs} batches). ` +\n              'You may need to use the repeat() function when building ' +\n              'your dataset.');\n          break;\n        }\n\n        if (iteratorOut.value != null) {\n          const {xs, ys} =\n              standardizeDataIteratorOutput(model, iteratorOut.value);\n          const batchLogs: UnresolvedLogs = {};\n          batchLogs['batch'] = batchIndex;\n          batchLogs['size'] = xs[0].shape[0];\n\n          await callbackList.onBatchBegin(batchIndex, batchLogs);\n\n          const sampleWeights: tfc.Tensor[] = [];\n          if (args.classWeight != null) {\n            const standardClassWeights =\n                standardizeClassWeights(args.classWeight, model.outputNames);\n            for (let i = 0; i < standardClassWeights.length; ++i) {\n              sampleWeights.push(await standardizeWeights(\n                  ys[i], null, standardClassWeights[i]));\n            }\n          }\n\n          // Train on batch.\n          const ins = xs.concat(ys).concat(sampleWeights);\n          const outs = trainFunction(ins);\n          tfc.dispose(ins);\n          for (let i = 0; i < outLabels.length; ++i) {\n            const label = outLabels[i];\n            const out = outs[i];\n            batchLogs[label] = out;\n            tfc.keep(out);\n          }\n\n          await callbackList.onBatchEnd(batchIndex, batchLogs);\n          disposeTensorsInLogs(batchLogs);\n\n          batchIndex++;\n          stepsDone++;\n        }\n\n        if (hasBatchesPerEpoch ? stepsDone >= args.batchesPerEpoch :\n                                 iteratorOut.done) {\n          // Epoch finished. Perform validation.\n          if (doValidation) {\n            let valOuts: tfc.Scalar[];\n            if (isDatasetObject(args.validationData)) {\n              valOuts = toList(await model.evaluateDataset(\n                  args.validationData, {batches: args.validationBatches}));\n            } else {\n              valOuts = toList(model.evaluate(valXs, valYs, {\n                batchSize: args.validationBatchSize == null ?\n                    DEFAULT_VALIDATION_BATCH_SIZE :\n                    args.validationBatchSize,\n                verbose: 0\n              }));\n            }\n            for (let i = 0; i < model.metricsNames.length; ++i) {\n              epochLogs[`val_${model.metricsNames[i]}`] = valOuts[i];\n            }\n          }\n          // Call `break` to exit one epoch lopp after validation is done. If\n          // config.batchesPerEpoch is specified, an epoch while loop will\n          // stop when `stepsDone >= config.batchesPerEpoch`. When\n          // config.batchesPerEpoch is not provided, the following `break` is\n          // required to exit the while lopp after dataset is exhausted.\n          break;\n        }\n\n        if (model.stopTraining_) {\n          break;\n        }\n      }\n      await callbackList.onEpochEnd(epoch, epochLogs);\n      epoch++;\n      if (model.stopTraining_) {\n        break;\n      }\n    }\n    await callbackList.onTrainEnd();\n    await model.history.syncData();\n    return model.history;\n  } finally {\n    model.isTraining = false;\n  }\n}\n\n/** Helper function that determines number of steps (batches) per epoch. */\nfunction getStepsPerEpoch<T>(\n    dataset: Dataset<T>, args: ModelFitDatasetArgs<T>): number {\n  // Attempt to determine # of batches in an epoch.\n  let stepsPerEpoch: number = null;\n  if (args.batchesPerEpoch != null) {\n    stepsPerEpoch = args.batchesPerEpoch;\n  } else if (Number.isFinite(dataset.size)) {\n    stepsPerEpoch = dataset.size;\n  }\n  return stepsPerEpoch;\n}\n\n// Check if provided object is a Dataset object by checking its .iterator\n// element.\nfunction isDatasetObject<T>(\n    dataset:\n        [\n          TensorOrArrayOrMap, TensorOrArrayOrMap\n        ]|[TensorOrArrayOrMap, TensorOrArrayOrMap, TensorOrArrayOrMap]|\n    Dataset<T>): boolean {\n  return (typeof (dataset as Dataset<T>).iterator === 'function');\n}\n\n// Check if provided object is a LazyIterator object by checking it's .next\n// element.\nfunction isLazyIteratorObject<T>(iterator: Dataset<T>|\n                                 LazyIterator<T>): boolean {\n  return (typeof (iterator as LazyIterator<T>).next === 'function');\n}\n\nexport async function evaluateDataset<T>(\n    // Type `model` as `any` here to avoid circular dependency w/\n    // training.ts.\n    // tslint:disable-next-line:no-any\n    model: any, dataset: Dataset<T>|LazyIterator<T>,\n    args: ModelEvaluateDatasetArgs): Promise<tfc.Scalar|tfc.Scalar[]> {\n  args = args || {};\n  const hasBatches = args.batches != null;\n  const f = model.testFunction;\n  let outs: tfc.Scalar[] = [];\n  if (args.verbose > 0) {\n    throw new NotImplementedError('Verbose mode is not implemented yet.');\n  }\n\n  tfc.util.assert(\n      !hasBatches || (args.batches > 0 && Number.isInteger(args.batches)),\n      () => 'Test loop expects `batches` to be a positive integer, but ' +\n          `received ${JSON.stringify(args.batches)}`);\n  const dataIterator = isLazyIteratorObject(dataset) ?\n      dataset as LazyIterator<T>:\n      await (dataset as Dataset<T>).iterator();\n  // Keeps track of number of examples used in this evaluation.\n  let numExamples = 0;\n  let batch = 0;\n\n  while (hasBatches ? batch < args.batches : true) {\n    const iteratorOut = await dataIterator.next();\n    outs = tfc.tidy(() => {\n      if (iteratorOut.value) {\n        // TODO(cais): Once real dataset is available, use\n        //   `map(x => standardizeDataIteratorOutput(model, x).map(f)`.\n        const {xs, ys} =\n            standardizeDataIteratorOutput(model, iteratorOut.value);\n        const xsAndYs = xs.concat(ys);\n        const batchOuts = tfc.tidy(() => f(xsAndYs));\n        tfc.dispose(xsAndYs);\n\n        if (batch === 0) {\n          for (let i = 0; i < batchOuts.length; ++i) {\n            outs.push(scalar(0));\n          }\n        }\n\n        const batchSize = xsAndYs[0].shape[0];\n        for (let i = 0; i < batchOuts.length; ++i) {\n          const batchOut = batchOuts[i];\n          const oldScalar = outs[i];\n          outs[i] =\n              tfc.tidy(() => tfc.add(outs[i], tfc.mul(batchSize, batchOut)));\n          if (batch > 0) {\n            tfc.dispose(oldScalar);\n          }\n        }\n        tfc.dispose(batchOuts);\n        numExamples += batchSize;\n\n        ++batch;\n      }\n      return outs;\n    });\n\n    if (iteratorOut.done) {\n      if (hasBatches) {\n        console.warn(\n            'Your dataset iterator ran out of data during evaluateDataset(). ' +\n            'Interrupting evalution. Make sure that your ' +\n            'dataset can generate at least `batches` ' +\n            `batches (in this case, ${args.batches} batches). ` +\n            'You may need to use the repeat() function when building ' +\n            'your dataset.');\n      }\n      break;\n    }\n  }\n\n  for (let i = 0; i < outs.length; ++i) {\n    const oldScalar = outs[i];\n    outs[i] = tfc.div(outs[i], numExamples);\n    tfc.dispose(oldScalar);\n  }\n\n  return singletonOrArray(outs);\n}\n"]}