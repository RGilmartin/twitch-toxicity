{"version":3,"file":"noise.js","sourceRoot":"","sources":["../../src/layers/noise.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;AAEH;;GAEG;AAEH,OAAO,EAAC,YAAY,EAAE,aAAa,EAAE,aAAa,EAAU,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAE/F,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,KAAK,EAAY,MAAM,oBAAoB,CAAC;AAGpD,OAAO,EAAC,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;AAOzD,MAAM,OAAO,aAAc,SAAQ,KAAK;IAKtC,YAAY,IAAuB;QACjC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC;IAC5B,CAAC;IAED,kBAAkB,CAAC,UAAyB;QAC1C,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,SAAS;QACP,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,MAAM,GAAG,EAAC,MAAM,EAAE,IAAI,CAAC,MAAM,EAAC,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,MAAM,KAAK,GAAG,mBAAmB,CAAC,MAAM,CAAC,CAAC;YAC1C,MAAM,MAAM,GAAG,GAAG,EAAE,CAChB,CAAC,CAAC,YAAY,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;YAC3D,MAAM,MAAM,GACR,CAAC,CAAC,YAAY,CAAC,MAAM,EAAE,GAAG,EAAE,CAAC,KAAK,EAAE,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC,CAAC;YACrE,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;;AA/BD,kBAAkB;AACX,uBAAS,GAAG,eAAe,CAAC;AAgCrC,aAAa,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC;AAO3C,MAAM,OAAO,eAAgB,SAAQ,KAAK;IAKxC,YAAY,IAAyB;QACnC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;IACxB,CAAC;IAED,kBAAkB,CAAC,UAAyB;QAC1C,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,SAAS;QACP,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,MAAM,GAAG,EAAC,IAAI,EAAE,IAAI,CAAC,IAAI,EAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,MAAM,KAAK,GAAG,mBAAmB,CAAC,MAAM,CAAC,CAAC;YAC1C,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,EAAE;gBAClC,MAAM,MAAM,GAAG,GAAG,EAAE;oBAClB,MAAM,MAAM,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBACtD,OAAO,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,YAAY,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC;gBAC3D,CAAC,CAAC;gBACF,OAAO,CAAC,CAAC,YAAY,CAAC,MAAM,EAAE,GAAG,EAAE,CAAC,KAAK,EAAE,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC,CAAC;aACzE;YACD,OAAO,KAAK,CAAC;QACf,CAAC,CAAC,CAAC;IACL,CAAC;;AAlCD,kBAAkB;AACX,yBAAS,GAAG,iBAAiB,CAAC;AAmCvC,aAAa,CAAC,aAAa,CAAC,eAAe,CAAC,CAAC;AAY7C;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA4BG;AACH,MAAM,OAAO,YAAa,SAAQ,KAAK;IAMrC,YAAY,IAAsB;QAChC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;QACtB,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;IACpC,CAAC;IAED,cAAc,CAAC,MAAuB;QACpC,OAAO,IAAI,CAAC,UAAU,IAAI,mBAAmB,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC;IAC9D,CAAC;IAED,kBAAkB,CAAC,UAAyB;QAC1C,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,SAAS;QACP,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,MAAM,GAAG,EAAC,IAAI,EAAE,IAAI,CAAC,IAAI,EAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,EAAE;gBAClC,MAAM,UAAU,GAAG,IAAI,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;gBAE/C,MAAM,aAAa,GAAG,GAAG,EAAE;oBACzB,MAAM,KAAK,GAAG,mBAAmB,CAAC,MAAM,CAAC,CAAC;oBAE1C,MAAM,KAAK,GAAG,iCAAiC,CAAC;oBAChD,MAAM,KAAK,GAAG,iCAAiC,CAAC;oBAEhD,MAAM,MAAM,GAAG,CAAC,KAAK,GAAG,KAAK,CAAC;oBAE9B,IAAI,OAAO,GAAG,YAAY,CAAC,aAAa,CAAC,UAAU,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;oBAEjE,OAAO,GAAG,CAAC,CAAC,IAAI,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC,CAAE,qBAAqB;oBAE5D,oCAAoC;oBACpC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,GAAG,MAAM,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC;oBACpE,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,GAAG,IAAI,CAAC,IAAI,CAAC;oBAElC,cAAc;oBACd,MAAM,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC;oBAE9D,OAAO,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;gBACzB,CAAC,CAAC;gBACF,OAAO,CAAC,CAAC,YAAY,CACjB,aAAa,EAAE,GAAG,EAAE,CAAC,mBAAmB,CAAC,MAAM,CAAC,EAChD,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC,CAAC;aAClC;YACD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;;AA3DD,kBAAkB;AACX,sBAAS,GAAG,cAAc,CAAC;AA4DpC,aAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC","sourcesContent":["/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\r\n\r\n/**\r\n * TensorFlow.js Layers: Noise Layers.\r\n */\r\n\r\nimport {greaterEqual, randomUniform, serialization, Tensor, tidy} from '@tensorflow/tfjs-core';\r\n\r\nimport * as K from '../backend/tfjs_backend';\r\nimport {Layer, LayerArgs} from '../engine/topology';\r\nimport {Shape} from '../keras_format/common';\r\nimport {Kwargs} from '../types';\r\nimport {getExactlyOneTensor} from '../utils/types_utils';\r\n\r\nexport declare interface GaussianNoiseArgs extends LayerArgs {\r\n  /** Standard Deviation.  */\r\n  stddev: number;\r\n}\r\n\r\nexport class GaussianNoise extends Layer {\r\n  /** @nocollapse */\r\n  static className = 'GaussianNoise';\r\n  readonly stddev: number;\r\n\r\n  constructor(args: GaussianNoiseArgs) {\r\n    super(args);\r\n    this.supportsMasking = true;\r\n    this.stddev = args.stddev;\r\n  }\r\n\r\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\r\n    return inputShape;\r\n  }\r\n\r\n  getConfig() {\r\n    const baseConfig = super.getConfig();\r\n    const config = {stddev: this.stddev};\r\n    Object.assign(config, baseConfig);\r\n    return config;\r\n  }\r\n\r\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\r\n    return tidy(() => {\r\n      this.invokeCallHook(inputs, kwargs);\r\n      const input = getExactlyOneTensor(inputs);\r\n      const noised = () =>\r\n          K.randomNormal(input.shape, 0, this.stddev).add(input);\r\n      const output =\r\n          K.inTrainPhase(noised, () => input, kwargs['training'] || false);\r\n      return output;\r\n    });\r\n  }\r\n}\r\nserialization.registerClass(GaussianNoise);\r\n\r\nexport declare interface GaussianDropoutArgs extends LayerArgs {\r\n  /** drop probability.  */\r\n  rate: number;\r\n}\r\n\r\nexport class GaussianDropout extends Layer {\r\n  /** @nocollapse */\r\n  static className = 'GaussianDropout';\r\n  readonly rate: number;\r\n\r\n  constructor(args: GaussianDropoutArgs) {\r\n    super(args);\r\n    this.supportsMasking = true;\r\n    this.rate = args.rate;\r\n  }\r\n\r\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\r\n    return inputShape;\r\n  }\r\n\r\n  getConfig() {\r\n    const baseConfig = super.getConfig();\r\n    const config = {rate: this.rate};\r\n    Object.assign(config, baseConfig);\r\n    return config;\r\n  }\r\n\r\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\r\n    return tidy(() => {\r\n      this.invokeCallHook(inputs, kwargs);\r\n      const input = getExactlyOneTensor(inputs);\r\n      if (this.rate > 0 && this.rate < 1) {\r\n        const noised = () => {\r\n          const stddev = Math.sqrt(this.rate / (1 - this.rate));\r\n          return input.mul(K.randomNormal(input.shape, 1, stddev));\r\n        };\r\n        return K.inTrainPhase(noised, () => input, kwargs['training'] || false);\r\n      }\r\n      return input;\r\n    });\r\n  }\r\n}\r\nserialization.registerClass(GaussianDropout);\r\n\r\nexport declare interface AlphaDropoutArgs extends LayerArgs {\r\n  /** drop probability.  */\r\n  rate: number;\r\n  /**\r\n   * A 1-D `Tensor` of type `int32`, representing the\r\n   * shape for randomly generated keep/drop flags.\r\n   */\r\n  noiseShape?: Shape;\r\n}\r\n\r\n/**\r\n * Applies Alpha Dropout to the input.\r\n *\r\n * As it is a regularization layer, it is only active at training time.\r\n *\r\n * Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\r\n * to their original values, in order to ensure the self-normalizing property\r\n * even after this dropout.\r\n * Alpha Dropout fits well to Scaled Exponential Linear Units\r\n * by randomly setting activations to the negative saturation value.\r\n *\r\n * Arguments:\r\n *   - `rate`: float, drop probability (as with `Dropout`).\r\n *     The multiplicative noise will have\r\n *     standard deviation `sqrt(rate / (1 - rate))`.\r\n *   - `noise_shape`: A 1-D `Tensor` of type `int32`, representing the\r\n *     shape for randomly generated keep/drop flags.\r\n *\r\n * Input shape:\r\n *   Arbitrary. Use the keyword argument `inputShape`\r\n *   (tuple of integers, does not include the samples axis)\r\n *   when using this layer as the first layer in a model.\r\n *\r\n * Output shape:\r\n *   Same shape as input.\r\n *\r\n * References:\r\n *   - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\r\n */\r\nexport class AlphaDropout extends Layer {\r\n  /** @nocollapse */\r\n  static className = 'AlphaDropout';\r\n  readonly rate: number;\r\n  readonly noiseShape: Shape;\r\n\r\n  constructor(args: AlphaDropoutArgs) {\r\n    super(args);\r\n    this.supportsMasking = true;\r\n    this.rate = args.rate;\r\n    this.noiseShape = args.noiseShape;\r\n  }\r\n\r\n  _getNoiseShape(inputs: Tensor|Tensor[]) {\r\n    return this.noiseShape || getExactlyOneTensor(inputs).shape;\r\n  }\r\n\r\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\r\n    return inputShape;\r\n  }\r\n\r\n  getConfig() {\r\n    const baseConfig = super.getConfig();\r\n    const config = {rate: this.rate};\r\n    Object.assign(config, baseConfig);\r\n    return config;\r\n  }\r\n\r\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\r\n    return tidy(() => {\r\n      if (this.rate < 1 && this.rate > 0) {\r\n        const noiseShape = this._getNoiseShape(inputs);\r\n\r\n        const droppedInputs = () => {\r\n          const input = getExactlyOneTensor(inputs);\r\n\r\n          const alpha = 1.6732632423543772848170429916717;\r\n          const scale = 1.0507009873554804934193349852946;\r\n\r\n          const alphaP = -alpha * scale;\r\n\r\n          let keptIdx = greaterEqual(randomUniform(noiseShape), this.rate);\r\n\r\n          keptIdx = K.cast(keptIdx, 'float32');  // get default dtype.\r\n\r\n          // Get affine transformation params.\r\n          const a = ((1 - this.rate) * (1 + this.rate * alphaP ** 2)) ** -0.5;\r\n          const b = -a * alphaP * this.rate;\r\n\r\n          // Apply mask.\r\n          const x = input.mul(keptIdx).add(keptIdx.add(-1).mul(alphaP));\r\n\r\n          return x.mul(a).add(b);\r\n        };\r\n        return K.inTrainPhase(\r\n            droppedInputs, () => getExactlyOneTensor(inputs),\r\n            kwargs['training'] || false);\r\n      }\r\n      return inputs;\r\n    });\r\n  }\r\n}\r\nserialization.registerClass(AlphaDropout);\r\n"]}