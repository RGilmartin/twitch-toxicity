{"version":3,"file":"recurrent.js","sourceRoot":"","sources":["../../src/layers/recurrent.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;AAEH;;GAEG;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAW,aAAa,EAAU,IAAI,EAAE,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAElF,OAAO,EAAa,aAAa,EAAE,mBAAmB,EAAC,MAAM,gBAAgB,CAAC;AAC9E,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,SAAS,EAAC,MAAM,WAAW,CAAC;AACpC,OAAO,EAAmC,aAAa,EAAE,mBAAmB,EAAC,MAAM,gBAAgB,CAAC;AACpG,OAAO,EAAC,SAAS,EAAE,cAAc,EAAC,MAAM,oBAAoB,CAAC;AAC7D,OAAO,EAAC,KAAK,EAAY,MAAM,oBAAoB,CAAC;AACpD,OAAO,EAAC,cAAc,EAAE,mBAAmB,EAAE,UAAU,EAAC,MAAM,WAAW,CAAC;AAC1E,OAAO,EAAC,cAAc,EAAE,WAAW,EAAyB,IAAI,EAAE,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAG/G,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,EAAC,qBAAqB,EAAC,MAAM,wBAAwB,CAAC;AAC7D,OAAO,KAAK,UAAU,MAAM,qBAAqB,CAAC;AAClD,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAE,eAAe,EAAC,MAAM,sBAAsB,CAAC;AAC9F,OAAO,EAAC,aAAa,EAAE,aAAa,EAAgB,MAAM,cAAc,CAAC;AACzE,OAAO,EAAC,WAAW,EAAC,MAAM,iBAAiB,CAAC;AAE5C;;;;;;;;;;;;;;;;;;;;;GAqBG;AACH,MAAM,UAAU,eAAe,CAC3B,MAAuD,EACvD,YAA6D,EAC7D,SAA0D,EAC1D,YAAqB;IAKvB,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;QACzB,IAAI,YAAY,IAAI,IAAI,IAAI,SAAS,IAAI,IAAI,EAAE;YAC7C,MAAM,IAAI,UAAU,CAChB,6DAA6D;gBAC7D,oBAAoB,CAAC,CAAC;SAC3B;QACD,IAAI,YAAY,IAAI,IAAI,EAAE;YACxB,SAAS,GAAG,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,MAAM,GAAG,YAAY,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;YACtE,MAAM,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,MAAM,CAAC,MAAM,GAAG,YAAY,CAAC,CAAC;SACxD;QACD,IAAI,MAAM,CAAC,MAAM,GAAG,CAAC,EAAE;YACrB,YAAY,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;SAC/C;QACD,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;KACpB;IAED,SAAS,YAAY,CAAC,CACgB;QACpC,IAAI,CAAC,IAAI,IAAI,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;YACjC,OAAO,CAAgC,CAAC;SACzC;aAAM;YACL,OAAO,CAAC,CAAC,CAAgC,CAAC;SAC3C;IACH,CAAC;IAED,YAAY,GAAG,YAAY,CAAC,YAAY,CAAC,CAAC;IAC1C,SAAS,GAAG,YAAY,CAAC,SAAS,CAAC,CAAC;IAEpC,OAAO,EAAC,MAAM,EAAE,YAAY,EAAE,SAAS,EAAC,CAAC;AAC3C,CAAC;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA0CG;AACH,MAAM,UAAU,GAAG,CACf,YAA6B,EAAE,MAAc,EAAE,aAAuB,EACtE,WAAW,GAAG,KAAK,EAAE,IAAa,EAAE,SAAoB,EAAE,MAAM,GAAG,KAAK,EACxE,kBAAkB,GAAG,KAAK;IAC5B,OAAO,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE;QACnB,MAAM,IAAI,GAAG,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC;QACjC,IAAI,IAAI,GAAG,CAAC,EAAE;YACZ,MAAM,IAAI,UAAU,CAAC,uCAAuC,IAAI,IAAI,CAAC,CAAC;SACvE;QAED,0EAA0E;QAC1E,QAAQ;QACR,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;QACtD,MAAM,GAAG,GAAG,CAAC,SAAS,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;QAErC,IAAI,SAAS,IAAI,IAAI,EAAE;YACrB,MAAM,IAAI,mBAAmB,CACzB,kEAAkE;gBAClE,gBAAgB,CAAC,CAAC;SACvB;QAED,wEAAwE;QACxE,IAAI,MAAM,EAAE;YACV,OAAO,CAAC,IAAI,CACR,mEAAmE;gBACnE,kCAAkC,CAAC,CAAC;SACzC;QAED,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;YAC7C,IAAI,IAAI,CAAC,IAAI,KAAK,IAAI,GAAG,CAAC,EAAE;gBAC1B,IAAI,GAAG,GAAG,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC;aACjC;YACD,IAAI,GAAG,GAAG,CAAC,SAAS,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC;SAClC;QAED,IAAI,WAAW,EAAE;YACf,MAAM,GAAG,GAAG,CAAC,OAAO,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;YAChC,IAAI,IAAI,IAAI,IAAI,EAAE;gBAChB,IAAI,GAAG,GAAG,CAAC,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;aAC7B;SACF;QAED,qEAAqE;QACrE,0EAA0E;QAC1E,4EAA4E;QAC5E,gBAAgB;QAChB,qEAAqE;QACrE,WAAW;QACX,2EAA2E;QAC3E,0EAA0E;QAC1E,SAAS;QAET,MAAM,cAAc,GAAa,EAAE,CAAC;QACpC,IAAI,UAAkB,CAAC;QACvB,IAAI,MAAM,GAAG,aAAa,CAAC;QAC3B,MAAM,SAAS,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,aAAa,GAAG,GAAG,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC;QAC1C,IAAI,YAAsB,CAAC;QAC3B,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,YAAY,GAAG,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;SAClC;QAED,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;YAClC,MAAM,YAAY,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;YACtC,MAAM,WAAW,GAAG,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,YAAY,CAAC,YAAY,EAAE,MAAM,CAAC,CAAC,CAAC;YAEvE,IAAI,IAAI,IAAI,IAAI,EAAE;gBAChB,UAAU,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;gBAC5B,MAAM,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;aACzB;iBAAM;gBACL,MAAM,aAAa,GAAG,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE;oBAClC,MAAM,QAAQ,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;oBACjC,MAAM,WAAW,GAAG,GAAG,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;oBACzD,2DAA2D;oBAC3D,MAAM,MAAM,GACR,WAAW,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,CAAC;oBACjE,MAAM,SAAS,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,CAAC,EAAE,EAAE;wBACxC,OAAO,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,CAAC;oBACrE,CAAC,CAAC,CAAC;oBACH,OAAO,EAAC,MAAM,EAAE,SAAS,EAAC,CAAC;gBAC7B,CAAC,CAAC,CAAC;gBACH,UAAU,GAAG,aAAa,CAAC,MAAM,CAAC;gBAClC,MAAM,GAAG,aAAa,CAAC,SAAS,CAAC;aAClC;YAED,IAAI,kBAAkB,EAAE;gBACtB,cAAc,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;aACjC;SACF;QACD,IAAI,OAAe,CAAC;QACpB,IAAI,kBAAkB,EAAE;YACtB,MAAM,IAAI,GAAG,CAAC,CAAC;YACf,OAAO,GAAG,GAAG,CAAC,KAAK,CAAC,cAAc,EAAE,IAAI,CAAC,CAAC;SAC3C;QACD,OAAO,CAAC,UAAU,EAAE,OAAO,EAAE,MAAM,CAA+B,CAAC;IACrE,CAAC,CAAC,CAAC;AACL,CAAC;AAuGD,MAAM,OAAO,GAAI,SAAQ,KAAK;IAqB5B,YAAY,IAAkB;QAC5B,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,IAAa,CAAC;QAClB,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,EAAE;YACrB,MAAM,IAAI,UAAU,CAChB,sDAAsD,CAAC,CAAC;SAC7D;aAAM,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;YACnC,IAAI,GAAG,IAAI,eAAe,CAAC,EAAC,KAAK,EAAE,IAAI,CAAC,IAAI,EAAC,CAAC,CAAC;SAChD;aAAM;YACL,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;SAClB;QACD,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;YAC1B,MAAM,IAAI,UAAU,CAChB,8DAA8D;gBAC9D,uCAAuC,CAAC,CAAC;SAC9C;QACD,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;QACjB,IAAI,CAAC,eAAe;YAChB,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,eAAe,CAAC;QAChE,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,WAAW,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,WAAW,CAAC;QACvE,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,WAAW,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,WAAW,CAAC;QACvE,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC;QAC/D,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC;QAExD,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,SAAS,GAAG,CAAC,IAAI,SAAS,CAAC,EAAC,IAAI,EAAE,CAAC,EAAC,CAAC,CAAC,CAAC;QAC5C,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC;QACtB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;QACpB,kDAAkD;QAClD,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC;QACzB,sEAAsE;QACtE,iBAAiB;QAEjB,IAAI,CAAC,UAAU,GAAG,EAAE,CAAC;IACvB,CAAC;IAED,0EAA0E;IAC1E,aAAa;IACb,SAAS;QACP,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;YACxB,MAAM,SAAS,GACX,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;YACxE,OAAO,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC;SACtD;aAAM;YACL,OAAO,IAAI,CAAC,OAAO,CAAC;SACrB;IACH,CAAC;IAED,8EAA8E;IAC9E,aAAa;IACb,SAAS,CAAC,MAAgB;QACxB,IAAI,CAAC,OAAO,GAAG,MAAM,CAAC;IACxB,CAAC;IAED,kBAAkB,CAAC,UAAyB;QAC1C,IAAI,eAAe,CAAC,UAAU,CAAC,EAAE;YAC/B,UAAU,GAAI,UAAsB,CAAC,CAAC,CAAC,CAAC;SACzC;QACD,UAAU,GAAG,UAAmB,CAAC;QAEjC,0EAA0E;QAC1E,IAAI,SAAS,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC;QACpC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC,EAAE;YAC7B,SAAS,GAAG,CAAC,SAAS,CAAC,CAAC;SACzB;QACD,MAAM,SAAS,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;QAC/B,IAAI,WAA0B,CAAC;QAC/B,IAAI,IAAI,CAAC,eAAe,EAAE;YACxB,WAAW,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;SACzD;aAAM;YACL,WAAW,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;SAC1C;QAED,IAAI,IAAI,CAAC,WAAW,EAAE;YACpB,MAAM,UAAU,GAAY,EAAE,CAAC;YAC/B,KAAK,MAAM,GAAG,IAAI,SAAS,EAAE;gBAC3B,UAAU,CAAC,IAAI,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,CAAC;aACvC;YACD,OAAO,CAAC,WAAW,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;SACzC;aAAM;YACL,OAAO,WAAW,CAAC;SACpB;IACH,CAAC;IAED,WAAW,CAAC,MAAuB,EAAE,IAAsB;QAEzD,OAAO,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE;YACnB,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;gBACvB,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;aAChB;YACD,MAAM,UAAU,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC;YAEtD,IAAI,IAAI,CAAC,WAAW,EAAE;gBACpB,MAAM,SAAS,GAAG,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC;gBAC7C,OAAO,CAAC,UAAU,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;aACvC;iBAAM;gBACL,OAAO,UAAU,CAAC;aACnB;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;;;;OAKG;IACH,IAAI,MAAM;QACR,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;YACxB,MAAM,SAAS,GACX,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;YACxE,MAAM,MAAM,GAAa,EAAE,CAAC;YAC5B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,EAAE,EAAE,CAAC,EAAE;gBAClC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;aACnB;YACD,OAAO,MAAM,CAAC;SACf;aAAM;YACL,OAAO,IAAI,CAAC,OAAO,CAAC;SACrB;IACH,CAAC;IAED,IAAI,MAAM,CAAC,CAAW;QACpB,IAAI,CAAC,OAAO,GAAG,CAAC,CAAC;IACnB,CAAC;IAEM,KAAK,CAAC,UAAyB;QACpC,mEAAmE;QACnE,4CAA4C;QAC5C,MAAM,aAAa,GAAY,IAAI,CAAC;QACpC,IAAI,IAAI,CAAC,YAAY,IAAI,IAAI,EAAE;YAC7B,MAAM,IAAI,mBAAmB,CACzB,kDAAkD,CAAC,CAAC;SACzD;QAED,IAAI,eAAe,CAAC,UAAU,CAAC,EAAE;YAC/B,UAAU,GAAI,UAAsB,CAAC,CAAC,CAAC,CAAC;SACzC;QACD,UAAU,GAAG,UAAmB,CAAC;QAEjC,MAAM,SAAS,GAAW,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;QAC/D,MAAM,QAAQ,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACrC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,GAAG,IAAI,SAAS,CAAC,EAAC,KAAK,EAAE,CAAC,SAAS,EAAE,IAAI,EAAE,GAAG,QAAQ,CAAC,EAAC,CAAC,CAAC;QAE3E,mEAAmE;QACnE,aAAa;QACb,MAAM,cAAc,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QACnE,IAAI,aAAa,IAAI,IAAI,EAAE;YACzB,MAAM,IAAI,mBAAmB,CACzB,kDAAkD,CAAC,CAAC;SACzD;aAAM;YACL,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,cAAc,CAAC,CAAC;SACjC;QAED,6BAA6B;QAC7B,IAAI,SAAmB,CAAC;QACxB,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;YACtC,SAAS,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC;SACjC;aAAM;YACL,SAAS,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;SACnC;QAED,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;YAC1B,IAAI,CAAC,IAAI,CAAC,WAAW,CACb,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,EAC7D,SAAS,CAAC,EAAE;gBAClB,MAAM,IAAI,UAAU,CAChB,yDAAyD;oBACzD,sCAAsC,IAAI,CAAC,SAAS,IAAI;oBACxD,6BAA6B,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,CAAC,CAAC;aACzD;SACF;aAAM;YACL,IAAI,CAAC,SAAS;gBACV,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,IAAI,SAAS,CAAC,EAAC,KAAK,EAAE,CAAC,IAAI,EAAE,GAAG,CAAC,EAAC,CAAC,CAAC,CAAC;SAC/D;QACD,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,IAAI,CAAC,WAAW,EAAE,CAAC;SACpB;IACH,CAAC;IAED;;;;;;;;;;;;;;;;OAgBG;IACH,WAAW,CAAC,MAAwB,EAAE,QAAQ,GAAG,KAAK;QACpD,IAAI,CAAC,GAAG,EAAE;YACR,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;gBAClB,MAAM,IAAI,cAAc,CACpB,iEAAiE,CAAC,CAAC;aACxE;YACD,MAAM,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAC7C,IAAI,SAAS,IAAI,IAAI,EAAE;gBACrB,MAAM,IAAI,UAAU,CAChB,kEAAkE;oBAClE,0CAA0C;oBAC1C,2DAA2D;oBAC3D,2DAA2D;oBAC3D,2DAA2D;oBAC3D,oDAAoD,CAAC,CAAC;aAC3D;YACD,4BAA4B;YAC5B,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;gBACxB,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;oBACtC,IAAI,CAAC,OAAO;wBACR,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,GAAG,CAAC,CAAC,CAAC,CAAC;iBACjE;qBAAM;oBACL,IAAI,CAAC,OAAO,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;iBAC9D;aACF;iBAAM,IAAI,MAAM,IAAI,IAAI,EAAE;gBACzB,6BAA6B;gBAC7B,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;gBAC1B,oDAAoD;gBACpD,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;oBAC3B,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;oBAC7B,IAAI,CAAC,UAAU,GAAG,EAAE,CAAC;iBACtB;gBAED,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;oBACtC,IAAI,CAAC,OAAO;wBACR,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,GAAG,CAAC,CAAC,CAAC,CAAC;iBACjE;qBAAM;oBACL,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC;iBAC/D;aACF;iBAAM;gBACL,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;oBAC1B,MAAM,GAAG,CAAC,MAAM,CAAC,CAAC;iBACnB;gBACD,IAAI,MAAM,CAAC,MAAM,KAAK,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE;oBACzC,MAAM,IAAI,UAAU,CAChB,SAAS,IAAI,CAAC,IAAI,YAAY,IAAI,CAAC,OAAO,CAAC,MAAM,aAAa;wBAC9D,mBAAmB,MAAM,CAAC,MAAM,yBAAyB;wBACzD,aAAa,MAAM,EAAE,CAAC,CAAC;iBAC5B;gBAED,IAAI,QAAQ,KAAK,IAAI,EAAE;oBACrB,oEAAoE;oBACpE,iEAAiE;oBACjE,oEAAoE;oBACpE,QAAQ;oBACR,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,KAAK,EAAE,CAAC,CAAC;iBAC5C;qBAAM;oBACL,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;iBAC3B;gBAED,KAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,EAAE,KAAK,EAAE;oBACxD,MAAM,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC;oBAC5B,MAAM,GAAG,GAAG,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC;wBAC5C,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,CAAC;wBAC5B,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC;oBACxB,MAAM,aAAa,GAAG,CAAC,SAAS,EAAE,GAAG,CAAC,CAAC;oBACvC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,KAAK,CAAC,KAAK,EAAE,aAAa,CAAC,EAAE;wBACjD,MAAM,IAAI,UAAU,CAChB,SAAS,KAAK,+BAA+B,IAAI,CAAC,IAAI,IAAI;4BAC1D,kBAAkB,aAAa,oBAC3B,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC;qBACxB;oBACD,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,GAAG,KAAK,CAAC;iBAC7B;aACF;YACD,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;QACpE,CAAC,CAAC,CAAC;IACL,CAAC;IAED,KAAK,CACD,MAAuD,EACvD,MAAe;QACjB,sEAAsE;QACtE,IAAI,YAAY,GACZ,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,cAAc,CAAC,CAAC;QACnD,IAAI,SAAS,GACT,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,WAAW,CAAC,CAAC;QAChD,IAAI,MAAM,IAAI,IAAI,EAAE;YAClB,MAAM,GAAG,EAAE,CAAC;SACb;QAED,MAAM,YAAY,GACd,eAAe,CAAC,MAAM,EAAE,YAAY,EAAE,SAAS,EAAE,IAAI,CAAC,YAAY,CAAC,CAAC;QACxE,MAAM,GAAG,YAAY,CAAC,MAAM,CAAC;QAC7B,YAAY,GAAG,YAAY,CAAC,YAAY,CAAC;QACzC,SAAS,GAAG,YAAY,CAAC,SAAS,CAAC;QAEnC,iEAAiE;QACjE,2EAA2E;QAC3E,kCAAkC;QAElC,IAAI,gBAAgB,GAAiC,EAAE,CAAC;QACxD,IAAI,eAAe,GAAgB,EAAE,CAAC;QACtC,IAAI,YAAY,IAAI,IAAI,EAAE;YACxB,MAAM,CAAC,cAAc,CAAC,GAAG,YAAY,CAAC;YACtC,gBAAgB,GAAG,gBAAgB,CAAC,MAAM,CAAC,YAAY,CAAC,CAAC;YACzD,IAAI,CAAC,SAAS,GAAG,EAAE,CAAC;YACpB,KAAK,MAAM,KAAK,IAAI,YAAY,EAAE;gBAChC,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,SAAS,CAAC,EAAC,KAAK,EAAE,KAAK,CAAC,KAAK,EAAC,CAAC,CAAC,CAAC;aAC1D;YACD,yCAAyC;YACzC,mEAAmE;YACnE,kBAAkB;YAClB,eAAe,GAAG,eAAe,CAAC,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;SAC1D;QACD,IAAI,SAAS,IAAI,IAAI,EAAE;YACrB,MAAM,CAAC,WAAW,CAAC,GAAG,SAAS,CAAC;YAChC,gBAAgB,GAAG,gBAAgB,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;YACtD,sCAAsC;YACtC,IAAI,CAAC,YAAY,GAAG,SAAS,CAAC,MAAM,CAAC;SACtC;QAED,MAAM,QAAQ,GAAG,gBAAgB,CAAC,CAAC,CAAC,YAAY,cAAc,CAAC;QAC/D,IAAI,QAAQ,EAAE;YACZ,0DAA0D;YAC1D,MAAM,SAAS,GACX,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,gBAAgB,CAAgC,CAAC;YACrE,MAAM,aAAa,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,eAAe,CAAC,CAAC;YAC7D,wDAAwD;YACxD,MAAM,iBAAiB,GAAG,IAAI,CAAC,SAAS,CAAC;YACzC,IAAI,CAAC,SAAS,GAAG,aAAa,CAAC;YAC/B,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,SAAS,EAAE,MAAM,CAAC,CAAC;YAC9C,IAAI,CAAC,SAAS,GAAG,iBAAiB,CAAC;YACnC,OAAO,MAAM,CAAC;SACf;aAAM;YACL,OAAO,KAAK,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;SACpC;IACH,CAAC;IAED,kCAAkC;IAClC,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,iEAAiE;QACjE,8DAA8D;QAC9D,iEAAiE;QACjE,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,MAAM,IAAI,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAW,CAAC;YAC9D,MAAM,QAAQ,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YAC5D,IAAI,YAAY,GACZ,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,cAAc,CAAC,CAAC;YAEnD,MAAM,GAAG,mBAAmB,CAAC,MAAM,CAAC,CAAC;YACrC,IAAI,YAAY,IAAI,IAAI,EAAE;gBACxB,IAAI,IAAI,CAAC,QAAQ,EAAE;oBACjB,YAAY,GAAG,IAAI,CAAC,OAAO,CAAC;iBAC7B;qBAAM;oBACL,YAAY,GAAG,IAAI,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;iBAC7C;aACF;YAED,MAAM,SAAS,GACX,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;YACxE,IAAI,YAAY,CAAC,MAAM,KAAK,SAAS,EAAE;gBACrC,MAAM,IAAI,UAAU,CAChB,iBAAiB,SAAS,2BAA2B;oBACrD,GAAG,YAAY,CAAC,MAAM,oBAAoB,CAAC,CAAC;aACjD;YACD,IAAI,IAAI,CAAC,MAAM,EAAE;gBACf,OAAO,CAAC,IAAI,CACR,kEAAkE,CAAC,CAAC;aACzE;YAED,MAAM,cAAc,GAAW,EAAC,QAAQ,EAAC,CAAC;YAE1C,yCAAyC;YACzC,MAAM,IAAI,GAAG,CAAC,MAAc,EAAE,MAAgB,EAAE,EAAE;gBAChD,qEAAqE;gBACrE,8CAA8C;gBAC9C,MAAM,OAAO,GACT,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,cAAc,CAAa,CAAC;gBACxE,wDAAwD;gBACxD,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAuB,CAAC;YAC9D,CAAC,CAAC;YAEF,yCAAyC;YAEzC,MAAM,UAAU,GACZ,GAAG,CAAC,IAAI,EAAE,MAAM,EAAE,YAAY,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,EAAE,IAAI,EACxD,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,eAAe,CAAC,CAAC;YAC3C,MAAM,UAAU,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YACjC,MAAM,OAAO,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YAC9B,MAAM,MAAM,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YAE7B,IAAI,IAAI,CAAC,QAAQ,EAAE;gBACjB,IAAI,CAAC,WAAW,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;aACpC;YAED,MAAM,MAAM,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,UAAU,CAAC;YAE3D,gDAAgD;YAEhD,IAAI,IAAI,CAAC,WAAW,EAAE;gBACpB,OAAO,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;aAChC;iBAAM;gBACL,OAAO,MAAM,CAAC;aACf;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAED,eAAe,CAAC,MAAc;QAC5B,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,0DAA0D;YAC1D,kCAAkC;YAClC,IAAI,YAAY,GAAG,GAAG,CAAC,KAAK,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;YAC3C,aAAa;YACb,YAAY,GAAG,GAAG,CAAC,GAAG,CAAC,YAAY,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YAC7C,YAAY,GAAG,CAAC,CAAC,UAAU,CAAC,YAAY,CAAC,CAAC,CAAE,gBAAgB;YAE5D,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;gBACtC,OAAO,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAC1B,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC;aACrE;iBAAM;gBACL,OAAO,IAAI,CAAC,IAAI,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;oBAC5B,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;oBAClD,CAAC,YAAY,CAAC,CAAC;aACpB;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAED,IAAI,gBAAgB;QAClB,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE;YACnB,OAAO,EAAE,CAAC;SACX;QACD,wEAAwE;QACxE,OAAO,IAAI,CAAC,IAAI,CAAC,gBAAgB,CAAC;IACpC,CAAC;IAED,IAAI,mBAAmB;QACrB,wEAAwE;QACxE,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE;YACnB,OAAO,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC;SAC1B;QACD,OAAO,IAAI,CAAC,IAAI,CAAC,mBAAmB,CAAC;IACvC,CAAC;IAED,4BAA4B,CAAC,KAAc;QACzC,KAAK,CAAC,4BAA4B,CAAC,KAAK,CAAC,CAAC;QAC1C,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,EAAE;YACrB,IAAI,CAAC,IAAI,CAAC,4BAA4B,CAAC,KAAK,CAAC,CAAC;SAC/C;IACH,CAAC;IAED,SAAS;QACP,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QAErC,MAAM,MAAM,GAA6B;YACvC,eAAe,EAAE,IAAI,CAAC,eAAe;YACrC,WAAW,EAAE,IAAI,CAAC,WAAW;YAC7B,WAAW,EAAE,IAAI,CAAC,WAAW;YAC7B,QAAQ,EAAE,IAAI,CAAC,QAAQ;YACvB,MAAM,EAAE,IAAI,CAAC,MAAM;SACpB,CAAC;QAEF,IAAI,IAAI,CAAC,YAAY,IAAI,IAAI,EAAE;YAC7B,MAAM,CAAC,cAAc,CAAC,GAAG,IAAI,CAAC,YAAY,CAAC;SAC5C;QAED,MAAM,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,CAAC;QAEzC,IAAI,IAAI,CAAC,YAAY,EAAE,KAAK,GAAG,CAAC,SAAS,EAAE;YACzC,MAAM,CAAC,MAAM,CAAC,GAAG;gBACf,WAAW,EAAE,IAAI,CAAC,IAAI,CAAC,YAAY,EAAE;gBACrC,QAAQ,EAAE,UAAU;aACY,CAAC;SACpC;QAED,0EAA0E;QAC1E,yBAAW,UAAU,EAAK,UAAU,EAAK,MAAM,EAAE;IACnD,CAAC;IAED,kBAAkB;IAClB,MAAM,CAAC,UAAU,CACb,GAA6C,EAC7C,MAAgC,EAChC,gBAAgB,EAA8B;QAChD,MAAM,UAAU,GAAG,MAAM,CAAC,MAAM,CAA6B,CAAC;QAC9D,MAAM,IAAI,GAAG,WAAW,CAAC,UAAU,EAAE,aAAa,CAAY,CAAC;QAC/D,OAAO,IAAI,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,EAAC,IAAI,EAAC,CAAC,CAAC,CAAC;IAChD,CAAC;;AAvfD,kBAAkB;AACX,aAAS,GAAG,KAAK,CAAC;AAwf3B,aAAa,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC;AAEjC,yEAAyE;AACzE,0EAA0E;AAC1E,uEAAuE;AACvE;;;;GAIG;AACH,MAAM,OAAgB,OAAQ,SAAQ,KAAK;CAU1C;AAgFD,MAAM,OAAO,aAAc,SAAQ,OAAO;IAiCxC,YAAY,IAA4B;QACtC,KAAK,CAAC,IAAI,CAAC,CAAC;QANL,uBAAkB,GAAG,MAAM,CAAC;QAC5B,+BAA0B,GAAG,cAAc,CAAC;QAC5C,kCAA6B,GAAG,YAAY,CAAC;QAC7C,6BAAwB,GAA0B,OAAO,CAAC;QAIjE,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QACxB,qBAAqB,CAAC,IAAI,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;QAC3C,IAAI,CAAC,UAAU,GAAG,aAAa,CAC3B,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;QACzE,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;QAE1D,IAAI,CAAC,iBAAiB,GAAG,cAAc,CACnC,IAAI,CAAC,iBAAiB,IAAI,IAAI,CAAC,0BAA0B,CAAC,CAAC;QAC/D,IAAI,CAAC,oBAAoB,GAAG,cAAc,CACtC,IAAI,CAAC,oBAAoB,IAAI,IAAI,CAAC,6BAA6B,CAAC,CAAC;QAErE,IAAI,CAAC,eAAe;YAChB,cAAc,CAAC,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC,wBAAwB,CAAC,CAAC;QAE1E,IAAI,CAAC,iBAAiB,GAAG,cAAc,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;QAChE,IAAI,CAAC,oBAAoB,GAAG,cAAc,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;QACtE,IAAI,CAAC,eAAe,GAAG,cAAc,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAE5D,IAAI,CAAC,gBAAgB,GAAG,aAAa,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAC7D,IAAI,CAAC,mBAAmB,GAAG,aAAa,CAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QACnE,IAAI,CAAC,cAAc,GAAG,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QAEzD,IAAI,CAAC,OAAO,GAAG,UAAU,CAAC,GAAG,CACzB,CAAC,CAAC,EAAE,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QACvE,IAAI,CAAC,gBAAgB,GAAG,UAAU,CAAC,GAAG,CAAC;YACrC,CAAC;YACD,UAAU,CAAC,GAAG,CACV,CAAC,CAAC,EAAE,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;SACpE,CAAC,CAAC;QACH,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC;QAC5B,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;QACxB,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC;IACnC,CAAC;IAED,KAAK,CAAC,UAAyB;QAC7B,UAAU,GAAG,kBAAkB,CAAC,UAAU,CAAC,CAAC;QAC5C,+BAA+B;QAC/B,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CACxB,QAAQ,EAAE,CAAC,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,EAC/D,IAAI,CAAC,iBAAiB,EAAE,IAAI,CAAC,iBAAiB,EAAE,IAAI,EACpD,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAC3B,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,SAAS,CACjC,kBAAkB,EAAE,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,EAClD,IAAI,CAAC,oBAAoB,EAAE,IAAI,CAAC,oBAAoB,EAAE,IAAI,EAC1D,IAAI,CAAC,mBAAmB,CAAC,CAAC;QAC9B,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,EAChD,IAAI,CAAC,eAAe,EAAE,IAAI,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;SACtD;aAAM;YACL,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;SAClB;QACD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAED,4EAA4E;IAC5E,sEAAsE;IACtE,kDAAkD;IAClD,sEAAsE;IACtE,0EAA0E;IAC1E,kDAAkD;IAClD,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,MAAM,GAAG,MAAkB,CAAC;YAC5B,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;gBACvB,MAAM,IAAI,UAAU,CAChB,8CAA8C,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC;aACrE;YACD,IAAI,UAAU,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YAC3B,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACnB,MAAM,QAAQ,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YAEzE,IAAI,CAAC,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBACpE,IAAI,CAAC,WAAW,GAAG,mBAAmB,CAAC;oBAClB,IAAI,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAgB,CAAC;oBAC1C,IAAI,EAAE,IAAI,CAAC,OAAO;oBAClB,QAAQ;iBACT,CAAW,CAAC;aACjC;YACD,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,gBAAgB,GAAG,CAAC;gBACtD,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBACrC,IAAI,CAAC,oBAAoB,GAAG,mBAAmB,CAAC;oBAClB,IAAI,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,UAAU,CAAC;oBACpC,IAAI,EAAE,IAAI,CAAC,gBAAgB;oBAC3B,QAAQ;iBACT,CAAW,CAAC;aAC1C;YACD,IAAI,CAAS,CAAC;YACd,MAAM,MAAM,GAAW,IAAI,CAAC,WAAqB,CAAC;YAClD,MAAM,SAAS,GAAW,IAAI,CAAC,oBAA8B,CAAC;YAC9D,IAAI,MAAM,IAAI,IAAI,EAAE;gBAClB,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC;aACxD;iBAAM;gBACL,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC;aACvC;YACD,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,EAAE;gBACrB,CAAC,GAAG,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;aACpC;YACD,IAAI,SAAS,IAAI,IAAI,EAAE;gBACrB,UAAU,GAAG,GAAG,CAAC,GAAG,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC;aAC7C;YACD,IAAI,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,UAAU,EAAE,IAAI,CAAC,eAAe,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YACxE,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;gBAC3B,MAAM,GAAG,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;aACxC;YAED,4DAA4D;YAC5D,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;QAC1B,CAAC,CAAC,CAAC;IACL,CAAC;IAED,SAAS;QACP,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QAErC,MAAM,MAAM,GAA6B;YACvC,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,UAAU,EAAE,mBAAmB,CAAC,IAAI,CAAC,UAAU,CAAC;YAChD,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,CAAC,oBAAoB,CAAC;YACrE,eAAe,EAAE,oBAAoB,CAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,CAAC,oBAAoB,CAAC;YACrE,eAAe,EAAE,oBAAoB,CAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,mBAAmB,EAAE,oBAAoB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YACnE,gBAAgB,EAAE,mBAAmB,CAAC,IAAI,CAAC,gBAAgB,CAAC;YAC5D,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YAClE,cAAc,EAAE,mBAAmB,CAAC,IAAI,CAAC,cAAc,CAAC;YACxD,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,gBAAgB,EAAE,IAAI,CAAC,gBAAgB;SACxC,CAAC;QAEF,yBAAW,UAAU,EAAK,MAAM,EAAE;IACpC,CAAC;;AAvKD,kBAAkB;AACX,uBAAS,GAAG,eAAe,CAAC;AAwKrC,aAAa,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC;AA2F3C,MAAM,OAAO,SAAU,SAAQ,GAAG;IAGhC,YAAY,IAAwB;QAClC,IAAI,CAAC,IAAI,GAAG,IAAI,aAAa,CAAC,IAAI,CAAC,CAAC;QACpC,KAAK,CAAC,IAAoB,CAAC,CAAC;QAC5B,uCAAuC;IACzC,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,IAAI,IAAI,CAAC,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBACjC,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;gBACnC,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;aAC9B;YACD,IAAI,IAAI,CAAC,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBAC1C,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;gBAC5C,IAAI,CAAC,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC;aACvC;YACD,MAAM,IAAI,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACpD,MAAM,QAAQ,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YAC5D,MAAM,YAAY,GACd,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,cAAc,CAAC,CAAC;YACnD,OAAO,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,EAAC,IAAI,EAAE,QAAQ,EAAE,YAAY,EAAC,CAAC,CAAC;QAC5D,CAAC,CAAC,CAAC;IACL,CAAC;IAED,kBAAkB;IAClB,MAAM,CAAC,UAAU,CACb,GAA6C,EAC7C,MAAgC;QAClC,OAAO,IAAI,GAAG,CAAC,MAAM,CAAC,CAAC;IACzB,CAAC;;AA/BD,kBAAkB;AACX,mBAAS,GAAG,WAAW,CAAC;AAgCjC,aAAa,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC;AAqCvC,MAAM,OAAO,OAAQ,SAAQ,OAAO;IAqClC,YAAY,IAAsB;QAChC,KAAK,CAAC,IAAI,CAAC,CAAC;QAZL,uBAAkB,GAAG,MAAM,CAAC;QAC5B,iCAA4B,GAAyB,aAAa,CAAC;QAEnE,+BAA0B,GAAG,cAAc,CAAC;QAC5C,kCAA6B,GAAG,YAAY,CAAC;QAC7C,6BAAwB,GAA0B,OAAO,CAAC;QAQjE,IAAI,IAAI,CAAC,UAAU,EAAE;YACnB,MAAM,IAAI,UAAU,CAChB,6DAA6D,CAAC,CAAC;SACpE;QACD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QACxB,qBAAqB,CAAC,IAAI,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;QAC3C,IAAI,CAAC,UAAU,GAAG,aAAa,CAC3B,IAAI,CAAC,UAAU,KAAK,SAAS,CAAC,CAAC,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC;YACzB,IAAI,CAAC,UAAU,CAAC,CAAC;QACrD,IAAI,CAAC,mBAAmB,GAAG,aAAa,CACpC,IAAI,CAAC,mBAAmB,KAAK,SAAS,CAAC,CAAC;YACpC,IAAI,CAAC,4BAA4B,CAAC,CAAC;YACnC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QAClC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;QAE1D,IAAI,CAAC,iBAAiB,GAAG,cAAc,CACnC,IAAI,CAAC,iBAAiB,IAAI,IAAI,CAAC,0BAA0B,CAAC,CAAC;QAC/D,IAAI,CAAC,oBAAoB,GAAG,cAAc,CACtC,IAAI,CAAC,oBAAoB,IAAI,IAAI,CAAC,6BAA6B,CAAC,CAAC;QAErE,IAAI,CAAC,eAAe;YAChB,cAAc,CAAC,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC,wBAAwB,CAAC,CAAC;QAE1E,IAAI,CAAC,iBAAiB,GAAG,cAAc,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;QAChE,IAAI,CAAC,oBAAoB,GAAG,cAAc,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;QACtE,IAAI,CAAC,eAAe,GAAG,cAAc,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAE5D,IAAI,CAAC,gBAAgB,GAAG,aAAa,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAC7D,IAAI,CAAC,mBAAmB,GAAG,aAAa,CAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QACnE,IAAI,CAAC,cAAc,GAAG,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QAEzD,IAAI,CAAC,OAAO,GAAG,UAAU,CAAC,GAAG,CACzB,CAAC,CAAC,EAAE,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QACvE,IAAI,CAAC,gBAAgB,GAAG,UAAU,CAAC,GAAG,CAAC;YACrC,CAAC;YACD,UAAU,CAAC,GAAG,CACV,CAAC,CAAC,EAAE,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;SACpE,CAAC,CAAC;QACH,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,cAAc,CAAC;QAC1C,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC;QAC5B,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;QACxB,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC;IACnC,CAAC;IAEM,KAAK,CAAC,UAAyB;QACpC,UAAU,GAAG,kBAAkB,CAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,QAAQ,GAAG,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QACnD,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CACxB,QAAQ,EAAE,CAAC,QAAQ,EAAE,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,iBAAiB,EAClE,IAAI,CAAC,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAC;QACzD,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,SAAS,CACjC,kBAAkB,EAAE,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,EAAE,IAAI,EACtD,IAAI,CAAC,oBAAoB,EAAE,IAAI,CAAC,oBAAoB,EAAE,IAAI,EAC1D,IAAI,CAAC,mBAAmB,CAAC,CAAC;QAC9B,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE,CAAC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,EACpD,IAAI,CAAC,eAAe,EAAE,IAAI,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;SACtD;aAAM;YACL,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;SAClB;QACD,uEAAuE;QACvE,qEAAqE;QACrE,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,MAAM,GAAG,MAAkB,CAAC;YAC5B,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;gBACvB,MAAM,IAAI,UAAU,CAChB,sDAAsD;oBACtD,GAAG,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC;aAC1B;YAED,MAAM,QAAQ,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YACzE,IAAI,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAE,yBAAyB;YACpD,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YAEnB,4DAA4D;YAC5D,sDAAsD;YACtD,yBAAyB;YACzB,IAAI,CAAC,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBACpE,IAAI,CAAC,WAAW,GAAG,mBAAmB,CAAC;oBAClB,IAAI,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAgB,CAAC;oBAC1C,IAAI,EAAE,IAAI,CAAC,OAAO;oBAClB,QAAQ;oBACR,KAAK,EAAE,CAAC;iBACT,CAAa,CAAC;aACnC;YACD,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,gBAAgB,GAAG,CAAC;gBACtD,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBACrC,IAAI,CAAC,oBAAoB,GAAG,mBAAmB,CAAC;oBAClB,IAAI,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,QAAQ,CAAC;oBAClC,IAAI,EAAE,IAAI,CAAC,gBAAgB;oBAC3B,QAAQ;oBACR,KAAK,EAAE,CAAC;iBACT,CAAa,CAAC;aAC5C;YACD,MAAM,MAAM,GAAG,IAAI,CAAC,WAAuC,CAAC;YAC5D,MAAM,SAAS,GAAG,IAAI,CAAC,oBAAgD,CAAC;YACxE,IAAI,CAAS,CAAC;YACd,IAAI,CAAS,CAAC;YACd,IAAI,EAAU,CAAC;YAEf,IAAI,CAAC,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE;gBACxC,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;aACrC;YACD,IAAI,OAAO,GAAG,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC;YAChD,IAAI,IAAI,CAAC,OAAO,EAAE;gBAChB,OAAO,GAAG,CAAC,CAAC,OAAO,CAAC,OAAO,EAAE,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;aAChD;YACD,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,gBAAgB,GAAG,CAAC,EAAE;gBAC1D,QAAQ,GAAG,GAAG,CAAC,GAAG,CAAC,QAAQ,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;aAC5C;YAED,MAAM,oBAAoB,GAAG,IAAI,CAAC,eAAe,CAAC,IAAI,EAAE,CAAC;YACzD,MAAM,CAAC,GAAG,EAAE,GAAG,CAAC,GAAG,GAAG,CAAC,KAAK,CACxB,oBAAoB,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC,EAClD,oBAAoB,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC;YACnC,MAAM,WAAW,GAAG,CAAC,CAAC,GAAG,CAAC,QAAQ,EAAE,GAAG,CAAC,CAAC;YAEzC,MAAM,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,OAAO,EAAE,CAAC,EAAE,OAAO,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC;YAC7D,MAAM,CAAC,UAAU,EAAE,UAAU,CAAC,GAC1B,GAAG,CAAC,KAAK,CAAC,WAAW,EAAE,CAAC,EAAE,WAAW,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC;YACpD,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC,CAAC;YAC5D,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC,CAAC;YAE5D,MAAM,UAAU,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,EAAE,GAAG,CAAC,CAAC;YACpD,EAAE,GAAG,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC,CAAC;YAEpD,MAAM,CAAC,GACH,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;YACvE,oDAAoD;YACpD,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;IAED,SAAS;QACP,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QAErC,MAAM,MAAM,GAA6B;YACvC,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,UAAU,EAAE,mBAAmB,CAAC,IAAI,CAAC,UAAU,CAAC;YAChD,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YAClE,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,CAAC,oBAAoB,CAAC;YACrE,eAAe,EAAE,oBAAoB,CAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,CAAC,oBAAoB,CAAC;YACrE,eAAe,EAAE,oBAAoB,CAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,mBAAmB,EAAE,oBAAoB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YACnE,gBAAgB,EAAE,mBAAmB,CAAC,IAAI,CAAC,gBAAgB,CAAC;YAC5D,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YAClE,cAAc,EAAE,mBAAmB,CAAC,IAAI,CAAC,cAAc,CAAC;YACxD,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,gBAAgB,EAAE,IAAI,CAAC,gBAAgB;YACvC,cAAc,EAAE,IAAI,CAAC,cAAc;YACnC,UAAU,EAAE,KAAK;SAClB,CAAC;QAEF,yBAAW,UAAU,EAAK,MAAM,EAAE;IACpC,CAAC;;AAzMD,kBAAkB;AACX,iBAAS,GAAG,SAAS,CAAC;AA0M/B,aAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AA8BrC,MAAM,OAAO,GAAI,SAAQ,GAAG;IAG1B,YAAY,IAAkB;QAC5B,IAAI,IAAI,CAAC,cAAc,KAAK,CAAC,EAAE;YAC7B,OAAO,CAAC,IAAI,CACR,8DAA8D;gBAC9D,oDAAoD,CAAC,CAAC;SAC3D;QACD,IAAI,CAAC,IAAI,GAAG,IAAI,OAAO,CAAC,IAAI,CAAC,CAAC;QAC9B,KAAK,CAAC,IAAoB,CAAC,CAAC;QAC5B,uCAAuC;IACzC,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,IAAI,IAAI,CAAC,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBACjC,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;gBACnC,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;aAC9B;YACD,IAAI,IAAI,CAAC,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBAC1C,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;gBAC5C,IAAI,CAAC,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC;aACvC;YACD,MAAM,IAAI,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACpD,MAAM,QAAQ,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YAC5D,MAAM,YAAY,GACd,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,cAAc,CAAC,CAAC;YACnD,OAAO,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,EAAC,IAAI,EAAE,QAAQ,EAAE,YAAY,EAAC,CAAC,CAAC;QAC5D,CAAC,CAAC,CAAC;IACL,CAAC;IAED,kBAAkB;IAClB,MAAM,CAAC,UAAU,CACb,GAA6C,EAC7C,MAAgC;QAClC,IAAI,MAAM,CAAC,eAAe,CAAC,KAAK,CAAC,EAAE;YACjC,MAAM,CAAC,gBAAgB,CAAC,GAAG,CAAC,CAAC;SAC9B;QACD,OAAO,IAAI,GAAG,CAAC,MAAM,CAAC,CAAC;IACzB,CAAC;;AAvCD,kBAAkB;AACX,aAAS,GAAG,KAAK,CAAC;AAwC3B,aAAa,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC;AAuCjC,MAAM,OAAO,QAAS,SAAQ,OAAO;IAsCnC,YAAY,IAAuB;QACjC,KAAK,CAAC,IAAI,CAAC,CAAC;QAZL,uBAAkB,GAAG,MAAM,CAAC;QAC5B,iCAA4B,GAAG,aAAa,CAAC;QAC7C,+BAA0B,GAAG,cAAc,CAAC;QAC5C,kCAA6B,GAAG,YAAY,CAAC;QAE7C,6BAAwB,GAAG,OAAO,CAAC;QAS1C,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QACxB,qBAAqB,CAAC,IAAI,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;QAC3C,IAAI,CAAC,UAAU,GAAG,aAAa,CAC3B,IAAI,CAAC,UAAU,KAAK,SAAS,CAAC,CAAC,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC;YACzB,IAAI,CAAC,UAAU,CAAC,CAAC;QACrD,IAAI,CAAC,mBAAmB,GAAG,aAAa,CACpC,IAAI,CAAC,mBAAmB,KAAK,SAAS,CAAC,CAAC;YACpC,IAAI,CAAC,4BAA4B,CAAC,CAAC;YACnC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QAClC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;QAE1D,IAAI,CAAC,iBAAiB,GAAG,cAAc,CACnC,IAAI,CAAC,iBAAiB,IAAI,IAAI,CAAC,0BAA0B,CAAC,CAAC;QAC/D,IAAI,CAAC,oBAAoB,GAAG,cAAc,CACtC,IAAI,CAAC,oBAAoB,IAAI,IAAI,CAAC,6BAA6B,CAAC,CAAC;QAErE,IAAI,CAAC,eAAe;YAChB,cAAc,CAAC,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC,wBAAwB,CAAC,CAAC;QAC1E,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,cAAc,CAAC;QAE1C,IAAI,CAAC,iBAAiB,GAAG,cAAc,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;QAChE,IAAI,CAAC,oBAAoB,GAAG,cAAc,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;QACtE,IAAI,CAAC,eAAe,GAAG,cAAc,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAE5D,IAAI,CAAC,gBAAgB,GAAG,aAAa,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAC7D,IAAI,CAAC,mBAAmB,GAAG,aAAa,CAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QACnE,IAAI,CAAC,cAAc,GAAG,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QAEzD,IAAI,CAAC,OAAO,GAAG,UAAU,CAAC,GAAG,CACzB,CAAC,CAAC,EAAE,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QACvE,IAAI,CAAC,gBAAgB,GAAG,UAAU,CAAC,GAAG,CAAC;YACrC,CAAC;YACD,UAAU,CAAC,GAAG,CACV,CAAC,CAAC,EAAE,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;SACpE,CAAC,CAAC;QACH,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,cAAc,CAAC;QAC1C,IAAI,CAAC,SAAS,GAAG,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC;QAC1C,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;QACxB,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC;IACnC,CAAC;IAEM,KAAK,CAAC,UAAyB;;QACpC,UAAU,GAAG,kBAAkB,CAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,QAAQ,GAAG,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QACnD,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CACxB,QAAQ,EAAE,CAAC,QAAQ,EAAE,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,IAAI,CAAC,iBAAiB,EAClE,IAAI,CAAC,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAC;QACzD,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,SAAS,CACjC,kBAAkB,EAAE,CAAC,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,EAAE,IAAI,EACtD,IAAI,CAAC,oBAAoB,EAAE,IAAI,CAAC,oBAAoB,EAAE,IAAI,EAC1D,IAAI,CAAC,mBAAmB,CAAC,CAAC;QAC9B,IAAI,eAA4B,CAAC;QACjC,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,IAAI,IAAI,CAAC,cAAc,EAAE;gBACvB,MAAM,gBAAgB,GAAG,IAAI,CAAC,eAAe,CAAC;gBAC9C,MAAM,aAAa,GAAG,IAAI,CAAC,KAAK,CAAC;gBACjC,eAAe,GAAG,IAAI,MAAC,MAAM,UAAW,SAAQ,WAAW;wBAIzD,KAAK,CAAC,KAAY,EAAE,KAAgB;4BAClC,+CAA+C;4BAC/C,MAAM,EAAE,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC,aAAa,CAAC,CAAC,CAAC;4BACnD,MAAM,EAAE,GAAG,CAAC,IAAI,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,aAAa,CAAC,CAAC,CAAC;4BAC/C,MAAM,MAAM,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC,aAAa,GAAG,CAAC,CAAC,CAAC,CAAC;4BAC3D,OAAO,CAAC,CAAC,oBAAoB,CACzB,CAAC,CAAC,oBAAoB,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,MAAM,CAAC,CAAC;wBAC9C,CAAC;qBACF;oBAXC,kBAAkB;oBACX,YAAS,GAAG,YAAa;uBAUhC,EAAE,CAAC;aACN;iBAAM;gBACL,eAAe,GAAG,IAAI,CAAC,eAAe,CAAC;aACxC;YACD,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE,CAAC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,eAAe,EAAE,IAAI,CAAC,eAAe,EACrE,IAAI,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;SAChC;aAAM;YACL,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;SAClB;QACD,uEAAuE;QACvE,qEAAqE;QACrE,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,MAAM,QAAQ,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YACzE,MAAM,GAAG,MAAkB,CAAC;YAC5B,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;gBACvB,MAAM,IAAI,UAAU,CAChB,uDAAuD;oBACvD,GAAG,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC;aAC1B;YACD,IAAI,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAI,yBAAyB;YACtD,MAAM,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAE,wBAAwB;YACrD,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;YACnB,IAAI,CAAC,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBACpE,IAAI,CAAC,WAAW,GAAG,mBAAmB,CAAC;oBAClB,IAAI,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAgB,CAAC;oBAC1C,IAAI,EAAE,IAAI,CAAC,OAAO;oBAClB,QAAQ;oBACR,KAAK,EAAE,CAAC;iBACT,CAAa,CAAC;aACnC;YACD,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,gBAAgB,GAAG,CAAC;gBACtD,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBACrC,IAAI,CAAC,oBAAoB,GAAG,mBAAmB,CAAC;oBAClB,IAAI,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,QAAQ,CAAC,QAAQ,CAAC;oBAClC,IAAI,EAAE,IAAI,CAAC,gBAAgB;oBAC3B,QAAQ;oBACR,KAAK,EAAE,CAAC;iBACT,CAAa,CAAC;aAC5C;YACD,MAAM,MAAM,GAAG,IAAI,CAAC,WAA+C,CAAC;YACpE,MAAM,SAAS,GACX,IAAI,CAAC,oBAAwD,CAAC;YAElE,4DAA4D;YAC5D,qDAAqD;YACrD,yBAAyB;YACzB,IAAI,CAAS,CAAC;YACd,IAAI,CAAS,CAAC;YACd,IAAI,CAAS,CAAC;YACd,IAAI,CAAS,CAAC;YACd,IAAI,CAAC,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE;gBACxC,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;aACrC;YACD,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC;YAC1C,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,gBAAgB,GAAG,CAAC,EAAE;gBAC1D,QAAQ,GAAG,GAAG,CAAC,GAAG,CAAC,QAAQ,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;aAC5C;YACD,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,QAAQ,EAAE,IAAI,CAAC,eAAe,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YAC7D,IAAI,IAAI,CAAC,OAAO,EAAE;gBAChB,CAAC,GAAG,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;aACpC;YAED,MAAM,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC;YAErD,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;YACvC,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;YACvC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YACzE,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;YAEvC,MAAM,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YAC/C,oDAAoD;YACpD,OAAO,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QACnB,CAAC,CAAC,CAAC;IACL,CAAC;IAED,SAAS;QACP,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QAErC,MAAM,MAAM,GAA6B;YACvC,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,UAAU,EAAE,mBAAmB,CAAC,IAAI,CAAC,UAAU,CAAC;YAChD,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YAClE,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,CAAC,oBAAoB,CAAC;YACrE,eAAe,EAAE,oBAAoB,CAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,cAAc,EAAE,IAAI,CAAC,cAAc;YACnC,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,CAAC,oBAAoB,CAAC;YACrE,eAAe,EAAE,oBAAoB,CAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,mBAAmB,EAAE,oBAAoB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YACnE,gBAAgB,EAAE,mBAAmB,CAAC,IAAI,CAAC,gBAAgB,CAAC;YAC5D,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,CAAC,mBAAmB,CAAC;YAClE,cAAc,EAAE,mBAAmB,CAAC,IAAI,CAAC,cAAc,CAAC;YACxD,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,gBAAgB,EAAE,IAAI,CAAC,gBAAgB;YACvC,cAAc,EAAE,IAAI,CAAC,cAAc;SACpC,CAAC;QAEF,yBAAW,UAAU,EAAK,MAAM,EAAE;IACpC,CAAC;;AArND,kBAAkB;AACX,kBAAS,GAAG,UAAU,CAAC;AAsNhC,aAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;AAqCtC,MAAM,OAAO,IAAK,SAAQ,GAAG;IAG3B,YAAY,IAAmB;QAC7B,IAAI,IAAI,CAAC,cAAc,KAAK,CAAC,EAAE;YAC7B,OAAO,CAAC,IAAI,CACR,8DAA8D;gBAC9D,oDAAoD,CAAC,CAAC;SAC3D;QACD,IAAI,CAAC,IAAI,GAAG,IAAI,QAAQ,CAAC,IAAI,CAAC,CAAC;QAC/B,KAAK,CAAC,IAAoB,CAAC,CAAC;QAC5B,uCAAuC;IACzC,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,IAAI,IAAI,CAAC,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBACjC,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;gBACnC,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;aAC9B;YACD,IAAI,IAAI,CAAC,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBAC1C,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;gBAC5C,IAAI,CAAC,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC;aACvC;YACD,MAAM,IAAI,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACpD,MAAM,QAAQ,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YAC5D,MAAM,YAAY,GACd,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,cAAc,CAAC,CAAC;YACnD,OAAO,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,EAAC,IAAI,EAAE,QAAQ,EAAE,YAAY,EAAC,CAAC,CAAC;QAC5D,CAAC,CAAC,CAAC;IACL,CAAC;IAED,kBAAkB;IAClB,MAAM,CAAC,UAAU,CACb,GAA6C,EAC7C,MAAgC;QAClC,IAAI,MAAM,CAAC,eAAe,CAAC,KAAK,CAAC,EAAE;YACjC,MAAM,CAAC,gBAAgB,CAAC,GAAG,CAAC,CAAC;SAC9B;QACD,OAAO,IAAI,GAAG,CAAC,MAAM,CAAC,CAAC;IACzB,CAAC;;AAvCD,kBAAkB;AACX,cAAS,GAAG,MAAM,CAAC;AAwC5B,aAAa,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;AASlC,MAAM,OAAO,eAAgB,SAAQ,OAAO;IAK1C,YAAY,IAAyB;QACnC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;IAC1B,CAAC;IAED,IAAI,SAAS;QACX,6DAA6D;QAC7D,iEAAiE;QACjE,0EAA0E;QAC1E,yCAAyC;QACzC,MAAM,SAAS,GAAa,EAAE,CAAC;QAC/B,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,OAAO,EAAE,EAAE;YAC/C,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;gBACjC,SAAS,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC;aACnC;iBAAM;gBACL,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;aAChC;SACF;QACD,OAAO,SAAS,CAAC;IACnB,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,OAAO,IAAI,CAAC,GAAG,EAAE;YACf,MAAM,GAAG,MAAkB,CAAC;YAC5B,IAAI,MAAM,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAE7B,2BAA2B;YAC3B,MAAM,YAAY,GAAe,EAAE,CAAC;YACpC,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,OAAO,EAAE,EAAE;gBAC/C,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;oBACjC,YAAY,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,EAAE,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,CAAC;iBAC5D;qBAAM;oBACL,YAAY,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;iBACxC;aACF;YACD,YAAY,CAAC,OAAO,EAAE,CAAC;YAEvB,yDAAyD;YACzD,MAAM,eAAe,GAAe,EAAE,CAAC;YACvC,IAAI,UAAoB,CAAC;YACzB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;gBAC1C,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;gBAC3B,MAAM,GAAG,YAAY,CAAC,CAAC,CAAC,CAAC;gBACzB,sCAAsC;gBACtC,IAAI,CAAC,KAAK,CAAC,EAAE;oBACX,UAAU,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;iBACzC;qBAAM;oBACL,UAAU,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;iBAC7C;gBACD,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE,MAAM,CAAa,CAAC;gBACvD,eAAe,CAAC,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;aAC3C;YAED,8DAA8D;YAC9D,MAAM,GAAG,EAAE,CAAC;YACZ,KAAK,MAAM,UAAU,IAAI,eAAe,CAAC,KAAK,EAAE,CAAC,OAAO,EAAE,EAAE;gBAC1D,MAAM,CAAC,IAAI,CAAC,GAAG,UAAU,CAAC,CAAC;aAC5B;YACD,OAAO,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QACxC,CAAC,CAAC,CAAC;IACL,CAAC;IAEM,KAAK,CAAC,UAAyB;QACpC,IAAI,eAAe,CAAC,UAAU,CAAC,EAAE;YAC/B,4CAA4C;YAC5C,6CAA6C;YAC7C,UAAU,GAAI,UAAsB,CAAC,CAAC,CAAC,CAAC;SACzC;QACD,UAAU,GAAG,UAAmB,CAAC;QACjC,IAAI,SAAiB,CAAC;QACtB,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,EAAE,EAAE;YAC7B,SAAS,CAAC,WAAW,CAAC,EAAE,EAAE,GAAG,EAAE;gBAC7B,4CAA4C;gBAE5C,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;gBACvB,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;oBACjC,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;iBAC/B;qBAAM;oBACL,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC;iBAC5B;gBACD,UAAU,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,SAAS,CAAU,CAAC;YACnD,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QACH,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAED,SAAS;QACP,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QAErC,MAAM,aAAa,GAAG,CAAC,IAAa,EAAE,EAAE;YACtC,OAAO;gBACL,WAAW,EAAE,IAAI,CAAC,YAAY,EAAE;gBAChC,QAAQ,EAAE,IAAI,CAAC,SAAS,EAAE;aAC3B,CAAC;QACJ,CAAC,CAAC;QAEF,MAAM,WAAW,GAAG,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,aAAa,CAAC,CAAC;QAElD,MAAM,MAAM,GAAG,EAAC,OAAO,EAAE,WAAW,EAAC,CAAC;QAEtC,yBAAW,UAAU,EAAK,MAAM,EAAE;IACpC,CAAC;IAED,kBAAkB;IAClB,MAAM,CAAC,UAAU,CACb,GAA6C,EAC7C,MAAgC,EAChC,gBAAgB,EAA8B;QAChD,MAAM,KAAK,GAAc,EAAE,CAAC;QAC5B,KAAK,MAAM,UAAU,IAAK,MAAM,CAAC,OAAO,CAAgC,EAAE;YACxE,KAAK,CAAC,IAAI,CAAC,WAAW,CAAC,UAAU,EAAE,aAAa,CAAY,CAAC,CAAC;SAC/D;QACD,OAAO,IAAI,GAAG,CAAC,EAAC,KAAK,EAAC,CAAC,CAAC;IAC1B,CAAC;IAED,IAAI,gBAAgB;QAClB,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE;YACnB,OAAO,EAAE,CAAC;SACX;QACD,MAAM,OAAO,GAAoB,EAAE,CAAC;QACpC,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,KAAK,EAAE;YAC7B,OAAO,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,CAAC,CAAC;SACxC;QACD,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,IAAI,mBAAmB;QACrB,MAAM,OAAO,GAAoB,EAAE,CAAC;QACpC,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,KAAK,EAAE;YAC7B,OAAO,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,CAAC;SAC3C;QACD,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE;YACnB,MAAM,gBAAgB,GAAoB,EAAE,CAAC;YAC7C,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,KAAK,EAAE;gBAC7B,gBAAgB,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,CAAC,CAAC;aACjD;YACD,OAAO,gBAAgB,CAAC,MAAM,CAAC,OAAO,CAAC,CAAC;SACzC;QACD,OAAO,OAAO,CAAC;IACjB,CAAC;IAED;;;;OAIG;IACH,UAAU;QACR,MAAM,OAAO,GAAoB,EAAE,CAAC;QACpC,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,KAAK,EAAE;YAC7B,OAAO,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC;SAC/B;QACD,OAAO,aAAa,CAAC,OAAO,CAAC,CAAC;IAChC,CAAC;IAED;;;;;OAKG;IACH,UAAU,CAAC,OAAiB;QAC1B,MAAM,MAAM,GAAmC,EAAE,CAAC;QAClD,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,KAAK,EAAE;YAC7B,MAAM,SAAS,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC;YACtC,MAAM,YAAY,GAAG,OAAO,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;YAC/C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;gBAC5C,MAAM,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;aACjD;SACF;QACD,aAAa,CAAC,MAAM,CAAC,CAAC;IACxB,CAAC;;AA9KD,kBAAkB;AACX,yBAAS,GAAG,iBAAiB,CAAC;AAiLvC,aAAa,CAAC,aAAa,CAAC,eAAe,CAAC,CAAC;AAE7C,MAAM,UAAU,mBAAmB,CAAC,IAKnC;IACC,MAAM,EAAC,IAAI,EAAE,IAAI,EAAE,QAAQ,GAAG,KAAK,EAAE,KAAK,GAAG,CAAC,EAAC,GAAG,IAAI,CAAC;IAEvD,MAAM,aAAa,GAAG,GAAG,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,EAAE,EAAE,IAAI,CAAC,CAAC;IAEpD,MAAM,UAAU,GAAG,GAAG,EAAE,CAAC,CAAC,CAAC,YAAY,CAAC,aAAa,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;IAEvE,wDAAwD;IACxD,IAAI,CAAC,KAAK,IAAI,KAAK,IAAI,CAAC,EAAE;QACxB,OAAO,GAAG,CAAC,IAAI,CAAC,UAAU,EAAE,CAAC,KAAK,EAAE,CAAC,CAAC;KACvC;IAED,MAAM,KAAK,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,GAAG,CAAC,UAAU,CAAC,CAAC;IAE3D,OAAO,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;AAC7C,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Recurrent Neural Network Layers.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {DataType, serialization, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {Activation, getActivation, serializeActivation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {nameScope} from '../common';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {InputSpec, SymbolicTensor} from '../engine/topology';\nimport {Layer, LayerArgs} from '../engine/topology';\nimport {AttributeError, NotImplementedError, ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, Ones, serializeInitializer} from '../initializers';\nimport {ActivationIdentifier} from '../keras_format/activation_config';\nimport {Shape} from '../keras_format/common';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs, RnnStepFunction} from '../types';\nimport {assertPositiveInteger} from '../utils/generic_utils';\nimport * as math_utils from '../utils/math_utils';\nimport {getExactlyOneShape, getExactlyOneTensor, isArrayOfShapes} from '../utils/types_utils';\nimport {batchGetValue, batchSetValue, LayerVariable} from '../variables';\nimport {deserialize} from './serialization';\n\n/**\n * Standardize `apply()` args to a single list of tensor inputs.\n *\n * When running a model loaded from file, the input tensors `initialState` and\n * `constants` are passed to `RNN.apply()` as part of `inputs` instead of the\n * dedicated kwargs fields. `inputs` consists of\n * `[inputs, initialState0, initialState1, ..., constant0, constant1]` in this\n * case.\n * This method makes sure that arguments are\n * separated and that `initialState` and `constants` are `Array`s of tensors\n * (or None).\n *\n * @param inputs Tensor or `Array` of  tensors.\n * @param initialState Tensor or `Array` of tensors or `null`/`undefined`.\n * @param constants Tensor or `Array` of tensors or `null`/`undefined`.\n * @returns An object consisting of\n *   inputs: A tensor.\n *   initialState: `Array` of tensors or `null`.\n *   constants: `Array` of tensors or `null`.\n * @throws ValueError, if `inputs` is an `Array` but either `initialState` or\n *   `constants` is provided.\n */\nexport function standardizeArgs(\n    inputs: Tensor|Tensor[]|SymbolicTensor|SymbolicTensor[],\n    initialState: Tensor|Tensor[]|SymbolicTensor|SymbolicTensor[],\n    constants: Tensor|Tensor[]|SymbolicTensor|SymbolicTensor[],\n    numConstants?: number): {\n  inputs: Tensor|SymbolicTensor,\n  initialState: Tensor[]|SymbolicTensor[],\n  constants: Tensor[]|SymbolicTensor[]\n} {\n  if (Array.isArray(inputs)) {\n    if (initialState != null || constants != null) {\n      throw new ValueError(\n          'When inputs is an array, neither initialState or constants ' +\n          'should be provided');\n    }\n    if (numConstants != null) {\n      constants = inputs.slice(inputs.length - numConstants, inputs.length);\n      inputs = inputs.slice(0, inputs.length - numConstants);\n    }\n    if (inputs.length > 1) {\n      initialState = inputs.slice(1, inputs.length);\n    }\n    inputs = inputs[0];\n  }\n\n  function toListOrNull(x: Tensor|Tensor[]|SymbolicTensor|\n                        SymbolicTensor[]): Tensor[]|SymbolicTensor[] {\n    if (x == null || Array.isArray(x)) {\n      return x as Tensor[] | SymbolicTensor[];\n    } else {\n      return [x] as Tensor[] | SymbolicTensor[];\n    }\n  }\n\n  initialState = toListOrNull(initialState);\n  constants = toListOrNull(constants);\n\n  return {inputs, initialState, constants};\n}\n\n/**\n * Iterates over the time dimension of a tensor.\n *\n * @param stepFunction RNN step function.\n *   Parameters:\n *     inputs: tensor with shape `[samples, ...]` (no time dimension),\n *       representing input for the batch of samples at a certain time step.\n *     states: an Array of tensors.\n *   Returns:\n *     outputs: tensor with shape `[samples, outputDim]` (no time dimension).\n *     newStates: list of tensors, same length and shapes as `states`. The first\n *       state in the list must be the output tensor at the previous timestep.\n * @param inputs Tensor of temporal data of shape `[samples, time, ...]` (at\n *   least 3D).\n * @param initialStates Tensor with shape `[samples, outputDim]` (no time\n *   dimension), containing the initial values of the states used in the step\n *   function.\n * @param goBackwards If `true`, do the iteration over the time dimension in\n *   reverse order and return the reversed sequence.\n * @param mask Binary tensor with shape `[sample, time, 1]`, with a zero for\n *   every element that is masked.\n * @param constants An Array of constant values passed at each step.\n * @param unroll Whether to unroll the RNN or to use a symbolic loop. *Not*\n *   applicable to this imperative deeplearn.js backend. Its value is ignored.\n * @param needPerStepOutputs Whether the per-step outputs are to be\n *   concatenated into a single tensor and returned (as the second return\n *   value). Default: `false`. This arg is included so that the relatively\n *   expensive concatenation of the stepwise outputs can be omitted unless\n *   the stepwise outputs need to be kept (e.g., for an LSTM layer of which\n *   `returnSequence` is `true`.)\n * @returns An Array: `[lastOutput, outputs, newStates]`.\n *   lastOutput: the lastest output of the RNN, of shape `[samples, ...]`.\n *   outputs: tensor with shape `[samples, time, ...]` where each entry\n *     `output[s, t]` is the output of the step function at time `t` for sample\n *     `s`. This return value is provided if and only if the\n *     `needPerStepOutputs` is set as `true`. If it is set as `false`, this\n *     return value will be `undefined`.\n *   newStates: Array of tensors, latest states returned by the step function,\n *      of shape `(samples, ...)`.\n * @throws ValueError If input dimension is less than 3.\n *\n * TODO(nielsene): This needs to be tidy-ed.\n */\nexport function rnn(\n    stepFunction: RnnStepFunction, inputs: Tensor, initialStates: Tensor[],\n    goBackwards = false, mask?: Tensor, constants?: Tensor[], unroll = false,\n    needPerStepOutputs = false): [Tensor, Tensor, Tensor[]] {\n  return tfc.tidy(() => {\n    const ndim = inputs.shape.length;\n    if (ndim < 3) {\n      throw new ValueError(`Input should be at least 3D, but is ${ndim}D.`);\n    }\n\n    // Transpose to time-major, i.e., from [batch, time, ...] to [time, batch,\n    // ...].\n    const axes = [1, 0].concat(math_utils.range(2, ndim));\n    inputs = tfc.transpose(inputs, axes);\n\n    if (constants != null) {\n      throw new NotImplementedError(\n          'The rnn() functoin of the deeplearn.js backend does not support ' +\n          'constants yet.');\n    }\n\n    // Porting Note: the unroll option is ignored by the imperative backend.\n    if (unroll) {\n      console.warn(\n          'Backend rnn(): the unroll = true option is not applicable to the ' +\n          'imperative deeplearn.js backend.');\n    }\n\n    if (mask != null) {\n      mask = mask.asType('bool').asType('float32');\n      if (mask.rank === ndim - 1) {\n        mask = tfc.expandDims(mask, -1);\n      }\n      mask = tfc.transpose(mask, axes);\n    }\n\n    if (goBackwards) {\n      inputs = tfc.reverse(inputs, 0);\n      if (mask != null) {\n        mask = tfc.reverse(mask, 0);\n      }\n    }\n\n    // Porting Note: PyKeras with TensorFlow backend uses a symbolic loop\n    //   (tf.while_loop). But for the imperative deeplearn.js backend, we just\n    //   use the usual TypeScript control flow to iterate over the time steps in\n    //   the inputs.\n    // Porting Note: PyKeras patches a \"_use_learning_phase\" attribute to\n    // outputs.\n    //   This is not idiomatic in TypeScript. The info regarding whether we are\n    //   in a learning (i.e., training) phase for RNN is passed in a different\n    //   way.\n\n    const perStepOutputs: Tensor[] = [];\n    let lastOutput: Tensor;\n    let states = initialStates;\n    const timeSteps = inputs.shape[0];\n    const perStepInputs = tfc.unstack(inputs);\n    let perStepMasks: Tensor[];\n    if (mask != null) {\n      perStepMasks = tfc.unstack(mask);\n    }\n\n    for (let t = 0; t < timeSteps; ++t) {\n      const currentInput = perStepInputs[t];\n      const stepOutputs = tfc.tidy(() => stepFunction(currentInput, states));\n\n      if (mask == null) {\n        lastOutput = stepOutputs[0];\n        states = stepOutputs[1];\n      } else {\n        const maskedOutputs = tfc.tidy(() => {\n          const stepMask = perStepMasks[t];\n          const negStepMask = tfc.onesLike(stepMask).sub(stepMask);\n          // TODO(cais): Would tfc.where() be better for performance?\n          const output =\n              stepOutputs[0].mul(stepMask).add(states[0].mul(negStepMask));\n          const newStates = states.map((state, i) => {\n            return stepOutputs[1][i].mul(stepMask).add(state.mul(negStepMask));\n          });\n          return {output, newStates};\n        });\n        lastOutput = maskedOutputs.output;\n        states = maskedOutputs.newStates;\n      }\n\n      if (needPerStepOutputs) {\n        perStepOutputs.push(lastOutput);\n      }\n    }\n    let outputs: Tensor;\n    if (needPerStepOutputs) {\n      const axis = 1;\n      outputs = tfc.stack(perStepOutputs, axis);\n    }\n    return [lastOutput, outputs, states] as [Tensor, Tensor, Tensor[]];\n  });\n}\n\nexport declare interface BaseRNNLayerArgs extends LayerArgs {\n  /**\n   * A RNN cell instance. A RNN cell is a class that has:\n   *   - a `call()` method, which takes `[Tensor, Tensor]` as the\n   *     first input argument. The first item is the input at time t, and\n   *     second item is the cell state at time t.\n   *     The `call()` method returns `[outputAtT, statesAtTPlus1]`.\n   *     The `call()` method of the cell can also take the argument `constants`,\n   *     see section \"Note on passing external constants\" below.\n   *     Porting Node: PyKeras overrides the `call()` signature of RNN cells,\n   *       which are Layer subtypes, to accept two arguments. tfjs-layers does\n   *       not do such overriding. Instead we preseve the `call()` signature,\n   *       which due to its `Tensor|Tensor[]` argument and return value, is\n   *       flexible enough to handle the inputs and states.\n   *   - a `stateSize` attribute. This can be a single integer (single state)\n   *     in which case it is the size of the recurrent state (which should be\n   *     the same as the size of the cell output). This can also be an Array of\n   *     integers (one size per state). In this case, the first entry\n   *     (`stateSize[0]`) should be the same as the size of the cell output.\n   * It is also possible for `cell` to be a list of RNN cell instances, in which\n   * case the cells get stacked on after the other in the RNN, implementing an\n   * efficient stacked RNN.\n   */\n  cell?: RNNCell|RNNCell[];\n\n  /**\n   * Whether to return the last output in the output sequence, or the full\n   * sequence.\n   */\n  returnSequences?: boolean;\n\n  /**\n   * Whether to return the last state in addition to the output.\n   */\n  returnState?: boolean;\n\n  /**\n   * If `true`, process the input sequence backwards and return the reversed\n   * sequence (default: `false`).\n   */\n  goBackwards?: boolean;\n\n  /**\n   * If `true`, the last state for each sample at index i in a batch will be\n   * used as initial state of the sample of index i in the following batch\n   * (default: `false`).\n   *\n   * You can set RNN layers to be \"stateful\", which means that the states\n   * computed for the samples in one batch will be reused as initial states\n   * for the samples in the next batch. This assumes a one-to-one mapping\n   * between samples in different successive batches.\n   *\n   * To enable \"statefulness\":\n   *   - specify `stateful: true` in the layer constructor.\n   *   - specify a fixed batch size for your model, by passing\n   *     - if sequential model:\n   *       `batchInputShape: [...]` to the first layer in your model.\n   *     - else for functional model with 1 or more Input layers:\n   *       `batchShape: [...]` to all the first layers in your model.\n   *     This is the expected shape of your inputs\n   *     *including the batch size*.\n   *     It should be a tuple of integers, e.g., `[32, 10, 100]`.\n   *   - specify `shuffle: false` when calling `LayersModel.fit()`.\n   *\n   * To reset the state of your model, call `resetStates()` on either the\n   * specific layer or on the entire model.\n   */\n  stateful?: boolean;\n  // TODO(cais): Explore whether we can warn users when they fail to set\n  //   `shuffle: false` when training a model consisting of stateful RNNs\n  //   and any stateful Layers in general.\n\n  /**\n   * If `true`, the network will be unrolled, else a symbolic loop will be\n   * used. Unrolling can speed-up a RNN, although it tends to be more memory-\n   * intensive. Unrolling is only suitable for short sequences (default:\n   * `false`).\n   * Porting Note: tfjs-layers has an imperative backend. RNNs are executed with\n   *   normal TypeScript control flow. Hence this property is inapplicable and\n   *   ignored in tfjs-layers.\n   */\n  unroll?: boolean;\n\n  /**\n   * Dimensionality of the input (integer).\n   *   This option (or alternatively, the option `inputShape`) is required when\n   *   this layer is used as the first layer in a model.\n   */\n  inputDim?: number;\n\n  /**\n   * Length of the input sequences, to be specified when it is constant.\n   * This argument is required if you are going to connect `Flatten` then\n   * `Dense` layers upstream (without it, the shape of the dense outputs cannot\n   * be computed). Note that if the recurrent layer is not the first layer in\n   * your model, you would need to specify the input length at the level of the\n   * first layer (e.g., via the `inputShape` option).\n   */\n  inputLength?: number;\n}\n\nexport class RNN extends Layer {\n  /** @nocollapse */\n  static className = 'RNN';\n  public readonly cell: RNNCell;\n  public readonly returnSequences: boolean;\n  public readonly returnState: boolean;\n  public readonly goBackwards: boolean;\n  public readonly unroll: boolean;\n\n  public stateSpec: InputSpec[];\n  protected states_: Tensor[];\n\n  // NOTE(cais): For stateful RNNs, the old states cannot be disposed right\n  // away when new states are set, because the old states may need to be used\n  // later for backpropagation through time (BPTT) and other purposes. So we\n  // keep them here for final disposal when the state is reset completely\n  // (i.e., through no-arg call to `resetStates()`).\n  protected keptStates: Tensor[][];\n\n  private numConstants: number;\n\n  constructor(args: RNNLayerArgs) {\n    super(args);\n    let cell: RNNCell;\n    if (args.cell == null) {\n      throw new ValueError(\n          'cell property is missing for the constructor of RNN.');\n    } else if (Array.isArray(args.cell)) {\n      cell = new StackedRNNCells({cells: args.cell});\n    } else {\n      cell = args.cell;\n    }\n    if (cell.stateSize == null) {\n      throw new ValueError(\n          'The RNN cell should have an attribute `stateSize` (tuple of ' +\n          'integers, one integer per RNN state).');\n    }\n    this.cell = cell;\n    this.returnSequences =\n        args.returnSequences == null ? false : args.returnSequences;\n    this.returnState = args.returnState == null ? false : args.returnState;\n    this.goBackwards = args.goBackwards == null ? false : args.goBackwards;\n    this._stateful = args.stateful == null ? false : args.stateful;\n    this.unroll = args.unroll == null ? false : args.unroll;\n\n    this.supportsMasking = true;\n    this.inputSpec = [new InputSpec({ndim: 3})];\n    this.stateSpec = null;\n    this.states_ = null;\n    // TODO(cais): Add constantsSpec and numConstants.\n    this.numConstants = null;\n    // TODO(cais): Look into the use of initial_state in the kwargs of the\n    //   constructor.\n\n    this.keptStates = [];\n  }\n\n  // Porting Note: This is the equivalent of `RNN.states` property getter in\n  //   PyKeras.\n  getStates(): Tensor[] {\n    if (this.states_ == null) {\n      const numStates =\n          Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n      return math_utils.range(0, numStates).map(x => null);\n    } else {\n      return this.states_;\n    }\n  }\n\n  // Porting Note: This is the equivalent of the `RNN.states` property setter in\n  //   PyKeras.\n  setStates(states: Tensor[]): void {\n    this.states_ = states;\n  }\n\n  computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    if (isArrayOfShapes(inputShape)) {\n      inputShape = (inputShape as Shape[])[0];\n    }\n    inputShape = inputShape as Shape;\n\n    // TODO(cais): Remove the casting once stacked RNN cells become supported.\n    let stateSize = this.cell.stateSize;\n    if (!Array.isArray(stateSize)) {\n      stateSize = [stateSize];\n    }\n    const outputDim = stateSize[0];\n    let outputShape: Shape|Shape[];\n    if (this.returnSequences) {\n      outputShape = [inputShape[0], inputShape[1], outputDim];\n    } else {\n      outputShape = [inputShape[0], outputDim];\n    }\n\n    if (this.returnState) {\n      const stateShape: Shape[] = [];\n      for (const dim of stateSize) {\n        stateShape.push([inputShape[0], dim]);\n      }\n      return [outputShape].concat(stateShape);\n    } else {\n      return outputShape;\n    }\n  }\n\n  computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]): Tensor\n      |Tensor[] {\n    return tfc.tidy(() => {\n      if (Array.isArray(mask)) {\n        mask = mask[0];\n      }\n      const outputMask = this.returnSequences ? mask : null;\n\n      if (this.returnState) {\n        const stateMask = this.states.map(s => null);\n        return [outputMask].concat(stateMask);\n      } else {\n        return outputMask;\n      }\n    });\n  }\n\n  /**\n   * Get the current state tensors of the RNN.\n   *\n   * If the state hasn't been set, return an array of `null`s of the correct\n   * length.\n   */\n  get states(): Tensor[] {\n    if (this.states_ == null) {\n      const numStates =\n          Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n      const output: Tensor[] = [];\n      for (let i = 0; i < numStates; ++i) {\n        output.push(null);\n      }\n      return output;\n    } else {\n      return this.states_;\n    }\n  }\n\n  set states(s: Tensor[]) {\n    this.states_ = s;\n  }\n\n  public build(inputShape: Shape|Shape[]): void {\n    // Note inputShape will be an Array of Shapes of initial states and\n    // constants if these are passed in apply().\n    const constantShape: Shape[] = null;\n    if (this.numConstants != null) {\n      throw new NotImplementedError(\n          'Constants support is not implemented in RNN yet.');\n    }\n\n    if (isArrayOfShapes(inputShape)) {\n      inputShape = (inputShape as Shape[])[0];\n    }\n    inputShape = inputShape as Shape;\n\n    const batchSize: number = this.stateful ? inputShape[0] : null;\n    const inputDim = inputShape.slice(2);\n    this.inputSpec[0] = new InputSpec({shape: [batchSize, null, ...inputDim]});\n\n    // Allow cell (if RNNCell Layer) to build before we set or validate\n    // stateSpec.\n    const stepInputShape = [inputShape[0]].concat(inputShape.slice(2));\n    if (constantShape != null) {\n      throw new NotImplementedError(\n          'Constants support is not implemented in RNN yet.');\n    } else {\n      this.cell.build(stepInputShape);\n    }\n\n    // Set or validate stateSpec.\n    let stateSize: number[];\n    if (Array.isArray(this.cell.stateSize)) {\n      stateSize = this.cell.stateSize;\n    } else {\n      stateSize = [this.cell.stateSize];\n    }\n\n    if (this.stateSpec != null) {\n      if (!util.arraysEqual(\n              this.stateSpec.map(spec => spec.shape[spec.shape.length - 1]),\n              stateSize)) {\n        throw new ValueError(\n            `An initialState was passed that is not compatible with ` +\n            `cell.stateSize. Received stateSpec=${this.stateSpec}; ` +\n            `However cell.stateSize is ${this.cell.stateSize}`);\n      }\n    } else {\n      this.stateSpec =\n          stateSize.map(dim => new InputSpec({shape: [null, dim]}));\n    }\n    if (this.stateful) {\n      this.resetStates();\n    }\n  }\n\n  /**\n   * Reset the state tensors of the RNN.\n   *\n   * If the `states` argument is `undefined` or `null`, will set the\n   * state tensor(s) of the RNN to all-zero tensors of the appropriate\n   * shape(s).\n   *\n   * If `states` is provided, will set the state tensors of the RNN to its\n   * value.\n   *\n   * @param states Optional externally-provided initial states.\n   * @param training Whether this call is done during training. For stateful\n   *   RNNs, this affects whether the old states are kept or discarded. In\n   *   particular, if `training` is `true`, the old states will be kept so\n   *   that subsequent backpropgataion through time (BPTT) may work properly.\n   *   Else, the old states will be discarded.\n   */\n  resetStates(states?: Tensor|Tensor[], training = false): void {\n    tidy(() => {\n      if (!this.stateful) {\n        throw new AttributeError(\n            'Cannot call resetStates() on an RNN Layer that is not stateful.');\n      }\n      const batchSize = this.inputSpec[0].shape[0];\n      if (batchSize == null) {\n        throw new ValueError(\n            'If an RNN is stateful, it needs to know its batch size. Specify ' +\n            'the batch size of your input tensors: \\n' +\n            '- If using a Sequential model, specify the batch size by ' +\n            'passing a `batchInputShape` option to your first layer.\\n' +\n            '- If using the functional API, specify the batch size by ' +\n            'passing a `batchShape` option to your Input layer.');\n      }\n      // Initialize state if null.\n      if (this.states_ == null) {\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ =\n              this.cell.stateSize.map(dim => tfc.zeros([batchSize, dim]));\n        } else {\n          this.states_ = [tfc.zeros([batchSize, this.cell.stateSize])];\n        }\n      } else if (states == null) {\n        // Dispose old state tensors.\n        tfc.dispose(this.states_);\n        // For stateful RNNs, fully dispose kept old states.\n        if (this.keptStates != null) {\n          tfc.dispose(this.keptStates);\n          this.keptStates = [];\n        }\n\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ =\n              this.cell.stateSize.map(dim => tfc.zeros([batchSize, dim]));\n        } else {\n          this.states_[0] = tfc.zeros([batchSize, this.cell.stateSize]);\n        }\n      } else {\n        if (!Array.isArray(states)) {\n          states = [states];\n        }\n        if (states.length !== this.states_.length) {\n          throw new ValueError(\n              `Layer ${this.name} expects ${this.states_.length} state(s), ` +\n              `but it received ${states.length} state value(s). Input ` +\n              `received: ${states}`);\n        }\n\n        if (training === true) {\n          // Store old state tensors for complete disposal later, i.e., during\n          // the next no-arg call to this method. We do not dispose the old\n          // states immediately because that BPTT (among other things) require\n          // them.\n          this.keptStates.push(this.states_.slice());\n        } else {\n          tfc.dispose(this.states_);\n        }\n\n        for (let index = 0; index < this.states_.length; ++index) {\n          const value = states[index];\n          const dim = Array.isArray(this.cell.stateSize) ?\n              this.cell.stateSize[index] :\n              this.cell.stateSize;\n          const expectedShape = [batchSize, dim];\n          if (!util.arraysEqual(value.shape, expectedShape)) {\n            throw new ValueError(\n                `State ${index} is incompatible with layer ${this.name}: ` +\n                `expected shape=${expectedShape}, received shape=${\n                    value.shape}`);\n          }\n          this.states_[index] = value;\n        }\n      }\n      this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n    });\n  }\n\n  apply(\n      inputs: Tensor|Tensor[]|SymbolicTensor|SymbolicTensor[],\n      kwargs?: Kwargs): Tensor|Tensor[]|SymbolicTensor|SymbolicTensor[] {\n    // TODO(cais): Figure out whether initialState is in kwargs or inputs.\n    let initialState: Tensor[]|SymbolicTensor[] =\n        kwargs == null ? null : kwargs['initialState'];\n    let constants: Tensor[]|SymbolicTensor[] =\n        kwargs == null ? null : kwargs['constants'];\n    if (kwargs == null) {\n      kwargs = {};\n    }\n\n    const standardized =\n        standardizeArgs(inputs, initialState, constants, this.numConstants);\n    inputs = standardized.inputs;\n    initialState = standardized.initialState;\n    constants = standardized.constants;\n\n    // If any of `initial_state` or `constants` are specified and are\n    // `tf.SymbolicTensor`s, then add them to the inputs and temporarily modify\n    // the input_spec to include them.\n\n    let additionalInputs: Array<Tensor|SymbolicTensor> = [];\n    let additionalSpecs: InputSpec[] = [];\n    if (initialState != null) {\n      kwargs['initialState'] = initialState;\n      additionalInputs = additionalInputs.concat(initialState);\n      this.stateSpec = [];\n      for (const state of initialState) {\n        this.stateSpec.push(new InputSpec({shape: state.shape}));\n      }\n      // TODO(cais): Use the following instead.\n      // this.stateSpec = initialState.map(state => new InputSpec({shape:\n      // state.shape}));\n      additionalSpecs = additionalSpecs.concat(this.stateSpec);\n    }\n    if (constants != null) {\n      kwargs['constants'] = constants;\n      additionalInputs = additionalInputs.concat(constants);\n      // TODO(cais): Add this.constantsSpec.\n      this.numConstants = constants.length;\n    }\n\n    const isTensor = additionalInputs[0] instanceof SymbolicTensor;\n    if (isTensor) {\n      // Compute full input spec, including state and constants.\n      const fullInput =\n          [inputs].concat(additionalInputs) as Tensor[] | SymbolicTensor[];\n      const fullInputSpec = this.inputSpec.concat(additionalSpecs);\n      // Perform the call with temporarily replaced inputSpec.\n      const originalInputSpec = this.inputSpec;\n      this.inputSpec = fullInputSpec;\n      const output = super.apply(fullInput, kwargs);\n      this.inputSpec = originalInputSpec;\n      return output;\n    } else {\n      return super.apply(inputs, kwargs);\n    }\n  }\n\n  // tslint:disable-next-line:no-any\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    // Input shape: `[samples, time (padded with zeros), input_dim]`.\n    // Note that the .build() method of subclasses **must** define\n    // this.inputSpec and this.stateSpec owith complete input shapes.\n    return tidy(() => {\n      const mask = kwargs == null ? null : kwargs['mask'] as Tensor;\n      const training = kwargs == null ? null : kwargs['training'];\n      let initialState: Tensor[] =\n          kwargs == null ? null : kwargs['initialState'];\n\n      inputs = getExactlyOneTensor(inputs);\n      if (initialState == null) {\n        if (this.stateful) {\n          initialState = this.states_;\n        } else {\n          initialState = this.getInitialState(inputs);\n        }\n      }\n\n      const numStates =\n          Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n      if (initialState.length !== numStates) {\n        throw new ValueError(\n            `RNN Layer has ${numStates} state(s) but was passed ` +\n            `${initialState.length} initial state(s).`);\n      }\n      if (this.unroll) {\n        console.warn(\n            'Ignoring unroll = true for RNN layer, due to imperative backend.');\n      }\n\n      const cellCallKwargs: Kwargs = {training};\n\n      // TODO(cais): Add support for constants.\n      const step = (inputs: Tensor, states: Tensor[]) => {\n        // `inputs` and `states` are concatenated to form a single `Array` of\n        // `tf.Tensor`s as the input to `cell.call()`.\n        const outputs =\n            this.cell.call([inputs].concat(states), cellCallKwargs) as Tensor[];\n        // Marshall the return value into output and new states.\n        return [outputs[0], outputs.slice(1)] as [Tensor, Tensor[]];\n      };\n\n      // TODO(cais): Add support for constants.\n\n      const rnnOutputs =\n          rnn(step, inputs, initialState, this.goBackwards, mask, null,\n              this.unroll, this.returnSequences);\n      const lastOutput = rnnOutputs[0];\n      const outputs = rnnOutputs[1];\n      const states = rnnOutputs[2];\n\n      if (this.stateful) {\n        this.resetStates(states, training);\n      }\n\n      const output = this.returnSequences ? outputs : lastOutput;\n\n      // TODO(cais): Porperty set learning phase flag.\n\n      if (this.returnState) {\n        return [output].concat(states);\n      } else {\n        return output;\n      }\n    });\n  }\n\n  getInitialState(inputs: Tensor): Tensor[] {\n    return tidy(() => {\n      // Build an all-zero tensor of shape [samples, outputDim].\n      // [Samples, timeSteps, inputDim].\n      let initialState = tfc.zeros(inputs.shape);\n      // [Samples].\n      initialState = tfc.sum(initialState, [1, 2]);\n      initialState = K.expandDims(initialState);  // [Samples, 1].\n\n      if (Array.isArray(this.cell.stateSize)) {\n        return this.cell.stateSize.map(\n            dim => dim > 1 ? K.tile(initialState, [1, dim]) : initialState);\n      } else {\n        return this.cell.stateSize > 1 ?\n            [K.tile(initialState, [1, this.cell.stateSize])] :\n            [initialState];\n      }\n    });\n  }\n\n  get trainableWeights(): LayerVariable[] {\n    if (!this.trainable) {\n      return [];\n    }\n    // Porting Note: In TypeScript, `this` is always an instance of `Layer`.\n    return this.cell.trainableWeights;\n  }\n\n  get nonTrainableWeights(): LayerVariable[] {\n    // Porting Note: In TypeScript, `this` is always an instance of `Layer`.\n    if (!this.trainable) {\n      return this.cell.weights;\n    }\n    return this.cell.nonTrainableWeights;\n  }\n\n  setFastWeightInitDuringBuild(value: boolean) {\n    super.setFastWeightInitDuringBuild(value);\n    if (this.cell != null) {\n      this.cell.setFastWeightInitDuringBuild(value);\n    }\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const baseConfig = super.getConfig();\n\n    const config: serialization.ConfigDict = {\n      returnSequences: this.returnSequences,\n      returnState: this.returnState,\n      goBackwards: this.goBackwards,\n      stateful: this.stateful,\n      unroll: this.unroll,\n    };\n\n    if (this.numConstants != null) {\n      config['numConstants'] = this.numConstants;\n    }\n\n    const cellConfig = this.cell.getConfig();\n\n    if (this.getClassName() === RNN.className) {\n      config['cell'] = {\n        'className': this.cell.getClassName(),\n        'config': cellConfig,\n      } as serialization.ConfigDictValue;\n    }\n\n    // this order is necessary, to prevent cell name from replacing layer name\n    return {...cellConfig, ...baseConfig, ...config};\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends serialization.Serializable>(\n      cls: serialization.SerializableConstructor<T>,\n      config: serialization.ConfigDict,\n      customObjects = {} as serialization.ConfigDict): T {\n    const cellConfig = config['cell'] as serialization.ConfigDict;\n    const cell = deserialize(cellConfig, customObjects) as RNNCell;\n    return new cls(Object.assign(config, {cell}));\n  }\n}\nserialization.registerClass(RNN);\n\n// Porting Note: This is a common parent class for RNN cells. There is no\n// equivalent of this in PyKeras. Having a common parent class forgoes the\n//  need for `has_attr(cell, ...)` checks or its TypeScript equivalent.\n/**\n * An RNNCell layer.\n *\n * @doc {heading: 'Layers', subheading: 'Classes'}\n */\nexport abstract class RNNCell extends Layer {\n  /**\n   * Size(s) of the states.\n   * For RNN cells with only a single state, this is a single integer.\n   */\n  // See\n  // https://www.typescriptlang.org/docs/handbook/release-notes/typescript-4-0.html#properties-overriding-accessors-and-vice-versa-is-an-error\n  public abstract stateSize: number|number[];\n  public dropoutMask: Tensor|Tensor[];\n  public recurrentDropoutMask: Tensor|Tensor[];\n}\n\nexport declare interface SimpleRNNCellLayerArgs extends LayerArgs {\n  /**\n   * units: Positive integer, dimensionality of the output space.\n   */\n  units: number;\n\n  /**\n   * Activation function to use.\n   * Default: hyperbolic tangent ('tanh').\n   * If you pass `null`,  'linear' activation will be applied.\n   */\n  activation?: ActivationIdentifier;\n\n  /**\n   * Whether the layer uses a bias vector.\n   */\n  useBias?: boolean;\n\n  /**\n   * Initializer for the `kernel` weights matrix, used for the linear\n   * transformation of the inputs.\n   */\n  kernelInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Initializer for the `recurrentKernel` weights matrix, used for\n   * linear transformation of the recurrent state.\n   */\n  recurrentInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Initializer for the bias vector.\n   */\n  biasInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Regularizer function applied to the `kernel` weights matrix.\n   */\n  kernelRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the `recurrent_kernel` weights matrix.\n   */\n  recurrentRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the bias vector.\n   */\n  biasRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Constraint function applied to the `kernel` weights matrix.\n   */\n  kernelConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint function applied to the `recurrentKernel` weights matrix.\n   */\n  recurrentConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraintfunction applied to the bias vector.\n   */\n  biasConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Float number between 0 and 1. Fraction of the units to drop for the linear\n   * transformation of the inputs.\n   */\n  dropout?: number;\n\n  /**\n   * Float number between 0 and 1. Fraction of the units to drop for the linear\n   * transformation of the recurrent state.\n   */\n  recurrentDropout?: number;\n}\n\nexport class SimpleRNNCell extends RNNCell {\n  /** @nocollapse */\n  static className = 'SimpleRNNCell';\n  readonly units: number;\n  readonly activation: Activation;\n  readonly useBias: boolean;\n\n  readonly kernelInitializer: Initializer;\n  readonly recurrentInitializer: Initializer;\n  readonly biasInitializer: Initializer;\n\n  readonly kernelConstraint: Constraint;\n  readonly recurrentConstraint: Constraint;\n  readonly biasConstraint: Constraint;\n\n  readonly kernelRegularizer: Regularizer;\n  readonly recurrentRegularizer: Regularizer;\n  readonly biasRegularizer: Regularizer;\n\n  readonly dropout: number;\n  readonly recurrentDropout: number;\n\n  readonly stateSize: number;\n\n  kernel: LayerVariable;\n  recurrentKernel: LayerVariable;\n  bias: LayerVariable;\n\n  readonly DEFAULT_ACTIVATION = 'tanh';\n  readonly DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n  readonly DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n  readonly DEFAULT_BIAS_INITIALIZER: InitializerIdentifier = 'zeros';\n\n  constructor(args: SimpleRNNCellLayerArgs) {\n    super(args);\n    this.units = args.units;\n    assertPositiveInteger(this.units, `units`);\n    this.activation = getActivation(\n        args.activation == null ? this.DEFAULT_ACTIVATION : args.activation);\n    this.useBias = args.useBias == null ? true : args.useBias;\n\n    this.kernelInitializer = getInitializer(\n        args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.recurrentInitializer = getInitializer(\n        args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);\n\n    this.biasInitializer =\n        getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.recurrentConstraint = getConstraint(args.recurrentConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n\n    this.dropout = math_utils.min(\n        [1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n    this.recurrentDropout = math_utils.min([\n      1,\n      math_utils.max(\n          [0, args.recurrentDropout == null ? 0 : args.recurrentDropout])\n    ]);\n    this.stateSize = this.units;\n    this.dropoutMask = null;\n    this.recurrentDropoutMask = null;\n  }\n\n  build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    // TODO(cais): Use regularizer.\n    this.kernel = this.addWeight(\n        'kernel', [inputShape[inputShape.length - 1], this.units], null,\n        this.kernelInitializer, this.kernelRegularizer, true,\n        this.kernelConstraint);\n    this.recurrentKernel = this.addWeight(\n        'recurrent_kernel', [this.units, this.units], null,\n        this.recurrentInitializer, this.recurrentRegularizer, true,\n        this.recurrentConstraint);\n    if (this.useBias) {\n      this.bias = this.addWeight(\n          'bias', [this.units], null, this.biasInitializer,\n          this.biasRegularizer, true, this.biasConstraint);\n    } else {\n      this.bias = null;\n    }\n    this.built = true;\n  }\n\n  // Porting Note: PyKeras' equivalent of this method takes two tensor inputs:\n  //   `inputs` and `states`. Here, the two tensors are combined into an\n  //   `Tensor[]` Array as the first input argument.\n  //   Similarly, PyKeras' equivalent of this method returns two values:\n  //    `output` and `[output]`. Here the two are combined into one length-2\n  //    `Tensor[]`, consisting of `output` repeated.\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = inputs as Tensor[];\n      if (inputs.length !== 2) {\n        throw new ValueError(\n            `SimpleRNNCell expects 2 input Tensors, got ${inputs.length}.`);\n      }\n      let prevOutput = inputs[1];\n      inputs = inputs[0];\n      const training = kwargs['training'] == null ? false : kwargs['training'];\n\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n                             ones: () => tfc.onesLike(inputs as Tensor),\n                             rate: this.dropout,\n                             training\n                           }) as Tensor;\n      }\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n          this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n                                      ones: () => tfc.onesLike(prevOutput),\n                                      rate: this.recurrentDropout,\n                                      training\n                                    }) as Tensor;\n      }\n      let h: Tensor;\n      const dpMask: Tensor = this.dropoutMask as Tensor;\n      const recDpMask: Tensor = this.recurrentDropoutMask as Tensor;\n      if (dpMask != null) {\n        h = K.dot(tfc.mul(inputs, dpMask), this.kernel.read());\n      } else {\n        h = K.dot(inputs, this.kernel.read());\n      }\n      if (this.bias != null) {\n        h = K.biasAdd(h, this.bias.read());\n      }\n      if (recDpMask != null) {\n        prevOutput = tfc.mul(prevOutput, recDpMask);\n      }\n      let output = tfc.add(h, K.dot(prevOutput, this.recurrentKernel.read()));\n      if (this.activation != null) {\n        output = this.activation.apply(output);\n      }\n\n      // TODO(cais): Properly set learning phase on output tensor?\n      return [output, output];\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const baseConfig = super.getConfig();\n\n    const config: serialization.ConfigDict = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout,\n    };\n\n    return {...baseConfig, ...config};\n  }\n}\nserialization.registerClass(SimpleRNNCell);\n\nexport declare interface SimpleRNNLayerArgs extends BaseRNNLayerArgs {\n  /**\n   * Positive integer, dimensionality of the output space.\n   */\n  units: number;\n\n  /**\n   * Activation function to use.\n   *\n   * Defaults to  hyperbolic tangent (`tanh`)\n   *\n   * If you pass `null`, no activation will be applied.\n   */\n  activation?: ActivationIdentifier;\n\n  /**\n   * Whether the layer uses a bias vector.\n   */\n  useBias?: boolean;\n\n  /**\n   * Initializer for the `kernel` weights matrix, used for the linear\n   * transformation of the inputs.\n   */\n  kernelInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Initializer for the `recurrentKernel` weights matrix, used for\n   * linear transformation of the recurrent state.\n   */\n  recurrentInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Initializer for the bias vector.\n   */\n  biasInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Regularizer function applied to the kernel weights matrix.\n   */\n  kernelRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the recurrentKernel weights matrix.\n   */\n  recurrentRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the bias vector.\n   */\n  biasRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Constraint function applied to the kernel weights matrix.\n   */\n  kernelConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint function applied to the recurrentKernel weights matrix.\n   */\n  recurrentConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint function applied to the bias vector.\n   */\n  biasConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Number between 0 and 1. Fraction of the units to drop for the linear\n   * transformation of the inputs.\n   */\n  dropout?: number;\n\n  /**\n   * Number between 0 and 1. Fraction of the units to drop for the linear\n   * transformation of the recurrent state.\n   */\n  recurrentDropout?: number;\n}\n\n/**\n * RNNLayerConfig is identical to BaseRNNLayerConfig, except it makes the\n * `cell` property required. This interface is to be used with constructors\n * of concrete RNN layer subtypes.\n */\nexport declare interface RNNLayerArgs extends BaseRNNLayerArgs {\n  cell: RNNCell|RNNCell[];\n}\n\nexport class SimpleRNN extends RNN {\n  /** @nocollapse */\n  static className = 'SimpleRNN';\n  constructor(args: SimpleRNNLayerArgs) {\n    args.cell = new SimpleRNNCell(args);\n    super(args as RNNLayerArgs);\n    // TODO(cais): Add activityRegularizer.\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n        this.cell.dropoutMask = null;\n      }\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n        this.cell.recurrentDropoutMask = null;\n      }\n      const mask = kwargs == null ? null : kwargs['mask'];\n      const training = kwargs == null ? null : kwargs['training'];\n      const initialState: Tensor[] =\n          kwargs == null ? null : kwargs['initialState'];\n      return super.call(inputs, {mask, training, initialState});\n    });\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends serialization.Serializable>(\n      cls: serialization.SerializableConstructor<T>,\n      config: serialization.ConfigDict): T {\n    return new cls(config);\n  }\n}\nserialization.registerClass(SimpleRNN);\n\n// Porting Note: Since this is a superset of SimpleRNNLayerConfig, we extend\n//   that interface instead of repeating the fields.\nexport declare interface GRUCellLayerArgs extends SimpleRNNCellLayerArgs {\n  /**\n   * Activation function to use for the recurrent step.\n   *\n   * Defaults to hard sigmoid (`hardSigmoid`).\n   *\n   * If `null`, no activation is applied.\n   */\n  recurrentActivation?: ActivationIdentifier;\n\n  /**\n   * Implementation mode, either 1 or 2.\n   *\n   * Mode 1 will structure its operations as a larger number of\n   *   smaller dot products and additions.\n   *\n   * Mode 2 will batch them into fewer, larger operations. These modes will\n   * have different performance profiles on different hardware and\n   * for different applications.\n   *\n   * Note: For superior performance, TensorFlow.js always uses implementation\n   * 2, regardless of the actual value of this configuration field.\n   */\n  implementation?: number;\n\n  /**\n   * GRU convention (whether to apply reset gate after or before matrix\n   * multiplication). false = \"before\", true = \"after\" (only false is\n   * supported).\n   */\n  resetAfter?: boolean;\n}\n\nexport class GRUCell extends RNNCell {\n  /** @nocollapse */\n  static className = 'GRUCell';\n  readonly units: number;\n  readonly activation: Activation;\n  readonly recurrentActivation: Activation;\n  readonly useBias: boolean;\n\n  readonly kernelInitializer: Initializer;\n  readonly recurrentInitializer: Initializer;\n  readonly biasInitializer: Initializer;\n\n  readonly kernelRegularizer: Regularizer;\n  readonly recurrentRegularizer: Regularizer;\n  readonly biasRegularizer: Regularizer;\n\n  readonly kernelConstraint: Constraint;\n  readonly recurrentConstraint: Constraint;\n  readonly biasConstraint: Constraint;\n\n  readonly dropout: number;\n  readonly recurrentDropout: number;\n\n  readonly stateSize: number;\n  readonly implementation: number;\n\n  readonly DEFAULT_ACTIVATION = 'tanh';\n  readonly DEFAULT_RECURRENT_ACTIVATION: ActivationIdentifier = 'hardSigmoid';\n\n  readonly DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n  readonly DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n  readonly DEFAULT_BIAS_INITIALIZER: InitializerIdentifier = 'zeros';\n\n  kernel: LayerVariable;\n  recurrentKernel: LayerVariable;\n  bias: LayerVariable;\n\n  constructor(args: GRUCellLayerArgs) {\n    super(args);\n    if (args.resetAfter) {\n      throw new ValueError(\n          `GRUCell does not support reset_after parameter set to true.`);\n    }\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(\n        args.activation === undefined ? this.DEFAULT_ACTIVATION :\n                                        args.activation);\n    this.recurrentActivation = getActivation(\n        args.recurrentActivation === undefined ?\n            this.DEFAULT_RECURRENT_ACTIVATION :\n            args.recurrentActivation);\n    this.useBias = args.useBias == null ? true : args.useBias;\n\n    this.kernelInitializer = getInitializer(\n        args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.recurrentInitializer = getInitializer(\n        args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);\n\n    this.biasInitializer =\n        getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.recurrentConstraint = getConstraint(args.recurrentConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n\n    this.dropout = math_utils.min(\n        [1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n    this.recurrentDropout = math_utils.min([\n      1,\n      math_utils.max(\n          [0, args.recurrentDropout == null ? 0 : args.recurrentDropout])\n    ]);\n    this.implementation = args.implementation;\n    this.stateSize = this.units;\n    this.dropoutMask = null;\n    this.recurrentDropoutMask = null;\n  }\n\n  public build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputDim = inputShape[inputShape.length - 1];\n    this.kernel = this.addWeight(\n        'kernel', [inputDim, this.units * 3], null, this.kernelInitializer,\n        this.kernelRegularizer, true, this.kernelConstraint);\n    this.recurrentKernel = this.addWeight(\n        'recurrent_kernel', [this.units, this.units * 3], null,\n        this.recurrentInitializer, this.recurrentRegularizer, true,\n        this.recurrentConstraint);\n    if (this.useBias) {\n      this.bias = this.addWeight(\n          'bias', [this.units * 3], null, this.biasInitializer,\n          this.biasRegularizer, true, this.biasConstraint);\n    } else {\n      this.bias = null;\n    }\n    // Porting Notes: Unlike the PyKeras implementation, we perform slicing\n    //   of the weights and bias in the call() method, at execution time.\n    this.built = true;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = inputs as Tensor[];\n      if (inputs.length !== 2) {\n        throw new ValueError(\n            `GRUCell expects 2 input Tensors (inputs, h, c), got ` +\n            `${inputs.length}.`);\n      }\n\n      const training = kwargs['training'] == null ? false : kwargs['training'];\n      let hTMinus1 = inputs[1];  // Previous memory state.\n      inputs = inputs[0];\n\n      // Note: For superior performance, TensorFlow.js always uses\n      // implementation 2, regardless of the actual value of\n      // config.implementation.\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n                             ones: () => tfc.onesLike(inputs as Tensor),\n                             rate: this.dropout,\n                             training,\n                             count: 3\n                           }) as Tensor[];\n      }\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n          this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n                                      ones: () => tfc.onesLike(hTMinus1),\n                                      rate: this.recurrentDropout,\n                                      training,\n                                      count: 3\n                                    }) as Tensor[];\n      }\n      const dpMask = this.dropoutMask as [Tensor, Tensor, Tensor];\n      const recDpMask = this.recurrentDropoutMask as [Tensor, Tensor, Tensor];\n      let z: Tensor;\n      let r: Tensor;\n      let hh: Tensor;\n\n      if (0 < this.dropout && this.dropout < 1) {\n        inputs = tfc.mul(inputs, dpMask[0]);\n      }\n      let matrixX = K.dot(inputs, this.kernel.read());\n      if (this.useBias) {\n        matrixX = K.biasAdd(matrixX, this.bias.read());\n      }\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1) {\n        hTMinus1 = tfc.mul(hTMinus1, recDpMask[0]);\n      }\n\n      const recurrentKernelValue = this.recurrentKernel.read();\n      const [rk1, rk2] = tfc.split(\n          recurrentKernelValue, [2 * this.units, this.units],\n          recurrentKernelValue.rank - 1);\n      const matrixInner = K.dot(hTMinus1, rk1);\n\n      const [xZ, xR, xH] = tfc.split(matrixX, 3, matrixX.rank - 1);\n      const [recurrentZ, recurrentR] =\n          tfc.split(matrixInner, 2, matrixInner.rank - 1);\n      z = this.recurrentActivation.apply(tfc.add(xZ, recurrentZ));\n      r = this.recurrentActivation.apply(tfc.add(xR, recurrentR));\n\n      const recurrentH = K.dot(tfc.mul(r, hTMinus1), rk2);\n      hh = this.activation.apply(tfc.add(xH, recurrentH));\n\n      const h =\n          tfc.add(tfc.mul(z, hTMinus1), tfc.mul(tfc.add(1, tfc.neg(z)), hh));\n      // TODO(cais): Add use_learning_phase flag properly.\n      return [h, h];\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const baseConfig = super.getConfig();\n\n    const config: serialization.ConfigDict = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      recurrentActivation: serializeActivation(this.recurrentActivation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout,\n      implementation: this.implementation,\n      resetAfter: false\n    };\n\n    return {...baseConfig, ...config};\n  }\n}\nserialization.registerClass(GRUCell);\n\n// Porting Note: Since this is a superset of SimpleRNNLayerConfig, we inherit\n//   from that interface instead of repeating the fields here.\nexport declare interface GRULayerArgs extends SimpleRNNLayerArgs {\n  /**\n   * Activation function to use for the recurrent step.\n   *\n   * Defaults to hard sigmoid (`hardSigmoid`).\n   *\n   * If `null`, no activation is applied.\n   */\n  recurrentActivation?: ActivationIdentifier;\n\n  /**\n   * Implementation mode, either 1 or 2.\n   *\n   * Mode 1 will structure its operations as a larger number of\n   * smaller dot products and additions.\n   *\n   * Mode 2 will batch them into fewer, larger operations. These modes will\n   * have different performance profiles on different hardware and\n   * for different applications.\n   *\n   * Note: For superior performance, TensorFlow.js always uses implementation\n   * 2, regardless of the actual value of this configuration field.\n   */\n  implementation?: number;\n}\n\nexport class GRU extends RNN {\n  /** @nocollapse */\n  static className = 'GRU';\n  constructor(args: GRULayerArgs) {\n    if (args.implementation === 0) {\n      console.warn(\n          '`implementation=0` has been deprecated, and now defaults to ' +\n          '`implementation=1`. Please update your layer call.');\n    }\n    args.cell = new GRUCell(args);\n    super(args as RNNLayerArgs);\n    // TODO(cais): Add activityRegularizer.\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n        this.cell.dropoutMask = null;\n      }\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n        this.cell.recurrentDropoutMask = null;\n      }\n      const mask = kwargs == null ? null : kwargs['mask'];\n      const training = kwargs == null ? null : kwargs['training'];\n      const initialState: Tensor[] =\n          kwargs == null ? null : kwargs['initialState'];\n      return super.call(inputs, {mask, training, initialState});\n    });\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends serialization.Serializable>(\n      cls: serialization.SerializableConstructor<T>,\n      config: serialization.ConfigDict): T {\n    if (config['implmentation'] === 0) {\n      config['implementation'] = 1;\n    }\n    return new cls(config);\n  }\n}\nserialization.registerClass(GRU);\n\n// Porting Note: Since this is a superset of SimpleRNNLayerConfig, we extend\n//   that interface instead of repeating the fields.\nexport declare interface LSTMCellLayerArgs extends SimpleRNNCellLayerArgs {\n  /**\n   * Activation function to use for the recurrent step.\n   *\n   * Defaults to hard sigmoid (`hardSigmoid`).\n   *\n   * If `null`, no activation is applied.\n   */\n  recurrentActivation?: ActivationIdentifier;\n\n  /**\n   * If `true`, add 1 to the bias of the forget gate at initialization.\n   * Setting it to `true` will also force `biasInitializer = 'zeros'`.\n   * This is recommended in\n   * [Jozefowicz et\n   * al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n   */\n  unitForgetBias?: boolean;\n\n  /**\n   * Implementation mode, either 1 or 2.\n   *\n   * Mode 1 will structure its operations as a larger number of\n   *   smaller dot products and additions.\n   *\n   * Mode 2 will batch them into fewer, larger operations. These modes will\n   * have different performance profiles on different hardware and\n   * for different applications.\n   *\n   * Note: For superior performance, TensorFlow.js always uses implementation\n   * 2, regardless of the actual value of this configuration field.\n   */\n  implementation?: number;\n}\n\nexport class LSTMCell extends RNNCell {\n  /** @nocollapse */\n  static className = 'LSTMCell';\n  readonly units: number;\n  readonly activation: Activation;\n  readonly recurrentActivation: Activation;\n  readonly useBias: boolean;\n\n  readonly kernelInitializer: Initializer;\n  readonly recurrentInitializer: Initializer;\n  readonly biasInitializer: Initializer;\n  readonly unitForgetBias: boolean;\n\n  readonly kernelConstraint: Constraint;\n  readonly recurrentConstraint: Constraint;\n  readonly biasConstraint: Constraint;\n\n  readonly kernelRegularizer: Regularizer;\n  readonly recurrentRegularizer: Regularizer;\n  readonly biasRegularizer: Regularizer;\n\n  readonly dropout: number;\n  readonly recurrentDropout: number;\n\n  readonly stateSize: number[];\n  readonly implementation: number;\n\n  readonly DEFAULT_ACTIVATION = 'tanh';\n  readonly DEFAULT_RECURRENT_ACTIVATION = 'hardSigmoid';\n  readonly DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n  readonly DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n\n  readonly DEFAULT_BIAS_INITIALIZER = 'zeros';\n\n  kernel: LayerVariable;\n  recurrentKernel: LayerVariable;\n  bias: LayerVariable;\n\n  constructor(args: LSTMCellLayerArgs) {\n    super(args);\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(\n        args.activation === undefined ? this.DEFAULT_ACTIVATION :\n                                        args.activation);\n    this.recurrentActivation = getActivation(\n        args.recurrentActivation === undefined ?\n            this.DEFAULT_RECURRENT_ACTIVATION :\n            args.recurrentActivation);\n    this.useBias = args.useBias == null ? true : args.useBias;\n\n    this.kernelInitializer = getInitializer(\n        args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.recurrentInitializer = getInitializer(\n        args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);\n\n    this.biasInitializer =\n        getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.unitForgetBias = args.unitForgetBias;\n\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.recurrentConstraint = getConstraint(args.recurrentConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n\n    this.dropout = math_utils.min(\n        [1, math_utils.max([0, args.dropout == null ? 0 : args.dropout])]);\n    this.recurrentDropout = math_utils.min([\n      1,\n      math_utils.max(\n          [0, args.recurrentDropout == null ? 0 : args.recurrentDropout])\n    ]);\n    this.implementation = args.implementation;\n    this.stateSize = [this.units, this.units];\n    this.dropoutMask = null;\n    this.recurrentDropoutMask = null;\n  }\n\n  public build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputDim = inputShape[inputShape.length - 1];\n    this.kernel = this.addWeight(\n        'kernel', [inputDim, this.units * 4], null, this.kernelInitializer,\n        this.kernelRegularizer, true, this.kernelConstraint);\n    this.recurrentKernel = this.addWeight(\n        'recurrent_kernel', [this.units, this.units * 4], null,\n        this.recurrentInitializer, this.recurrentRegularizer, true,\n        this.recurrentConstraint);\n    let biasInitializer: Initializer;\n    if (this.useBias) {\n      if (this.unitForgetBias) {\n        const capturedBiasInit = this.biasInitializer;\n        const capturedUnits = this.units;\n        biasInitializer = new (class CustomInit extends Initializer {\n          /** @nocollapse */\n          static className = 'CustomInit';\n\n          apply(shape: Shape, dtype?: DataType): Tensor {\n            // TODO(cais): More informative variable names?\n            const bI = capturedBiasInit.apply([capturedUnits]);\n            const bF = (new Ones()).apply([capturedUnits]);\n            const bCAndH = capturedBiasInit.apply([capturedUnits * 2]);\n            return K.concatAlongFirstAxis(\n                K.concatAlongFirstAxis(bI, bF), bCAndH);\n          }\n        })();\n      } else {\n        biasInitializer = this.biasInitializer;\n      }\n      this.bias = this.addWeight(\n          'bias', [this.units * 4], null, biasInitializer, this.biasRegularizer,\n          true, this.biasConstraint);\n    } else {\n      this.bias = null;\n    }\n    // Porting Notes: Unlike the PyKeras implementation, we perform slicing\n    //   of the weights and bias in the call() method, at execution time.\n    this.built = true;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      const training = kwargs['training'] == null ? false : kwargs['training'];\n      inputs = inputs as Tensor[];\n      if (inputs.length !== 3) {\n        throw new ValueError(\n            `LSTMCell expects 3 input Tensors (inputs, h, c), got ` +\n            `${inputs.length}.`);\n      }\n      let hTMinus1 = inputs[1];    // Previous memory state.\n      const cTMinus1 = inputs[2];  // Previous carry state.\n      inputs = inputs[0];\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n                             ones: () => tfc.onesLike(inputs as Tensor),\n                             rate: this.dropout,\n                             training,\n                             count: 4\n                           }) as Tensor[];\n      }\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n          this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n                                      ones: () => tfc.onesLike(hTMinus1),\n                                      rate: this.recurrentDropout,\n                                      training,\n                                      count: 4\n                                    }) as Tensor[];\n      }\n      const dpMask = this.dropoutMask as [Tensor, Tensor, Tensor, Tensor];\n      const recDpMask =\n          this.recurrentDropoutMask as [Tensor, Tensor, Tensor, Tensor];\n\n      // Note: For superior performance, TensorFlow.js always uses\n      // implementation 2 regardless of the actual value of\n      // config.implementation.\n      let i: Tensor;\n      let f: Tensor;\n      let c: Tensor;\n      let o: Tensor;\n      if (0 < this.dropout && this.dropout < 1) {\n        inputs = tfc.mul(inputs, dpMask[0]);\n      }\n      let z = K.dot(inputs, this.kernel.read());\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1) {\n        hTMinus1 = tfc.mul(hTMinus1, recDpMask[0]);\n      }\n      z = tfc.add(z, K.dot(hTMinus1, this.recurrentKernel.read()));\n      if (this.useBias) {\n        z = K.biasAdd(z, this.bias.read());\n      }\n\n      const [z0, z1, z2, z3] = tfc.split(z, 4, z.rank - 1);\n\n      i = this.recurrentActivation.apply(z0);\n      f = this.recurrentActivation.apply(z1);\n      c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, this.activation.apply(z2)));\n      o = this.recurrentActivation.apply(z3);\n\n      const h = tfc.mul(o, this.activation.apply(c));\n      // TODO(cais): Add use_learning_phase flag properly.\n      return [h, h, c];\n    });\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const baseConfig = super.getConfig();\n\n    const config: serialization.ConfigDict = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      recurrentActivation: serializeActivation(this.recurrentActivation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      recurrentInitializer: serializeInitializer(this.recurrentInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      unitForgetBias: this.unitForgetBias,\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      recurrentConstraint: serializeConstraint(this.recurrentConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint),\n      dropout: this.dropout,\n      recurrentDropout: this.recurrentDropout,\n      implementation: this.implementation,\n    };\n\n    return {...baseConfig, ...config};\n  }\n}\nserialization.registerClass(LSTMCell);\n\n// Porting Note: Since this is a superset of SimpleRNNLayerConfig, we inherit\n//   from that interface instead of repeating the fields here.\nexport declare interface LSTMLayerArgs extends SimpleRNNLayerArgs {\n  /**\n   * Activation function to use for the recurrent step.\n   *\n   * Defaults to hard sigmoid (`hardSigmoid`).\n   *\n   * If `null`, no activation is applied.\n   */\n  recurrentActivation?: ActivationIdentifier;\n\n  /**\n   * If `true`, add 1 to the bias of the forget gate at initialization.\n   * Setting it to `true` will also force `biasInitializer = 'zeros'`.\n   * This is recommended in\n   * [Jozefowicz et\n   * al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n   */\n  unitForgetBias?: boolean;\n\n  /**\n   * Implementation mode, either 1 or 2.\n   *   Mode 1 will structure its operations as a larger number of\n   *   smaller dot products and additions, whereas mode 2 will\n   *   batch them into fewer, larger operations. These modes will\n   *   have different performance profiles on different hardware and\n   *   for different applications.\n   *\n   * Note: For superior performance, TensorFlow.js always uses implementation\n   * 2, regardless of the actual value of this config field.\n   */\n  implementation?: number;\n}\n\nexport class LSTM extends RNN {\n  /** @nocollapse */\n  static className = 'LSTM';\n  constructor(args: LSTMLayerArgs) {\n    if (args.implementation === 0) {\n      console.warn(\n          '`implementation=0` has been deprecated, and now defaults to ' +\n          '`implementation=1`. Please update your layer call.');\n    }\n    args.cell = new LSTMCell(args);\n    super(args as RNNLayerArgs);\n    // TODO(cais): Add activityRegularizer.\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n        this.cell.dropoutMask = null;\n      }\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n        this.cell.recurrentDropoutMask = null;\n      }\n      const mask = kwargs == null ? null : kwargs['mask'];\n      const training = kwargs == null ? null : kwargs['training'];\n      const initialState: Tensor[] =\n          kwargs == null ? null : kwargs['initialState'];\n      return super.call(inputs, {mask, training, initialState});\n    });\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends serialization.Serializable>(\n      cls: serialization.SerializableConstructor<T>,\n      config: serialization.ConfigDict): T {\n    if (config['implmentation'] === 0) {\n      config['implementation'] = 1;\n    }\n    return new cls(config);\n  }\n}\nserialization.registerClass(LSTM);\n\nexport declare interface StackedRNNCellsArgs extends LayerArgs {\n  /**\n   * A `Array` of `RNNCell` instances.\n   */\n  cells: RNNCell[];\n}\n\nexport class StackedRNNCells extends RNNCell {\n  /** @nocollapse */\n  static className = 'StackedRNNCells';\n  protected cells: RNNCell[];\n\n  constructor(args: StackedRNNCellsArgs) {\n    super(args);\n    this.cells = args.cells;\n  }\n\n  get stateSize(): number[] {\n    // States are a flat list in reverse order of the cell stack.\n    // This allows perserving the requirement `stack.statesize[0] ===\n    // outputDim`. E.g., states of a 2-layer LSTM would be `[h2, c2, h1, c1]`,\n    // assuming one LSTM has states `[h, c]`.\n    const stateSize: number[] = [];\n    for (const cell of this.cells.slice().reverse()) {\n      if (Array.isArray(cell.stateSize)) {\n        stateSize.push(...cell.stateSize);\n      } else {\n        stateSize.push(cell.stateSize);\n      }\n    }\n    return stateSize;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = inputs as Tensor[];\n      let states = inputs.slice(1);\n\n      // Recover per-cell states.\n      const nestedStates: Tensor[][] = [];\n      for (const cell of this.cells.slice().reverse()) {\n        if (Array.isArray(cell.stateSize)) {\n          nestedStates.push(states.splice(0, cell.stateSize.length));\n        } else {\n          nestedStates.push(states.splice(0, 1));\n        }\n      }\n      nestedStates.reverse();\n\n      // Call the cells in order and store the returned states.\n      const newNestedStates: Tensor[][] = [];\n      let callInputs: Tensor[];\n      for (let i = 0; i < this.cells.length; ++i) {\n        const cell = this.cells[i];\n        states = nestedStates[i];\n        // TODO(cais): Take care of constants.\n        if (i === 0) {\n          callInputs = [inputs[0]].concat(states);\n        } else {\n          callInputs = [callInputs[0]].concat(states);\n        }\n        callInputs = cell.call(callInputs, kwargs) as Tensor[];\n        newNestedStates.push(callInputs.slice(1));\n      }\n\n      // Format the new states as a flat list in reverse cell order.\n      states = [];\n      for (const cellStates of newNestedStates.slice().reverse()) {\n        states.push(...cellStates);\n      }\n      return [callInputs[0]].concat(states);\n    });\n  }\n\n  public build(inputShape: Shape|Shape[]): void {\n    if (isArrayOfShapes(inputShape)) {\n      // TODO(cais): Take care of input constants.\n      // const constantShape = inputShape.slice(1);\n      inputShape = (inputShape as Shape[])[0];\n    }\n    inputShape = inputShape as Shape;\n    let outputDim: number;\n    this.cells.forEach((cell, i) => {\n      nameScope(`RNNCell_${i}`, () => {\n        // TODO(cais): Take care of input constants.\n\n        cell.build(inputShape);\n        if (Array.isArray(cell.stateSize)) {\n          outputDim = cell.stateSize[0];\n        } else {\n          outputDim = cell.stateSize;\n        }\n        inputShape = [inputShape[0], outputDim] as Shape;\n      });\n    });\n    this.built = true;\n  }\n\n  getConfig(): serialization.ConfigDict {\n    const baseConfig = super.getConfig();\n\n    const getCellConfig = (cell: RNNCell) => {\n      return {\n        'className': cell.getClassName(),\n        'config': cell.getConfig(),\n      };\n    };\n\n    const cellConfigs = this.cells.map(getCellConfig);\n\n    const config = {'cells': cellConfigs};\n\n    return {...baseConfig, ...config};\n  }\n\n  /** @nocollapse */\n  static fromConfig<T extends serialization.Serializable>(\n      cls: serialization.SerializableConstructor<T>,\n      config: serialization.ConfigDict,\n      customObjects = {} as serialization.ConfigDict): T {\n    const cells: RNNCell[] = [];\n    for (const cellConfig of (config['cells'] as serialization.ConfigDict[])) {\n      cells.push(deserialize(cellConfig, customObjects) as RNNCell);\n    }\n    return new cls({cells});\n  }\n\n  get trainableWeights(): LayerVariable[] {\n    if (!this.trainable) {\n      return [];\n    }\n    const weights: LayerVariable[] = [];\n    for (const cell of this.cells) {\n      weights.push(...cell.trainableWeights);\n    }\n    return weights;\n  }\n\n  get nonTrainableWeights(): LayerVariable[] {\n    const weights: LayerVariable[] = [];\n    for (const cell of this.cells) {\n      weights.push(...cell.nonTrainableWeights);\n    }\n    if (!this.trainable) {\n      const trainableWeights: LayerVariable[] = [];\n      for (const cell of this.cells) {\n        trainableWeights.push(...cell.trainableWeights);\n      }\n      return trainableWeights.concat(weights);\n    }\n    return weights;\n  }\n\n  /**\n   * Retrieve the weights of a the model.\n   *\n   * @returns A flat `Array` of `tf.Tensor`s.\n   */\n  getWeights(): Tensor[] {\n    const weights: LayerVariable[] = [];\n    for (const cell of this.cells) {\n      weights.push(...cell.weights);\n    }\n    return batchGetValue(weights);\n  }\n\n  /**\n   * Set the weights of the model.\n   *\n   * @param weights An `Array` of `tf.Tensor`s with shapes and types matching\n   *     the output of `getWeights()`.\n   */\n  setWeights(weights: Tensor[]): void {\n    const tuples: Array<[LayerVariable, Tensor]> = [];\n    for (const cell of this.cells) {\n      const numParams = cell.weights.length;\n      const inputWeights = weights.splice(numParams);\n      for (let i = 0; i < cell.weights.length; ++i) {\n        tuples.push([cell.weights[i], inputWeights[i]]);\n      }\n    }\n    batchSetValue(tuples);\n  }\n\n  // TODO(cais): Maybe implemnt `losses` and `getLossesFor`.\n}\nserialization.registerClass(StackedRNNCells);\n\nexport function generateDropoutMask(args: {\n  ones: () => tfc.Tensor,\n  rate: number,\n  training?: boolean,\n  count?: number,\n}): tfc.Tensor|tfc.Tensor[] {\n  const {ones, rate, training = false, count = 1} = args;\n\n  const droppedInputs = () => K.dropout(ones(), rate);\n\n  const createMask = () => K.inTrainPhase(droppedInputs, ones, training);\n\n  // just in case count is provided with null or undefined\n  if (!count || count <= 1) {\n    return tfc.keep(createMask().clone());\n  }\n\n  const masks = Array(count).fill(undefined).map(createMask);\n\n  return masks.map(m => tfc.keep(m.clone()));\n}\n"]}