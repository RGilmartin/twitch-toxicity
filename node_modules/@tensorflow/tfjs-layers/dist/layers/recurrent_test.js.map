{"version":3,"file":"recurrent_test.js","sourceRoot":"","sources":["../../src/layers/recurrent_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;GAQG;;;;;;;;;;;;AAEH;;GAEG;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;AAC7C,OAAO,EAAK,YAAY,EAAE,MAAM,EAAU,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAC,MAAM,uBAAuB,CAAC;AAE/G,OAAO,EAAC,mBAAmB,EAAE,IAAI,EAAC,MAAM,gBAAgB,CAAC;AACzD,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,MAAM,EAAE,mBAAmB,EAAE,QAAQ,EAAC,MAAM,gBAAgB,CAAC;AACrE,OAAO,KAAK,GAAG,MAAM,UAAU,CAAC;AAChC,OAAO,EAAC,aAAa,EAAE,SAAS,EAAE,IAAI,EAAE,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAErF,OAAO,EAAwB,aAAa,EAAC,MAAM,WAAW,CAAC;AAC/D,OAAO,EAAC,IAAI,EAAE,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAE3D,OAAO,EAAC,mBAAmB,EAAE,mBAAmB,EAAC,MAAM,8BAA8B,CAAC;AACtF,OAAO,EAAC,eAAe,EAAE,qBAAqB,EAAE,eAAe,EAAE,kBAAkB,EAAC,MAAM,qBAAqB,CAAC;AAEhH,OAAO,EAAmE,GAAG,EAAO,OAAO,EAA6C,MAAM,aAAa,CAAC;AAE5J;;;;;;;;;GASG;AACH,SAAS,cAAc,CAAC,MAAc,EAAE,MAAgB;IACtD,MAAM,IAAI,GAAG,GAAG,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IAC9B,MAAM,SAAS,GAAG,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,CAAC;IAC5D,MAAM,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;IACrC,OAAO,CAAC,MAAM,EAAE,SAAS,CAAC,CAAC;AAC7B,CAAC;AAED,qBAAqB,CAAC,KAAK,EAAE,GAAG,EAAE;IAChC,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,MAAM,aAAa,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,UAAU,GACZ,GAAG,CAAC,cAAc,EAAE,MAAM,EAAE,aAAa,EAAE,KAAK,CAAC,iBAAiB,EAC9D,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,eAAe,EAAE,KAAK,CAAC,YAAY,EACzD,IAAI,CAAC,wBAAwB,CAAC,CAAC;QACvC,MAAM,UAAU,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,OAAO,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAC9B,MAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAChC,kBAAkB,CACd,UAAU,EACV,QAAQ,CACJ;YACE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;SACnE,EACD,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjB,kBAAkB,CACd,OAAO,EACP,QAAQ,CACJ;YACE;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC1D,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACjC;YACD;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC1D,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACjC;SACF,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpB,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACpC,kBAAkB,CACd,SAAS,CAAC,CAAC,CAAC,EACZ,QAAQ,CACJ,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,EAC5D,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACnB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2CAA2C,EAAE,GAAG,EAAE;QACnD,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,+CAA+C;QAC/C,MAAM,aAAa,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5D,MAAM,UAAU,GACZ,GAAG,CAAC,cAAc,EAAE,MAAM,EAAE,aAAa,EAAE,KAAK,CAAC,iBAAiB,EAC9D,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,eAAe,EAAE,KAAK,CAAC,YAAY,EACzD,IAAI,CAAC,wBAAwB,CAAC,CAAC;QACvC,MAAM,UAAU,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,OAAO,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAC9B,MAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAChC,kBAAkB,CACd,UAAU,EACV,QAAQ,CACJ;YACE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;SACnE,EACD,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjB,kBAAkB,CACd,OAAO,EACP,QAAQ,CACJ;YACE;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC1D,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACjC;YACD;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC1D,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACjC;SACF,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpB,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACpC,kBAAkB,CACd,SAAS,CAAC,CAAC,CAAC,EACZ,QAAQ,CACJ,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,EAC5D,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjB,kBAAkB,CACd,SAAS,CAAC,CAAC,CAAC,EACZ,QAAQ,CAAC,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACxE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2CAA2C,EAAE,GAAG,EAAE;QACnD,MAAM,MAAM,GAAG,QAAQ,CACnB;YACE,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YACpC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;SAC3C,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClB,+CAA+C;QAC/C,MAAM,aAAa,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5D,MAAM,UAAU,GACZ,GAAG,CAAC,cAAc,EAAE,MAAM,EAAE,aAAa,EAAE,KAAK,CAAC,iBAAiB,EAC9D,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,eAAe,EAAE,KAAK,CAAC,YAAY,EACzD,IAAI,CAAC,wBAAwB,CAAC,CAAC;QACvC,MAAM,UAAU,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,OAAO,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAC9B,MAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAChC,kBAAkB,CACd,UAAU,EACV,QAAQ,CACJ;YACE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;SACnE,EACD,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjB,kBAAkB,CACd,OAAO,EACP,QAAQ,CACJ;YACE;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC1D,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACjC;YACD;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC1D,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACjC;SACF,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpB,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACpC,kBAAkB,CACd,SAAS,CAAC,CAAC,CAAC,EACZ,QAAQ,CACJ,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,EAC5D,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACjB,kBAAkB,CACd,SAAS,CAAC,CAAC,CAAC,EACZ,QAAQ,CAAC,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACxE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,sCAAsC,EAAE,GAAG,EAAE;QAC9C,MAAM,MAAM,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,aAAa,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,cAAc,EAAE,MAAM,EAAE,aAAa,CAAC,CAAC,CAAC,YAAY,EAAE,CAAC;IAC1E,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH;;;;;;;;GAQG;AACH,MAAM,cAAe,SAAQ,OAAO;IAIlC,YAAY,UAA2B;QACrC,KAAK,CAAC,EAAE,CAAC,CAAC;QACV,IAAI,CAAC,SAAS,GAAG,UAAU,CAAC;IAC9B,CAAC;IAED,IAAI,CAAC,MAAuB,EAAE,MAAc;QAC1C,MAAM,GAAG,MAAkB,CAAC;QAC5B,MAAM,UAAU,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;QAC7B,MAAM,MAAM,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAC/B,MAAM,IAAI,GAAG,GAAG,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC,CAAC;QAC5D,MAAM,MAAM,GAAG,GAAG,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;QACrC,OAAO,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;IACpC,CAAC;;AAhBD,kBAAkB;AACX,wBAAS,GAAG,gBAAgB,CAAC;AAkBtC,eAAe,CAAC,WAAW,EAAE,GAAG,EAAE;IAChC,4EAA4E;IAC5E,iBAAiB;IACjB,oDAAoD;IACpD,wDAAwD;IAExD,EAAE,CAAC,wBAAwB,EAAE,GAAG,EAAE;QAChC,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAC,CAAC,CAAC;QACnC,MAAM,CAAC,GAAG,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC3C,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QACvC,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,sCAAsC,EAAE,GAAG,EAAE;QAC9C,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YACzB,IAAI;YACJ,eAAe,EAAE,IAAI;YACrB,WAAW,EAAE,IAAI;YACjB,WAAW,EAAE,IAAI;SAClB,CAAC,CAAC;QACH,MAAM,CAAC,GAAG,CAAC,eAAe,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QAC1C,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QACtC,MAAM,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uEAAuE,EACvE,GAAG,EAAE;QACH,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAC,CAAC,CAAC;QACnC,MAAM,UAAU,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAC7B,MAAM,CAAC,GAAG,CAAC,kBAAkB,CAAC,UAAU,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC7D,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,sEAAsE,EACtE,GAAG,EAAE;QACH,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;QAC1D,MAAM,UAAU,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAC7B,MAAM,CAAC,GAAG,CAAC,kBAAkB,CAAC,UAAU,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAChE,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,qEAAqE,EACrE,GAAG,EAAE;QACH,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GACL,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACrE,MAAM,UAAU,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAC7B,MAAM,CAAC,GAAG,CAAC,kBAAkB,CAAC,UAAU,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC1E,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,sEAAsE,EACtE,GAAG,EAAE;QACH,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,GAAG,GACL,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACrE,MAAM,UAAU,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAC7B,MAAM,CAAC,GAAG,CAAC,kBAAkB,CAAC,UAAU,CAAC,CAAC,CAAC,OAAO,CAAC;YACjD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;SAC1B,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,oEAAoE,EACpE,GAAG,EAAE;QACH,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAC,CAAC,CAAC;QACnC,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QACtD,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,mEAAmE,EACnE,GAAG,EAAE;QACH,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;QAC1D,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QACtD,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,kEAAkE,EAAE,GAAG,EAAE;QAC1E,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GACL,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACrE,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QACxD,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,mEAAmE,EACnE,GAAG,EAAE;QACH,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GACL,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,KAAK,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACtE,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QACxD,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEN,EAAE,CAAC,mEAAmE,EACnE,GAAG,EAAE;QACH,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,GAAG,GACL,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACrE,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QACxD,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QACzC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;AACR,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,gBAAgB,EAAE,GAAG,EAAE;IAC3C,EAAE,CAAC,0BAA0B,EAAE,GAAG,EAAE;QAClC,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAC,CAAC,CAAC;QACnC,MAAM,aAAa,GAAG,GAAG,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;QAClD,MAAM,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACxC,kBAAkB,CAAC,aAAa,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC1D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2BAA2B,EAAE,GAAG,EAAE;QACnC,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAC,CAAC,CAAC;QACnC,MAAM,aAAa,GAAG,GAAG,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;QAClD,MAAM,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACxC,kBAAkB,CAAC,aAAa,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACxD,kBAAkB,CAAC,aAAa,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAC1D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yDAAyD,EAAE,GAAG,EAAE;QACjE,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAC,CAAC,CAAC;QACnC,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,MAAM,OAAO,GAAG,GAAG,CAAC,KAAK,CAAC,MAAM,CAAW,CAAC;QAC5C,kBAAkB,CAAC,OAAO,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACzE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yDAAyD,EAAE,GAAG,EAAE;QACjE,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;QAC1D,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,MAAM,OAAO,GAAG,GAAG,CAAC,KAAK,CAAC,MAAM,CAAW,CAAC;QAC5C,kBAAkB,CACd,OAAO,EACP,QAAQ,CACJ;YACE;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC5C,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACzB;YACD;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC5C,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACzB;SACF,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACtB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wDAAwD,EAAE,GAAG,EAAE;QAChE,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GACL,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,MAAM,OAAO,GAAG,GAAG,CAAC,KAAK,CAAC,MAAM,CAAa,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,kBAAkB,CACd,OAAO,CAAC,CAAC,CAAC,EACV,QAAQ,CACJ;YACE;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC5C,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACzB;YACD;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC5C,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACzB;SACF,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpB,kBAAkB,CACd,OAAO,CAAC,CAAC,CAAC,EACV,QAAQ,CAAC,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACxE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yDAAyD,EAAE,GAAG,EAAE;QACjE,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,GAAG,GACL,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,eAAe,EAAE,IAAI,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACrE,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,MAAM,OAAO,GAAG,GAAG,CAAC,KAAK,CAAC,MAAM,CAAa,CAAC;QAC9C,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,kBAAkB,CACd,OAAO,CAAC,CAAC,CAAC,EACV,QAAQ,CACJ;YACE;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC5C,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACzB;YACD;gBACE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,IAAI,CAAC;gBAC5C,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC;aACzB;SACF,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACpB,kBAAkB,CACd,OAAO,CAAC,CAAC,CAAC,EACV,QAAQ,CAAC,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACtE,kBAAkB,CACd,OAAO,CAAC,CAAC,CAAC,EACV,QAAQ,CACJ,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,EAC5D,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACnB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2BAA2B,EAAE,GAAG,EAAE;QACnC,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAC,CAAC,CAAC;QACnC,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,MAAM,OAAO,GACT,GAAG,CAAC,KAAK,CAAC,MAAM,EAAE,EAAC,cAAc,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAC,CAAW,CAAC;QACtE,kBAAkB,CAAC,OAAO,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACzE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4BAA4B,EAAE,GAAG,EAAE;QACpC,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACtD,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,MAAM,OAAO,GAAG,GAAG,CAAC,KAAK,CAAC,MAAM,EAAE;YAChC,cAAc,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;SACzE,CAAa,CAAC;QACf,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,KAAK,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC1E,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACzE,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,iEAAiE,EAAE,GAAG,EAAE;QACzE,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACtD,MAAM,MAAM,GAAG,QAAQ,CACnB,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3E,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,KAAK,CAAC,MAAM,EAAE;YAC7B,cAAc,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;SACnC,CAAC,CAAC,CAAC,YAAY,CAAC,wDAAwD,CAAC,CAAC;IAC7E,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,oBAAoB,EAAE,GAAG,EAAE;IACzC,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC;QACnD,MAAM,MAAM,GAAG,SAAS,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QAC5D,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yCAAyC,EAAE,GAAG,EAAE;QACjD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACtE,MAAM,MAAM,GAAG,SAAS,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QAC9D,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yCAAyC,EAAE,GAAG,EAAE;QACjD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;QAC1E,MAAM,MAAM,GAAG,SAAS,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QAC5D,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YACrC,KAAK,EAAE,CAAC;YACR,eAAe,EAAE,IAAI;YACrB,WAAW,EAAE,IAAI;SAClB,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,SAAS,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QAC9D,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0BAA0B,EAAE,GAAG,EAAE;QAClC,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC;QAC/C,MAAM,cAAc,GAAG,mBAAmB,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC;QAC9D,kCAAkC;QAClC,MAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAQ,CAAC;QAC5D,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,QAAQ,CAAC,CAAC;QAClD,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IAClD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8BAA8B,EAAE,GAAG,EAAE;QACtC,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAChC,KAAK,EAAE,IAAI;SACZ,CAAC,CAAC,CAAC,YAAY,CAAC,mCAAmC,CAAC,CAAC;QACtD,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAChC,KAAK,EAAE,CAAC;SACT,CAAC,CAAC,CAAC,YAAY,CAAC,+BAA+B,CAAC,CAAC;QAClD,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAChC,KAAK,EAAE,CAAC,EAAE;SACX,CAAC,CAAC,CAAC,YAAY,CAAC,iCAAiC,CAAC,CAAC;IACtD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,kBAAkB,EAAE,GAAG,EAAE;IAC7C,MAAM,KAAK,GAAG,CAAC,CAAC;IAChB,MAAM,SAAS,GAAG,CAAC,CAAC;IACpB,MAAM,SAAS,GAAG,CAAC,CAAC;IAEpB,4EAA4E;IAC5E,+BAA+B;IAE/B,MAAM,QAAQ,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;IAC5B,MAAM,SAAS,GAAG,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IAChC,KAAK,MAAM,QAAQ,IAAI,SAAS,EAAE;QAChC,KAAK,MAAM,OAAO,IAAI,QAAQ,EAAE;YAC9B,MAAM,SAAS,GACX,yDAAyD;gBACzD,IAAI,QAAQ,aAAa,OAAO,EAAE,CAAC;YACvC,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;gBACjB,MAAM,SAAS,GAAG,CAAC,CAAC;gBACpB,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;oBACrC,KAAK;oBACL,iBAAiB,EAAE,MAAM;oBACzB,oBAAoB,EAAE,MAAM;oBAC5B,eAAe,EAAE,MAAM;oBACvB,OAAO;iBACR,CAAC,CAAC;gBACH,MAAM,MAAM,GAAW,EAAE,CAAC;gBAC1B,IAAI,QAAQ,EAAE;oBACZ,MAAM,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC;iBAC3B;gBACD,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;gBAC1D,KAAK,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC;gBACxC,IAAI,UAAU,GAAG,CAAC,CAAC;gBACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;oBAC1B,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,KAAK,CAAC,KAAK,EAAE,MAAM,CAAW,CAAC,CAAC;oBACtD,IAAI,OAAO,KAAK,GAAG,IAAI,QAAQ,EAAE;wBAC/B,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;qBACxD;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,CAAC,CAAC;qBAC9C;oBACD,IAAI,CAAC,KAAK,CAAC,EAAE;wBACX,UAAU,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;qBACtC;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;qBACrD;iBACF;YACH,CAAC,CAAC,CAAC;SACJ;KACF;IAED,MAAM,iBAAiB,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;IACrC,KAAK,MAAM,QAAQ,IAAI,SAAS,EAAE;QAChC,KAAK,MAAM,gBAAgB,IAAI,iBAAiB,EAAE;YAChD,MAAM,SAAS,GACX,yDAAyD;gBACzD,IAAI,QAAQ,sBAAsB,gBAAgB,EAAE,CAAC;YACzD,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;gBACjB,MAAM,SAAS,GAAG,CAAC,CAAC;gBACpB,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;oBACrC,KAAK;oBACL,iBAAiB,EAAE,MAAM;oBACzB,oBAAoB,EAAE,MAAM;oBAC5B,eAAe,EAAE,MAAM;oBACvB,gBAAgB;iBACjB,CAAC,CAAC;gBACH,MAAM,MAAM,GAAW,EAAE,CAAC;gBAC1B,IAAI,QAAQ,EAAE;oBACZ,MAAM,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC;iBAC3B;gBACD,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;gBAC1D,KAAK,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC;gBACxC,IAAI,UAAU,GAAG,CAAC,CAAC;gBACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;oBAC1B,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,KAAK,CAAC,KAAK,EAAE,MAAM,CAAW,CAAC,CAAC;oBACtD,IAAI,gBAAgB,KAAK,GAAG,IAAI,QAAQ,EAAE;wBACxC,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;qBACxD;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,CAAC,CAAC;qBAC9C;oBACD,IAAI,CAAC,KAAK,CAAC,EAAE;wBACX,UAAU,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;qBACtC;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;qBACrD;iBACF;YACH,CAAC,CAAC,CAAC;SACJ;KACF;IAED,MAAM,WAAW,GAA2B,CAAC,QAAQ,EAAE,MAAM,CAAC,CAAC;IAC/D,KAAK,MAAM,UAAU,IAAI,WAAW,EAAE;QACpC,MAAM,SAAS,GACX,2DAA2D,UAAU,EAAE,CAAC;QAC5E,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;YACjB,MAAM,SAAS,GAAG,CAAC,CAAC;YACpB,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;gBACrC,KAAK;gBACL,iBAAiB,EAAE,MAAM;gBACzB,oBAAoB,EAAE,MAAM;gBAC5B,eAAe,EAAE,MAAM;gBACvB,UAAU;aACX,CAAC,CAAC;YACH,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;YAC1D,MAAM,MAAM,GAAG,SAAS,CAAC,KAAK,CAAC,KAAK,CAAW,CAAC;YAChD,IAAI,oBAAoB,GAAG,SAAS,GAAG,CAAC,CAAC;YACzC,IAAI,UAAU,KAAK,MAAM,EAAE;gBACzB,oBAAoB,GAAG,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;aACxD;YACD,kBAAkB,CACd,MAAM,EACN,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,oBAAoB,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3E,CAAC,CAAC,CAAC;KACJ;IAED,MAAM,iBAAiB,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;IACxC,KAAK,MAAM,WAAW,IAAI,iBAAiB,EAAE;QAC3C,MAAM,SAAS,GAAG,wBAAwB;YACtC,eAAe,WAAW,wBAAwB,CAAC;QACvD,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;YACjB,MAAM,SAAS,GAAG,CAAC,CAAC;YACpB,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;gBACrC,KAAK;gBACL,eAAe,EAAE,IAAI;gBACrB,WAAW;gBACX,iBAAiB,EAAE,MAAM;gBACzB,oBAAoB,EAAE,MAAM;gBAC5B,eAAe,EAAE,MAAM;gBACvB,UAAU,EAAE,QAAQ;aACrB,CAAC,CAAC;YACH,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;YAC1D,IAAI,MAAM,GAAG,SAAS,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;YACpC,IAAI,UAAkB,CAAC;YACvB,IAAI,WAAW,EAAE;gBACf,MAAM,GAAG,MAAkB,CAAC;gBAC5B,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;gBACjC,UAAU,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;gBACvB,MAAM,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;aACpB;iBAAM;gBACL,MAAM,GAAG,MAAgB,CAAC;aAC3B;YAED,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC;YAC5D,MAAM,eAAe,GAAG,GAAG,CAAC,SAAS,CAAC,MAAM,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;YACzD,MAAM,QAAQ,GAAG,CAAC,CAAC,mBAAmB,CAAC,eAAe,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAC9D,MAAM,QAAQ,GAAG,CAAC,CAAC,mBAAmB,CAAC,eAAe,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YAC9D,kBAAkB,CACd,QAAQ,EACR,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,GAAG,CAAC,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YACrE,kBAAkB,CACd,QAAQ,EACR,GAAG,CAAC,GAAG,CACH,MAAM,CAAC,CAAC,SAAS,GAAG,CAAC,CAAC,GAAG,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,EACrC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YAC1C,IAAI,WAAW,EAAE;gBACf,kBAAkB,CAAC,UAAU,EAAE,QAAQ,CAAC,OAAO,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;aACtE;QACH,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,iDAAiD,EAAE,GAAG,EAAE;YACzD,MAAM,cAAc,GAAG,CAAC,CAAC;YACzB,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;gBACrC,KAAK;gBACL,iBAAiB,EAAE,MAAM;gBACzB,oBAAoB,EAAE,MAAM;gBAC5B,eAAe,EAAE,OAAO;gBACxB,UAAU,EAAE,QAAQ;gBACpB,QAAQ,EAAE,IAAI;gBACd,UAAU,EAAE,CAAC,cAAc,EAAE,SAAS,CAAC;aACxC,CAAQ,CAAC;YACV,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;YAC/B,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC;iBAC7B,YAAY,CAAC,8BAA8B,CAAC,CAAC;QACpD,CAAC,CAAC,CAAC;QAEH,gEAAgE;QAChE,YAAY;QACZ,eAAe;QACf,qBAAqB;QACrB,EAAE;QACF,YAAY;QACZ,iBAAiB;QACjB,iBAAiB;QACjB,sBAAsB;QACtB,EAAE;QACF,sCAAsC;QACtC,yDAAyD;QACzD,4DAA4D;QAC5D,wDAAwD;QACxD,mDAAmD;QACnD,6CAA6C;QAC7C,6DAA6D;QAC7D,mEAAmE;QACnE,+DAA+D;QAC/D,EAAE;QACF,yDAAyD;QACzD,EAAE;QACF,6BAA6B;QAC7B,iBAAiB;QACjB,0BAA0B;QAC1B,0BAA0B;QAC1B,uBAAuB;QACvB,0BAA0B;QAC1B,0BAA0B;QAC1B,MAAM;QACN,EAAE,CAAC,kCAAkC,EAAE,KAAK,IAAI,EAAE;YAChD,MAAM,cAAc,GAAG,CAAC,CAAC;YACzB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;gBAC/B,KAAK;gBACL,iBAAiB,EAAE,MAAM;gBACzB,oBAAoB,EAAE,MAAM;gBAC5B,eAAe,EAAE,OAAO;gBACxB,UAAU,EAAE,QAAQ;gBACpB,QAAQ,EAAE,IAAI;gBACd,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;aACxD,CAAC,CAAC;YACH,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;YAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;YACf,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;YAC3D,MAAM,OAAO,GAAG,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC;YAC/B,MAAM,OAAO,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;YAEjC,IAAI,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;YACpC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC5B,IAAI,UAAU,GACV,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC;YAC9D,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YAEnC,IAAI,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;YACpC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC5B,uDAAuD;YACvD,MAAM,CAAC,EAAE,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAClC,IAAI,UAAU,GACV,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC;YAC9D,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YACnC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;YAE9C,KAAK,CAAC,WAAW,EAAE,CAAC;YACpB,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;YAE5C,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;YAChC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC5B,UAAU,GAAG,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC;YACvE,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YAEnC,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;YAChC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC5B,uDAAuD;YACvD,MAAM,CAAC,EAAE,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAClC,UAAU,GAAG,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC;YACvE,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YACnC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;YAE9C,kEAAkE;YAClE,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACvD,CAAC,CAAC,CAAC;KACJ;IAED,yBAAyB;IACzB,QAAQ;IACR,qBAAqB;IACrB,+BAA+B;IAC/B,EAAE;IACF,6BAA6B;IAC7B,oCAAoC;IACpC,eAAe;IACf,iCAAiC;IACjC,oCAAoC;IACpC,gCAAgC;IAChC,2BAA2B;IAC3B,qBAAqB;IACrB,oCAAoC;IACpC,oEAAoE;IACpE,4DAA4D;IAC5D,kBAAkB;IAClB,EAAE;IACF,0BAA0B;IAC1B,yBAAyB;IACzB,YAAY;IACZ,yBAAyB;IACzB,YAAY;IACZ,EAAE;IACF,sDAAsD;IACtD,yBAAyB;IACzB,MAAM;IACN,EAAE,CAAC,wCAAwC,EAAE,KAAK,IAAI,EAAE;QACtD,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC7B,KAAK;YACL,iBAAiB,EAAE,MAAM;YACzB,oBAAoB,EAAE,MAAM;YAC5B,eAAe,EAAE,OAAO;YACxB,UAAU,EAAE,QAAQ;YACpB,QAAQ,EAAE,IAAI;YACd,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;SACxD,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC,CAAC;QACnE,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAC5D,MAAM,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC5D,MAAM,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,IAAI,EAAU,CAAC;QACf,IAAI,EAAU,CAAC;QACf,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE;YACZ,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;YACjC,kBAAkB,CAAC,EAAE,EAAE,GAAG,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YACnE,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;YACjC,kBAAkB,CACd,EAAE,EAAE,GAAG,CAAC,QAAQ,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9D,CAAC,CAAC,CAAC;QACH,KAAK,CAAC,WAAW,EAAE,CAAC;QACpB,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAE5C,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE;YACZ,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;YACjC,MAAM,CAAC,EAAE,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;YACzC,kBAAkB,CAAC,EAAE,EAAE,GAAG,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YACnE,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;YACjC,kBAAkB,CACd,EAAE,EAAE,GAAG,CAAC,QAAQ,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9D,CAAC,CAAC,CAAC;QACH,kEAAkE;QAClE,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QAErD,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,CAAC,EAAE,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;QACnE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,cAAc,CAAC,CAAC;IAC9D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0DAA0D,EAAE,GAAG,EAAE;QAClE,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC/B,KAAK;YACL,eAAe,EAAE,KAAK;YACtB,WAAW,EAAE,KAAK;YAClB,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;SACxD,CAAC,CAAC;QACH,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,cAAc,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,IAAI,GAAG,GAAG,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACnC,MAAM,CAAC,IAAI,CAAC,CAAC,QAAQ,EAAE,CAAC;IAC1B,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yDAAyD,EAAE,GAAG,EAAE;QACjE,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC/B,KAAK;YACL,eAAe,EAAE,IAAI;YACrB,WAAW,EAAE,KAAK;YAClB,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;SACxD,CAAC,CAAC;QACH,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,cAAc,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,IAAI,GAAG,GAAG,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAW,CAAC;QAC7C,kBAAkB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;IAC9B,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wDAAwD,EAAE,GAAG,EAAE;QAChE,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC/B,KAAK;YACL,eAAe,EAAE,IAAI;YACrB,WAAW,EAAE,IAAI;YACjB,QAAQ,EAAE,IAAI;YACd,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;SACxD,CAAC,CAAC;QACH,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC3D,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACb,GAAG,CAAC,WAAW,EAAE,CAAC,CAAE,sDAAsD;QAC1E,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,cAAc,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,KAAK,GAAG,GAAG,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,CAAa,CAAC;QAChD,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAChC,kBAAkB,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAChC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,QAAQ,EAAE,CAAC;IAC9B,CAAC,CAAC,CAAC;IAEH,wEAAwE;IACxE,YAAY;IACZ,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,iBAAiB;IACjB,sBAAsB;IACtB,iBAAiB;IACjB,EAAE;IACF,6BAA6B;IAC7B,oCAAoC;IACpC,eAAe;IACf,mEAAmE;IACnE,iCAAiC;IACjC,oCAAoC;IACpC,gCAAgC;IAChC,sBAAsB;IACtB,kCAAkC;IAClC,2DAA2D;IAC3D,gDAAgD;IAChD,4DAA4D;IAC5D,EAAE;IACF,4DAA4D;IAC5D,6DAA6D;IAC7D,uCAAuC;IACvC,6DAA6D;IAC7D,EAAE;IACF,oEAAoE;IACpE,yBAAyB;IACzB,MAAM;IACN,EAAE,CAAC,eAAe,EAAE,KAAK,IAAI,EAAE;QAC7B,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC7B,KAAK;YACL,iBAAiB,EAAE,MAAM;YACzB,oBAAoB,EAAE,MAAM;YAC5B,eAAe,EAAE,OAAO;YACxB,QAAQ,EAAE,IAAI;YACd,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;SACxD,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC,CAAC;QAC7D,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC7D,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC7D,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC;QACrC,MAAM,EAAE,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAErE,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,SAAS,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC;QACrE,sEAAsE;QACtE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,SAAS,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,MAAM,EAAE,KAAK,IAAI,EAAE;QACpB,qEAAqE;QACrE,+BAA+B;QAC/B,YAAY;QACZ,eAAe;QACf,qBAAqB;QACrB,EAAE;QACF,sBAAsB;QACtB,iBAAiB;QACjB,iBAAiB;QACjB,EAAE;QACF,uDAAuD;QACvD,yCAAyC;QACzC,iEAAiE;QACjE,oEAAoE;QACpE,sDAAsD;QACtD,gCAAgC;QAChC,wDAAwD;QACxD,6CAA6C;QAC7C,sCAAsC;QACtC,uCAAuC;QACvC,sCAAsC;QACtC,gEAAgE;QAChE,EAAE;QACF,yDAAyD;QACzD,gCAAgC;QAChC,mDAAmD;QACnD,qCAAqC;QACrC,qCAAqC;QACrC,gCAAgC;QAChC,MAAM;QACN,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC7B,KAAK,EAAE,CAAC;YACR,iBAAiB,EAAE,MAAM;YACzB,oBAAoB,EAAE,MAAM;YAC5B,OAAO,EAAE,KAAK;YACd,UAAU,EAAE,CAAC,cAAc,EAAE,SAAS,CAAC;SACxC,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC;YACzB,KAAK,EAAE,CAAC;YACR,iBAAiB,EAAE,MAAM;YACzB,OAAO,EAAE,KAAK;SACf,CAAC,CAAC,CAAC;QAEJ,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QAC7B,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,GAAG,EAAC,CAAC,CAAC;QAC1D,MAAM,KAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QAEnC,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAClD,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAClD,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACpD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,yBAAyB,EAAE,GAAG,EAAE;IAC9C,MAAM,UAAU,GAA2B;QACzC,KAAK,EAAE,CAAC;QACR,UAAU,EAAE,MAAM;QAClB,OAAO,EAAE,IAAI;QACb,iBAAiB,EAAE,eAAe;QAClC,oBAAoB,EAAE,WAAW;QACjC,eAAe,EAAE,MAAM;QACvB,iBAAiB,EAAE,MAAM;QACzB,oBAAoB,EAAE,MAAM;QAC5B,eAAe,EAAE,MAAM;QACvB,gBAAgB,EAAE,UAAU;QAC5B,mBAAmB,EAAE,UAAU;QAC/B,cAAc,EAAE,QAAQ;QACxB,OAAO,EAAE,GAAG;QACZ,gBAAgB,EAAE,GAAG;QACrB,IAAI,EAAE,QAAQ;QACd,SAAS,EAAE,EAAE;QACb,eAAe,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;QAC3B,UAAU,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;QAClB,KAAK,EAAE,OAAO;QACd,UAAU,EAAE,OAAO;QACnB,SAAS,EAAE,IAAI;KAChB,CAAC;IAEF,MAAM,uBAAuB,GAAG;QAC9B,IAAI,EAAE,QAAQ;QACd,SAAS,EAAE,IAAI;QACf,eAAe,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;QAC3B,KAAK,EAAE,OAAO;QACd,KAAK,EAAE,CAAC;QACR,UAAU,EAAE,mBAAmB,CAAC,IAAI,IAAI,EAAE,CAAC;QAC3C,OAAO,EAAE,IAAI;QACb,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,aAAa,EAAE,CAAC;QAC5D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,SAAS,EAAE,CAAC;QAC3D,eAAe,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACjD,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACnD,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACtD,eAAe,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACjD,mBAAmB,EAAE,oBAAoB,CAAC,IAAI,CAAC;QAC/C,gBAAgB,EAAE,mBAAmB,CAAC,IAAI,QAAQ,CAAC,EAAE,CAAC,CAAC;QACvD,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,QAAQ,CAAC,EAAE,CAAC,CAAC;QAC1D,cAAc,EAAE,mBAAmB,CAAC,IAAI,MAAM,EAAE,CAAC;KAClD,CAAC;IAEF,QAAQ,CAAC,yBAAyB,EAAE,GAAG,EAAE;QACvC,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;YAC3C,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC;YAElD,MAAM,qBAA8D,EAA9D,EAAC,OAAO,EAAE,gBAAgB,OAAoC,EAAlC,yDAAkC,CAAC;YAErE,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,uBAAuB,CAAC,CAAC;YACrD,MAAM,CAAC,OAAO,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;YACjC,MAAM,CAAC,gBAAgB,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAC5C,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,qBAAqB,EAAE,GAAG,EAAE;QACnC,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;YAC3C,MAAM,MAAM,qBACP,UAAU,IACb,IAAI,EAAE,SAAS,IACZ;gBACD,eAAe,EAAE,IAAI;gBACrB,WAAW,EAAE,IAAI;gBACjB,QAAQ,EAAE,IAAI;gBACd,MAAM,EAAE,IAAI;gBACZ,WAAW,EAAE,IAAI;gBACjB,QAAQ,EAAE,CAAC;gBACX,WAAW,EAAE,CAAC;aAC2C,CAC5D,CAAC;YAEF,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC;YAE1C,MAAM,qBAA8D,EAA9D,EAAC,OAAO,EAAE,gBAAgB,OAAoC,EAAlC,yDAAkC,CAAC;YAErE,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,mBACtB,uBAAuB,IAC1B,IAAI,EAAE,SAAS,EACf,eAAe,EAAE,IAAI,EACrB,WAAW,EAAE,IAAI,EACjB,QAAQ,EAAE,IAAI,EACd,MAAM,EAAE,IAAI,EACZ,WAAW,EAAE,IAAI,IACjB,CAAC;YACH,MAAM,CAAC,OAAO,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;YACjC,MAAM,CAAC,gBAAgB,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAC5C,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,cAAc,EAAE,GAAG,EAAE;IACnC,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QACtD,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yCAAyC,EAAE,GAAG,EAAE;QACjD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QAC1D,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QACxD,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yCAAyC,EAAE,GAAG,EAAE;QACjD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;QAC9D,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QACtD,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YACzB,KAAK,EAAE,CAAC;YACR,eAAe,EAAE,IAAI;YACrB,WAAW,EAAE,IAAI;SAClB,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QACxD,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wEAAwE,EACxE,GAAG,EAAE;QACH,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACjE,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QAC1D,GAAG,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;QACjB,MAAM,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QACpC,wDAAwD;QACxD,MAAM,CAAC,GAAG,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,GAAG,CAAC,mBAAmB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;IAEN,KAAK,MAAM,cAAc,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE;QACnC,EAAE,CAAC,0BAA0B,EAAE,GAAG,EAAE;YAClC,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,cAAc,EAAC,CAAC,CAAC;YACzD,MAAM,cAAc,GAAG,mBAAmB,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC;YAC9D,kCAAkC;YAClC,MAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAQ,CAAC;YAC5D,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;YAC5C,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;YAChD,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,cAAc,CAAC,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC;QACxE,CAAC,CAAC,CAAC;KACJ;IAED,EAAE,CAAC,8BAA8B,EAAE,GAAG,EAAE;QACtC,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YAC1B,KAAK,EAAE,IAAI;SACZ,CAAC,CAAC,CAAC,YAAY,CAAC,mCAAmC,CAAC,CAAC;QACtD,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YAC1B,KAAK,EAAE,CAAC;SACT,CAAC,CAAC,CAAC,YAAY,CAAC,+BAA+B,CAAC,CAAC;QAClD,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YAC1B,KAAK,EAAE,CAAC,EAAE;SACX,CAAC,CAAC,CAAC,YAAY,CAAC,iCAAiC,CAAC,CAAC;IACtD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,YAAY,EAAE,GAAG,EAAE;IACvC,QAAQ;IACR,4EAA4E;IAC5E,6EAA6E;IAC7E,gDAAgD;IAChD,EAAE;IACF,YAAY;IACZ,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,YAAY;IACZ,iBAAiB;IACjB,iBAAiB;IACjB,iBAAiB;IACjB,EAAE;IACF,6BAA6B;IAC7B,sCAAsC;IACtC,0DAA0D;IAC1D,6DAA6D;IAC7D,wDAAwD;IACxD,sDAAsD;IACtD,kDAAkD;IAClD,wEAAwE;IACxE,2BAA2B;IAC3B,EAAE;IACF,gDAAgD;IAChD,gEAAgE;IAChE,8DAA8D;IAC9D,MAAM;IAEN,MAAM,KAAK,GAAG,CAAC,CAAC;IAChB,MAAM,SAAS,GAAG,CAAC,CAAC;IACpB,MAAM,SAAS,GAAG,CAAC,CAAC;IACpB,MAAM,SAAS,GAAG,CAAC,CAAC;IACpB,MAAM,yBAAyB,GAAG,CAAC,UAAU,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC;IAEtE,4EAA4E;IAC5E,+BAA+B;IAE/B,MAAM,QAAQ,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;IAC5B,MAAM,SAAS,GAAG,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IAChC,KAAK,MAAM,QAAQ,IAAI,SAAS,EAAE;QAChC,KAAK,MAAM,OAAO,IAAI,QAAQ,EAAE;YAC9B,MAAM,SAAS,GACX,yDAAyD;gBACzD,IAAI,QAAQ,aAAa,OAAO,EAAE,CAAC;YACvC,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;gBACjB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;oBACzB,KAAK;oBACL,iBAAiB,EAAE,MAAM;oBACzB,oBAAoB,EAAE,MAAM;oBAC5B,eAAe,EAAE,MAAM;oBACvB,OAAO;oBACP,cAAc,EAAE,CAAC;iBAClB,CAAC,CAAC;gBACH,MAAM,MAAM,GAAW,EAAE,CAAC;gBAC1B,IAAI,QAAQ,EAAE;oBACZ,MAAM,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC;iBAC3B;gBACD,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;gBAC1D,KAAK,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC;gBACxC,IAAI,UAAU,GAAG,CAAC,CAAC;gBACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;oBAC1B,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,KAAK,EAAE,MAAM,CAAW,CAAC,CAAC;oBAChD,IAAI,OAAO,KAAK,GAAG,IAAI,QAAQ,EAAE;wBAC/B,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;qBACxD;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,CAAC,CAAC;qBAC9C;oBACD,IAAI,CAAC,KAAK,CAAC,EAAE;wBACX,UAAU,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;qBACtC;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;qBACrD;iBACF;YACH,CAAC,CAAC,CAAC;SACJ;KACF;IAED,MAAM,iBAAiB,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;IACrC,KAAK,MAAM,QAAQ,IAAI,SAAS,EAAE;QAChC,KAAK,MAAM,gBAAgB,IAAI,iBAAiB,EAAE;YAChD,MAAM,SAAS,GACX,yDAAyD;gBACzD,IAAI,QAAQ,sBAAsB,gBAAgB,EAAE,CAAC;YACzD,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;gBACjB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;oBACzB,KAAK;oBACL,iBAAiB,EAAE,MAAM;oBACzB,oBAAoB,EAAE,MAAM;oBAC5B,eAAe,EAAE,MAAM;oBACvB,gBAAgB;oBAChB,cAAc,EAAE,CAAC;iBAClB,CAAC,CAAC;gBACH,MAAM,MAAM,GAAW,EAAE,CAAC;gBAC1B,IAAI,QAAQ,EAAE;oBACZ,MAAM,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC;iBAC3B;gBACD,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;gBAC1D,KAAK,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC;gBACxC,IAAI,UAAU,GAAG,CAAC,CAAC;gBACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;oBAC1B,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,KAAK,EAAE,MAAM,CAAW,CAAC,CAAC;oBAChD,IAAI,gBAAgB,KAAK,GAAG,IAAI,QAAQ,EAAE;wBACxC,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;qBACxD;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,CAAC,CAAC;qBAC9C;oBACD,IAAI,CAAC,KAAK,CAAC,EAAE;wBACX,UAAU,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;qBACtC;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;qBACrD;iBACF;YACH,CAAC,CAAC,CAAC;SACJ;KACF;IAED,MAAM,eAAe,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IAC/B,MAAM,iBAAiB,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;IACxC,MAAM,qBAAqB,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;IAC5C,KAAK,MAAM,cAAc,IAAI,eAAe,EAAE;QAC5C,KAAK,MAAM,WAAW,IAAI,iBAAiB,EAAE;YAC3C,KAAK,MAAM,eAAe,IAAI,qBAAqB,EAAE;gBACnD,MAAM,SAAS,GAAG,kBAAkB,cAAc,IAAI;oBAClD,mBAAmB,eAAe,IAAI;oBACtC,eAAe,WAAW,EAAE,CAAC;gBACjC,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;oBACjB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;wBACzB,KAAK;wBACL,iBAAiB,EAAE,MAAM;wBACzB,oBAAoB,EAAE,MAAM;wBAC5B,eAAe,EAAE,MAAM;wBACvB,WAAW;wBACX,eAAe;wBACf,cAAc;qBACf,CAAC,CAAC;oBACH,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;oBAC3D,IAAI,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;oBAE9B,MAAM,6BAA6B,GAC/B,yBAAyB,CAAC,yBAAyB,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;oBAEpE,IAAI,cAAsB,CAAC;oBAC3B,IAAI,eAAe,EAAE;wBACnB,MAAM,OAAO,GAAG,yBAAyB,CAAC,GAAG,CACzC,KAAK,CAAC,EAAE,CACJ,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;wBACjE,cAAc,GAAG,GAAG,CAAC,SAAS,CAC1B,CAAC,CAAC,oBAAoB,CAClB,CAAC,CAAC,oBAAoB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,EAC/D,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;qBAChB;yBAAM;wBACL,cAAc,GAAG,GAAG,CAAC,GAAG,CACpB,MAAM,CAAC,6BAA6B,CAAC,EACrC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;qBACnC;oBACD,IAAI,WAAW,EAAE;wBACf,MAAM,GAAG,MAAkB,CAAC;wBAC5B,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;wBACjC,kBAAkB,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,cAAc,CAAC,CAAC;wBAC9C,kBAAkB,CACd,MAAM,CAAC,CAAC,CAAC,EACT,GAAG,CAAC,GAAG,CACH,MAAM,CAAC,6BAA6B,CAAC,EACrC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;qBACxC;yBAAM;wBACL,MAAM,GAAG,MAAgB,CAAC;wBAC1B,kBAAkB,CAAC,MAAM,EAAE,cAAc,CAAC,CAAC;qBAC5C;gBACH,CAAC,CAAC,CAAC;aACJ;SACF;KACF;IAED,gEAAgE;IAChE,YAAY;IACZ,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,YAAY;IACZ,iBAAiB;IACjB,iBAAiB;IACjB,sBAAsB;IACtB,EAAE;IACF,gCAAgC;IAChC,oDAAoD;IACpD,wDAAwD;IACxD,mDAAmD;IACnD,8CAA8C;IAC9C,wCAAwC;IACxC,wDAAwD;IACxD,6DAA6D;IAC7D,yDAAyD;IACzD,EAAE;IACF,yDAAyD;IACzD,EAAE;IACF,6BAA6B;IAC7B,iBAAiB;IACjB,0BAA0B;IAC1B,0BAA0B;IAC1B,uBAAuB;IACvB,0BAA0B;IAC1B,0BAA0B;IAC1B,MAAM;IACN,EAAE,CAAC,kBAAkB,EAAE,KAAK,IAAI,EAAE;QAChC,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YACzB,KAAK;YACL,iBAAiB,EAAE,MAAM;YACzB,oBAAoB,EAAE,OAAO;YAC7B,eAAe,EAAE,OAAO;YACxB,UAAU,EAAE,QAAQ;YACpB,QAAQ,EAAE,IAAI;YACd,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;SACxD,CAAC,CAAC;QACH,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QACf,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC3D,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;QACtC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAC5B,MAAM,UAAU,GACZ,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACxE,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;QACnC,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;QACtC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAC5B,uDAAuD;QACvD,MAAM,CAAC,EAAE,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAClC,MAAM,UAAU,GACZ,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;QAC5E,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;QAEnC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QAC9C,KAAK,CAAC,WAAW,EAAE,CAAC;QACpB,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAE5C,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;QACtC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAC5B,MAAM,UAAU,GACZ,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACxE,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;QACnC,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;QACtC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAC5B,uDAAuD;QACvD,MAAM,CAAC,EAAE,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAClC,MAAM,UAAU,GACZ,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;QAC5E,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;QACnC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,UAAU,EAAE,EAAE,EAAE,UAAU,CAAC,CAAC,CAAC;QAC9C,kEAAkE;QAClE,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IACvD,CAAC,CAAC,CAAC;IAEH,wEAAwE;IACxE,YAAY;IACZ,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,iBAAiB;IACjB,sBAAsB;IACtB,iBAAiB;IACjB,EAAE;IACF,6BAA6B;IAC7B,8BAA8B;IAC9B,eAAe;IACf,mEAAmE;IACnE,iCAAiC;IACjC,oCAAoC;IACpC,gCAAgC;IAChC,sBAAsB;IACtB,kCAAkC;IAClC,2DAA2D;IAC3D,gDAAgD;IAChD,4DAA4D;IAC5D,EAAE;IACF,4DAA4D;IAC5D,6DAA6D;IAC7D,uCAAuC;IACvC,6DAA6D;IAC7D,EAAE;IACF,oEAAoE;IACpE,yBAAyB;IACzB,MAAM;IACN,EAAE,CAAC,eAAe,EAAE,KAAK,IAAI,EAAE;QAC7B,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YACvB,KAAK;YACL,iBAAiB,EAAE,MAAM;YACzB,oBAAoB,EAAE,MAAM;YAC5B,eAAe,EAAE,OAAO;YACxB,QAAQ,EAAE,IAAI;YACd,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;SACxD,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,OAAO,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC,CAAC;QAC7D,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC7D,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC7D,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC;QACrC,MAAM,EAAE,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAErE,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,SAAS,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC;QACrE,sEAAsE;QACtE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,KAAK,CAAC,CAAC;IACrD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,MAAM,EAAE,KAAK,IAAI,EAAE;QACpB,qEAAqE;QACrE,+BAA+B;QAC/B,YAAY;QACZ,eAAe;QACf,qBAAqB;QAErB,sBAAsB;QACtB,iBAAiB;QACjB,iBAAiB;QAEjB,uDAAuD;QACvD,4BAA4B;QAC5B,qDAAqD;QACrD,wDAAwD;QACxD,yCAAyC;QACzC,gCAAgC;QAChC,wDAAwD;QACxD,6CAA6C;QAC7C,+BAA+B;QAC/B,uCAAuC;QACvC,sCAAsC;QACtC,gEAAgE;QAEhE,yDAAyD;QACzD,+BAA+B;QAC/B,mDAAmD;QACnD,8BAA8B;QAC9B,8BAA8B;QAC9B,gCAAgC;QAChC,MAAM;QACN,MAAM,cAAc,GAAG,CAAC,CAAC;QACzB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,SAAS,GAAG,CAAC,CAAC;QACpB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YACvB,KAAK,EAAE,CAAC;YACR,iBAAiB,EAAE,OAAO;YAC1B,oBAAoB,EAAE,OAAO;YAC7B,OAAO,EAAE,KAAK;YACd,UAAU,EAAE,CAAC,cAAc,EAAE,SAAS,CAAC;SACxC,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC,CAAC;QAE5D,MAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QAC7B,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,GAAG,EAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,KAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;QACnC,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACrE,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,QAAQ,CAAC,CAAC,CAAC,CAAC,YAAY,EAAE,CAAC,EAAE,YAAY,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC1D,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACxE,CAAC,CAAC,CAAC;IAEH,yBAAyB;IACzB,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,+BAA+B;IAC/B,+BAA+B;IAC/B,uDAAuD;IACvD,2DAA2D;IAC3D,kCAAkC;IAClC,6BAA6B;IAC7B,wDAAwD;IACxD,qDAAqD;IACrD,6EAA6E;IAC7E,+DAA+D;IAC/D,EAAE;IACF,8CAA8C;IAC9C,mEAAmE;IACnE,0CAA0C;IAC1C,mCAAmC;IACnC,MAAM;IACN,EAAE,CAAC,yDAAyD,EAAE,KAAK,IAAI,EAAE;QACvE,MAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACpC,MAAM,IAAI,GACN,GAAG,CAAC,MAAM;aACL,KAAK,CACF,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,eAAe,EAAE,OAAO,EAAC,CAAC;aACnE,KAAK,CAAC,GAAG,CAAuB,CAAC;QAC1C,MAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAC,CAAC,CAAC;QACvC,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM;aACL,GAAG,CAAC;YACH,KAAK,EAAE,CAAC;YACR,oBAAoB,EAAE,MAAM;YAC5B,iBAAiB,EAAE,MAAM;YACzB,eAAe,EAAE,OAAO;SACzB,CAAC;aACD,KAAK,CAAC,GAAG,EAAE,EAAC,YAAY,EAAE,IAAI,EAAC,CAAuB,CAAC;QAEzE,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,OAAO,EAAE,CAAC,IAAI,EAAE,IAAI,CAAC,EAAC,CAAC,CAAC;QAErE,MAAM,GAAG,GAAG,QAAQ,CAAC,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC,CAAC;QAClD,MAAM,GAAG,GAAG,QAAQ,CAAC;YACnB,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;SACvE,CAAC,CAAC;QACH,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,CAAa,CAAC;QACjD,MAAM,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7B,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;QAClD,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;QAE9D,kEAAkE;QAClE,iEAAiE;QACjE,sBAAsB;QACtB,MAAM,SAAS,GAAG,KAAK,CAAC,MAAM,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;QAC5C,MAAM,UAAU,GACZ,MAAM,GAAG,CAAC,MAAM,CAAC,aAAa,CAAC,EAAC,aAAa,EAAE,SAAS,EAAC,CAAC,CAAC;QAC/D,MAAM,OAAO,GAAG,UAAU,CAAC,OAAO,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,CAAa,CAAC;QAC3D,MAAM,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAClC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACtC,kBAAkB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IACxC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,qBAAqB,EAAE,GAAG,EAAE;IAC1C,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC;QACzC,MAAM,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAW,CAAC;QACnC,MAAM,cAAc,GAAG,mBAAmB,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC;QAC9D,kCAAkC;QAClC,MAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAQ,CAAC;QAC5D,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC5C,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAW,CAAC;QACxC,kBAAkB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;QAC9B,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,qBAAqB,CAAC,CAAC;aAChD,OAAO,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,qBAAqB,CAAC,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,MAAM,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,KAAK,GACP,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,mBAAmB,EAAE,MAAM,EAAC,CAAC,CAAC;QAC5D,MAAM,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAW,CAAC;QACnC,MAAM,cAAc,GAAG,mBAAmB,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC;QAC9D,kCAAkC;QAClC,MAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAQ,CAAC;QAC5D,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;QAC5C,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAW,CAAC;QACxC,kBAAkB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;QAC9B,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,qBAAqB,CAAC,CAAC;aAChD,OAAO,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,qBAAqB,CAAC,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,mBAAmB,EAAE,GAAG,EAAE;IACxC,MAAM,UAAU,GAAqB;QACnC,KAAK,EAAE,CAAC;QACR,UAAU,EAAE,MAAM;QAClB,mBAAmB,EAAE,MAAM;QAC3B,OAAO,EAAE,IAAI;QACb,iBAAiB,EAAE,eAAe;QAClC,oBAAoB,EAAE,WAAW;QACjC,eAAe,EAAE,MAAM;QACvB,iBAAiB,EAAE,MAAM;QACzB,oBAAoB,EAAE,MAAM;QAC5B,eAAe,EAAE,MAAM;QACvB,gBAAgB,EAAE,UAAU;QAC5B,mBAAmB,EAAE,UAAU;QAC/B,cAAc,EAAE,QAAQ;QACxB,OAAO,EAAE,GAAG;QACZ,gBAAgB,EAAE,GAAG;QACrB,IAAI,EAAE,QAAQ;QACd,SAAS,EAAE,EAAE;QACb,eAAe,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;QAC3B,UAAU,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;QAClB,KAAK,EAAE,OAAO;QACd,UAAU,EAAE,OAAO;QACnB,SAAS,EAAE,IAAI;QACf,cAAc,EAAE,CAAC;KAClB,CAAC;IAEF,MAAM,uBAAuB,GAAG;QAC9B,IAAI,EAAE,QAAQ;QACd,SAAS,EAAE,IAAI;QACf,eAAe,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;QAC3B,KAAK,EAAE,OAAO;QACd,KAAK,EAAE,CAAC;QACR,UAAU,EAAE,mBAAmB,CAAC,IAAI,IAAI,EAAE,CAAC;QAC3C,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,IAAI,EAAE,CAAC;QACpD,OAAO,EAAE,IAAI;QACb,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,aAAa,EAAE,CAAC;QAC5D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,SAAS,EAAE,CAAC;QAC3D,eAAe,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACjD,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACnD,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACtD,eAAe,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACjD,mBAAmB,EAAE,oBAAoB,CAAC,IAAI,CAAC;QAC/C,gBAAgB,EAAE,mBAAmB,CAAC,IAAI,QAAQ,CAAC,EAAE,CAAC,CAAC;QACvD,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,QAAQ,CAAC,EAAE,CAAC,CAAC;QAC1D,cAAc,EAAE,mBAAmB,CAAC,IAAI,MAAM,EAAE,CAAC;QACjD,cAAc,EAAE,CAAC;QACjB,UAAU,EAAE,KAAK;KAClB,CAAC;IAEF,QAAQ,CAAC,mBAAmB,EAAE,GAAG,EAAE;QACjC,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;YAC3C,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;YAE5C,MAAM,qBAA8D,EAA9D,EAAC,OAAO,EAAE,gBAAgB,OAAoC,EAAlC,yDAAkC,CAAC;YAErE,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,uBAAuB,CAAC,CAAC;YACrD,MAAM,CAAC,OAAO,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;YACjC,MAAM,CAAC,gBAAgB,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAC5C,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,eAAe,EAAE,GAAG,EAAE;QAC7B,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;YAC3C,MAAM,MAAM,qBACP,UAAU,IACb,IAAI,EAAE,SAAS,IACZ;gBACD,eAAe,EAAE,IAAI;gBACrB,WAAW,EAAE,IAAI;gBACjB,QAAQ,EAAE,IAAI;gBACd,MAAM,EAAE,IAAI;gBACZ,WAAW,EAAE,IAAI;gBACjB,QAAQ,EAAE,CAAC;gBACX,WAAW,EAAE,CAAC;aAC+B,CAChD,CAAC;YAEF,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAEpC,MAAM,qBAA8D,EAA9D,EAAC,OAAO,EAAE,gBAAgB,OAAoC,EAAlC,yDAAkC,CAAC;YAErE,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,mBACtB,uBAAuB,IAC1B,IAAI,EAAE,SAAS,EACf,eAAe,EAAE,IAAI,EACrB,WAAW,EAAE,IAAI,EACjB,QAAQ,EAAE,IAAI,EACd,MAAM,EAAE,IAAI,EACZ,WAAW,EAAE,IAAI,IACjB,CAAC;YACH,MAAM,CAAC,OAAO,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;YACjC,MAAM,CAAC,gBAAgB,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAC5C,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,eAAe,EAAE,GAAG,EAAE;IACpC,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC;QACzC,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QACvD,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yCAAyC,EAAE,GAAG,EAAE;QACjD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QAC5D,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QACzD,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yCAAyC,EAAE,GAAG,EAAE;QACjD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;QAChE,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QACvD,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;IAC3C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,KAAK,GAAG,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QAC5E,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YAC3B,KAAK,EAAE,CAAC;YACR,eAAe,EAAE,IAAI;YACrB,WAAW,EAAE,IAAI;SAClB,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,CAAyB,CAAC;QACzD,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wEAAwE,EACxE,GAAG,EAAE;QACH,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACjE,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QAC5D,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;QAClB,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;QACrC,wDAAwD;QACxD,MAAM,CAAC,IAAI,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAChD,MAAM,CAAC,IAAI,CAAC,mBAAmB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IAEN,KAAK,MAAM,cAAc,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE;QACnC,EAAE,CAAC,0BAA0B,EAAE,GAAG,EAAE;YAClC,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,cAAc,EAAC,CAAC,CAAC;YAC1D,MAAM,cAAc,GAAG,mBAAmB,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC;YAC9D,kCAAkC;YAClC,MAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAQ,CAAC;YAC5D,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;YAC7C,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;YAChD,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,cAAc,CAAC,CAAC,OAAO,CAAC,cAAc,CAAC,CAAC;QACxE,CAAC,CAAC,CAAC;KACJ;IAED,EAAE,CAAC,0BAA0B,EAAE,KAAK,IAAI,EAAE;QACxC,MAAM,UAAU,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAC1B,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAC,CAAC,CAAC,CAAC;QACpD,MAAM,KAAK,GAAG;YACZ,GAAG,CAAC,MAAM,CAAC,QAAQ,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC;YAC/B,GAAG,CAAC,MAAM,CAAC,QAAQ,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC;SAChC,CAAC;QACF,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,KAAK,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;QACjE,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QAEf,MAAM,WAAW,GAAG,CAAC,CAAC;QACtB,MAAM,EAAE,GAAG,YAAY,CAAC,CAAC,WAAW,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC;QAC1D,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QAEvC,IAAI,cAAiC,CAAC;QACtC,MAAM,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,eAAe,CAAC,KAAK,EAAE,SAAS,EAAE,EAAE;YAC1D,cAAc,GAAG,SAAS,CAAC;YAC3B,OAAO,IAAI,CAAC;QACd,CAAC,CAAC,CAAC,CAAC;QAEJ,MAAM,WAAW,GACb,MAAM,GAAG,CAAC,eAAe,CAAC,GAAG,CAAC,EAAE,CAAC,UAAU,CAAC,cAAc,CAAC,CAAC,CAAC;QAEjE,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;QACnE,MAAM,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;QACrE,kBAAkB,CAAC,WAAW,CAAC,OAAO,CAAC,EAAE,CAAW,EAAE,EAAE,CAAC,CAAC;IAC5D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8BAA8B,EAAE,GAAG,EAAE;QACtC,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YAC3B,KAAK,EAAE,IAAI;SACZ,CAAC,CAAC,CAAC,YAAY,CAAC,mCAAmC,CAAC,CAAC;QACtD,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YAC3B,KAAK,EAAE,CAAC;SACT,CAAC,CAAC,CAAC,YAAY,CAAC,+BAA+B,CAAC,CAAC;QAClD,MAAM,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YAC3B,KAAK,EAAE,CAAC,EAAE;SACX,CAAC,CAAC,CAAC,YAAY,CAAC,iCAAiC,CAAC,CAAC;IACtD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,qBAAqB,CAAC,aAAa,EAAE,GAAG,EAAE;IACxC,QAAQ;IACR,4EAA4E;IAC5E,oEAAoE;IACpE,yDAAyD;IACzD,EAAE;IACF,YAAY;IACZ,qBAAqB;IACrB,0BAA0B;IAC1B,EAAE;IACF,YAAY;IACZ,iBAAiB;IACjB,iBAAiB;IACjB,iBAAiB;IACjB,EAAE;IACF,6BAA6B;IAC7B,uCAAuC;IACvC,2DAA2D;IAC3D,8DAA8D;IAC9D,yDAAyD;IACzD,uDAAuD;IACvD,mDAAmD;IACnD,uDAAuD;IACvD,wEAAwE;IACxE,2BAA2B;IAC3B,EAAE;IACF,gDAAgD;IAChD,gEAAgE;IAChE,8DAA8D;IAC9D,MAAM;IAEN,MAAM,KAAK,GAAG,CAAC,CAAC;IAChB,MAAM,SAAS,GAAG,CAAC,CAAC;IACpB,MAAM,SAAS,GAAG,CAAC,CAAC;IACpB,MAAM,SAAS,GAAG,CAAC,CAAC;IAEpB,4EAA4E;IAC5E,+BAA+B;IAE/B,MAAM,QAAQ,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;IAC5B,MAAM,SAAS,GAAG,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IAChC,KAAK,MAAM,QAAQ,IAAI,SAAS,EAAE;QAChC,KAAK,MAAM,OAAO,IAAI,QAAQ,EAAE;YAC9B,MAAM,SAAS,GACX,yDAAyD;gBACzD,IAAI,QAAQ,aAAa,OAAO,EAAE,CAAC;YACvC,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;gBACjB,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;oBAC3B,KAAK;oBACL,iBAAiB,EAAE,MAAM;oBACzB,oBAAoB,EAAE,MAAM;oBAC5B,eAAe,EAAE,MAAM;oBACvB,OAAO;oBACP,cAAc,EAAE,CAAC;iBAClB,CAAC,CAAC;gBACH,MAAM,MAAM,GAAW,EAAE,CAAC;gBAC1B,IAAI,QAAQ,EAAE;oBACZ,MAAM,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC;iBAC3B;gBACD,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;gBAC1D,KAAK,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC;gBACxC,IAAI,UAAU,GAAG,CAAC,CAAC;gBACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;oBAC1B,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,EAAE,MAAM,CAAW,CAAC,CAAC;oBACjD,IAAI,OAAO,KAAK,GAAG,IAAI,QAAQ,EAAE;wBAC/B,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;qBACxD;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,CAAC,CAAC;qBAC9C;oBACD,IAAI,CAAC,KAAK,CAAC,EAAE;wBACX,UAAU,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;qBACtC;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;qBACrD;iBACF;YACH,CAAC,CAAC,CAAC;SACJ;KACF;IAED,MAAM,iBAAiB,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;IACrC,KAAK,MAAM,QAAQ,IAAI,SAAS,EAAE;QAChC,KAAK,MAAM,gBAAgB,IAAI,iBAAiB,EAAE;YAChD,MAAM,SAAS,GACX,yDAAyD;gBACzD,IAAI,QAAQ,sBAAsB,gBAAgB,EAAE,CAAC;YACzD,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;gBACjB,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;oBAC3B,KAAK;oBACL,iBAAiB,EAAE,MAAM;oBACzB,oBAAoB,EAAE,MAAM;oBAC5B,eAAe,EAAE,MAAM;oBACvB,gBAAgB;oBAChB,cAAc,EAAE,CAAC;iBAClB,CAAC,CAAC;gBACH,MAAM,MAAM,GAAW,EAAE,CAAC;gBAC1B,IAAI,QAAQ,EAAE;oBACZ,MAAM,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC;iBAC3B;gBACD,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;gBAC1D,KAAK,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC,GAAG,CAAC,WAAW,EAAE,CAAC;gBACxC,IAAI,UAAU,GAAG,CAAC,CAAC;gBACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE;oBAC1B,GAAG,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,EAAE,MAAM,CAAW,CAAC,CAAC;oBACjD,IAAI,gBAAgB,KAAK,GAAG,IAAI,QAAQ,EAAE;wBACxC,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;qBACxD;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,qBAAqB,CAAC,CAAC,CAAC,CAAC;qBAC9C;oBACD,IAAI,CAAC,KAAK,CAAC,EAAE;wBACX,UAAU,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;qBACtC;yBAAM;wBACL,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;qBACrD;iBACF;YACH,CAAC,CAAC,CAAC;SACJ;KACF;IAED,MAAM,eAAe,GAAmB,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;IAC/C,MAAM,iBAAiB,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;IACxC,MAAM,qBAAqB,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,CAAC;IAC5C,KAAK,MAAM,cAAc,IAAI,eAAe,EAAE;QAC5C,KAAK,MAAM,WAAW,IAAI,iBAAiB,EAAE;YAC3C,KAAK,MAAM,eAAe,IAAI,qBAAqB,EAAE;gBACnD,MAAM,SAAS,GAAG,kBAAkB,cAAc,IAAI;oBAClD,mBAAmB,eAAe,IAAI;oBACtC,eAAe,WAAW,EAAE,CAAC;gBACjC,EAAE,CAAC,SAAS,EAAE,GAAG,EAAE;oBACjB,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;wBAC3B,KAAK;wBACL,iBAAiB,EAAE,MAAM;wBACzB,oBAAoB,EAAE,MAAM;wBAC5B,eAAe,EAAE,MAAM;wBACvB,WAAW;wBACX,eAAe;wBACf,cAAc;qBACf,CAAC,CAAC;oBACH,MAAM,KAAK,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;oBAC1D,IAAI,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;oBAE/B,gEAAgE;oBAChE,gDAAgD;oBAChD,MAAM,4BAA4B,GAAG,SAAS,CAAC;oBAC/C,MAAM,4BAA4B,GAAG,UAAU,CAAC;oBAChD,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;oBAC9D,MAAM,wBAAwB,GAAG,UAAU,CAAC;oBAE5C,IAAI,cAAsB,CAAC;oBAC3B,IAAI,eAAe,EAAE;wBACnB,MAAM,UAAU,GAAG,GAAG,CAAC,GAAG,CACtB,MAAM,CAAC,4BAA4B,CAAC,EACpC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;wBACrC,MAAM,UAAU,GAAG,GAAG,CAAC,GAAG,CACtB,MAAM,CAAC,4BAA4B,CAAC,EACpC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;wBACrC,cAAc,GAAG,GAAG,CAAC,SAAS,CAC1B,CAAC,CAAC,oBAAoB,CAAC,UAAU,EAAE,UAAU,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;qBAChE;yBAAM;wBACL,cAAc,GAAG,GAAG,CAAC,GAAG,CACpB,MAAM,CAAC,4BAA4B,CAAC,EACpC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC;qBACnC;oBACD,IAAI,WAAW,EAAE;wBACf,MAAM,GAAG,MAAkB,CAAC;wBAC5B,MAAM,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;wBACjC,kBAAkB,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,cAAc,CAAC,CAAC;wBAC9C,kBAAkB,CACd,MAAM,CAAC,CAAC,CAAC,EACT,GAAG,CAAC,GAAG,CACH,MAAM,CAAC,wBAAwB,CAAC,EAChC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;wBACvC,kBAAkB,CACd,MAAM,CAAC,CAAC,CAAC,EACT,GAAG,CAAC,GAAG,CACH,MAAM,CAAC,wBAAwB,CAAC,EAChC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;qBACxC;yBAAM;wBACL,MAAM,GAAG,MAAgB,CAAC;wBAC1B,kBAAkB,CAAC,MAAM,EAAE,cAAc,CAAC,CAAC;qBAC5C;gBACH,CAAC,CAAC,CAAC;aACJ;SACF;QAED,gEAAgE;QAChE,YAAY;QACZ,eAAe;QACf,qBAAqB;QACrB,EAAE;QACF,YAAY;QACZ,iBAAiB;QACjB,iBAAiB;QACjB,sBAAsB;QACtB,EAAE;QACF,iCAAiC;QACjC,qDAAqD;QACrD,wDAAwD;QACxD,mDAAmD;QACnD,yCAAyC;QACzC,yDAAyD;QACzD,8DAA8D;QAC9D,0DAA0D;QAC1D,EAAE;QACF,yDAAyD;QACzD,EAAE;QACF,6BAA6B;QAC7B,iBAAiB;QACjB,0BAA0B;QAC1B,0BAA0B;QAC1B,uBAAuB;QACvB,0BAA0B;QAC1B,0BAA0B;QAC1B,MAAM;QACN,EAAE,CAAC,kBAAkB,EAAE,KAAK,IAAI,EAAE;YAChC,MAAM,cAAc,GAAG,CAAC,CAAC;YACzB,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;gBAC1B,KAAK;gBACL,iBAAiB,EAAE,MAAM;gBACzB,oBAAoB,EAAE,MAAM;gBAC5B,eAAe,EAAE,MAAM;gBACvB,QAAQ,EAAE,IAAI;gBACd,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;aACxD,CAAC,CAAC;YACH,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;YAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;YACf,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;YAE3D,IAAI,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;YACpC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC5B,IAAI,UAAU,GACV,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YACxE,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YACnC,IAAI,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;YACpC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC5B,uDAAuD;YACvD,MAAM,CAAC,EAAE,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAClC,IAAI,UAAU,GAAG,GAAG,CAAC,IAAI,CACrB,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YACpE,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YAEnC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;YAC9C,KAAK,CAAC,WAAW,EAAE,CAAC;YACpB,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;YAE5C,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;YAChC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC5B,UAAU;gBACN,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YACxE,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YACnC,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,CAAW,CAAC;YAChC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAC5B,uDAAuD;YACvD,MAAM,CAAC,EAAE,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YAClC,UAAU,GAAG,GAAG,CAAC,IAAI,CACjB,GAAG,EAAE,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;YACpE,kBAAkB,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YACnC,GAAG,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;YAC9C,kEAAkE;YAClE,MAAM,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACvD,CAAC,CAAC,CAAC;QAEH,wEAAwE;QACxE,YAAY;QACZ,eAAe;QACf,qBAAqB;QACrB,EAAE;QACF,iBAAiB;QACjB,sBAAsB;QACtB,iBAAiB;QACjB,EAAE;QACF,6BAA6B;QAC7B,+BAA+B;QAC/B,SAAS;QACT,mEAAmE;QACnE,iCAAiC;QACjC,oCAAoC;QACpC,+BAA+B;QAC/B,sBAAsB;QACtB,kCAAkC;QAClC,0DAA0D;QAC1D,gDAAgD;QAChD,4DAA4D;QAC5D,EAAE;QACF,4DAA4D;QAC5D,4DAA4D;QAC5D,uCAAuC;QACvC,0DAA0D;QAC1D,EAAE;QACF,oEAAoE;QACpE,yBAAyB;QACzB,MAAM;QACN,EAAE,CAAC,eAAe,EAAE,KAAK,IAAI,EAAE;YAC7B,MAAM,cAAc,GAAG,CAAC,CAAC;YACzB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;YAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;gBACxB,KAAK;gBACL,iBAAiB,EAAE,MAAM;gBACzB,oBAAoB,EAAE,MAAM;gBAC5B,eAAe,EAAE,MAAM;gBACvB,QAAQ,EAAE,IAAI;gBACd,eAAe,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC;aACxD,CAAC,CAAC,CAAC;YACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC,CAAC;YAC5D,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;YAE5D,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;YAC7D,MAAM,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;YAC7D,MAAM,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC;YACrC,MAAM,EAAE,GAAG,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YAElE,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,SAAS,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC,CAAC;YACrE,sEAAsE;YACtE,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;QACtD,CAAC,CAAC,CAAC;QAEH,EAAE,CAAC,MAAM,EAAE,KAAK,IAAI,EAAE;YACpB,qEAAqE;YACrE,+BAA+B;YAC/B,YAAY;YACZ,eAAe;YACf,qBAAqB;YACrB,EAAE;YACF,sBAAsB;YACtB,iBAAiB;YACjB,iBAAiB;YACjB,EAAE;YACF,uDAAuD;YACvD,8BAA8B;YAC9B,uDAAuD;YACvD,0DAA0D;YAC1D,2CAA2C;YAC3C,gCAAgC;YAChC,wDAAwD;YACxD,6CAA6C;YAC7C,gCAAgC;YAChC,uCAAuC;YACvC,sCAAsC;YACtC,gEAAgE;YAChE,EAAE;YACF,yDAAyD;YACzD,+BAA+B;YAC/B,mDAAmD;YACnD,+BAA+B;YAC/B,+BAA+B;YAC/B,gCAAgC;YAChC,MAAM;YACN,MAAM,cAAc,GAAG,CAAC,CAAC;YACzB,MAAM,SAAS,GAAG,CAAC,CAAC;YACpB,MAAM,SAAS,GAAG,CAAC,CAAC;YACpB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;YAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;gBACxB,KAAK,EAAE,CAAC;gBACR,iBAAiB,EAAE,OAAO;gBAC1B,oBAAoB,EAAE,OAAO;gBAC7B,OAAO,EAAE,KAAK;gBACd,UAAU,EAAE,CAAC,cAAc,EAAE,SAAS,CAAC;aACxC,CAAC,CAAC,CAAC;YACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CAAC;gBACzB,KAAK,EAAE,CAAC;gBACR,iBAAiB,EAAE,MAAM;gBACzB,OAAO,EAAE,KAAK;aACf,CAAC,CAAC,CAAC;YAEJ,MAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;YAC7B,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,GAAG,EAAC,CAAC,CAAC;YAE1D,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,cAAc,EAAE,SAAS,CAAC,CAAC,CAAC;YAC3D,MAAM,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;YACnC,MAAM,KAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,MAAM,EAAE,CAAC,EAAC,CAAC,CAAC;YAEnC,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,CAAC,CAAC,IAAI,CACF,QAAQ,CACJ,CAAC,CAAC,UAAU,EAAE,UAAU,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAC9D,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YACjB,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAC/B,QAAQ,CAAC,CAAC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YAC1E,kBAAkB,CACd,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACxE,CAAC,CAAC,CAAC;KACJ;IAED,yBAAyB;IACzB,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,6BAA6B;IAC7B,uCAAuC;IACvC,sCAAsC;IACtC,mDAAmD;IACnD,mDAAmD;IACnD,mEAAmE;IACnE,iCAAiC;IACjC,4DAA4D;IAC5D,yDAAyD;IACzD,yDAAyD;IACzD,kCAAkC;IAClC,0DAA0D;IAC1D,yDAAyD;IACzD,EAAE;IACF,qCAAqC;IACrC,qCAAqC;IACrC,qCAAqC;IACrC,sCAAsC;IACtC,yBAAyB;IACzB,YAAY;IACZ,MAAM;IACN,EAAE,CAAC,WAAW,EAAE,GAAG,EAAE;QACnB,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC7B,QAAQ,EAAE,EAAE;YACZ,SAAS,EAAE,CAAC;YACZ,WAAW,EAAE,CAAC;YACd,QAAQ,EAAE,IAAI;YACd,qBAAqB,EAAE,MAAM;SAC9B,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YACxB,KAAK,EAAE,CAAC;YACR,oBAAoB,EAAE,MAAM;YAC5B,iBAAiB,EAAE,MAAM;YACzB,eAAe,EAAE,OAAO;SACzB,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,eAAe,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;QAEtE,MAAM,EAAE,GAAG,QAAQ,CAAC;YAClB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;YAC1D,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;SACnB,CAAC,CAAC;QACH,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QACvC,kBAAkB,CACd,EAAE,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,EAAE,CAAC,QAAQ,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;IAChE,CAAC,CAAC,CAAC;IAEH,yBAAyB;IACzB,QAAQ;IACR,eAAe;IACf,EAAE;IACF,6BAA6B;IAC7B,8CAA8C;IAC9C,8CAA8C;IAC9C,2DAA2D;IAC3D,2DAA2D;IAC3D,6BAA6B;IAC7B,uDAAuD;IACvD,wBAAwB;IACxB,kCAAkC;IAClC,0DAA0D;IAC1D,yDAAyD;IACzD,EAAE;IACF,gCAAgC;IAChC,uEAAuE;IACvE,kCAAkC;IAClC,2BAA2B;IAC3B,0CAA0C;IAC1C,oDAAoD;IACpD,0CAA0C;IAC1C,oDAAoD;IACpD,2CAA2C;IAC3C,EAAE;IACF,4BAA4B;IAC5B,4BAA4B;IAC5B,4BAA4B;IAC5B,6BAA6B;IAC7B,yBAAyB;IACzB,YAAY;IACZ,MAAM;IACN,EAAE,CAAC,+BAA+B,EAAE,GAAG,EAAE;QACvC,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,MAAM,cAAc,GAAG,GAAG,CAAC,MAAM,CAAC,SAAS,CACvC,EAAC,QAAQ,EAAE,CAAC,EAAE,SAAS,EAAE,CAAC,EAAE,WAAW,EAAE,CAAC,EAAE,QAAQ,EAAE,IAAI,EAAC,CAAC,CAAC;QACjE,KAAK,CAAC,GAAG,CAAC,cAAc,CAAC,CAAC;QAC1B,MAAM,SAAS,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,WAAW,EAAE,IAAI,EAAC,CAAC,CAAC;QACjE,KAAK,CAAC,GAAG,CAAC,SAAS,CAAC,CAAC;QACrB,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,eAAe,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;QAEtE,wEAAwE;QACxE,YAAY;QACZ,cAAc,CAAC,UAAU,CACrB,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtE,SAAS,CAAC,UAAU,CAAC;YACnB,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YACtE,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YACtE,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;SACnC,CAAC,CAAC;QAEH,MAAM,EAAE,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAClE,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QACvC,kBAAkB,CACd,EAAE,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,SAAS,CAAC,EAAE,CAAC,SAAS,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;IAClE,CAAC,CAAC,CAAC;IAEH,yBAAyB;IACzB,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,6BAA6B;IAC7B,qEAAqE;IACrE,oCAAoC;IACpC,8CAA8C;IAC9C,6CAA6C;IAC7C,0DAA0D;IAC1D,0DAA0D;IAC1D,0EAA0E;IAC1E,wCAAwC;IACxC,mEAAmE;IACnE,gEAAgE;IAChE,gEAAgE;IAChE,0BAA0B;IAC1B,kCAAkC;IAClC,0DAA0D;IAC1D,yDAAyD;IACzD,4DAA4D;IAC5D,EAAE;IACF,qCAAqC;IACrC,oCAAoC;IACpC,oCAAoC;IACpC,qCAAqC;IACrC,yBAAyB;IACzB,YAAY;IACZ,MAAM;IACN,EAAE,CAAC,8BAA8B,EAAE,GAAG,EAAE;QACtC,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,OAAO,CACxB,EAAC,WAAW,EAAE,CAAC,CAAC,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC,CAAC,CAAE,uBAAuB;QACnE,MAAM,WAAW,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QACrC,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YACnC,QAAQ,EAAE,EAAE;YACZ,SAAS,EAAE,CAAC;YACZ,WAAW,EAAE,CAAC;YACd,QAAQ,EAAE,IAAI;YACd,qBAAqB,EAAE,MAAM;SAC9B,CAAC,CAAC,CAAC;QACJ,WAAW,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YAC9B,KAAK,EAAE,CAAC;YACR,oBAAoB,EAAE,MAAM;YAC5B,iBAAiB,EAAE,MAAM;YACzB,eAAe,EAAE,OAAO;SACzB,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,WAAW,CAAC,CAAC;QACvB,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,eAAe,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;QAEtE,MAAM,EAAE,GAAG,QAAQ,CAAC;YAClB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;YAC1D,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;SACnB,CAAC,CAAC;QACH,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QACvC,kBAAkB,CACd,EAAE,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,QAAQ,CAAC,EAAE,CAAC,QAAQ,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC;IAChE,CAAC,CAAC,CAAC;IAEH,yBAAyB;IACzB,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,6BAA6B;IAC7B,uCAAuC;IACvC,sCAAsC;IACtC,mDAAmD;IACnD,mDAAmD;IACnD,kEAAkE;IAClE,iCAAiC;IACjC,4DAA4D;IAC5D,yDAAyD;IACzD,yDAAyD;IACzD,kCAAkC;IAClC,yDAAyD;IACzD,wDAAwD;IACxD,4DAA4D;IAC5D,EAAE;IACF,qCAAqC;IACrC,oCAAoC;IACpC,oCAAoC;IACpC,qCAAqC;IACrC,sCAAsC;IACtC,EAAE;IACF,4CAA4C;IAC5C,sDAAsD;IACtD,yBAAyB;IACzB,MAAM;IACN,EAAE,CAAC,yCAAyC,EAAE,KAAK,IAAI,EAAE;QACvD,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC7B,QAAQ,EAAE,EAAE;YACZ,SAAS,EAAE,CAAC;YACZ,WAAW,EAAE,CAAC;YACd,QAAQ,EAAE,IAAI;YACd,qBAAqB,EAAE,MAAM;SAC9B,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YACxB,KAAK,EAAE,CAAC;YACR,oBAAoB,EAAE,MAAM;YAC5B,iBAAiB,EAAE,MAAM;YACzB,eAAe,EAAE,OAAO;SACzB,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,eAAe,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;QACtE,KAAK,CAAC,OAAO,CAAC,EAAC,IAAI,EAAE,kBAAkB,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC,CAAC;QAE5D,MAAM,EAAE,GAAG,QAAQ,CAAC;YAClB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;YAC1D,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;SACnB,CAAC,CAAC;QACH,MAAM,EAAE,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAE1C,iEAAiE;QACjE,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,CAAC,EAAE,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;QAEnD,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,OAAO,GAAG,MAAM,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,EAAC,MAAM,EAAE,CAAC,EAAE,SAAS,EAAE,CAAC,EAAC,CAAC,CAAC;QACnE,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,yBAAyB;QACzB,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;QACtD,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEH,yBAAyB;IACzB,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,+BAA+B;IAC/B,iCAAiC;IACjC,gCAAgC;IAChC,6CAA6C;IAC7C,6CAA6C;IAC7C,iEAAiE;IACjE,2BAA2B;IAC3B,2CAA2C;IAC3C,sDAAsD;IACtD,mDAAmD;IACnD,qDAAqD;IACrD,EAAE;IACF,6CAA6C;IAC7C,EAAE;IACF,qCAAqC;IACrC,qCAAqC;IACrC,qCAAqC;IACrC,sCAAsC;IACtC,yBAAyB;IACzB,YAAY;IACZ,MAAM;IACN,EAAE,CAAC,gCAAgC,EAAE,GAAG,EAAE;QACxC,MAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAC,CAAC,CAAC;QACpC,IAAI,CAAC,GACD,GAAG,CAAC,MAAM;aACL,SAAS,CAAC;YACT,QAAQ,EAAE,EAAE;YACZ,SAAS,EAAE,CAAC;YACZ,WAAW,EAAE,CAAC;YACd,QAAQ,EAAE,IAAI;YACd,qBAAqB,EAAE,MAAM;SAC9B,CAAC;aACD,KAAK,CAAC,GAAG,CAAuB,CAAC;QAC1C,CAAC,GAAG,GAAG,CAAC,MAAM;aACL,IAAI,CAAC;YACJ,KAAK,EAAE,CAAC;YACR,WAAW,EAAE,IAAI;YACjB,oBAAoB,EAAE,MAAM;YAC5B,iBAAiB,EAAE,MAAM;YACzB,eAAe,EAAE,OAAO;SACzB,CAAC;aACD,KAAK,CAAC,CAAC,CAAyB,CAAC;QAC1C,MAAM,KAAK,GAAG,GAAG,CAAC,KAAK,CAAC,EAAC,MAAM,EAAE,GAAG,EAAE,OAAO,EAAE,CAAC,EAAC,CAAC,CAAC;QACnD,MAAM,EAAE,GAAG,QAAQ,CAAC;YAClB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;YAC1D,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;SACnB,CAAC,CAAC;QACH,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAa,CAAC;QACzC,MAAM,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC7B,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC;YACd,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC;YAC/C,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;YACjC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC;SACrC,CAAC,CAAC,CAAC;QACvB,kBAAkB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC;YACd,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC;YAC/C,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;YACjC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC;SACrC,CAAC,CAAC,CAAC;QACvB,kBAAkB,CACd,EAAE,CAAC,CAAC,CAAC,EAAE,QAAQ,CAAC;YACd,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;YAC5C,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC,EAAE,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;SACrE,CAAC,CAAC,CAAC;IACV,CAAC,CAAC,CAAC;IAEH,0BAA0B;IAC1B,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,6BAA6B;IAC7B,uCAAuC;IACvC,qCAAqC;IACrC,kDAAkD;IAClD,kDAAkD;IAClD,kEAAkE;IAClE,iCAAiC;IACjC,qDAAqD;IACrD,4DAA4D;IAC5D,yDAAyD;IACzD,yDAAyD;IACzD,kCAAkC;IAClC,yDAAyD;IACzD,yDAAyD;IACzD,EAAE;IACF,4BAA4B;IAC5B,2BAA2B;IAC3B,2BAA2B;IAC3B,4BAA4B;IAC5B,yBAAyB;IACzB,YAAY;IACZ,MAAM;IACN,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;QAC3C,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC7B,QAAQ,EAAE,EAAE;YACZ,SAAS,EAAE,CAAC;YACZ,WAAW,EAAE,CAAC;YACd,QAAQ,EAAE,IAAI;YACd,qBAAqB,EAAE,MAAM;SAC9B,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YACxB,KAAK,EAAE,CAAC;YACR,eAAe,EAAE,IAAI;YACrB,oBAAoB,EAAE,MAAM;YAC5B,iBAAiB,EAAE,MAAM;YACzB,eAAe,EAAE,OAAO;SACzB,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,eAAe,EAAE,OAAO,EAAC,CAAC,CAAC,CAAC;QAEtE,MAAM,EAAE,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAClE,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QACvC,kBAAkB,CAAC,EAAE,EAAE,QAAQ,CAAC;YACX,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,QAAQ,CAAC,EAAE,CAAC,QAAQ,CAAC,EAAE,CAAC,QAAQ,CAAC,CAAC;YACrD,CAAC,CAAC,QAAQ,CAAC,EAAE,CAAC,SAAS,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC;YACtC,CAAC,CAAC,QAAQ,CAAC,EAAE,CAAC,SAAS,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC;SACvC,CAAC,CAAC,CAAC;IACzB,CAAC,CAAC,CAAC;IAEH,yBAAyB;IACzB,QAAQ;IACR,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,6BAA6B;IAC7B,uCAAuC;IACvC,sCAAsC;IACtC,mDAAmD;IACnD,mDAAmD;IACnD,mEAAmE;IACnE,sCAAsC;IACtC,0DAA0D;IAC1D,iEAAiE;IACjE,8DAA8D;IAC9D,8DAA8D;IAC9D,iCAAiC;IACjC,4DAA4D;IAC5D,yDAAyD;IACzD,yDAAyD;IACzD,EAAE;IACF,4BAA4B;IAC5B,4BAA4B;IAC5B,4BAA4B;IAC5B,6BAA6B;IAC7B,yBAAyB;IACzB,YAAY;IACZ,MAAM;IACN,EAAE,CAAC,oDAAoD,EAAE,GAAG,EAAE;QAC5D,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC7B,QAAQ,EAAE,EAAE;YACZ,SAAS,EAAE,CAAC;YACZ,WAAW,EAAE,CAAC;YACd,QAAQ,EAAE,IAAI;YACd,qBAAqB,EAAE,MAAM;SAC9B,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,SAAS,CAAC;YAC7B,KAAK,EAAE,CAAC;YACR,eAAe,EAAE,IAAI;YACrB,oBAAoB,EAAE,MAAM;YAC5B,iBAAiB,EAAE,MAAM;YACzB,eAAe,EAAE,OAAO;SACzB,CAAC,CAAC,CAAC;QACJ,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;YACxB,KAAK,EAAE,CAAC;YACR,oBAAoB,EAAE,MAAM;YAC5B,iBAAiB,EAAE,MAAM;YACzB,eAAe,EAAE,OAAO;SACzB,CAAC,CAAC,CAAC;QAEJ,MAAM,EAAE,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAElE,iDAAiD;QACjD,KAAK,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAElB,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QACvC,MAAM,WAAW,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,UAAU,CAAC;QAC5C,kBAAkB,CAAC,EAAE,EAAE,QAAQ,CAAC;YACX,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC;YAC/C,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC;YACpC,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;SAClC,CAAC,CAAC,CAAC;QACvB,EAAE,CAAC,OAAO,EAAE,CAAC;QACb,yBAAyB;QACzB,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,WAAW,GAAG,CAAC,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,sBAAsB,EAAE,GAAG,EAAE;IAC3C,EAAE,CAAC,iBAAiB,EAAE,KAAK,IAAI,EAAE;QAC/B,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,aAAa,CAAC,CAAC;QACjD,MAAM,aAAa,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC;QACvD,MAAM,aAAa,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC;QACvD,MAAM,OAAO,GAAG,KAAK,CAAC,OAAO,CAAC,CAAC,aAAa,EAAE,aAAa,CAAC,CAAW,CAAC;QACxE,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;IAC5C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,KAAK,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,CAAC,EAAC,CAAC,CAAC;QAC1C,MAAM,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAW,CAAC;QACnC,MAAM,cAAc,GAAG,mBAAmB,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC;QAC9D,kCAAkC;QAClC,MAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAQ,CAAC;QAC5D,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QAC7C,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAW,CAAC;QACxC,kBAAkB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;QAC9B,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,qBAAqB,CAAC,CAAC;aAChD,OAAO,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,qBAAqB,CAAC,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,MAAM,CAAC,GAAG,YAAY,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,KAAK,GACP,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,mBAAmB,EAAE,MAAM,EAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAW,CAAC;QACnC,MAAM,cAAc,GAAG,mBAAmB,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,CAAC;QAC9D,kCAAkC;QAClC,MAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAQ,CAAC;QAC5D,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QAC7C,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAW,CAAC;QACxC,kBAAkB,CAAC,MAAM,EAAE,CAAC,CAAC,CAAC;QAC9B,MAAM,CAAC,UAAU,CAAC,SAAS,EAAE,CAAC,qBAAqB,CAAC,CAAC;aAChD,OAAO,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC,qBAAqB,CAAC,CAAC,CAAC;IACzD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,MAAM,aAAa,GAA0B;IAC3C,aAAa,EAAE;QACb,YAAY,EAAE,OAAO;QACrB,eAAe,EAAE,OAAO;QACxB,QAAQ,EAAE;YACR,QAAQ,EAAE;gBACR;oBACE,YAAY,EAAE,YAAY;oBAC1B,QAAQ,EAAE;wBACR,OAAO,EAAE,SAAS;wBAClB,mBAAmB,EAAE,CAAC,IAAI,EAAE,IAAI,EAAE,EAAE,CAAC;wBACrC,MAAM,EAAE,SAAS;wBACjB,QAAQ,EAAE,KAAK;qBAChB;oBACD,eAAe,EAAE,EAAE;oBACnB,MAAM,EAAE,SAAS;iBAClB;gBACD;oBACE,YAAY,EAAE,YAAY;oBAC1B,QAAQ,EAAE;wBACR,OAAO,EAAE,SAAS;wBAClB,mBAAmB,EAAE,CAAC,IAAI,EAAE,IAAI,EAAE,EAAE,CAAC;wBACrC,MAAM,EAAE,SAAS;wBACjB,QAAQ,EAAE,KAAK;qBAChB;oBACD,eAAe,EAAE,EAAE;oBACnB,MAAM,EAAE,SAAS;iBAClB;gBACD;oBACE,YAAY,EAAE,MAAM;oBACpB,QAAQ,EAAE;wBACR,sBAAsB,EAAE,cAAc;wBACtC,WAAW,EAAE,IAAI;wBACjB,uBAAuB,EAAE;4BACvB,YAAY,EAAE,iBAAiB;4BAC/B,QAAQ,EAAE;gCACR,cAAc,EAAE,SAAS;gCACzB,OAAO,EAAE,GAAG;gCACZ,MAAM,EAAE,IAAI;gCACZ,MAAM,EAAE,SAAS;6BAClB;yBACF;wBACD,UAAU,EAAE,IAAI;wBAChB,kBAAkB,EAAE,IAAI;wBACxB,cAAc,EAAE,IAAI;wBACpB,QAAQ,EAAE,KAAK;wBACf,YAAY,EAAE,MAAM;wBACpB,kBAAkB,EAAE,EAAC,YAAY,EAAE,OAAO,EAAE,QAAQ,EAAE,EAAE,EAAC;wBACzD,OAAO,EAAE,GAAG;wBACZ,kBAAkB,EAAE,IAAI;wBACxB,sBAAsB,EAAE,IAAI;wBAC5B,mBAAmB,EAAE,GAAG;wBACxB,oBAAoB,EAAE;4BACpB,YAAY,EAAE,iBAAiB;4BAC/B,QAAQ,EAAE;gCACR,cAAc,EAAE,SAAS;gCACzB,OAAO,EAAE,GAAG;gCACZ,MAAM,EAAE,IAAI;gCACZ,MAAM,EAAE,SAAS;6BAClB;yBACF;wBACD,mBAAmB,EAAE,IAAI;wBACzB,SAAS,EAAE,GAAG;wBACd,UAAU,EAAE,KAAK;wBACjB,uBAAuB,EAAE,IAAI;wBAC7B,MAAM,EAAE,QAAQ;wBAChB,iBAAiB,EAAE,IAAI;wBACvB,cAAc,EAAE,KAAK;wBACrB,gBAAgB,EAAE,CAAC;wBACnB,oBAAoB,EAAE,IAAI;wBAC1B,kBAAkB,EAAE,KAAK;wBACzB,sBAAsB,EAAE,IAAI;qBAC7B;oBACD,eAAe,EAAE,CAAC,CAAC,CAAC,SAAS,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;oBAC1C,MAAM,EAAE,QAAQ;iBACjB;gBACD;oBACE,YAAY,EAAE,MAAM;oBACpB,QAAQ,EAAE;wBACR,sBAAsB,EAAE,cAAc;wBACtC,WAAW,EAAE,IAAI;wBACjB,uBAAuB,EAAE;4BACvB,YAAY,EAAE,iBAAiB;4BAC/B,QAAQ,EAAE;gCACR,cAAc,EAAE,SAAS;gCACzB,OAAO,EAAE,GAAG;gCACZ,MAAM,EAAE,IAAI;gCACZ,MAAM,EAAE,SAAS;6BAClB;yBACF;wBACD,UAAU,EAAE,IAAI;wBAChB,kBAAkB,EAAE,IAAI;wBACxB,cAAc,EAAE,IAAI;wBACpB,QAAQ,EAAE,KAAK;wBACf,YAAY,EAAE,MAAM;wBACpB,kBAAkB,EAAE,EAAC,YAAY,EAAE,OAAO,EAAE,QAAQ,EAAE,EAAE,EAAC;wBACzD,OAAO,EAAE,GAAG;wBACZ,kBAAkB,EAAE,IAAI;wBACxB,sBAAsB,EAAE,IAAI;wBAC5B,mBAAmB,EAAE,GAAG;wBACxB,oBAAoB,EAAE;4BACpB,YAAY,EAAE,iBAAiB;4BAC/B,QAAQ,EAAE;gCACR,cAAc,EAAE,SAAS;gCACzB,OAAO,EAAE,GAAG;gCACZ,MAAM,EAAE,IAAI;gCACZ,MAAM,EAAE,SAAS;6BAClB;yBACF;wBACD,mBAAmB,EAAE,IAAI;wBACzB,SAAS,EAAE,GAAG;wBACd,UAAU,EAAE,KAAK;wBACjB,uBAAuB,EAAE,IAAI;wBAC7B,MAAM,EAAE,QAAQ;wBAChB,iBAAiB,EAAE,IAAI;wBACvB,cAAc,EAAE,KAAK;wBACrB,gBAAgB,EAAE,CAAC;wBACnB,oBAAoB,EAAE,IAAI;wBAC1B,kBAAkB,EAAE,IAAI;wBACxB,sBAAsB,EAAE,IAAI;qBAC7B;oBACD,eAAe,EAAE;wBACf,CAAC,CAAC,SAAS,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC;qBACpE;oBACD,MAAM,EAAE,QAAQ;iBACjB;gBACD;oBACE,YAAY,EAAE,OAAO;oBACrB,QAAQ,EAAE;wBACR,oBAAoB,EAAE;4BACpB,YAAY,EAAE,iBAAiB;4BAC/B,QAAQ,EAAE;gCACR,cAAc,EAAE,SAAS;gCACzB,OAAO,EAAE,GAAG;gCACZ,MAAM,EAAE,IAAI;gCACZ,MAAM,EAAE,SAAS;6BAClB;yBACF;wBACD,MAAM,EAAE,SAAS;wBACjB,mBAAmB,EAAE,IAAI;wBACzB,kBAAkB,EAAE,IAAI;wBACxB,iBAAiB,EAAE,IAAI;wBACvB,YAAY,EAAE,SAAS;wBACvB,WAAW,EAAE,IAAI;wBACjB,oBAAoB,EAAE,IAAI;wBAC1B,kBAAkB,EAAE,EAAC,YAAY,EAAE,OAAO,EAAE,QAAQ,EAAE,EAAE,EAAC;wBACzD,OAAO,EAAE,EAAE;wBACX,UAAU,EAAE,IAAI;wBAChB,sBAAsB,EAAE,IAAI;qBAC7B;oBACD,eAAe,EAAE,CAAC,CAAC,CAAC,QAAQ,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;oBACzC,MAAM,EAAE,SAAS;iBAClB;aACF;YACD,cAAc,EAAE,CAAC,CAAC,SAAS,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,SAAS,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACtD,eAAe,EAAE,CAAC,CAAC,SAAS,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;YACpC,MAAM,EAAE,SAAS;SAClB;QACD,SAAS,EAAE,YAAY;KACxB;CACF,CAAC;AAEF,eAAe,CAAC,oBAAoB,EAAE,GAAG,EAAE;IACzC,MAAM,UAAU,GAAsB;QACpC,KAAK,EAAE,CAAC;QACR,UAAU,EAAE,MAAM;QAClB,mBAAmB,EAAE,MAAM;QAC3B,OAAO,EAAE,IAAI;QACb,iBAAiB,EAAE,eAAe;QAClC,oBAAoB,EAAE,WAAW;QACjC,eAAe,EAAE,MAAM;QACvB,iBAAiB,EAAE,MAAM;QACzB,oBAAoB,EAAE,MAAM;QAC5B,eAAe,EAAE,MAAM;QACvB,gBAAgB,EAAE,UAAU;QAC5B,mBAAmB,EAAE,UAAU;QAC/B,cAAc,EAAE,QAAQ;QACxB,OAAO,EAAE,GAAG;QACZ,gBAAgB,EAAE,GAAG;QACrB,IAAI,EAAE,QAAQ;QACd,SAAS,EAAE,EAAE;QACb,eAAe,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;QAC3B,UAAU,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC;QAClB,KAAK,EAAE,OAAO;QACd,UAAU,EAAE,OAAO;QACnB,SAAS,EAAE,IAAI;QACf,cAAc,EAAE,CAAC;QACjB,cAAc,EAAE,IAAI;KACrB,CAAC;IAEF,MAAM,uBAAuB,GAAG;QAC9B,IAAI,EAAE,QAAQ;QACd,SAAS,EAAE,IAAI;QACf,eAAe,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;QAC3B,KAAK,EAAE,OAAO;QACd,KAAK,EAAE,CAAC;QACR,UAAU,EAAE,mBAAmB,CAAC,IAAI,IAAI,EAAE,CAAC;QAC3C,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,IAAI,EAAE,CAAC;QACpD,OAAO,EAAE,IAAI;QACb,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,aAAa,EAAE,CAAC;QAC5D,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,SAAS,EAAE,CAAC;QAC3D,eAAe,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACjD,iBAAiB,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACnD,oBAAoB,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACtD,eAAe,EAAE,oBAAoB,CAAC,IAAI,IAAI,EAAE,CAAC;QACjD,mBAAmB,EAAE,oBAAoB,CAAC,IAAI,CAAC;QAC/C,gBAAgB,EAAE,mBAAmB,CAAC,IAAI,QAAQ,CAAC,EAAE,CAAC,CAAC;QACvD,mBAAmB,EAAE,mBAAmB,CAAC,IAAI,QAAQ,CAAC,EAAE,CAAC,CAAC;QAC1D,cAAc,EAAE,mBAAmB,CAAC,IAAI,MAAM,EAAE,CAAC;QACjD,cAAc,EAAE,CAAC;QACjB,cAAc,EAAE,IAAI;KACrB,CAAC;IAEF,QAAQ,CAAC,oBAAoB,EAAE,GAAG,EAAE;QAClC,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;YAC3C,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,QAAQ,CAAC,UAAU,CAAC,CAAC;YAE7C,MAAM,qBAA8D,EAA9D,EAAC,OAAO,EAAE,gBAAgB,OAAoC,EAAlC,yDAAkC,CAAC;YAErE,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC,uBAAuB,CAAC,CAAC;YACrD,MAAM,CAAC,OAAO,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;YACjC,MAAM,CAAC,gBAAgB,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAC5C,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,QAAQ,CAAC,gBAAgB,EAAE,GAAG,EAAE;QAC9B,EAAE,CAAC,mCAAmC,EAAE,GAAG,EAAE;YAC3C,MAAM,MAAM,qBACP,UAAU,IACb,IAAI,EAAE,SAAS,IACZ;gBACD,eAAe,EAAE,IAAI;gBACrB,WAAW,EAAE,IAAI;gBACjB,QAAQ,EAAE,IAAI;gBACd,MAAM,EAAE,IAAI;gBACZ,WAAW,EAAE,IAAI;gBACjB,QAAQ,EAAE,CAAC;gBACX,WAAW,EAAE,CAAC;aACiC,CAClD,CAAC;YAEF,MAAM,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YAErC,MAAM,qBAA8D,EAA9D,EAAC,OAAO,EAAE,gBAAgB,OAAoC,EAAlC,yDAAkC,CAAC;YAErE,MAAM,CAAC,WAAW,CAAC,CAAC,OAAO,mBACtB,uBAAuB,IAC1B,IAAI,EAAE,SAAS,EACf,eAAe,EAAE,IAAI,EACrB,WAAW,EAAE,IAAI,EACjB,QAAQ,EAAE,IAAI,EACd,MAAM,EAAE,IAAI,EACZ,WAAW,EAAE,IAAI,IACjB,CAAC;YACH,MAAM,CAAC,OAAO,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;YACjC,MAAM,CAAC,gBAAgB,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAC5C,CAAC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,0BAA0B,EAAE,GAAG,EAAE;IAC/C,EAAE,CAAC,oBAAoB,EAAE,GAAG,EAAE;QAC5B,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YAChC,IAAI,EAAE,GAAG,CAAC,MAAM,CAAC,eAAe,CAAC;gBAC/B,KAAK,EAAE;oBACL,GAAG,CAAC,MAAM,CAAC,aAAa,CACpB,EAAC,KAAK,EAAE,CAAC,EAAE,oBAAoB,EAAE,cAAc,EAAC,CAAC;oBACrD,GAAG,CAAC,MAAM,CAAC,aAAa,CACpB,EAAC,KAAK,EAAE,CAAC,EAAE,oBAAoB,EAAE,cAAc,EAAC,CAAC;iBACtD;aACF,CAAC;SACH,CAAC,CAAC;QACH,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,UAAU,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QAC7D,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAEtC,sCAAsC;QACtC,MAAM,CAAC,UAAU,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,CAAC,UAAU,CAAC,mBAAmB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACzD,iDAAiD;QACjD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtD,iDAAiD;QACjD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,eAAe,EAAE,GAAG,EAAE;QACvB,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YAChC,IAAI,EAAE,GAAG,CAAC,MAAM,CAAC,eAAe,CAAC;gBAC/B,KAAK,EAAE;oBACL,GAAG,CAAC,MAAM,CAAC,QAAQ,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,oBAAoB,EAAE,cAAc,EAAC,CAAC;oBACrE,GAAG,CAAC,MAAM,CAAC,QAAQ,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,oBAAoB,EAAE,cAAc,EAAC,CAAC;iBACtE;aACF,CAAC;SACH,CAAC,CAAC;QACH,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,UAAU,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QAC7D,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAEtC,sCAAsC;QACtC,MAAM,CAAC,UAAU,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,CAAC,UAAU,CAAC,mBAAmB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACzD,iDAAiD;QACjD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;QAC1D,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACvD,yDAAyD;QACzD,iDAAiD;QACjD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YAChC,IAAI,EAAE;gBACJ,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,oBAAoB,EAAE,cAAc,EAAC,CAAC;gBACpE,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC,EAAC,KAAK,EAAE,CAAC,EAAE,oBAAoB,EAAE,cAAc,EAAC,CAAC;aACrE;SACF,CAAC,CAAC;QACH,MAAM,KAAK,GACP,IAAI,GAAG,CAAC,cAAc,CAAC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,UAAU,CAAC,KAAK,CAAC,KAAK,CAAuB,CAAC;QAC7D,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;QAEtC,sCAAsC;QACtC,MAAM,CAAC,UAAU,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,CAAC,UAAU,CAAC,mBAAmB,CAAC,MAAM,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;QACzD,iDAAiD;QACjD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtD,yDAAyD;QACzD,iDAAiD;QACjD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACxD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,2BAA2B,EAAE,GAAG,EAAE;IAChD,EAAE,CAAC,iBAAiB,EAAE,KAAK,IAAI,EAAE;QAC/B,MAAM,KAAK,GAAG,GAAG,CAAC,UAAU,EAAE,CAAC;QAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,CACtB,EAAC,KAAK,EAAE,CAAC,EAAE,UAAU,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAC,CAAC,CAAC,CAAC;QAChE,MAAM,KAAK,GAAG;YACZ,GAAG,CAAC,MAAM,CAAC,QAAQ,CACf,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,oBAAoB,EAAE,MAAM,EAAC,CAAC;YACxE,GAAG,CAAC,MAAM,CAAC,QAAQ,CACf,EAAC,KAAK,EAAE,CAAC,EAAE,iBAAiB,EAAE,MAAM,EAAE,oBAAoB,EAAE,MAAM,EAAC,CAAC;SACzE,CAAC;QACF,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,EAAC,IAAI,EAAE,KAAK,EAAE,eAAe,EAAE,IAAI,EAAC,CAAC,CAAC;QACjE,KAAK,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QACf,MAAM,EAAE,GAAG,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QACxC,MAAM,EAAE,GAAG,KAAK,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QAEvC,MAAM,SAAS,GAAG,KAAK,CAAC,MAAM,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;QAC5C,MAAM,UAAU,GACZ,MAAM,GAAG,CAAC,MAAM,CAAC,aAAa,CAAC,EAAC,aAAa,EAAE,SAAS,EAAC,CAAC,CAAC;QAC/D,MAAM,OAAO,GAAG,UAAU,CAAC,OAAO,CAAC,EAAE,CAAW,CAAC;QACjD,kBAAkB,CAAC,OAAO,EAAE,EAAE,CAAC,CAAC;IAClC,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,eAAe,CAAC,wBAAwB,EAAE,GAAG,EAAE;IAC7C,2EAA2E;IAC3E,qBAAqB;IACrB,EAAE;IACF,YAAY;IACZ,eAAe;IACf,qBAAqB;IACrB,EAAE;IACF,kCAAkC;IAClC,QAAQ;IACR,oCAAoC;IACpC,eAAe;IACf,uCAAuC;IACvC,0CAA0C;IAC1C,6BAA6B;IAC7B,8BAA8B;IAC9B,eAAe;IACf,uCAAuC;IACvC,0CAA0C;IAC1C,6BAA6B;IAC7B,+BAA+B;IAC/B,eAAe;IACf,uCAAuC;IACvC,0CAA0C;IAC1C,6BAA6B;IAC7B,SAAS;IACT,EAAE;IACF,sDAAsD;IACtD,kCAAkC;IAClC,uBAAuB;IACvB,wBAAwB;IACxB,EAAE;IACF,yCAAyC;IACzC,EAAE;IACF,yBAAyB;IACzB,QAAQ;IACR,0DAA0D;IAC1D,iCAAiC;IACjC,SAAS;IACT,QAAQ;IACR,8DAA8D;IAC9D,mCAAmC;IACnC,QAAQ;IACR,KAAK;IACL,kCAAkC;IAClC,MAAM;IACN,EAAE,CAAC,cAAc,EAAE,GAAG,EAAE;QACtB,MAAM,UAAU,GAAG,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC;YAChC,IAAI,EAAE,GAAG,CAAC,MAAM,CAAC,eAAe,CAAC;gBAC/B,KAAK,EAAE;oBACL,GAAG,CAAC,MAAM,CAAC,aAAa,CAAC;wBACvB,KAAK,EAAE,CAAC;wBACR,oBAAoB,EAAE,MAAM;wBAC5B,iBAAiB,EAAE,MAAM;wBACzB,OAAO,EAAE,KAAK;qBACf,CAAC;oBACF,GAAG,CAAC,MAAM,CAAC,OAAO,CAAC;wBACjB,KAAK,EAAE,CAAC;wBACR,oBAAoB,EAAE,MAAM;wBAC5B,iBAAiB,EAAE,MAAM;wBACzB,OAAO,EAAE,KAAK;qBACf,CAAC;oBACF,GAAG,CAAC,MAAM,CAAC,QAAQ,CAAC;wBAClB,KAAK,EAAE,CAAC;wBACR,oBAAoB,EAAE,MAAM;wBAC5B,iBAAiB,EAAE,MAAM;wBACzB,OAAO,EAAE,KAAK;qBACf,CAAC;iBACH;aACF,CAAC;SACH,CAAC,CAAC;QACH,MAAM,KAAK,GAAG,QAAQ,CAClB;YACE;gBACE,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;gBAC9C,CAAC,GAAG,EAAE,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC;aACvB;YACD;gBACE,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,GAAG,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,IAAI,EAAE,IAAI,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC;gBAClD,CAAC,IAAI,EAAE,IAAI,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC;aACzB;SACF,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACf,MAAM,MAAM,GAAG,UAAU,CAAC,KAAK,CAAC,KAAK,CAAW,CAAC;QACjD,kBAAkB,CACd,MAAM,EAAE,QAAQ,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC,UAAU,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;IAChE,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Unit tests for recurrent.ts.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {io, randomNormal, scalar, Tensor, tensor1d, tensor2d, tensor3d, tensor4d} from '@tensorflow/tfjs-core';\n\nimport {serializeActivation, Tanh} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {NonNeg, serializeConstraint, UnitNorm} from '../constraints';\nimport * as tfl from '../index';\nimport {GlorotUniform, HeUniform, Ones, serializeInitializer} from '../initializers';\nimport {ActivationIdentifier} from '../keras_format/activation_config';\nimport {ModelAndWeightsConfig, modelFromJSON} from '../models';\nimport {L1L2, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {convertPythonicToTs, convertTsToPythonic} from '../utils/serialization_utils';\nimport {describeMathCPU, describeMathCPUAndGPU, describeMathGPU, expectTensorsClose} from '../utils/test_utils';\n\nimport {GRUCellLayerArgs, GRULayerArgs, LSTMCellLayerArgs, LSTMLayerArgs, rnn, RNN, RNNCell, SimpleRNNCellLayerArgs, SimpleRNNLayerArgs} from './recurrent';\n\n/**\n * A simplistic RNN step function for testing.\n * This step function simply\n * - calculates a reduced mean over all input elements, for each sample.\n * - adds that mean to the state tensor(s),\n * - take the negative of the 1st current state tensor and use it as the\n *   output.\n * @param inputs\n * @param states\n */\nfunction rnnStepForTest(inputs: Tensor, states: Tensor[]): [Tensor, Tensor[]] {\n  const mean = tfc.mean(inputs);\n  const newStates = states.map(state => tfc.add(mean, state));\n  const output = tfc.neg(newStates[0]);\n  return [output, newStates];\n}\n\ndescribeMathCPUAndGPU('rnn', () => {\n  it('Simple step function: 3D inputs, 1 state', () => {\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    const initialStates = [tfc.zeros([2, 4])];\n    const rnnOutputs =\n        rnn(rnnStepForTest, inputs, initialStates, false /* goBackwards */,\n            null /* mask */, null /* constants */, false /* unroll */,\n            true /* needPerStepOutputs */);\n    const lastOutput = rnnOutputs[0];\n    const outputs = rnnOutputs[1];\n    const newStates = rnnOutputs[2];\n    expectTensorsClose(\n        lastOutput,\n        tensor2d(\n            [\n              [-57.75, -57.75, -57.75, -57.75], [-57.75, -57.75, -57.75, -57.75]\n            ],\n            [2, 4]));\n    expectTensorsClose(\n        outputs,\n        tensor3d(\n            [\n              [\n                [-8.25, -8.25, -8.25, -8.25], [-27.5, -27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75, -57.75]\n              ],\n              [\n                [-8.25, -8.25, -8.25, -8.25], [-27.5, -27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75, -57.75]\n              ]\n            ],\n            [2, 3, 4]));\n    expect(newStates.length).toEqual(1);\n    expectTensorsClose(\n        newStates[0],\n        tensor2d(\n            [[57.75, 57.75, 57.75, 57.75], [57.75, 57.75, 57.75, 57.75]],\n            [2, 4]));\n  });\n\n  it('Simple step function: 3D inputs, 2 states', () => {\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    // The two state tensors have different shapes.\n    const initialStates = [tfc.zeros([2, 4]), tfc.ones([2, 3])];\n    const rnnOutputs =\n        rnn(rnnStepForTest, inputs, initialStates, false /* goBackwards */,\n            null /* mask */, null /* constants */, false /* unroll */,\n            true /* needPerStepOutputs */);\n    const lastOutput = rnnOutputs[0];\n    const outputs = rnnOutputs[1];\n    const newStates = rnnOutputs[2];\n    expectTensorsClose(\n        lastOutput,\n        tensor2d(\n            [\n              [-57.75, -57.75, -57.75, -57.75], [-57.75, -57.75, -57.75, -57.75]\n            ],\n            [2, 4]));\n    expectTensorsClose(\n        outputs,\n        tensor3d(\n            [\n              [\n                [-8.25, -8.25, -8.25, -8.25], [-27.5, -27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75, -57.75]\n              ],\n              [\n                [-8.25, -8.25, -8.25, -8.25], [-27.5, -27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75, -57.75]\n              ]\n            ],\n            [2, 3, 4]));\n    expect(newStates.length).toEqual(2);\n    expectTensorsClose(\n        newStates[0],\n        tensor2d(\n            [[57.75, 57.75, 57.75, 57.75], [57.75, 57.75, 57.75, 57.75]],\n            [2, 4]));\n    expectTensorsClose(\n        newStates[1],\n        tensor2d([[58.75, 58.75, 58.75], [58.75, 58.75, 58.75]], [2, 3]));\n  });\n\n  it('Simple step function: 4D inputs, 2 states', () => {\n    const inputs = tensor4d(\n        [\n          [[[1], [2]], [[3], [4]], [[5], [6]]],\n          [[[10], [20]], [[30], [40]], [[50], [60]]]\n        ],\n        [2, 3, 2, 1]);\n    // The two state tensors have different shapes.\n    const initialStates = [tfc.zeros([2, 4]), tfc.ones([2, 3])];\n    const rnnOutputs =\n        rnn(rnnStepForTest, inputs, initialStates, false /* goBackwards */,\n            null /* mask */, null /* constants */, false /* unroll */,\n            true /* needPerStepOutputs */);\n    const lastOutput = rnnOutputs[0];\n    const outputs = rnnOutputs[1];\n    const newStates = rnnOutputs[2];\n    expectTensorsClose(\n        lastOutput,\n        tensor2d(\n            [\n              [-57.75, -57.75, -57.75, -57.75], [-57.75, -57.75, -57.75, -57.75]\n            ],\n            [2, 4]));\n    expectTensorsClose(\n        outputs,\n        tensor3d(\n            [\n              [\n                [-8.25, -8.25, -8.25, -8.25], [-27.5, -27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75, -57.75]\n              ],\n              [\n                [-8.25, -8.25, -8.25, -8.25], [-27.5, -27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75, -57.75]\n              ]\n            ],\n            [2, 3, 4]));\n    expect(newStates.length).toEqual(2);\n    expectTensorsClose(\n        newStates[0],\n        tensor2d(\n            [[57.75, 57.75, 57.75, 57.75], [57.75, 57.75, 57.75, 57.75]],\n            [2, 4]));\n    expectTensorsClose(\n        newStates[1],\n        tensor2d([[58.75, 58.75, 58.75], [58.75, 58.75, 58.75]], [2, 3]));\n  });\n\n  it('Using inputs <3D leads to ValueError', () => {\n    const inputs = tensor2d([[1, 2], [3, 4]], [2, 2]);\n    const initialStates = [tfc.zeros([4]), tfc.ones([3])];\n    expect(() => rnn(rnnStepForTest, inputs, initialStates)).toThrowError();\n  });\n});\n\n/**\n * A simplistic RNNCell for testing.\n *\n * This RNNCell performs the following with the inputs and states.\n * - calculates a reduced mean over all input elements,\n * - adds that mean to the state tensor(s),\n * - take the negative of the 1st current state tensor and use it as the\n *   output.\n */\nclass RNNCellForTest extends RNNCell {\n  /** @nocollapse */\n  static className = 'RNNCellForTest';\n  stateSize: number|number[];\n  constructor(stateSizes: number|number[]) {\n    super({});\n    this.stateSize = stateSizes;\n  }\n\n  call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    inputs = inputs as Tensor[];\n    const dataInputs = inputs[0];\n    const states = inputs.slice(1);\n    const mean = tfc.mean(dataInputs);\n    const newStates = states.map(state => tfc.add(mean, state));\n    const output = tfc.neg(newStates[0]);\n    return [output].concat(newStates);\n  }\n}\n\ndescribeMathCPU('RNN-Layer', () => {\n  // TODO(cais): Add tests for stacked RNN cell (i.e., multiple cells) once it\n  //   implemented.\n  // TODO(cais): Add tests for masks once implemented.\n  // TODO(cais): Add tests for constants once implemented.\n\n  it('constructor: only cell', () => {\n    const cell = new RNNCellForTest(5);\n    const rnn = tfl.layers.rnn({cell});\n    expect(rnn.returnSequences).toEqual(false);\n    expect(rnn.returnState).toEqual(false);\n    expect(rnn.goBackwards).toEqual(false);\n  });\n\n  it('constructor: cell and custom options', () => {\n    const cell = new RNNCellForTest(5);\n    const rnn = tfl.layers.rnn({\n      cell,\n      returnSequences: true,\n      returnState: true,\n      goBackwards: true\n    });\n    expect(rnn.returnSequences).toEqual(true);\n    expect(rnn.returnState).toEqual(true);\n    expect(rnn.goBackwards).toEqual(true);\n  });\n\n  it('computeOutputShape: 1 state, returnSequences=false, returnState=false',\n     () => {\n       const cell = new RNNCellForTest(5);\n       const rnn = tfl.layers.rnn({cell});\n       const inputShape = [4, 3, 2];\n       expect(rnn.computeOutputShape(inputShape)).toEqual([4, 5]);\n     });\n\n  it('computeOutputShape: 1 state, returnSequences=true, returnState=false',\n     () => {\n       const cell = new RNNCellForTest([5, 6]);\n       const rnn = tfl.layers.rnn({cell, returnSequences: true});\n       const inputShape = [4, 3, 2];\n       expect(rnn.computeOutputShape(inputShape)).toEqual([4, 3, 5]);\n     });\n\n  it('computeOutputShape: 1 state, returnSequences=true, returnState=true',\n     () => {\n       const cell = new RNNCellForTest(6);\n       const rnn =\n           tfl.layers.rnn({cell, returnSequences: true, returnState: true});\n       const inputShape = [4, 3, 2];\n       expect(rnn.computeOutputShape(inputShape)).toEqual([[4, 3, 6], [4, 6]]);\n     });\n\n  it('computeOutputShape: 2 states, returnSequences=true, returnState=true',\n     () => {\n       const cell = new RNNCellForTest([5, 6]);\n       const rnn =\n           tfl.layers.rnn({cell, returnSequences: true, returnState: true});\n       const inputShape = [4, 3, 2];\n       expect(rnn.computeOutputShape(inputShape)).toEqual([\n         [4, 3, 5], [4, 5], [4, 6]\n       ]);\n     });\n\n  it('apply: Symbolic: 1 state, returnSequences=false, returnState=false',\n     () => {\n       const cell = new RNNCellForTest(6);\n       const rnn = tfl.layers.rnn({cell});\n       const input =\n           new tfl.SymbolicTensor('float32', [16, 10, 8], null, [], null);\n       const output = rnn.apply(input) as tfl.SymbolicTensor;\n       expect(output.shape).toEqual([16, 6]);\n     });\n\n  it('apply: Symbolic: 1 state, returnSequences=true, returnState=false',\n     () => {\n       const cell = new RNNCellForTest(6);\n       const rnn = tfl.layers.rnn({cell, returnSequences: true});\n       const input =\n           new tfl.SymbolicTensor('float32', [16, 10, 8], null, [], null);\n       const output = rnn.apply(input) as tfl.SymbolicTensor;\n       expect(output.shape).toEqual([16, 10, 6]);\n     });\n\n  it('apply: Symbolic: 1 state, returnSequences=true, returnState=true', () => {\n    const cell = new RNNCellForTest(6);\n    const rnn =\n        tfl.layers.rnn({cell, returnSequences: true, returnState: true});\n    const input =\n        new tfl.SymbolicTensor('float32', [16, 10, 8], null, [], null);\n    const output = rnn.apply(input) as tfl.SymbolicTensor[];\n    expect(output.length).toEqual(2);\n    expect(output[0].shape).toEqual([16, 10, 6]);\n    expect(output[1].shape).toEqual([16, 6]);\n  });\n\n  it('apply: Symbolic: 1 state, returnSequences=false, returnState=true',\n     () => {\n       const cell = new RNNCellForTest(6);\n       const rnn =\n           tfl.layers.rnn({cell, returnSequences: false, returnState: true});\n       const input =\n           new tfl.SymbolicTensor('float32', [16, 10, 8], null, [], null);\n       const output = rnn.apply(input) as tfl.SymbolicTensor[];\n       expect(output.length).toEqual(2);\n       expect(output[0].shape).toEqual([16, 6]);\n       expect(output[1].shape).toEqual([16, 6]);\n     });\n\n  it('apply: Symbolic: 2 states, returnSequences=true, returnState=true',\n     () => {\n       const cell = new RNNCellForTest([5, 6]);\n       const rnn =\n           tfl.layers.rnn({cell, returnSequences: true, returnState: true});\n       const input =\n           new tfl.SymbolicTensor('float32', [16, 10, 8], null, [], null);\n       const output = rnn.apply(input) as tfl.SymbolicTensor[];\n       expect(output.length).toEqual(3);\n       expect(output[0].shape).toEqual([16, 10, 5]);\n       expect(output[1].shape).toEqual([16, 5]);\n       expect(output[2].shape).toEqual([16, 6]);\n     });\n});\n\ndescribeMathCPUAndGPU('RNN-Layer-Math', () => {\n  it('getInitialState: 1 state', () => {\n    const cell = new RNNCellForTest(5);\n    const inputs = tfc.zeros([4, 3, 2]);\n    const rnn = tfl.layers.rnn({cell});\n    const initialStates = rnn.getInitialState(inputs);\n    expect(initialStates.length).toEqual(1);\n    expectTensorsClose(initialStates[0], tfc.zeros([4, 5]));\n  });\n\n  it('getInitialState: 2 states', () => {\n    const cell = new RNNCellForTest([5, 6]);\n    const inputs = tfc.zeros([4, 3, 2]);\n    const rnn = tfl.layers.rnn({cell});\n    const initialStates = rnn.getInitialState(inputs);\n    expect(initialStates.length).toEqual(2);\n    expectTensorsClose(initialStates[0], tfc.zeros([4, 5]));\n    expectTensorsClose(initialStates[1], tfc.zeros([4, 6]));\n  });\n\n  it('call: 1 state: returnSequences=false, returnState=false', () => {\n    const cell = new RNNCellForTest(4);\n    const rnn = tfl.layers.rnn({cell});\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    const outputs = rnn.apply(inputs) as Tensor;\n    expectTensorsClose(outputs, tfc.mul(scalar(-57.75), tfc.ones([2, 4])));\n  });\n\n  it('apply: 1 state: returnSequences=true, returnState=false', () => {\n    const cell = new RNNCellForTest(3);\n    const rnn = tfl.layers.rnn({cell, returnSequences: true});\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    const outputs = rnn.apply(inputs) as Tensor;\n    expectTensorsClose(\n        outputs,\n        tensor3d(\n            [\n              [\n                [-8.25, -8.25, -8.25], [-27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75]\n              ],\n              [\n                [-8.25, -8.25, -8.25], [-27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75]\n              ],\n            ],\n            [2, 3, 3]));\n  });\n\n  it('apply: 1 state: returnSequences=true, returnState=true', () => {\n    const cell = new RNNCellForTest(3);\n    const rnn =\n        tfl.layers.rnn({cell, returnSequences: true, returnState: true});\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    const outputs = rnn.apply(inputs) as Tensor[];\n    expect(outputs.length).toEqual(2);\n    expectTensorsClose(\n        outputs[0],\n        tensor3d(\n            [\n              [\n                [-8.25, -8.25, -8.25], [-27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75]\n              ],\n              [\n                [-8.25, -8.25, -8.25], [-27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75]\n              ],\n            ],\n            [2, 3, 3]));\n    expectTensorsClose(\n        outputs[1],\n        tensor2d([[57.75, 57.75, 57.75], [57.75, 57.75, 57.75]], [2, 3]));\n  });\n\n  it('apply: 2 states: returnSequences=true, returnState=true', () => {\n    const cell = new RNNCellForTest([3, 4]);\n    const rnn =\n        tfl.layers.rnn({cell, returnSequences: true, returnState: true});\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    const outputs = rnn.apply(inputs) as Tensor[];\n    expect(outputs.length).toEqual(3);\n    expectTensorsClose(\n        outputs[0],\n        tensor3d(\n            [\n              [\n                [-8.25, -8.25, -8.25], [-27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75]\n              ],\n              [\n                [-8.25, -8.25, -8.25], [-27.5, -27.5, -27.5],\n                [-57.75, -57.75, -57.75]\n              ],\n            ],\n            [2, 3, 3]));\n    expectTensorsClose(\n        outputs[1],\n        tensor2d([[57.75, 57.75, 57.75], [57.75, 57.75, 57.75]], [2, 3]));\n    expectTensorsClose(\n        outputs[2],\n        tensor2d(\n            [[57.75, 57.75, 57.75, 57.75], [57.75, 57.75, 57.75, 57.75]],\n            [2, 4]));\n  });\n\n  it('call: with 1 initialState', () => {\n    const cell = new RNNCellForTest(4);\n    const rnn = tfl.layers.rnn({cell});\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    const outputs =\n        rnn.apply(inputs, {'initialState': [tfc.ones([2, 4])]}) as Tensor;\n    expectTensorsClose(outputs, tfc.mul(scalar(-58.75), tfc.ones([2, 4])));\n  });\n\n  it('call: with 2 initialStates', () => {\n    const cell = new RNNCellForTest([4, 5]);\n    const rnn = tfl.layers.rnn({cell, returnState: true});\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    const outputs = rnn.apply(inputs, {\n      'initialState': [tfc.ones([2, 4]), tfc.mul(scalar(2), tfc.ones([2, 5]))]\n    }) as Tensor[];\n    expect(outputs.length).toEqual(3);\n    expectTensorsClose(outputs[0], tfc.mul(scalar(-58.75), tfc.ones([2, 4])));\n    expectTensorsClose(outputs[1], tfc.mul(scalar(58.75), tfc.ones([2, 4])));\n    expectTensorsClose(outputs[2], tfc.mul(scalar(59.75), tfc.ones([2, 5])));\n  });\n\n  it('call with incorrect number of initialStates leads to ValueError', () => {\n    const cell = new RNNCellForTest([4, 5]);\n    const rnn = tfl.layers.rnn({cell, returnState: true});\n    const inputs = tensor3d(\n        [[[1, 2], [3, 4], [5, 6]], [[10, 20], [30, 40], [50, 60]]], [2, 3, 2]);\n    expect(() => rnn.apply(inputs, {\n      'initialState': [tfc.ones([2, 4])]\n    })).toThrowError(/An initialState was passed that is not compatible with/);\n  });\n});\n\ndescribeMathCPU('SimpleRNN Symbolic', () => {\n  it('returnSequences=false, returnState=false', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const simpleRNN = tfl.layers.simpleRNN({units: 5});\n    const output = simpleRNN.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([9, 5]);\n  });\n\n  it('returnSequences=false, returnState=true', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const simpleRNN = tfl.layers.simpleRNN({units: 5, returnState: true});\n    const output = simpleRNN.apply(input) as tfl.SymbolicTensor[];\n    expect(output.length).toEqual(2);\n    expect(output[0].shape).toEqual([9, 5]);\n    expect(output[1].shape).toEqual([9, 5]);\n  });\n\n  it('returnSequences=true, returnState=false', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const simpleRNN = tfl.layers.simpleRNN({units: 5, returnSequences: true});\n    const output = simpleRNN.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([9, 10, 5]);\n  });\n\n  it('returnSequences=true, returnState=true', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const simpleRNN = tfl.layers.simpleRNN({\n      units: 5,\n      returnSequences: true,\n      returnState: true,\n    });\n    const output = simpleRNN.apply(input) as tfl.SymbolicTensor[];\n    expect(output.length).toEqual(2);\n    expect(output[0].shape).toEqual([9, 10, 5]);\n    expect(output[1].shape).toEqual([9, 5]);\n  });\n\n  it('Serialization round trip', () => {\n    const layer = tfl.layers.simpleRNN({units: 4});\n    const pythonicConfig = convertTsToPythonic(layer.getConfig());\n    // tslint:disable-next-line:no-any\n    const tsConfig = convertPythonicToTs(pythonicConfig) as any;\n    const layerPrime = tfl.layers.simpleRNN(tsConfig);\n    expect(layerPrime.getConfig().units).toEqual(4);\n  });\n\n  it('Invalid units leads to Error', () => {\n    expect(() => tfl.layers.simpleRNN({\n      units: 12.5\n    })).toThrowError(/units.*positive integer.*12\\.5\\.$/);\n    expect(() => tfl.layers.simpleRNN({\n      units: 0\n    })).toThrowError(/units.*positive integer.*0\\.$/);\n    expect(() => tfl.layers.simpleRNN({\n      units: -25\n    })).toThrowError(/units.*positive integer.*-25\\.$/);\n  });\n});\n\ndescribeMathCPUAndGPU('SimpleRNN Tensor', () => {\n  const units = 5;\n  const batchSize = 4;\n  const inputSize = 2;\n\n  // TODO(cais): Add test for the default recurrent initializer ('Orthogonal')\n  //   when it becomes available.\n\n  const dropouts = [0.0, 0.1];\n  const trainings = [true, false];\n  for (const training of trainings) {\n    for (const dropout of dropouts) {\n      const testTitle =\n          `returnSequences=false, returnState=false, useBias=true,` +\n          ` ${training}, dropout=${dropout}`;\n      it(testTitle, () => {\n        const timeSteps = 3;\n        const simpleRNN = tfl.layers.simpleRNN({\n          units,\n          kernelInitializer: 'ones',\n          recurrentInitializer: 'ones',\n          biasInitializer: 'ones',\n          dropout,\n        });\n        const kwargs: Kwargs = {};\n        if (training) {\n          kwargs['training'] = true;\n        }\n        const input = tfc.ones([batchSize, timeSteps, inputSize]);\n        spyOn(tfc, 'dropout').and.callThrough();\n        let numTensors = 0;\n        for (let i = 0; i < 2; i++) {\n          tfc.dispose(simpleRNN.apply(input, kwargs) as Tensor);\n          if (dropout !== 0.0 && training) {\n            expect(tfc.dropout).toHaveBeenCalledTimes(1 * (i + 1));\n          } else {\n            expect(tfc.dropout).toHaveBeenCalledTimes(0);\n          }\n          if (i === 0) {\n            numTensors = tfc.memory().numTensors;\n          } else {\n            expect(tfc.memory().numTensors).toEqual(numTensors);\n          }\n        }\n      });\n    }\n  }\n\n  const recurrentDropouts = [0.0, 0.1];\n  for (const training of trainings) {\n    for (const recurrentDropout of recurrentDropouts) {\n      const testTitle =\n          `returnSequences=false, returnState=false, useBias=true,` +\n          ` ${training}, recurrentDropout=${recurrentDropout}`;\n      it(testTitle, () => {\n        const timeSteps = 3;\n        const simpleRNN = tfl.layers.simpleRNN({\n          units,\n          kernelInitializer: 'ones',\n          recurrentInitializer: 'ones',\n          biasInitializer: 'ones',\n          recurrentDropout,\n        });\n        const kwargs: Kwargs = {};\n        if (training) {\n          kwargs['training'] = true;\n        }\n        const input = tfc.ones([batchSize, timeSteps, inputSize]);\n        spyOn(tfc, 'dropout').and.callThrough();\n        let numTensors = 0;\n        for (let i = 0; i < 2; i++) {\n          tfc.dispose(simpleRNN.apply(input, kwargs) as Tensor);\n          if (recurrentDropout !== 0.0 && training) {\n            expect(tfc.dropout).toHaveBeenCalledTimes(1 * (i + 1));\n          } else {\n            expect(tfc.dropout).toHaveBeenCalledTimes(0);\n          }\n          if (i === 0) {\n            numTensors = tfc.memory().numTensors;\n          } else {\n            expect(tfc.memory().numTensors).toEqual(numTensors);\n          }\n        }\n      });\n    }\n  }\n\n  const activations: ActivationIdentifier[] = ['linear', 'tanh'];\n  for (const activation of activations) {\n    const testTitle =\n        `returnSequences=false, returnState=false, useBias=true, ${activation}`;\n    it(testTitle, () => {\n      const timeSteps = 1;\n      const simpleRNN = tfl.layers.simpleRNN({\n        units,\n        kernelInitializer: 'ones',\n        recurrentInitializer: 'ones',\n        biasInitializer: 'ones',\n        activation\n      });\n      const input = tfc.ones([batchSize, timeSteps, inputSize]);\n      const output = simpleRNN.apply(input) as Tensor;\n      let expectedElementValue = inputSize + 1;\n      if (activation === 'tanh') {\n        expectedElementValue = Math.tanh(expectedElementValue);\n      }\n      expectTensorsClose(\n          output,\n          tfc.mul(scalar(expectedElementValue), tfc.ones([batchSize, units])));\n    });\n  }\n\n  const returnStateValues = [false, true];\n  for (const returnState of returnStateValues) {\n    const testTitle = `returnSequences=true, ` +\n        `returnState=${returnState}, useBias=true, linear`;\n    it(testTitle, () => {\n      const timeSteps = 2;\n      const simpleRNN = tfl.layers.simpleRNN({\n        units,\n        returnSequences: true,\n        returnState,\n        kernelInitializer: 'ones',\n        recurrentInitializer: 'ones',\n        biasInitializer: 'ones',\n        activation: 'linear'\n      });\n      const input = tfc.ones([batchSize, timeSteps, inputSize]);\n      let output = simpleRNN.apply(input);\n      let finalState: Tensor;\n      if (returnState) {\n        output = output as Tensor[];\n        expect(output.length).toEqual(2);\n        finalState = output[1];\n        output = output[0];\n      } else {\n        output = output as Tensor;\n      }\n\n      expect(output.shape).toEqual([batchSize, timeSteps, units]);\n      const timeMajorOutput = tfc.transpose(output, [1, 0, 2]);\n      const outputT0 = K.sliceAlongFirstAxis(timeMajorOutput, 0, 1);\n      const outputT1 = K.sliceAlongFirstAxis(timeMajorOutput, 1, 1);\n      expectTensorsClose(\n          outputT0,\n          tfc.mul(scalar(inputSize + 1), tfc.ones([1, batchSize, units])));\n      expectTensorsClose(\n          outputT1,\n          tfc.mul(\n              scalar((inputSize + 1) * (units + 1)),\n              tfc.ones([1, batchSize, units])));\n      if (returnState) {\n        expectTensorsClose(finalState, outputT1.reshape([batchSize, units]));\n      }\n    });\n\n    it('stateful missing batchInputShape leads to error', () => {\n      const sequenceLength = 3;\n      const simpleRNN = tfl.layers.simpleRNN({\n        units,\n        kernelInitializer: 'ones',\n        recurrentInitializer: 'ones',\n        biasInitializer: 'zeros',\n        activation: 'linear',\n        stateful: true,\n        inputShape: [sequenceLength, inputSize]\n      }) as RNN;\n      const model = tfl.sequential();\n      expect(() => model.add(simpleRNN))\n          .toThrowError(/needs to know its batch size/);\n    });\n\n    // The reference values below can be obtained with PyKeras code:\n    // ```python\n    // import keras\n    // import numpy as np\n    //\n    // units = 5\n    // batch_size = 4\n    // input_size = 2\n    // sequence_length = 3\n    //\n    // rnn = keras.layers.SimpleRNN(units,\n    //                             kernel_initializer='ones',\n    //                             recurrent_initializer='ones',\n    //                             bias_initializer='zeros',\n    //                             activation='linear',\n    //                             stateful=True,\n    //                             batch_input_shape=[batch_size,\n    //                                                 sequence_length,\n    //                                                 input_size])\n    //\n    // x = np.ones([batch_size, sequence_length, input_size])\n    //\n    // model = keras.Sequential()\n    // model.add(rnn)\n    // print(model.predict(x))\n    // print(model.predict(x))\n    // model.reset_states()\n    // print(model.predict(x))\n    // print(model.predict(x))\n    // ```\n    it('stateful forward: only RNN layer', async () => {\n      const sequenceLength = 3;\n      const rnn = tfl.layers.simpleRNN({\n        units,\n        kernelInitializer: 'ones',\n        recurrentInitializer: 'ones',\n        biasInitializer: 'zeros',\n        activation: 'linear',\n        stateful: true,\n        batchInputShape: [batchSize, sequenceLength, inputSize]\n      });\n      const model = tfl.sequential();\n      model.add(rnn);\n      const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n      const scalar1 = tfc.scalar(62);\n      const scalar2 = tfc.scalar(7812);\n\n      let y1 = model.predict(x) as Tensor;\n      expect(y1.kept).toBe(false);\n      let y1Expected =\n          tfc.tidy(() => tfc.ones([batchSize, units]).mul(scalar1));\n      expectTensorsClose(y1, y1Expected);\n\n      let y2 = model.predict(x) as Tensor;\n      expect(y2.kept).toBe(false);\n      // Future predicts should not dispose previous outputs.\n      expect(y1.isDisposed).toBe(false);\n      let y2Expected =\n          tfc.tidy(() => tfc.ones([batchSize, units]).mul(scalar2));\n      expectTensorsClose(y2, y2Expected);\n      tfc.dispose([y1, y2, y1Expected, y2Expected]);\n\n      model.resetStates();\n      const numTensors0 = tfc.memory().numTensors;\n\n      y1 = model.predict(x) as Tensor;\n      expect(y1.kept).toBe(false);\n      y1Expected = tfc.tidy(() => tfc.ones([batchSize, units]).mul(scalar1));\n      expectTensorsClose(y1, y1Expected);\n\n      y2 = model.predict(x) as Tensor;\n      expect(y2.kept).toBe(false);\n      // Future predicts should not dispose previous outputs.\n      expect(y1.isDisposed).toBe(false);\n      y2Expected = tfc.tidy(() => tfc.ones([batchSize, units]).mul(scalar2));\n      expectTensorsClose(y2, y2Expected);\n      tfc.dispose([y1, y2, y1Expected, y2Expected]);\n\n      // Assert no memory leak, even without resetStates() being called.\n      expect(tfc.memory().numTensors).toEqual(numTensors0);\n    });\n  }\n\n  // Reference Python code:\n  // ```py\n  // import numpy as np\n  // from tensorflow import keras\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.SimpleRNN(\n  //     units=5,\n  //     kernel_initializer='ones',\n  //     recurrent_initializer='ones',\n  //     bias_initializer='zeros',\n  //     activation='linear',\n  //     stateful=True,\n  //     batch_input_shape=[4, 3, 2]))\n  // model.add(keras.layers.Dense(units=1, kernel_initializer='ones'))\n  // model.compile(loss='mean_squared_error', optimizer='sgd')\n  // model.summary()\n  //\n  // xs = np.ones([4, 3, 2])\n  // y1 = model.predict(xs)\n  // print(y1)\n  // y2 = model.predict(xs)\n  // print(y2)\n  //\n  // history = model.fit(xs, ys, batch_size=4, epochs=3)\n  // print(history.history)\n  // ```\n  it('stateful forward: RNN and dense layers', async () => {\n    const sequenceLength = 3;\n    const model = tfl.sequential();\n    model.add(tfl.layers.simpleRNN({\n      units,\n      kernelInitializer: 'ones',\n      recurrentInitializer: 'ones',\n      biasInitializer: 'zeros',\n      activation: 'linear',\n      stateful: true,\n      batchInputShape: [batchSize, sequenceLength, inputSize]\n    }));\n    model.add(tfl.layers.dense({units: 1, kernelInitializer: 'ones'}));\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n    const xs = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const ys = tfc.ones([batchSize, 1]);\n    let y1: Tensor;\n    let y2: Tensor;\n    tfc.tidy(() => {\n      y1 = model.predict(xs) as Tensor;\n      expectTensorsClose(y1, tfc.tensor2d([310, 310, 310, 310], [4, 1]));\n      y2 = model.predict(xs) as Tensor;\n      expectTensorsClose(\n          y2, tfc.tensor2d([39060, 39060, 39060, 39060], [4, 1]));\n    });\n    model.resetStates();\n    const numTensors0 = tfc.memory().numTensors;\n\n    tfc.tidy(() => {\n      y1 = model.predict(xs) as Tensor;\n      expect(y1.shape).toEqual([batchSize, 1]);\n      expectTensorsClose(y1, tfc.tensor2d([310, 310, 310, 310], [4, 1]));\n      y2 = model.predict(xs) as Tensor;\n      expectTensorsClose(\n          y2, tfc.tensor2d([39060, 39060, 39060, 39060], [4, 1]));\n    });\n    // Assert no memory leak, even without resetStates() being called.\n    expect(tfc.memory().numTensors).toEqual(numTensors0);\n\n    const history = await model.fit(xs, ys, {epochs: 1, batchSize: 4});\n    expect(history.history.loss[0]).toBeCloseTo(23841822736384);\n  });\n\n  it('computeMask: returnSequence = false, returnState = false', () => {\n    const sequenceLength = 3;\n    const rnn = tfl.layers.simpleRNN({\n      units,\n      returnSequences: false,\n      returnState: false,\n      batchInputShape: [batchSize, sequenceLength, inputSize]\n    });\n    const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const m = tfc.ones([sequenceLength, 1]);\n    const mask = rnn.computeMask(x, m);\n    expect(mask).toBeNull();\n  });\n\n  it('computeMask: returnSequence = true, returnState = false', () => {\n    const sequenceLength = 3;\n    const rnn = tfl.layers.simpleRNN({\n      units,\n      returnSequences: true,\n      returnState: false,\n      batchInputShape: [batchSize, sequenceLength, inputSize]\n    });\n    const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const m = tfc.ones([sequenceLength, 1]);\n    const mask = rnn.computeMask(x, m) as Tensor;\n    expectTensorsClose(mask, m);\n  });\n\n  it('computeMask: returnSequence = true, returnState = true', () => {\n    const sequenceLength = 3;\n    const rnn = tfl.layers.simpleRNN({\n      units,\n      returnSequences: true,\n      returnState: true,\n      stateful: true,\n      batchInputShape: [batchSize, sequenceLength, inputSize]\n    });\n    const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n    rnn.apply(x);\n    rnn.resetStates();  // Let the RNN layer object construct its state first.\n    const m = tfc.ones([sequenceLength, 1]);\n    const masks = rnn.computeMask(x, m) as Tensor[];\n    expect(masks.length).toEqual(2);\n    expectTensorsClose(masks[0], m);\n    expect(masks[1]).toBeNull();\n  });\n\n  // The reference values can be obtained with the following PyKeras code:\n  // ```python\n  // import keras\n  // import numpy as np\n  //\n  // batch_size = 4\n  // sequence_length = 3\n  // input_size = 2\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.SimpleRNN(\n  //     units=5,\n  //     batch_input_shape=[batch_size, sequence_length, input_size],\n  //     kernel_initializer='ones',\n  //     recurrent_initializer='ones',\n  //     bias_initializer='zeros',\n  //     stateful=True))\n  // model.add(keras.layers.Dense(1,\n  //                              kernel_initializer='zeros',\n  //                              use_bias=False))\n  // model.compile(loss='mean_squared_error', optimizer='sgd')\n  //\n  // xs_1 = np.ones([batch_size, sequence_length, input_size])\n  // xs_2 = np.zeros([batch_size, sequence_length, input_size])\n  // xs = np.concatenate([xs_1, xs_2], 0)\n  // ys = np.array([[-1], [-2], [0], [1], [1], [2], [0], [-1]])\n  //\n  // history = model.fit(xs, ys, batch_size=batch_size, shuffle=False)\n  // print(history.history)\n  // ```\n  it('stateful BPTT', async () => {\n    const sequenceLength = 3;\n    const model = tfl.sequential();\n    model.add(tfl.layers.simpleRNN({\n      units,\n      kernelInitializer: 'ones',\n      recurrentInitializer: 'ones',\n      biasInitializer: 'zeros',\n      stateful: true,\n      batchInputShape: [batchSize, sequenceLength, inputSize]\n    }));\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'zeros', useBias: false}));\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const xs1 = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const xs2 = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const xs = tfc.concat([xs1, xs2], 0);\n    const ys = tfc.tensor2d([[-1], [-2], [0], [1], [1], [2], [0], [-1]]);\n\n    const history = await model.fit(xs, ys, {batchSize, shuffle: false});\n    // See code snippet above for the code used to obtain this loss value.\n    expect(history.history.loss[0]).toBeCloseTo(1.5262475);\n  });\n\n  it('BPTT', async () => {\n    // The following golden values for assertion can be obtained with the\n    // following Python Keras code.\n    // ```python\n    // import keras\n    // import numpy as np\n    //\n    // sequence_length = 3\n    // input_size = 4\n    // batch_size = 5\n    //\n    // t_input = keras.Input([sequence_length, input_size])\n    // simple_rnn = keras.layers.SimpleRNN(1,\n    //                                     kernel_initializer='ones',\n    //                                     recurrent_initializer='ones',\n    //                                     use_bias=False)\n    // dense = keras.layers.Dense(1,\n    //                            kernel_initializer='ones',\n    //                            use_bias=False)\n    // output = dense(simple_rnn(t_input))\n    // model = keras.Model(t_input, output)\n    // optimizer = keras.optimizers.SGD(5)\n    // model.compile(optimizer=optimizer, loss='mean_squared_error')\n    //\n    // x = np.ones([batch_size, sequence_length, input_size])\n    // y = np.zeros([batch_size, 1])\n    // model.fit(x, y, batch_size=batch_size, epochs=2)\n    // print(simple_rnn.get_weights()[0])\n    // print(simple_rnn.get_weights()[1])\n    // print(dense.get_weights()[0])\n    // ```\n    const sequenceLength = 3;\n    const inputSize = 4;\n    const batchSize = 5;\n    const model = tfl.sequential();\n    model.add(tfl.layers.simpleRNN({\n      units: 1,\n      kernelInitializer: 'ones',\n      recurrentInitializer: 'ones',\n      useBias: false,\n      inputShape: [sequenceLength, inputSize],\n    }));\n    model.add(tfl.layers.dense({\n      units: 1,\n      kernelInitializer: 'ones',\n      useBias: false,\n    }));\n\n    const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const y = tfc.zeros([batchSize, 1]);\n    const sgd = tfc.train.sgd(5);\n    model.compile({loss: 'meanSquaredError', optimizer: sgd});\n    await model.fit(x, y, {epochs: 2});\n\n    expectTensorsClose(\n        model.layers[0].getWeights()[0],\n        tfc.mul(scalar(0.8484658), tfc.ones([4, 1])));\n    expectTensorsClose(\n        model.layers[0].getWeights()[1],\n        tfc.mul(scalar(0.8484799), tfc.ones([1, 1])));\n    expectTensorsClose(\n        model.layers[1].getWeights()[0],\n        tfc.mul(scalar(80.967026), tfc.ones([1, 1])));\n  });\n});\n\ndescribeMathCPU('SimpleRNN Serialization', () => {\n  const cellConfig: SimpleRNNCellLayerArgs = {\n    units: 8,\n    activation: 'tanh',\n    useBias: true,\n    kernelInitializer: 'glorotUniform',\n    recurrentInitializer: 'heUniform',\n    biasInitializer: 'ones',\n    kernelRegularizer: 'l1l2',\n    recurrentRegularizer: 'l1l2',\n    biasRegularizer: 'l1l2',\n    kernelConstraint: 'unitNorm',\n    recurrentConstraint: 'unitNorm',\n    biasConstraint: 'nonNeg',\n    dropout: 0.1,\n    recurrentDropout: 0.2,\n    name: 'cell_1',\n    batchSize: 12,\n    batchInputShape: [12, 8, 8],\n    inputShape: [8, 8],\n    dtype: 'int32',\n    inputDType: 'int32',\n    trainable: true,\n  };\n\n  const expectedCellConfigPrime = {\n    name: 'cell_1',\n    trainable: true,\n    batchInputShape: [12, 8, 8],\n    dtype: 'int32',\n    units: 8,\n    activation: serializeActivation(new Tanh()),\n    useBias: true,\n    kernelInitializer: serializeInitializer(new GlorotUniform()),\n    recurrentInitializer: serializeInitializer(new HeUniform()),\n    biasInitializer: serializeInitializer(new Ones()),\n    kernelRegularizer: serializeRegularizer(new L1L2()),\n    recurrentRegularizer: serializeRegularizer(new L1L2()),\n    biasRegularizer: serializeRegularizer(new L1L2()),\n    activityRegularizer: serializeRegularizer(null),\n    kernelConstraint: serializeConstraint(new UnitNorm({})),\n    recurrentConstraint: serializeConstraint(new UnitNorm({})),\n    biasConstraint: serializeConstraint(new NonNeg()),\n  };\n\n  describe('SimpleRNNCell.getConfig', () => {\n    it('should return the expected values', () => {\n      const cell = tfl.layers.simpleRNNCell(cellConfig);\n\n      const {dropout, recurrentDropout, ...configPrime} = cell.getConfig();\n\n      expect(configPrime).toEqual(expectedCellConfigPrime);\n      expect(dropout).toBeCloseTo(0.1);\n      expect(recurrentDropout).toBeCloseTo(0.2);\n    });\n  });\n\n  describe('SimpleRNN.getConfig', () => {\n    it('should return the expected values', () => {\n      const config: SimpleRNNLayerArgs = {\n        ...cellConfig,\n        name: 'layer_1',\n        ...{\n          returnSequences: true,\n          returnState: true,\n          stateful: true,\n          unroll: true,\n          goBackwards: true,\n          inputDim: 8,\n          inputLength: 8,\n        } as Omit<SimpleRNNLayerArgs, keyof SimpleRNNCellLayerArgs>\n      };\n\n      const cell = tfl.layers.simpleRNN(config);\n\n      const {dropout, recurrentDropout, ...configPrime} = cell.getConfig();\n\n      expect(configPrime).toEqual({\n        ...expectedCellConfigPrime,\n        name: 'layer_1',\n        returnSequences: true,\n        returnState: true,\n        stateful: true,\n        unroll: true,\n        goBackwards: true,\n      });\n      expect(dropout).toBeCloseTo(0.1);\n      expect(recurrentDropout).toBeCloseTo(0.2);\n    });\n  });\n});\n\ndescribeMathCPU('GRU Symbolic', () => {\n  it('returnSequences=false, returnState=false', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const gru = tfl.layers.gru({units: 5});\n    const output = gru.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([9, 5]);\n  });\n\n  it('returnSequences=false, returnState=true', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const gru = tfl.layers.gru({units: 5, returnState: true});\n    const output = gru.apply(input) as tfl.SymbolicTensor[];\n    expect(output.length).toEqual(2);\n    expect(output[0].shape).toEqual([9, 5]);\n    expect(output[1].shape).toEqual([9, 5]);\n  });\n\n  it('returnSequences=true, returnState=false', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const gru = tfl.layers.gru({units: 5, returnSequences: true});\n    const output = gru.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([9, 10, 5]);\n  });\n\n  it('returnSequences=true, returnState=true', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const gru = tfl.layers.gru({\n      units: 5,\n      returnSequences: true,\n      returnState: true,\n    });\n    const output = gru.apply(input) as tfl.SymbolicTensor[];\n    expect(output.length).toEqual(2);\n    expect(output[0].shape).toEqual([9, 10, 5]);\n    expect(output[1].shape).toEqual([9, 5]);\n  });\n\n  it('trainableWeights, nonTrainableWeights and weights give correct outputs',\n     () => {\n       const input =\n           new tfl.SymbolicTensor('float32', [2, 3, 4], null, [], null);\n       const gru = tfl.layers.gru({units: 5, returnState: true});\n       gru.apply(input);\n       expect(gru.trainable).toEqual(true);\n       // Trainable weights: kernel, recurrent kernel and bias.\n       expect(gru.trainableWeights.length).toEqual(3);\n       expect(gru.nonTrainableWeights.length).toEqual(0);\n       expect(gru.weights.length).toEqual(3);\n     });\n\n  for (const implementation of [1, 2]) {\n    it('Serialization round trip', () => {\n      const layer = tfl.layers.gru({units: 4, implementation});\n      const pythonicConfig = convertTsToPythonic(layer.getConfig());\n      // tslint:disable-next-line:no-any\n      const tsConfig = convertPythonicToTs(pythonicConfig) as any;\n      const layerPrime = tfl.layers.gru(tsConfig);\n      expect(layerPrime.getConfig().units).toEqual(4);\n      expect(layerPrime.getConfig().implementation).toEqual(implementation);\n    });\n  }\n\n  it('Invalid units leads to Error', () => {\n    expect(() => tfl.layers.gru({\n      units: 12.5\n    })).toThrowError(/units.*positive integer.*12\\.5\\.$/);\n    expect(() => tfl.layers.gru({\n      units: 0\n    })).toThrowError(/units.*positive integer.*0\\.$/);\n    expect(() => tfl.layers.gru({\n      units: -25\n    })).toThrowError(/units.*positive integer.*-25\\.$/);\n  });\n});\n\ndescribeMathCPUAndGPU('GRU Tensor', () => {\n  // Note:\n  // The golden expected values used for assertions in these unit tests can be\n  // obtained through running the Python code similar to the following example.\n  // TensorFlow 1.5 was used to obtain the values.\n  //\n  // ```python\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // units = 5\n  // batch_size = 4\n  // input_size = 2\n  // time_steps = 3\n  //\n  // with tf.Session() as sess:\n  //   lstm = tf.keras.layers.GRU(units,\n  //                              kernel_initializer=\"ones\",\n  //                              recurrent_initializer=\"ones\",\n  //                              bias_initializer=\"ones\",\n  //                              return_sequences=True,\n  //                              return_state=True)\n  //   inputs = tf.placeholder(tf.float32, shape=[None, None, input_size])\n  //   outputs = lstm(inputs)\n  //\n  //   sess.run(tf.global_variables_initializer())\n  //   feed_inputs = np.ones([batch_size, time_steps, input_size])\n  //   print(sess.run(outputs, feed_dict={inputs: feed_inputs}))\n  // ```\n\n  const units = 5;\n  const batchSize = 4;\n  const inputSize = 2;\n  const timeSteps = 3;\n  const goldenOutputElementValues = [0.22847827, 0.2813754, 0.29444352];\n\n  // TODO(cais): Add test for the default recurrent initializer ('Orthogonal')\n  //   when it becomes available.\n\n  const dropouts = [0.0, 0.1];\n  const trainings = [true, false];\n  for (const training of trainings) {\n    for (const dropout of dropouts) {\n      const testTitle =\n          `returnSequences=false, returnState=false, useBias=true,` +\n          ` ${training}, dropout=${dropout}`;\n      it(testTitle, () => {\n        const gru = tfl.layers.gru({\n          units,\n          kernelInitializer: 'ones',\n          recurrentInitializer: 'ones',\n          biasInitializer: 'ones',\n          dropout,\n          implementation: 1\n        });\n        const kwargs: Kwargs = {};\n        if (training) {\n          kwargs['training'] = true;\n        }\n        const input = tfc.ones([batchSize, timeSteps, inputSize]);\n        spyOn(tfc, 'dropout').and.callThrough();\n        let numTensors = 0;\n        for (let i = 0; i < 2; i++) {\n          tfc.dispose(gru.apply(input, kwargs) as Tensor);\n          if (dropout !== 0.0 && training) {\n            expect(tfc.dropout).toHaveBeenCalledTimes(3 * (i + 1));\n          } else {\n            expect(tfc.dropout).toHaveBeenCalledTimes(0);\n          }\n          if (i === 0) {\n            numTensors = tfc.memory().numTensors;\n          } else {\n            expect(tfc.memory().numTensors).toEqual(numTensors);\n          }\n        }\n      });\n    }\n  }\n\n  const recurrentDropouts = [0.0, 0.1];\n  for (const training of trainings) {\n    for (const recurrentDropout of recurrentDropouts) {\n      const testTitle =\n          `returnSequences=false, returnState=false, useBias=true,` +\n          ` ${training}, recurrentDropout=${recurrentDropout}`;\n      it(testTitle, () => {\n        const gru = tfl.layers.gru({\n          units,\n          kernelInitializer: 'ones',\n          recurrentInitializer: 'ones',\n          biasInitializer: 'ones',\n          recurrentDropout,\n          implementation: 1\n        });\n        const kwargs: Kwargs = {};\n        if (training) {\n          kwargs['training'] = true;\n        }\n        const input = tfc.ones([batchSize, timeSteps, inputSize]);\n        spyOn(tfc, 'dropout').and.callThrough();\n        let numTensors = 0;\n        for (let i = 0; i < 2; i++) {\n          tfc.dispose(gru.apply(input, kwargs) as Tensor);\n          if (recurrentDropout !== 0.0 && training) {\n            expect(tfc.dropout).toHaveBeenCalledTimes(3 * (i + 1));\n          } else {\n            expect(tfc.dropout).toHaveBeenCalledTimes(0);\n          }\n          if (i === 0) {\n            numTensors = tfc.memory().numTensors;\n          } else {\n            expect(tfc.memory().numTensors).toEqual(numTensors);\n          }\n        }\n      });\n    }\n  }\n\n  const implementations = [1, 2];\n  const returnStateValues = [false, true];\n  const returnSequencesValues = [false, true];\n  for (const implementation of implementations) {\n    for (const returnState of returnStateValues) {\n      for (const returnSequences of returnSequencesValues) {\n        const testTitle = `implementation=${implementation}, ` +\n            `returnSequences=${returnSequences}, ` +\n            `returnState=${returnState}`;\n        it(testTitle, () => {\n          const gru = tfl.layers.gru({\n            units,\n            kernelInitializer: 'ones',\n            recurrentInitializer: 'ones',\n            biasInitializer: 'ones',\n            returnState,\n            returnSequences,\n            implementation\n          });\n          const input = tfc.zeros([batchSize, timeSteps, inputSize]);\n          let output = gru.apply(input);\n\n          const goldenOutputElementValueFinal =\n              goldenOutputElementValues[goldenOutputElementValues.length - 1];\n\n          let expectedOutput: Tensor;\n          if (returnSequences) {\n            const outputs = goldenOutputElementValues.map(\n                value =>\n                    tfc.mul(scalar(value), tfc.ones([1, batchSize, units])));\n            expectedOutput = tfc.transpose(\n                K.concatAlongFirstAxis(\n                    K.concatAlongFirstAxis(outputs[0], outputs[1]), outputs[2]),\n                [1, 0, 2]);\n          } else {\n            expectedOutput = tfc.mul(\n                scalar(goldenOutputElementValueFinal),\n                tfc.ones([batchSize, units]));\n          }\n          if (returnState) {\n            output = output as Tensor[];\n            expect(output.length).toEqual(2);\n            expectTensorsClose(output[0], expectedOutput);\n            expectTensorsClose(\n                output[1],\n                tfc.mul(\n                    scalar(goldenOutputElementValueFinal),\n                    tfc.ones([batchSize, units])));\n          } else {\n            output = output as Tensor;\n            expectTensorsClose(output, expectedOutput);\n          }\n        });\n      }\n    }\n  }\n\n  // The reference values below can be obtained with PyKeras code:\n  // ```python\n  // import keras\n  // import numpy as np\n  //\n  // units = 5\n  // batch_size = 4\n  // input_size = 2\n  // sequence_length = 3\n  //\n  // rnn = keras.layers.GRU(units,\n  //                        kernel_initializer='ones',\n  //                        recurrent_initializer='zeros',\n  //                        bias_initializer='zeros',\n  //                        activation='linear',\n  //                        stateful=True,\n  //                        batch_input_shape=[batch_size,\n  //                                           sequence_length,\n  //                                           input_size])\n  //\n  // x = np.ones([batch_size, sequence_length, input_size])\n  //\n  // model = keras.Sequential()\n  // model.add(rnn)\n  // print(model.predict(x))\n  // print(model.predict(x))\n  // model.reset_states()\n  // print(model.predict(x))\n  // print(model.predict(x))\n  // ```\n  it('stateful forward', async () => {\n    const sequenceLength = 3;\n    const rnn = tfl.layers.gru({\n      units,\n      kernelInitializer: 'ones',\n      recurrentInitializer: 'zeros',\n      biasInitializer: 'zeros',\n      activation: 'linear',\n      stateful: true,\n      batchInputShape: [batchSize, sequenceLength, inputSize]\n    });\n    const model = tfl.sequential();\n    model.add(rnn);\n    const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const y1 = model.predict(x) as Tensor;\n    expect(y1.kept).toBe(false);\n    const y1Expected =\n        tfc.tidy(() => tfc.ones([batchSize, units]).mul(tfc.scalar(0.542)));\n    expectTensorsClose(y1, y1Expected);\n    const y2 = model.predict(x) as Tensor;\n    expect(y2.kept).toBe(false);\n    // Future predicts should not dispose previous outputs.\n    expect(y1.isDisposed).toBe(false);\n    const y2Expected =\n        tfc.tidy(() => tfc.ones([batchSize, units]).mul(tfc.scalar(0.9371182)));\n    expectTensorsClose(y2, y2Expected);\n\n    tfc.dispose([y1, y2, y1Expected, y2Expected]);\n    model.resetStates();\n    const numTensors0 = tfc.memory().numTensors;\n\n    const y3 = model.predict(x) as Tensor;\n    expect(y3.kept).toBe(false);\n    const y3Expected =\n        tfc.tidy(() => tfc.ones([batchSize, units]).mul(tfc.scalar(0.542)));\n    expectTensorsClose(y3, y3Expected);\n    const y4 = model.predict(x) as Tensor;\n    expect(y4.kept).toBe(false);\n    // Future predicts should not dispose previous outputs.\n    expect(y3.isDisposed).toBe(false);\n    const y4Expected =\n        tfc.tidy(() => tfc.ones([batchSize, units]).mul(tfc.scalar(0.9371182)));\n    expectTensorsClose(y4, y4Expected);\n    tfc.dispose([y3, y3Expected, y4, y4Expected]);\n    // Assert no memory leak, even without resetStates() being called.\n    expect(tfc.memory().numTensors).toEqual(numTensors0);\n  });\n\n  // The reference values can be obtained with the following PyKeras code:\n  // ```python\n  // import keras\n  // import numpy as np\n  //\n  // batch_size = 4\n  // sequence_length = 3\n  // input_size = 2\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.GRU(\n  //     units=5,\n  //     batch_input_shape=[batch_size, sequence_length, input_size],\n  //     kernel_initializer='ones',\n  //     recurrent_initializer='ones',\n  //     bias_initializer='zeros',\n  //     stateful=True))\n  // model.add(keras.layers.Dense(1,\n  //                              kernel_initializer='zeros',\n  //                              use_bias=False))\n  // model.compile(loss='mean_squared_error', optimizer='sgd')\n  //\n  // xs_1 = np.ones([batch_size, sequence_length, input_size])\n  // xs_2 = np.zeros([batch_size, sequence_length, input_size])\n  // xs = np.concatenate([xs_1, xs_2], 0)\n  // ys = np.array([[-1], [-2], [0], [1], [1], [2], [0], [-1]])\n  //\n  // history = model.fit(xs, ys, batch_size=batch_size, shuffle=False)\n  // print(history.history)\n  // ```\n  it('stateful BPTT', async () => {\n    const sequenceLength = 3;\n    const model = tfl.sequential();\n    model.add(tfl.layers.gru({\n      units,\n      kernelInitializer: 'ones',\n      recurrentInitializer: 'ones',\n      biasInitializer: 'zeros',\n      stateful: true,\n      batchInputShape: [batchSize, sequenceLength, inputSize]\n    }));\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'zeros', useBias: false}));\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const xs1 = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const xs2 = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const xs = tfc.concat([xs1, xs2], 0);\n    const ys = tfc.tensor2d([[-1], [-2], [0], [1], [1], [2], [0], [-1]]);\n\n    const history = await model.fit(xs, ys, {batchSize, shuffle: false});\n    // See code snippet above for the code used to obtain this loss value.\n    expect(history.history.loss[0]).toBeCloseTo(1.501);\n  });\n\n  it('BPTT', async () => {\n    // The following golden values for assertion can be obtained with the\n    // following Python Keras code.\n    // ```python\n    // import keras\n    // import numpy as np\n\n    // sequence_length = 3\n    // input_size = 4\n    // batch_size = 5\n\n    // t_input = keras.Input([sequence_length, input_size])\n    // gru = keras.layers.GRU(1,\n    //                        kernel_initializer='zeros',\n    //                        recurrent_initializer='zeros',\n    //                        use_bias=False)\n    // dense = keras.layers.Dense(1,\n    //                            kernel_initializer='ones',\n    //                            use_bias=False)\n    // output = dense(gru(t_input))\n    // model = keras.Model(t_input, output)\n    // optimizer = keras.optimizers.SGD(1)\n    // model.compile(optimizer=optimizer, loss='mean_squared_error')\n\n    // x = np.ones([batch_size, sequence_length, input_size])\n    // y = np.ones([batch_size, 1])\n    // model.fit(x, y, batch_size=batch_size, epochs=2)\n    // print(gru.get_weights()[0])\n    // print(gru.get_weights()[1])\n    // print(dense.get_weights()[0])\n    // ```\n    const sequenceLength = 3;\n    const inputSize = 4;\n    const batchSize = 5;\n    const model = tfl.sequential();\n    model.add(tfl.layers.gru({\n      units: 1,\n      kernelInitializer: 'zeros',\n      recurrentInitializer: 'zeros',\n      useBias: false,\n      inputShape: [sequenceLength, inputSize]\n    }));\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'ones', useBias: false}));\n\n    const sgd = tfc.train.sgd(1);\n    model.compile({loss: 'meanSquaredError', optimizer: sgd});\n    const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n    const y = tfc.ones([batchSize, 1]);\n    await model.fit(x, y, {epochs: 2});\n    expectTensorsClose(\n        model.layers[0].getWeights()[0],\n        K.tile(tensor2d([[-0.03750037, 0, 1.7500007]], [1, 3]), [4, 1]));\n    expectTensorsClose(\n        model.layers[0].getWeights()[1],\n        tensor2d([[-1.562513e-02, 0, 2.086183e-07]], [1, 3]));\n    expectTensorsClose(\n        model.layers[1].getWeights()[0], tensor2d([[1.2187521]], [1, 1]));\n  });\n\n  // Reference Python code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // in1 = keras.Input(shape=[5])\n  // out1 = keras.layers.Dense(2,\n  //                           kernel_initializer='ones',\n  //                           bias_initializer='zeros')(in1)\n  // in2 = keras.Input(shape=[3, 4])\n  // out2 = keras.layers.GRU(2,\n  //                         recurrent_initializer='ones',\n  //                         kernel_initializer='ones',\n  //                         bias_initializer='zeros')(in2, initial_state=out1)\n  // model = keras.Model(inputs=[in1, in2], outputs=[out1, out2])\n  //\n  // xs1 = np.array([[0.1, 0.2, 0.3, 0.4, 0.5]])\n  // xs2 = np.array([[[0.1, 0.2, 0.3, 0.4], [-0.1, -0.2, -0.3, -0.4],\n  //                 [0.3, 0.4, 0.5, 0.6]]])\n  // print(model.predict([xs1, xs2]))\n  // ```\n  it('SymbolicTensor as initialState thru kwargs; Save & Load', async () => {\n    const in1 = tfl.input({shape: [5]});\n    const out1 =\n        tfl.layers\n            .dense(\n                {units: 2, kernelInitializer: 'ones', biasInitializer: 'zeros'})\n            .apply(in1) as tfl.SymbolicTensor;\n    const in2 = tfl.input({shape: [3, 4]});\n    const out2 = tfl.layers\n                     .gru({\n                       units: 2,\n                       recurrentInitializer: 'ones',\n                       kernelInitializer: 'ones',\n                       biasInitializer: 'zeros'\n                     })\n                     .apply(in2, {initialState: out1}) as tfl.SymbolicTensor;\n\n    const model = tfl.model({inputs: [in1, in2], outputs: [out1, out2]});\n\n    const xs1 = tensor2d([[0.1, 0.2, 0.3, 0.4, 0.5]]);\n    const xs2 = tensor3d([\n      [[0.1, 0.2, 0.3, 0.4], [-0.1, -0.2, -0.3, -0.4], [0.3, 0.4, 0.5, 0.6]]\n    ]);\n    const ys = model.predict([xs1, xs2]) as Tensor[];\n    expect(ys.length).toEqual(2);\n    expectTensorsClose(ys[0], tensor2d([[1.5, 1.5]]));\n    expectTensorsClose(ys[1], tensor2d([[1.4435408, 1.4435408]]));\n\n    // NOTE: Here on down, i.e., the part that tests serialization and\n    // deserialization of the model, has no counterpart in the Python\n    // code snippet above.\n    const modelJSON = model.toJSON(null, false);\n    const modelPrime =\n        await tfl.models.modelFromJSON({modelTopology: modelJSON});\n    const ysPrime = modelPrime.predict([xs1, xs2]) as Tensor[];\n    expect(ysPrime.length).toEqual(2);\n    expectTensorsClose(ysPrime[0], ys[0]);\n    expectTensorsClose(ysPrime[1], ys[1]);\n  });\n});\n\ndescribeMathCPU('GRU-deserialization', () => {\n  it('Default recurrentActivation round trip', () => {\n    const x = randomNormal([1, 2, 3]);\n    const layer = tfl.layers.gru({units: 4});\n    const y = layer.apply(x) as Tensor;\n    const pythonicConfig = convertTsToPythonic(layer.getConfig());\n    // tslint:disable-next-line:no-any\n    const tsConfig = convertPythonicToTs(pythonicConfig) as any;\n    const layerPrime = tfl.layers.gru(tsConfig);\n    const yPrime = layer.apply(x) as Tensor;\n    expectTensorsClose(yPrime, y);\n    expect(layerPrime.getConfig()['recurrentActivation'])\n        .toEqual(layer.getConfig()['recurrentActivation']);\n  });\n\n  it('Non-default recurrentActivation round trip', () => {\n    const x = randomNormal([1, 2, 3]);\n    const layer =\n        tfl.layers.gru({units: 4, recurrentActivation: 'tanh'});\n    const y = layer.apply(x) as Tensor;\n    const pythonicConfig = convertTsToPythonic(layer.getConfig());\n    // tslint:disable-next-line:no-any\n    const tsConfig = convertPythonicToTs(pythonicConfig) as any;\n    const layerPrime = tfl.layers.gru(tsConfig);\n    const yPrime = layer.apply(x) as Tensor;\n    expectTensorsClose(yPrime, y);\n    expect(layerPrime.getConfig()['recurrentActivation'])\n        .toEqual(layer.getConfig()['recurrentActivation']);\n  });\n});\n\ndescribeMathCPU('GRU Serialization', () => {\n  const cellConfig: GRUCellLayerArgs = {\n    units: 8,\n    activation: 'tanh',\n    recurrentActivation: 'tanh',\n    useBias: true,\n    kernelInitializer: 'glorotUniform',\n    recurrentInitializer: 'heUniform',\n    biasInitializer: 'ones',\n    kernelRegularizer: 'l1l2',\n    recurrentRegularizer: 'l1l2',\n    biasRegularizer: 'l1l2',\n    kernelConstraint: 'unitNorm',\n    recurrentConstraint: 'unitNorm',\n    biasConstraint: 'nonNeg',\n    dropout: 0.1,\n    recurrentDropout: 0.2,\n    name: 'cell_1',\n    batchSize: 12,\n    batchInputShape: [12, 8, 8],\n    inputShape: [8, 8],\n    dtype: 'int32',\n    inputDType: 'int32',\n    trainable: true,\n    implementation: 1,\n  };\n\n  const expectedCellConfigPrime = {\n    name: 'cell_1',\n    trainable: true,\n    batchInputShape: [12, 8, 8],\n    dtype: 'int32',\n    units: 8,\n    activation: serializeActivation(new Tanh()),\n    recurrentActivation: serializeActivation(new Tanh()),\n    useBias: true,\n    kernelInitializer: serializeInitializer(new GlorotUniform()),\n    recurrentInitializer: serializeInitializer(new HeUniform()),\n    biasInitializer: serializeInitializer(new Ones()),\n    kernelRegularizer: serializeRegularizer(new L1L2()),\n    recurrentRegularizer: serializeRegularizer(new L1L2()),\n    biasRegularizer: serializeRegularizer(new L1L2()),\n    activityRegularizer: serializeRegularizer(null),\n    kernelConstraint: serializeConstraint(new UnitNorm({})),\n    recurrentConstraint: serializeConstraint(new UnitNorm({})),\n    biasConstraint: serializeConstraint(new NonNeg()),\n    implementation: 1,\n    resetAfter: false,\n  };\n\n  describe('GRUCell.getConfig', () => {\n    it('should return the expected values', () => {\n      const cell = tfl.layers.gruCell(cellConfig);\n\n      const {dropout, recurrentDropout, ...configPrime} = cell.getConfig();\n\n      expect(configPrime).toEqual(expectedCellConfigPrime);\n      expect(dropout).toBeCloseTo(0.1);\n      expect(recurrentDropout).toBeCloseTo(0.2);\n    });\n  });\n\n  describe('GRU.getConfig', () => {\n    it('should return the expected values', () => {\n      const config: GRULayerArgs = {\n        ...cellConfig,\n        name: 'layer_1',\n        ...{\n          returnSequences: true,\n          returnState: true,\n          stateful: true,\n          unroll: true,\n          goBackwards: true,\n          inputDim: 8,\n          inputLength: 8,\n        } as Omit<GRULayerArgs, keyof GRUCellLayerArgs>\n      };\n\n      const cell = tfl.layers.gru(config);\n\n      const {dropout, recurrentDropout, ...configPrime} = cell.getConfig();\n\n      expect(configPrime).toEqual({\n        ...expectedCellConfigPrime,\n        name: 'layer_1',\n        returnSequences: true,\n        returnState: true,\n        stateful: true,\n        unroll: true,\n        goBackwards: true,\n      });\n      expect(dropout).toBeCloseTo(0.1);\n      expect(recurrentDropout).toBeCloseTo(0.2);\n    });\n  });\n});\n\ndescribeMathCPU('LSTM Symbolic', () => {\n  it('returnSequences=false, returnState=false', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const lstm = tfl.layers.lstm({units: 5});\n    const output = lstm.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([9, 5]);\n  });\n\n  it('returnSequences=false, returnState=true', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const lstm = tfl.layers.lstm({units: 5, returnState: true});\n    const output = lstm.apply(input) as tfl.SymbolicTensor[];\n    expect(output.length).toEqual(3);\n    expect(output[0].shape).toEqual([9, 5]);\n    expect(output[1].shape).toEqual([9, 5]);\n    expect(output[2].shape).toEqual([9, 5]);\n  });\n\n  it('returnSequences=true, returnState=false', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const lstm = tfl.layers.lstm({units: 5, returnSequences: true});\n    const output = lstm.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([9, 10, 5]);\n  });\n\n  it('returnSequences=true, returnState=true', () => {\n    const input = new tfl.SymbolicTensor('float32', [9, 10, 8], null, [], null);\n    const lstm = tfl.layers.lstm({\n      units: 5,\n      returnSequences: true,\n      returnState: true,\n    });\n    const output = lstm.apply(input) as tfl.SymbolicTensor[];\n    expect(output.length).toEqual(3);\n    expect(output[0].shape).toEqual([9, 10, 5]);\n    expect(output[1].shape).toEqual([9, 5]);\n    expect(output[2].shape).toEqual([9, 5]);\n  });\n\n  it('trainableWeights, nonTrainableWeights and weights give correct outputs',\n     () => {\n       const input =\n           new tfl.SymbolicTensor('float32', [2, 3, 4], null, [], null);\n       const lstm = tfl.layers.lstm({units: 5, returnState: true});\n       lstm.apply(input);\n       expect(lstm.trainable).toEqual(true);\n       // Trainable weights: kernel, recurrent kernel and bias.\n       expect(lstm.trainableWeights.length).toEqual(3);\n       expect(lstm.nonTrainableWeights.length).toEqual(0);\n       expect(lstm.weights.length).toEqual(3);\n     });\n\n  for (const implementation of [1, 2]) {\n    it('Serialization round trip', () => {\n      const layer = tfl.layers.lstm({units: 4, implementation});\n      const pythonicConfig = convertTsToPythonic(layer.getConfig());\n      // tslint:disable-next-line:no-any\n      const tsConfig = convertPythonicToTs(pythonicConfig) as any;\n      const layerPrime = tfl.layers.lstm(tsConfig);\n      expect(layerPrime.getConfig().units).toEqual(4);\n      expect(layerPrime.getConfig().implementation).toEqual(implementation);\n    });\n  }\n\n  it('LSTM Cells save and load', async () => {\n    const inputShape = [2, 3];\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense({units: 1, inputShape}));\n    const cells = [\n      tfl.layers.lstmCell({units: 3}),\n      tfl.layers.lstmCell({units: 4}),\n    ];\n    const rnn = tfl.layers.rnn({cell: cells, returnSequences: true});\n    model.add(rnn);\n\n    const numExamples = 5;\n    const xs = randomNormal([numExamples].concat(inputShape));\n    const ys = model.predict(xs) as Tensor;\n\n    let savedArtifacts: io.ModelArtifacts;\n    await model.save(tfc.io.withSaveHandler(async (artifacts) => {\n      savedArtifacts = artifacts;\n      return null;\n    }));\n\n    const loadedModel =\n        await tfl.loadLayersModel(tfc.io.fromMemory(savedArtifacts));\n\n    expect(model.inputs[0].shape).toEqual(loadedModel.inputs[0].shape);\n    expect(model.outputs[0].shape).toEqual(loadedModel.outputs[0].shape);\n    expectTensorsClose(loadedModel.predict(xs) as Tensor, ys);\n  });\n\n  it('Invalid units leads to Error', () => {\n    expect(() => tfl.layers.lstm({\n      units: 12.5\n    })).toThrowError(/units.*positive integer.*12\\.5\\.$/);\n    expect(() => tfl.layers.lstm({\n      units: 0\n    })).toThrowError(/units.*positive integer.*0\\.$/);\n    expect(() => tfl.layers.lstm({\n      units: -25\n    })).toThrowError(/units.*positive integer.*-25\\.$/);\n  });\n});\n\ndescribeMathCPUAndGPU('LSTM Tensor', () => {\n  // Note:\n  // The golden expected values used for assertions in these unit tests can be\n  // obtained through running the Python code similar to the following\n  // example. TensorFlow 1.5 was used to obtain the values.\n  //\n  // ```python\n  // import numpy as np\n  // import tensorflow as tf\n  //\n  // units = 5\n  // batch_size = 4\n  // input_size = 2\n  // time_steps = 2\n  //\n  // with tf.Session() as sess:\n  //   lstm = tf.keras.layers.LSTM(units,\n  //                               kernel_initializer=\"ones\",\n  //                               recurrent_initializer=\"ones\",\n  //                               bias_initializer=\"ones\",\n  //                               return_sequences=True,\n  //                               return_state=True,\n  //                               unit_forget_bias=True)\n  //   inputs = tf.placeholder(tf.float32, shape=[None, None, input_size])\n  //   outputs = lstm(inputs)\n  //\n  //   sess.run(tf.global_variables_initializer())\n  //   feed_inputs = np.ones([batch_size, time_steps, input_size])\n  //   print(sess.run(outputs, feed_dict={inputs: feed_inputs}))\n  // ```\n\n  const units = 5;\n  const batchSize = 4;\n  const inputSize = 2;\n  const timeSteps = 2;\n\n  // TODO(cais): Add test for the default recurrent initializer ('Orthogonal')\n  //   when it becomes available.\n\n  const dropouts = [0.0, 0.1];\n  const trainings = [true, false];\n  for (const training of trainings) {\n    for (const dropout of dropouts) {\n      const testTitle =\n          `returnSequences=false, returnState=false, useBias=true,` +\n          ` ${training}, dropout=${dropout}`;\n      it(testTitle, () => {\n        const lstm = tfl.layers.lstm({\n          units,\n          kernelInitializer: 'ones',\n          recurrentInitializer: 'ones',\n          biasInitializer: 'ones',\n          dropout,\n          implementation: 1\n        });\n        const kwargs: Kwargs = {};\n        if (training) {\n          kwargs['training'] = true;\n        }\n        const input = tfc.ones([batchSize, timeSteps, inputSize]);\n        spyOn(tfc, 'dropout').and.callThrough();\n        let numTensors = 0;\n        for (let i = 0; i < 2; i++) {\n          tfc.dispose(lstm.apply(input, kwargs) as Tensor);\n          if (dropout !== 0.0 && training) {\n            expect(tfc.dropout).toHaveBeenCalledTimes(4 * (i + 1));\n          } else {\n            expect(tfc.dropout).toHaveBeenCalledTimes(0);\n          }\n          if (i === 0) {\n            numTensors = tfc.memory().numTensors;\n          } else {\n            expect(tfc.memory().numTensors).toEqual(numTensors);\n          }\n        }\n      });\n    }\n  }\n\n  const recurrentDropouts = [0.0, 0.1];\n  for (const training of trainings) {\n    for (const recurrentDropout of recurrentDropouts) {\n      const testTitle =\n          `returnSequences=false, returnState=false, useBias=true,` +\n          ` ${training}, recurrentDropout=${recurrentDropout}`;\n      it(testTitle, () => {\n        const lstm = tfl.layers.lstm({\n          units,\n          kernelInitializer: 'ones',\n          recurrentInitializer: 'ones',\n          biasInitializer: 'ones',\n          recurrentDropout,\n          implementation: 1\n        });\n        const kwargs: Kwargs = {};\n        if (training) {\n          kwargs['training'] = true;\n        }\n        const input = tfc.ones([batchSize, timeSteps, inputSize]);\n        spyOn(tfc, 'dropout').and.callThrough();\n        let numTensors = 0;\n        for (let i = 0; i < 2; i++) {\n          tfc.dispose(lstm.apply(input, kwargs) as Tensor);\n          if (recurrentDropout !== 0.0 && training) {\n            expect(tfc.dropout).toHaveBeenCalledTimes(4 * (i + 1));\n          } else {\n            expect(tfc.dropout).toHaveBeenCalledTimes(0);\n          }\n          if (i === 0) {\n            numTensors = tfc.memory().numTensors;\n          } else {\n            expect(tfc.memory().numTensors).toEqual(numTensors);\n          }\n        }\n      });\n    }\n  }\n\n  const implementations: Array<(1 | 2)> = [1, 2];\n  const returnStateValues = [false, true];\n  const returnSequencesValues = [false, true];\n  for (const implementation of implementations) {\n    for (const returnState of returnStateValues) {\n      for (const returnSequences of returnSequencesValues) {\n        const testTitle = `implementation=${implementation}, ` +\n            `returnSequences=${returnSequences}, ` +\n            `returnState=${returnState}`;\n        it(testTitle, () => {\n          const lstm = tfl.layers.lstm({\n            units,\n            kernelInitializer: 'ones',\n            recurrentInitializer: 'ones',\n            biasInitializer: 'ones',\n            returnState,\n            returnSequences,\n            implementation\n          });\n          const input = tfc.ones([batchSize, timeSteps, inputSize]);\n          let output = lstm.apply(input);\n\n          // See comments at the beginning of this describe() block on how\n          // these golden expected values can be obtained.\n          const goldenOutputElementValueAtT0 = 0.7595095;\n          const goldenOutputElementValueAtT1 = 0.96367633;\n          const goldenHStateElementValue = goldenOutputElementValueAtT1;\n          const goldenCStateElementValue = 1.99505234;\n\n          let expectedOutput: Tensor;\n          if (returnSequences) {\n            const outputAtT0 = tfc.mul(\n                scalar(goldenOutputElementValueAtT0),\n                tfc.ones([1, batchSize, units]));\n            const outputAtT1 = tfc.mul(\n                scalar(goldenOutputElementValueAtT1),\n                tfc.ones([1, batchSize, units]));\n            expectedOutput = tfc.transpose(\n                K.concatAlongFirstAxis(outputAtT0, outputAtT1), [1, 0, 2]);\n          } else {\n            expectedOutput = tfc.mul(\n                scalar(goldenOutputElementValueAtT1),\n                tfc.ones([batchSize, units]));\n          }\n          if (returnState) {\n            output = output as Tensor[];\n            expect(output.length).toEqual(3);\n            expectTensorsClose(output[0], expectedOutput);\n            expectTensorsClose(\n                output[1],\n                tfc.mul(\n                    scalar(goldenHStateElementValue),\n                    tfc.ones([batchSize, units])));\n            expectTensorsClose(\n                output[2],\n                tfc.mul(\n                    scalar(goldenCStateElementValue),\n                    tfc.ones([batchSize, units])));\n          } else {\n            output = output as Tensor;\n            expectTensorsClose(output, expectedOutput);\n          }\n        });\n      }\n    }\n\n    // The reference values below can be obtained with PyKeras code:\n    // ```python\n    // import keras\n    // import numpy as np\n    //\n    // units = 5\n    // batch_size = 4\n    // input_size = 2\n    // sequence_length = 3\n    //\n    // rnn = keras.layers.LSTM(units,\n    //                         kernel_initializer='ones',\n    //                         recurrent_initializer='ones',\n    //                         bias_initializer='ones',\n    //                         stateful=True,\n    //                         batch_input_shape=[batch_size,\n    //                                            sequence_length,\n    //                                            input_size])\n    //\n    // x = np.ones([batch_size, sequence_length, input_size])\n    //\n    // model = keras.Sequential()\n    // model.add(rnn)\n    // print(model.predict(x))\n    // print(model.predict(x))\n    // model.reset_states()\n    // print(model.predict(x))\n    // print(model.predict(x))\n    // ```\n    it('stateful forward', async () => {\n      const sequenceLength = 3;\n      const rnn = tfl.layers.lstm({\n        units,\n        kernelInitializer: 'ones',\n        recurrentInitializer: 'ones',\n        biasInitializer: 'ones',\n        stateful: true,\n        batchInputShape: [batchSize, sequenceLength, inputSize]\n      });\n      const model = tfl.sequential();\n      model.add(rnn);\n      const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n\n      let y1 = model.predict(x) as Tensor;\n      expect(y1.kept).toBe(false);\n      let y1Expected =\n          tfc.tidy(() => tfc.ones([batchSize, units]).mul(tfc.scalar(0.995)));\n      expectTensorsClose(y1, y1Expected);\n      let y2 = model.predict(x) as Tensor;\n      expect(y2.kept).toBe(false);\n      // Future predicts should not dispose previous outputs.\n      expect(y1.isDisposed).toBe(false);\n      let y2Expected = tfc.tidy(\n          () => tfc.ones([batchSize, units]).mul(tfc.scalar(0.99998766)));\n      expectTensorsClose(y2, y2Expected);\n\n      tfc.dispose([y1, y2, y1Expected, y2Expected]);\n      model.resetStates();\n      const numTensors0 = tfc.memory().numTensors;\n\n      y1 = model.predict(x) as Tensor;\n      expect(y1.kept).toBe(false);\n      y1Expected =\n          tfc.tidy(() => tfc.ones([batchSize, units]).mul(tfc.scalar(0.995)));\n      expectTensorsClose(y1, y1Expected);\n      y2 = model.predict(x) as Tensor;\n      expect(y2.kept).toBe(false);\n      // Future predicts should not dispose previous outputs.\n      expect(y1.isDisposed).toBe(false);\n      y2Expected = tfc.tidy(\n          () => tfc.ones([batchSize, units]).mul(tfc.scalar(0.99998766)));\n      expectTensorsClose(y2, y2Expected);\n      tfc.dispose([y1, y2, y1Expected, y2Expected]);\n      // Assert no memory leak, even without resetStates() being called.\n      expect(tfc.memory().numTensors).toEqual(numTensors0);\n    });\n\n    // The reference values can be obtained with the following PyKeras code:\n    // ```python\n    // import keras\n    // import numpy as np\n    //\n    // batch_size = 4\n    // sequence_length = 3\n    // input_size = 2\n    //\n    // model = keras.Sequential()\n    // model.add(keras.layers.LSTM(\n    //     5,\n    //     batch_input_shape=[batch_size, sequence_length, input_size],\n    //     kernel_initializer='ones',\n    //     recurrent_initializer='ones',\n    //     bias_initializer='ones',\n    //     stateful=True))\n    // model.add(keras.layers.Dense(1,\n    //                              kernel_initializer='ones',\n    //                              use_bias=False))\n    // model.compile(loss='mean_squared_error', optimizer='sgd')\n    //\n    // xs_1 = np.ones([batch_size, sequence_length, input_size])\n    // xs_2 = np.ones([batch_size, sequence_length, input_size])\n    // xs = np.concatenate([xs_1, xs_2], 0)\n    // ys = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])\n    //\n    // history = model.fit(xs, ys, batch_size=batch_size, shuffle=False)\n    // print(history.history)\n    // ```\n    it('stateful BPTT', async () => {\n      const sequenceLength = 3;\n      const model = tfl.sequential();\n      model.add(tfl.layers.lstm({\n        units,\n        kernelInitializer: 'ones',\n        recurrentInitializer: 'ones',\n        biasInitializer: 'ones',\n        stateful: true,\n        batchInputShape: [batchSize, sequenceLength, inputSize]\n      }));\n      model.add(tfl.layers.dense(\n          {units: 1, kernelInitializer: 'ones', useBias: false}));\n      model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n      const xs1 = tfc.ones([batchSize, sequenceLength, inputSize]);\n      const xs2 = tfc.ones([batchSize, sequenceLength, inputSize]);\n      const xs = tfc.concat([xs1, xs2], 0);\n      const ys = tfc.tensor2d([[1], [2], [3], [4], [5], [6], [7], [8]]);\n\n      const history = await model.fit(xs, ys, {batchSize, shuffle: false});\n      // See code snippet above for the code used to obtain this loss value.\n      expect(history.history.loss[0]).toBeCloseTo(5.8377);\n    });\n\n    it('BPTT', async () => {\n      // The following golden values for assertion can be obtained with the\n      // following Python Keras code.\n      // ```python\n      // import keras\n      // import numpy as np\n      //\n      // sequence_length = 3\n      // input_size = 4\n      // batch_size = 5\n      //\n      // t_input = keras.Input([sequence_length, input_size])\n      // lstm = keras.layers.LSTM(1,\n      //                          kernel_initializer='zeros',\n      //                          recurrent_initializer='zeros',\n      //                          use_bias=False)\n      // dense = keras.layers.Dense(1,\n      //                            kernel_initializer='ones',\n      //                            use_bias=False)\n      // output = dense(lstm(t_input))\n      // model = keras.Model(t_input, output)\n      // optimizer = keras.optimizers.SGD(1)\n      // model.compile(optimizer=optimizer, loss='mean_squared_error')\n      //\n      // x = np.ones([batch_size, sequence_length, input_size])\n      // y = np.ones([batch_size, 1])\n      // model.fit(x, y, batch_size=batch_size, epochs=2)\n      // print(lstm.get_weights()[0])\n      // print(lstm.get_weights()[1])\n      // print(dense.get_weights()[0])\n      // ```\n      const sequenceLength = 3;\n      const inputSize = 4;\n      const batchSize = 5;\n      const model = tfl.sequential();\n      model.add(tfl.layers.lstm({\n        units: 1,\n        kernelInitializer: 'zeros',\n        recurrentInitializer: 'zeros',\n        useBias: false,\n        inputShape: [sequenceLength, inputSize]\n      }));\n      model.add(tfl.layers.dense({\n        units: 1,\n        kernelInitializer: 'ones',\n        useBias: false,\n      }));\n\n      const sgd = tfc.train.sgd(1);\n      model.compile({loss: 'meanSquaredError', optimizer: sgd});\n\n      const x = tfc.ones([batchSize, sequenceLength, inputSize]);\n      const y = tfc.ones([batchSize, 1]);\n      await model.fit(x, y, {epochs: 2});\n\n      expectTensorsClose(\n          model.layers[0].getWeights()[0],\n          K.tile(\n              tensor2d(\n                  [[0.11455188, 0.06545822, 0.8760446, 0.18237013]], [1, 4]),\n              [4, 1]));\n      expectTensorsClose(\n          model.layers[0].getWeights()[1],\n          tensor2d([[0.02831176, 0.01934617, 0.00025817, 0.05784169]], [1, 4]));\n      expectTensorsClose(\n          model.layers[1].getWeights()[0], tensor2d([[1.4559253]], [1, 1]));\n    });\n  }\n\n  // Reference Python code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.Embedding(10,\n  //                                  4,\n  //                                  input_length=6,\n  //                                  mask_zero=True,\n  //                                  embeddings_initializer='ones'))\n  // model.add(keras.layers.LSTM(3,\n  //                             recurrent_initializer='ones',\n  //                             kernel_initializer='ones',\n  //                             bias_initializer='zeros'))\n  // model.add(keras.layers.Dense(1,\n  //                              kernel_initializer='ones',\n  //                              bias_initializer='zero'))\n  //\n  // xs = np.array([[0, 0, 0, 0, 0, 0],\n  //                [1, 0, 0, 0, 0, 0],\n  //                [1, 2, 0, 0, 0, 0],\n  //                [1, 2, 3, 0, 0, 0]])\n  // ys = model.predict(xs)\n  // print(ys)\n  // ```\n  it('With mask', () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.embedding({\n      inputDim: 10,\n      outputDim: 4,\n      inputLength: 6,\n      maskZero: true,\n      embeddingsInitializer: 'ones'\n    }));\n    model.add(tfl.layers.lstm({\n      units: 3,\n      recurrentInitializer: 'ones',\n      kernelInitializer: 'ones',\n      biasInitializer: 'zeros'\n    }));\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'ones', biasInitializer: 'zeros'}));\n\n    const xs = tensor2d([\n      [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [1, 2, 0, 0, 0, 0],\n      [1, 2, 3, 0, 0, 0]\n    ]);\n    const ys = model.predict(xs) as Tensor;\n    expectTensorsClose(\n        ys, tensor2d([[0], [2.283937], [2.891939], [2.9851441]]));\n  });\n\n  // Reference Python code:\n  // ```py\n  // import keras\n  //\n  // model = keras.Sequential()\n  // embedding_layer = keras.layers.Embedding(4,\n  //                                          2,\n  //                                          input_length=3,\n  //                                          mask_zero=True)\n  // model.add(embedding_layer)\n  // lstm_layer = keras.layers.LSTM(2, go_backwards=True)\n  // model.add(lstm_layer)\n  // model.add(keras.layers.Dense(1,\n  //                              kernel_initializer='ones',\n  //                              bias_initializer='zero'))\n  //\n  // embedding_layer.set_weights([\n  //     np.array([[0.1, 0.2], [0.3, 0.4], [-0.1, -0.2], [-0.3, -0.4]])])\n  // print(lstm_layer.get_weights())\n  // lstm_layer.set_weights([\n  //     np.array([[1, 2, 3, 4, 5, 6, 7, 8],\n  //               [-1, -2, -3, -4, -5, -6, -7, -8]]),\n  //     np.array([[1, 2, 3, 4, 5, 6, 7, 8],\n  //               [-1, -2, -3, -4, -5, -6, -7, -8]]),\n  //     np.array([1, 2, 3, 4, 5, 6, 7, 8])])\n  //\n  // xs = np.array([[0, 0, 0],\n  //                [1, 0, 0],\n  //                [1, 2, 0],\n  //                [1, 2, 3]])\n  // ys = model.predict(xs)\n  // print(ys)\n  // ```\n  it('With mask, goBackwards = true', () => {\n    const model = tfl.sequential();\n    const embeddingLayer = tfl.layers.embedding(\n        {inputDim: 4, outputDim: 2, inputLength: 3, maskZero: true});\n    model.add(embeddingLayer);\n    const lstmLayer = tfl.layers.lstm({units: 2, goBackwards: true});\n    model.add(lstmLayer);\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'ones', biasInitializer: 'zeros'}));\n\n    // Setting weights to asymmetric, so that the effect of goBackwards=true\n    // can show.\n    embeddingLayer.setWeights(\n        [tensor2d([[0.1, 0.2], [0.3, 0.4], [-0.1, -0.2], [-0.3, -0.4]])]);\n    lstmLayer.setWeights([\n      tensor2d([[1, 2, 3, 4, 5, 6, 7, 8], [-1, -2, -3, -4, -5, -6, -7, -8]]),\n      tensor2d([[1, 2, 3, 4, 5, 6, 7, 8], [-1, -2, -3, -4, -5, -6, -7, -8]]),\n      tensor1d([1, 2, 3, 4, 5, 6, 7, 8])\n    ]);\n\n    const xs = tensor2d([[0, 0, 0], [1, 0, 0], [1, 2, 0], [1, 2, 3]]);\n    const ys = model.predict(xs) as Tensor;\n    expectTensorsClose(\n        ys, tensor2d([[0], [1.2876499], [1.8165315], [1.9599037]]));\n  });\n\n  // Reference Python code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.Reshape(target_shape=[6], input_shape=[6]))\n  // nested_model = keras.Sequential()\n  // nested_model.add(keras.layers.Embedding(10,\n  //                                         4,\n  //                                         input_length=6,\n  //                                         mask_zero=True,\n  //                                         embeddings_initializer='ones'))\n  // nested_model.add(keras.layers.LSTM(3,\n  //                                    recurrent_initializer='ones',\n  //                                    kernel_initializer='ones',\n  //                                    bias_initializer='zeros'))\n  // model.add(nested_model)\n  // model.add(keras.layers.Dense(1,\n  //                              kernel_initializer='ones',\n  //                              bias_initializer='zero'))\n  // model.compile(loss='mean_squared_error', optimizer='sgd')\n  //\n  // xs = np.array([[0, 0, 0, 0, 0, 0],\n  //               [1, 0, 0, 0, 0, 0],\n  //               [1, 2, 0, 0, 0, 0],\n  //               [1, 2, 3, 0, 0, 0]])\n  // ys = model.predict(xs)\n  // print(ys)\n  // ```\n  it('With mask and a nested model', () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.reshape(\n        {targetShape: [6], inputShape: [6]}));  // A dummy input layer.\n    const nestedModel = tfl.sequential();\n    nestedModel.add(tfl.layers.embedding({\n      inputDim: 10,\n      outputDim: 4,\n      inputLength: 6,\n      maskZero: true,\n      embeddingsInitializer: 'ones'\n    }));\n    nestedModel.add(tfl.layers.lstm({\n      units: 3,\n      recurrentInitializer: 'ones',\n      kernelInitializer: 'ones',\n      biasInitializer: 'zeros'\n    }));\n    model.add(nestedModel);\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'ones', biasInitializer: 'zeros'}));\n\n    const xs = tensor2d([\n      [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [1, 2, 0, 0, 0, 0],\n      [1, 2, 3, 0, 0, 0]\n    ]);\n    const ys = model.predict(xs) as Tensor;\n    expectTensorsClose(\n        ys, tensor2d([[0], [2.283937], [2.891939], [2.9851441]]));\n  });\n\n  // Reference Python code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.Embedding(10,\n  //                                  4,\n  //                                  input_length=6,\n  //                                  mask_zero=True,\n  //                                 embeddings_initializer='ones'))\n  // model.add(keras.layers.LSTM(3,\n  //                             recurrent_initializer='ones',\n  //                             kernel_initializer='ones',\n  //                             bias_initializer='zeros'))\n  // model.add(keras.layers.Dense(1,\n  //                             kernel_initializer='ones',\n  //                             bias_initializer='zero'))\n  // model.compile(loss='mean_squared_error', optimizer='sgd')\n  //\n  // xs = np.array([[0, 0, 0, 0, 0, 0],\n  //               [1, 0, 0, 0, 0, 0],\n  //               [1, 2, 0, 0, 0, 0],\n  //               [1, 2, 3, 0, 0, 0]])\n  // ys = np.array([[1], [2], [3], [4]])\n  //\n  // model.fit(xs, ys, epochs=2, batch_size=4)\n  // history = model.fit(xs, ys, epochs=2, batch_size=4)\n  // print(history.history)\n  // ```\n  it('BPTT with mask: correctness and no leak', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.embedding({\n      inputDim: 10,\n      outputDim: 4,\n      inputLength: 6,\n      maskZero: true,\n      embeddingsInitializer: 'ones'\n    }));\n    model.add(tfl.layers.lstm({\n      units: 3,\n      recurrentInitializer: 'ones',\n      kernelInitializer: 'ones',\n      biasInitializer: 'zeros'\n    }));\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'ones', biasInitializer: 'zeros'}));\n    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n\n    const xs = tensor2d([\n      [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [1, 2, 0, 0, 0, 0],\n      [1, 2, 3, 0, 0, 0]\n    ]);\n    const ys = tensor2d([[1], [2], [3], [4]]);\n\n    // Serves as burn-in call for subsequent tracking of memory leak.\n    await model.fit(xs, ys, {epochs: 2, batchSize: 4});\n\n    const numTensors0 = tfc.memory().numTensors;\n    const history = await model.fit(xs, ys, {epochs: 2, batchSize: 4});\n    const numTensors1 = tfc.memory().numTensors;\n    // Assert no memory leak.\n    expect(numTensors1).toEqual(numTensors0);\n    expect(history.history.loss.length).toEqual(2);\n    expect(history.history.loss[0]).toBeCloseTo(0.503677);\n    expect(history.history.loss[1]).toBeCloseTo(0.492173);\n  });\n\n  // Reference Python code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // inp = keras.Input(shape=[6])\n  // y = keras.layers.Embedding(10,\n  //                            4,\n  //                            input_length=6,\n  //                            mask_zero=True,\n  //                            embeddings_initializer='ones')(inp)\n  // y = keras.layers.LSTM(3,\n  //                       return_state=True,\n  //                       recurrent_initializer='ones',\n  //                       kernel_initializer='ones',\n  //                       bias_initializer='zeros')(y)\n  //\n  // model = keras.Model(inputs=inp, outputs=y)\n  //\n  // xs = np.array([[0, 0, 0, 0, 0, 0],\n  //                [1, 0, 0, 0, 0, 0],\n  //                [1, 2, 0, 0, 0, 0],\n  //                [1, 2, 3, 0, 0, 0]])\n  // ys = model.predict(xs)\n  // print(ys)\n  // ```\n  it('With mask, returnStates = true', () => {\n    const inp = tfl.input({shape: [6]});\n    let y: tfl.SymbolicTensor|tfl.SymbolicTensor[] =\n        tfl.layers\n            .embedding({\n              inputDim: 10,\n              outputDim: 4,\n              inputLength: 6,\n              maskZero: true,\n              embeddingsInitializer: 'ones'\n            })\n            .apply(inp) as tfl.SymbolicTensor;\n    y = tfl.layers\n            .lstm({\n              units: 3,\n              returnState: true,\n              recurrentInitializer: 'ones',\n              kernelInitializer: 'ones',\n              biasInitializer: 'zeros'\n            })\n            .apply(y) as tfl.SymbolicTensor[];\n    const model = tfl.model({inputs: inp, outputs: y});\n    const xs = tensor2d([\n      [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [1, 2, 0, 0, 0, 0],\n      [1, 2, 3, 0, 0, 0]\n    ]);\n    const ys = model.predict(xs) as Tensor[];\n    expect(ys.length).toEqual(3);\n    expectTensorsClose(ys[0], tensor2d([\n                         [0, 0, 0], [0.76131237, 0.76131237, 0.76131237],\n                         [0.9639796, 0.9639796, 0.9639796],\n                         [0.99504817, 0.99504817, 0.99504817]\n                       ]));\n    expectTensorsClose(ys[1], tensor2d([\n                         [0, 0, 0], [0.76131237, 0.76131237, 0.76131237],\n                         [0.9639796, 0.9639796, 0.9639796],\n                         [0.99504817, 0.99504817, 0.99504817]\n                       ]));\n    expectTensorsClose(\n        ys[2], tensor2d([\n          [0, 0, 0], [0.9993292, 0.9993292, 0.9993292],\n          [1.9993222, 1.9993222, 1.9993222], [2.9993203, 2.9993203,　2.9993203]\n        ]));\n  });\n\n  // Referernce Python code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.Embedding(10,\n  //                                 4,\n  //                                 input_length=3,\n  //                                 mask_zero=True,\n  //                                 embeddings_initializer='ones'))\n  // model.add(keras.layers.LSTM(3,\n  //                             return_sequences=True,\n  //                             recurrent_initializer='ones',\n  //                             kernel_initializer='ones',\n  //                             bias_initializer='zeros'))\n  // model.add(keras.layers.Dense(1,\n  //                             kernel_initializer='ones',\n  //                             bias_initializer='zeros'))\n  //\n  // xs = np.array([[0, 0, 0],\n  //               [1, 0, 0],\n  //               [1, 2, 0],\n  //               [1, 2, 3]])\n  // ys = model.predict(xs)\n  // print(ys)\n  // ```\n  it('With mask, returnSequences = true', () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.embedding({\n      inputDim: 10,\n      outputDim: 4,\n      inputLength: 3,\n      maskZero: true,\n      embeddingsInitializer: 'ones'\n    }));\n    model.add(tfl.layers.lstm({\n      units: 3,\n      returnSequences: true,\n      recurrentInitializer: 'ones',\n      kernelInitializer: 'ones',\n      biasInitializer: 'zeros'\n    }));\n    model.add(tfl.layers.dense(\n        {units: 1, kernelInitializer: 'ones', biasInitializer: 'zeros'}));\n\n    const xs = tensor2d([[0, 0, 0], [1, 0, 0], [1, 2, 0], [1, 2, 3]]);\n    const ys = model.predict(xs) as Tensor;\n    expectTensorsClose(ys, tensor3d([\n                         [[0], [0], [0]], [[2.283937], [2.283937], [2.283937]],\n                         [[2.283937], [2.8919387], [2.8919387]],\n                         [[2.283937], [2.8919387], [2.9851446]]\n                       ]));\n  });\n\n  // Reference Python code:\n  // ```py\n  // import keras\n  // import numpy as np\n  //\n  // model = keras.Sequential()\n  // model.add(keras.layers.Embedding(10,\n  //                                  4,\n  //                                  input_length=3,\n  //                                  mask_zero=True,\n  //                                  embeddings_initializer='ones'))\n  // model.add(keras.layers.SimpleRNN(3,\n  //                                  return_sequences=True,\n  //                                  recurrent_initializer='ones',\n  //                                  kernel_initializer='ones',\n  //                                  bias_initializer='zeros'))\n  // model.add(keras.layers.LSTM(3,\n  //                             recurrent_initializer='ones',\n  //                             kernel_initializer='ones',\n  //                             bias_initializer='zeros'))\n  //\n  // xs = np.array([[0, 0, 0],\n  //                [1, 0, 0],\n  //                [1, 2, 0],\n  //                [1, 2, 3]])\n  // ys = model.predict(xs)\n  // print(ys)\n  // ```\n  it('Stacked RNNs with masking: correctness and no leak', () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.embedding({\n      inputDim: 10,\n      outputDim: 4,\n      inputLength: 3,\n      maskZero: true,\n      embeddingsInitializer: 'ones'\n    }));\n    model.add(tfl.layers.simpleRNN({\n      units: 3,\n      returnSequences: true,\n      recurrentInitializer: 'ones',\n      kernelInitializer: 'ones',\n      biasInitializer: 'zeros'\n    }));\n    model.add(tfl.layers.lstm({\n      units: 3,\n      recurrentInitializer: 'ones',\n      kernelInitializer: 'ones',\n      biasInitializer: 'zeros'\n    }));\n\n    const xs = tensor2d([[0, 0, 0], [1, 0, 0], [1, 2, 0], [1, 2, 3]]);\n\n    // Burn-in call for subsequent memory leak check.\n    model.predict(xs);\n\n    const numTensors0 = tfc.memory().numTensors;\n    const ys = model.predict(xs) as Tensor;\n    const numTensors1 = tfc.memory().numTensors;\n    expectTensorsClose(ys, tensor2d([\n                         [0, 0, 0], [0.75950104, 0.75950104, 0.75950104],\n                         [0.96367145, 0.96367145, 0.96367145],\n                         [0.9950049, 0.9950049, 0.9950049]\n                       ]));\n    ys.dispose();\n    // Assert no memory leak.\n    expect(numTensors1).toEqual(numTensors0 + 1);\n  });\n});\n\ndescribeMathCPU('LSTM-deserialization', () => {\n  it('modelFromConfig', async () => {\n    const model = await modelFromJSON(fakeLSTMModel);\n    const encoderInputs = tfc.zeros([1, 3, 71], 'float32');\n    const decoderInputs = tfc.zeros([1, 3, 94], 'float32');\n    const outputs = model.predict([encoderInputs, decoderInputs]) as Tensor;\n    expect(outputs.shape).toEqual([1, 3, 94]);\n  });\n\n  it('Default recurrentActivation round trip', () => {\n    const x = randomNormal([1, 2, 3]);\n    const layer = tfl.layers.lstm({units: 4});\n    const y = layer.apply(x) as Tensor;\n    const pythonicConfig = convertTsToPythonic(layer.getConfig());\n    // tslint:disable-next-line:no-any\n    const tsConfig = convertPythonicToTs(pythonicConfig) as any;\n    const layerPrime = tfl.layers.lstm(tsConfig);\n    const yPrime = layer.apply(x) as Tensor;\n    expectTensorsClose(yPrime, y);\n    expect(layerPrime.getConfig()['recurrentActivation'])\n        .toEqual(layer.getConfig()['recurrentActivation']);\n  });\n\n  it('Non-default recurrentActivation round trip', () => {\n    const x = randomNormal([1, 2, 3]);\n    const layer =\n        tfl.layers.lstm({units: 4, recurrentActivation: 'tanh'});\n    const y = layer.apply(x) as Tensor;\n    const pythonicConfig = convertTsToPythonic(layer.getConfig());\n    // tslint:disable-next-line:no-any\n    const tsConfig = convertPythonicToTs(pythonicConfig) as any;\n    const layerPrime = tfl.layers.lstm(tsConfig);\n    const yPrime = layer.apply(x) as Tensor;\n    expectTensorsClose(yPrime, y);\n    expect(layerPrime.getConfig()['recurrentActivation'])\n        .toEqual(layer.getConfig()['recurrentActivation']);\n  });\n});\n\nconst fakeLSTMModel: ModelAndWeightsConfig = {\n  modelTopology: {\n    'class_name': 'Model',\n    'keras_version': '2.1.2',\n    'config': {\n      'layers': [\n        {\n          'class_name': 'InputLayer',\n          'config': {\n            'dtype': 'float32',\n            'batch_input_shape': [null, null, 71],\n            'name': 'input_1',\n            'sparse': false\n          },\n          'inbound_nodes': [],\n          'name': 'input_1'\n        },\n        {\n          'class_name': 'InputLayer',\n          'config': {\n            'dtype': 'float32',\n            'batch_input_shape': [null, null, 94],\n            'name': 'input_2',\n            'sparse': false\n          },\n          'inbound_nodes': [],\n          'name': 'input_2'\n        },\n        {\n          'class_name': 'LSTM',\n          'config': {\n            'recurrent_activation': 'hard_sigmoid',\n            'trainable': true,\n            'recurrent_initializer': {\n              'class_name': 'VarianceScaling',\n              'config': {\n                'distribution': 'uniform',\n                'scale': 1.0,\n                'seed': null,\n                'mode': 'fan_avg'\n              }\n            },\n            'use_bias': true,\n            'bias_regularizer': null,\n            'return_state': true,\n            'unroll': false,\n            'activation': 'tanh',\n            'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n            'units': 256,\n            'unit_forget_bias': true,\n            'activity_regularizer': null,\n            'recurrent_dropout': 0.0,\n            'kernel_initializer': {\n              'class_name': 'VarianceScaling',\n              'config': {\n                'distribution': 'uniform',\n                'scale': 1.0,\n                'seed': null,\n                'mode': 'fan_avg'\n              }\n            },\n            'kernel_constraint': null,\n            'dropout': 0.0,\n            'stateful': false,\n            'recurrent_regularizer': null,\n            'name': 'lstm_1',\n            'bias_constraint': null,\n            'go_backwards': false,\n            'implementation': 1,\n            'kernel_regularizer': null,\n            'return_sequences': false,\n            'recurrent_constraint': null\n          },\n          'inbound_nodes': [[['input_1', 0, 0, {}]]],\n          'name': 'lstm_1'\n        },\n        {\n          'class_name': 'LSTM',\n          'config': {\n            'recurrent_activation': 'hard_sigmoid',\n            'trainable': true,\n            'recurrent_initializer': {\n              'class_name': 'VarianceScaling',\n              'config': {\n                'distribution': 'uniform',\n                'scale': 1.0,\n                'seed': null,\n                'mode': 'fan_avg'\n              }\n            },\n            'use_bias': true,\n            'bias_regularizer': null,\n            'return_state': true,\n            'unroll': false,\n            'activation': 'tanh',\n            'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n            'units': 256,\n            'unit_forget_bias': true,\n            'activity_regularizer': null,\n            'recurrent_dropout': 0.0,\n            'kernel_initializer': {\n              'class_name': 'VarianceScaling',\n              'config': {\n                'distribution': 'uniform',\n                'scale': 1.0,\n                'seed': null,\n                'mode': 'fan_avg'\n              }\n            },\n            'kernel_constraint': null,\n            'dropout': 0.0,\n            'stateful': false,\n            'recurrent_regularizer': null,\n            'name': 'lstm_2',\n            'bias_constraint': null,\n            'go_backwards': false,\n            'implementation': 1,\n            'kernel_regularizer': null,\n            'return_sequences': true,\n            'recurrent_constraint': null\n          },\n          'inbound_nodes': [\n            [['input_2', 0, 0, {}], ['lstm_1', 0, 1, {}], ['lstm_1', 0, 2, {}]]\n          ],\n          'name': 'lstm_2'\n        },\n        {\n          'class_name': 'Dense',\n          'config': {\n            'kernel_initializer': {\n              'class_name': 'VarianceScaling',\n              'config': {\n                'distribution': 'uniform',\n                'scale': 1.0,\n                'seed': null,\n                'mode': 'fan_avg'\n              }\n            },\n            'name': 'dense_1',\n            'kernel_constraint': null,\n            'bias_regularizer': null,\n            'bias_constraint': null,\n            'activation': 'softmax',\n            'trainable': true,\n            'kernel_regularizer': null,\n            'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n            'units': 94,\n            'use_bias': true,\n            'activity_regularizer': null\n          },\n          'inbound_nodes': [[['lstm_2', 0, 0, {}]]],\n          'name': 'dense_1'\n        }\n      ],\n      'input_layers': [['input_1', 0, 0], ['input_2', 0, 0]],\n      'output_layers': [['dense_1', 0, 0]],\n      'name': 'model_1'\n    },\n    'backend': 'tensorflow'\n  }\n};\n\ndescribeMathCPU('LSTM Serialization', () => {\n  const cellConfig: LSTMCellLayerArgs = {\n    units: 8,\n    activation: 'tanh',\n    recurrentActivation: 'tanh',\n    useBias: true,\n    kernelInitializer: 'glorotUniform',\n    recurrentInitializer: 'heUniform',\n    biasInitializer: 'ones',\n    kernelRegularizer: 'l1l2',\n    recurrentRegularizer: 'l1l2',\n    biasRegularizer: 'l1l2',\n    kernelConstraint: 'unitNorm',\n    recurrentConstraint: 'unitNorm',\n    biasConstraint: 'nonNeg',\n    dropout: 0.1,\n    recurrentDropout: 0.2,\n    name: 'cell_1',\n    batchSize: 12,\n    batchInputShape: [12, 8, 8],\n    inputShape: [8, 8],\n    dtype: 'int32',\n    inputDType: 'int32',\n    trainable: true,\n    implementation: 1,\n    unitForgetBias: true,\n  };\n\n  const expectedCellConfigPrime = {\n    name: 'cell_1',\n    trainable: true,\n    batchInputShape: [12, 8, 8],\n    dtype: 'int32',\n    units: 8,\n    activation: serializeActivation(new Tanh()),\n    recurrentActivation: serializeActivation(new Tanh()),\n    useBias: true,\n    kernelInitializer: serializeInitializer(new GlorotUniform()),\n    recurrentInitializer: serializeInitializer(new HeUniform()),\n    biasInitializer: serializeInitializer(new Ones()),\n    kernelRegularizer: serializeRegularizer(new L1L2()),\n    recurrentRegularizer: serializeRegularizer(new L1L2()),\n    biasRegularizer: serializeRegularizer(new L1L2()),\n    activityRegularizer: serializeRegularizer(null),\n    kernelConstraint: serializeConstraint(new UnitNorm({})),\n    recurrentConstraint: serializeConstraint(new UnitNorm({})),\n    biasConstraint: serializeConstraint(new NonNeg()),\n    implementation: 1,\n    unitForgetBias: true,\n  };\n\n  describe('LSTMCell.getConfig', () => {\n    it('should return the expected values', () => {\n      const cell = tfl.layers.lstmCell(cellConfig);\n\n      const {dropout, recurrentDropout, ...configPrime} = cell.getConfig();\n\n      expect(configPrime).toEqual(expectedCellConfigPrime);\n      expect(dropout).toBeCloseTo(0.1);\n      expect(recurrentDropout).toBeCloseTo(0.2);\n    });\n  });\n\n  describe('LSTM.getConfig', () => {\n    it('should return the expected values', () => {\n      const config: LSTMLayerArgs = {\n        ...cellConfig,\n        name: 'layer_1',\n        ...{\n          returnSequences: true,\n          returnState: true,\n          stateful: true,\n          unroll: true,\n          goBackwards: true,\n          inputDim: 8,\n          inputLength: 8,\n        } as Omit<LSTMLayerArgs, keyof LSTMCellLayerArgs>\n      };\n\n      const cell = tfl.layers.lstm(config);\n\n      const {dropout, recurrentDropout, ...configPrime} = cell.getConfig();\n\n      expect(configPrime).toEqual({\n        ...expectedCellConfigPrime,\n        name: 'layer_1',\n        returnSequences: true,\n        returnState: true,\n        stateful: true,\n        unroll: true,\n        goBackwards: true,\n      });\n      expect(dropout).toBeCloseTo(0.1);\n      expect(recurrentDropout).toBeCloseTo(0.2);\n    });\n  });\n});\n\ndescribeMathCPU('StackedRNNCells Symbolic', () => {\n  it('With SimpleRNNCell', () => {\n    const stackedRNN = tfl.layers.rnn({\n      cell: tfl.layers.stackedRNNCells({\n        cells: [\n          tfl.layers.simpleRNNCell(\n              {units: 3, recurrentInitializer: 'glorotNormal'}),\n          tfl.layers.simpleRNNCell(\n              {units: 2, recurrentInitializer: 'glorotNormal'})\n        ],\n      })\n    });\n    const input =\n        new tfl.SymbolicTensor('float32', [16, 10, 7], null, [], null);\n    const output = stackedRNN.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([16, 2]);\n\n    // 3 trainable weights from each cell.\n    expect(stackedRNN.trainableWeights.length).toEqual(6);\n    expect(stackedRNN.nonTrainableWeights.length).toEqual(0);\n    // Kernel, recurrent kernel and bias of 1st cell.\n    expect(stackedRNN.getWeights()[0].shape).toEqual([7, 3]);\n    expect(stackedRNN.getWeights()[1].shape).toEqual([3, 3]);\n    expect(stackedRNN.getWeights()[2].shape).toEqual([3]);\n    // Kernel, recurrent kernel and bias of 2nd cell.\n    expect(stackedRNN.getWeights()[3].shape).toEqual([3, 2]);\n    expect(stackedRNN.getWeights()[4].shape).toEqual([2, 2]);\n    expect(stackedRNN.getWeights()[5].shape).toEqual([2]);\n  });\n\n  it('With LSTMCell', () => {\n    const stackedRNN = tfl.layers.rnn({\n      cell: tfl.layers.stackedRNNCells({\n        cells: [\n          tfl.layers.lstmCell({units: 3, recurrentInitializer: 'glorotNormal'}),\n          tfl.layers.lstmCell({units: 2, recurrentInitializer: 'glorotNormal'})\n        ],\n      })\n    });\n    const input =\n        new tfl.SymbolicTensor('float32', [16, 10, 7], null, [], null);\n    const output = stackedRNN.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([16, 2]);\n\n    // 3 trainable weights from each cell.\n    expect(stackedRNN.trainableWeights.length).toEqual(6);\n    expect(stackedRNN.nonTrainableWeights.length).toEqual(0);\n    // Kernel, recurrent kernel and bias of 1st cell.\n    expect(stackedRNN.getWeights()[0].shape).toEqual([7, 12]);\n    expect(stackedRNN.getWeights()[1].shape).toEqual([3, 12]);\n    expect(stackedRNN.getWeights()[2].shape).toEqual([12]);\n    // expect(stackedRNN.getWeights()[2].shape).toEqual([3]);\n    // Kernel, recurrent kernel and bias of 2nd cell.\n    expect(stackedRNN.getWeights()[3].shape).toEqual([3, 8]);\n    expect(stackedRNN.getWeights()[4].shape).toEqual([2, 8]);\n    expect(stackedRNN.getWeights()[5].shape).toEqual([8]);\n  });\n\n  it('RNN with cell array creates StackedRNNCell', () => {\n    const stackedRNN = tfl.layers.rnn({\n      cell: [\n        tfl.layers.gruCell({units: 3, recurrentInitializer: 'glorotNormal'}),\n        tfl.layers.gruCell({units: 2, recurrentInitializer: 'glorotNormal'}),\n      ],\n    });\n    const input =\n        new tfl.SymbolicTensor('float32', [16, 10, 7], null, [], null);\n    const output = stackedRNN.apply(input) as tfl.SymbolicTensor;\n    expect(output.shape).toEqual([16, 2]);\n\n    // 3 trainable weights from each cell.\n    expect(stackedRNN.trainableWeights.length).toEqual(6);\n    expect(stackedRNN.nonTrainableWeights.length).toEqual(0);\n    // Kernel, recurrent kernel and bias of 1st cell.\n    expect(stackedRNN.getWeights()[0].shape).toEqual([7, 9]);\n    expect(stackedRNN.getWeights()[1].shape).toEqual([3, 9]);\n    expect(stackedRNN.getWeights()[2].shape).toEqual([9]);\n    // expect(stackedRNN.getWeights()[2].shape).toEqual([3]);\n    // Kernel, recurrent kernel and bias of 2nd cell.\n    expect(stackedRNN.getWeights()[3].shape).toEqual([3, 6]);\n    expect(stackedRNN.getWeights()[4].shape).toEqual([2, 6]);\n    expect(stackedRNN.getWeights()[5].shape).toEqual([6]);\n  });\n});\n\ndescribeMathCPU('Stacked RNN serialization', () => {\n  it('StackedRNNCells', async () => {\n    const model = tfl.sequential();\n    model.add(tfl.layers.dense(\n        {units: 1, inputShape: [3, 4], kernelInitializer: 'ones'}));\n    const cells = [\n      tfl.layers.lstmCell(\n          {units: 5, kernelInitializer: 'ones', recurrentInitializer: 'ones'}),\n      tfl.layers.lstmCell(\n          {units: 6, kernelInitializer: 'ones', recurrentInitializer: 'ones'})\n    ];\n    const rnn = tfl.layers.rnn({cell: cells, returnSequences: true});\n    model.add(rnn);\n    const xs = tfc.ones([1, 3, 4]).mul(0.1);\n    const ys = model.predict(xs) as Tensor;\n\n    const modelJSON = model.toJSON(null, false);\n    const modelPrime =\n        await tfl.models.modelFromJSON({modelTopology: modelJSON});\n    const ysPrime = modelPrime.predict(xs) as Tensor;\n    expectTensorsClose(ysPrime, ys);\n  });\n});\n\ndescribeMathGPU('StackedRNNCells Tensor', () => {\n  // The golden values for assertion below can be obtained with the following\n  // Python Keras code:\n  //\n  // ```python\n  // import keras\n  // import numpy as np\n  //\n  // stacked_rnn = keras.layers.RNN(\n  //     [\n  //       keras.layers.SimpleRNNCell(\n  //           3,\n  //           kernel_initializer='ones',\n  //           recurrent_initializer='ones',\n  //           use_bias=False),\n  //       keras.layers.GRUCell(\n  //           2,\n  //           kernel_initializer='ones',\n  //           recurrent_initializer='ones',\n  //           use_bias=False),\n  //       keras.layers.LSTMCell(\n  //           1,\n  //           kernel_initializer='ones',\n  //           recurrent_initializer='ones',\n  //           use_bias=False),\n  //     ])\n  //\n  // t_input = keras.layers.Input(batch_shape=(2, 3, 4))\n  // t_output = stacked_rnn(t_input)\n  // print(t_input.shape)\n  // print(t_output.shape)\n  //\n  // model = keras.Model(t_input, t_output)\n  //\n  // input_val = np.array([\n  //     [\n  //         [0.1, -0.1, 0.2, -0.2], [-0.1, 0.1, -0.2, 0.2],\n  //         [0.1, 0.1, -0.2, -0.2]\n  //     ],\n  //     [\n  //         [0.05, -0.05, 0.1, -0.1], [-0.05, 0.05, -0.1, 0.1],\n  //         [0.05, 0.05, -0.1, -0.1]\n  //     ]\n  // ])\n  // print(model.predict(input_val))\n  // ```\n  it('Forward pass', () => {\n    const stackedRNN = tfl.layers.rnn({\n      cell: tfl.layers.stackedRNNCells({\n        cells: [\n          tfl.layers.simpleRNNCell({\n            units: 3,\n            recurrentInitializer: 'ones',\n            kernelInitializer: 'ones',\n            useBias: false\n          }),\n          tfl.layers.gruCell({\n            units: 2,\n            recurrentInitializer: 'ones',\n            kernelInitializer: 'ones',\n            useBias: false\n          }),\n          tfl.layers.lstmCell({\n            units: 1,\n            recurrentInitializer: 'ones',\n            kernelInitializer: 'ones',\n            useBias: false\n          }),\n        ],\n      })\n    });\n    const input = tensor3d(\n        [\n          [\n            [0.1, -0.1, 0.2, -0.2], [-0.1, 0.1, -0.2, 0.2],\n            [0.1, 0.1, -0.2, -0.2]\n          ],\n          [\n            [0.05, -0.05, 0.1, -0.1], [-0.05, 0.05, -0.1, 0.1],\n            [0.05, 0.05, -0.1, -0.1]\n          ]\n        ],\n        [2, 3, 4]);\n    const output = stackedRNN.apply(input) as Tensor;\n    expectTensorsClose(\n        output, tensor2d([[-0.07715216], [-0.05906887]], [2, 1]));\n  });\n});\n"]}