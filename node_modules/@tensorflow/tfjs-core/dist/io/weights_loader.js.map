{"version":3,"file":"weights_loader.js","sourceRoot":"","sources":["../../src/io/weights_loader.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AAEH,OAAO,EAAC,GAAG,EAAC,MAAM,gBAAgB,CAAC;AAGnC,OAAO,KAAK,IAAI,MAAM,SAAS,CAAC;AAChC,OAAO,EAAC,aAAa,EAAC,MAAM,YAAY,CAAC;AACzC,OAAO,EAAC,uBAAuB,EAAC,MAAM,YAAY,CAAC;AACnD,OAAO,EAAC,oBAAoB,EAA2D,MAAM,SAAS,CAAC;AAEvG;;;;;;;;;;GAUG;AACH,MAAM,CAAC,KAAK,UAAU,wBAAwB,CAC1C,SAAmB,EAAE,WAAyB;IAChD,IAAI,WAAW,IAAI,IAAI,EAAE;QACvB,WAAW,GAAG,EAAE,CAAC;KAClB;IAED,MAAM,SAAS,GAAG,WAAW,CAAC,SAAS,IAAI,IAAI,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC;QACtB,WAAW,CAAC,SAAS,CAAC;IAExE,0DAA0D;IAC1D,MAAM,QAAQ,GAAG,SAAS,CAAC,GAAG,CAC1B,QAAQ,CAAC,EAAE,CACP,SAAS,CAAC,QAAQ,EAAE,WAAW,CAAC,WAAW,EAAE,EAAC,QAAQ,EAAE,IAAI,EAAC,CAAC,CAAC,CAAC;IAExE,MAAM,kBAAkB,GAAG,CAAC,CAAC;IAC7B,MAAM,gBAAgB,GAAG,GAAG,CAAC;IAE7B,MAAM,SAAS,GAAG,WAAW,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC;QAC9C,MAAM,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC,CAAC;QAC7B,MAAM,uBAAuB,CACzB,QAAQ,EAAE,WAAW,CAAC,UAAU,EAAE,kBAAkB,EACpD,gBAAgB,CAAC,CAAC;IAE1B,MAAM,cAAc,GAAG,SAAS,CAAC,GAAG,CAAC,QAAQ,CAAC,EAAE,CAAC,QAAQ,CAAC,WAAW,EAAE,CAAC,CAAC;IAEzE,MAAM,mBAAmB,GAAG,GAAG,CAAC;IAChC,MAAM,iBAAiB,GAAG,CAAC,CAAC;IAE5B,MAAM,OAAO,GAAG,WAAW,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC;QAC5C,MAAM,OAAO,CAAC,GAAG,CAAC,cAAc,CAAC,CAAC,CAAC;QACnC,MAAM,uBAAuB,CACzB,cAAc,EAAE,WAAW,CAAC,UAAU,EAAE,mBAAmB,EAC3D,iBAAiB,CAAC,CAAC;IAC3B,OAAO,OAAO,CAAC;AACjB,CAAC;AAED;;;;;;;;GAQG;AACH,MAAM,CAAC,KAAK,UAAU,WAAW,CAC7B,QAA+B,EAAE,cAAc,GAAG,EAAE,EACpD,WAAsB,EACtB,WAAyB;IAC3B,yEAAyE;IACzE,2EAA2E;IAC3E,uEAAuE;IACvE,6DAA6D;IAC7D,sDAAsD;IAEtD,MAAM,YAAY,GAAG,CAAC,SAAmB,EAAE,EAAE,CACzC,wBAAwB,CAAC,SAAS,EAAE,EAAC,WAAW,EAAC,CAAC,CAAC;IACvD,MAAM,WAAW,GAAG,oBAAoB,CAAC,YAAY,CAAC,CAAC;IAEvD,OAAO,WAAW,CAAC,QAAQ,EAAE,cAAc,EAAE,WAAW,CAAC,CAAC;AAC5D,CAAC;AAED;;;;;;;;;;;;;;;;;;;;;;;GAuBG;AACH,MAAM,UAAU,oBAAoB,CAChC,oBAAqE;IAGvE,OAAO,KAAK,EACD,QAA+B,EAAE,cAAc,GAAG,EAAE,EACpD,WAAsB,EAA2B,EAAE;QAC5D,oEAAoE;QACpE,WAAW;QACX,MAAM,sBAAsB,GAAG,QAAQ,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC;QACzD,MAAM,mBAAmB,GAKrB,EAAE,CAAC;QACP,MAAM,YAAY,GACd,WAAW,IAAI,IAAI,CAAC,CAAC,CAAC,WAAW,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC;QAC5D,MAAM,sBAAsB,GAAa,EAAE,CAAC;QAC5C,QAAQ,CAAC,OAAO,CAAC,CAAC,mBAAmB,EAAE,UAAU,EAAE,EAAE;YACnD,IAAI,WAAW,GAAG,CAAC,CAAC;YACpB,mBAAmB,CAAC,OAAO,CAAC,OAAO,CAAC,YAAY,CAAC,EAAE;gBACjD,MAAM,QAAQ,GAAG,CAAC,cAAc,IAAI,YAAY,CAAC,CAAC,CAAC;oBAC/C,YAAY,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC;oBACjC,YAAY,CAAC,KAAK,CAAC;gBAEvB,MAAM,YAAY,GAAG,oBAAoB,CAAC,QAAQ,CAAC;oBAC/C,IAAI,CAAC,aAAa,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC;gBAE3C,MAAM,2BAA2B,GAAG,GAAG,EAAE;oBACvC,sBAAsB,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC;oBAC1C,IAAI,mBAAmB,CAAC,UAAU,CAAC,IAAI,IAAI,EAAE;wBAC3C,mBAAmB,CAAC,UAAU,CAAC,GAAG,EAAE,CAAC;qBACtC;oBAED,mBAAmB,CAAC,UAAU,CAAC,CAAC,IAAI,CAAC;wBACnC,aAAa,EAAE,YAAY;wBAC3B,WAAW;wBACX,SAAS,EAAE,YAAY;qBACxB,CAAC,CAAC;gBACL,CAAC,CAAC;gBAEF,IAAI,WAAW,IAAI,IAAI,EAAE;oBACvB,WAAW,CAAC,OAAO,CAAC,CAAC,UAAU,EAAE,WAAW,EAAE,EAAE;wBAC9C,IAAI,UAAU,KAAK,YAAY,CAAC,IAAI,EAAE;4BACpC,2BAA2B,EAAE,CAAC;4BAC9B,YAAY,CAAC,WAAW,CAAC,GAAG,IAAI,CAAC;yBAClC;oBACH,CAAC,CAAC,CAAC;iBACJ;qBAAM;oBACL,2BAA2B,EAAE,CAAC;iBAC/B;gBAED,sBAAsB,CAAC,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,CAAC;gBAC/C,WAAW,IAAI,YAAY,CAAC;YAC9B,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE,CAAC,KAAK,CAAC,EAAE;YACvC,MAAM,eAAe,GAAG,WAAW,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;YACvE,MAAM,IAAI,KAAK,CACX,iDAAiD;gBACjD,GAAG,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM;gBACnC,wCAAwC;gBACxC,GAAG,sBAAsB,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;SAC9C;QAED,4EAA4E;QAC5E,OAAO;QACP,MAAM,mBAAmB,GACrB,sBAAsB,CAAC,MAAM,CAAC,CAAC,WAAW,EAAE,WAAW,EAAE,CAAC,EAAE,EAAE;YAC5D,IAAI,WAAW,EAAE;gBACf,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;aACrB;YACD,OAAO,WAAW,CAAC;QACrB,CAAC,EAAE,EAAE,CAAC,CAAC;QAEX,MAAM,SAAS,GAAa,EAAE,CAAC;QAC/B,mBAAmB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;YAC9B,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,EAAE;gBACnC,MAAM,QAAQ,GAAG,cAAc;oBAC3B,CAAC,CAAC,cAAc,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC;gBAC1D,SAAS,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;YAC3B,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QACH,MAAM,OAAO,GAAG,MAAM,oBAAoB,CAAC,SAAS,CAAC,CAAC;QAEtD,MAAM,gBAAgB,GAAmB,EAAE,CAAC;QAC5C,IAAI,iBAAiB,GAAG,CAAC,CAAC;QAC1B,mBAAmB,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;YAC9B,MAAM,UAAU,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC;YAE5C,IAAI,UAAU,GAAG,CAAC,CAAC;YACnB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,CAAC,EAAE,EAAE;gBACnC,UAAU,IAAI,OAAO,CAAC,iBAAiB,GAAG,CAAC,CAAC,CAAC,UAAU,CAAC;aACzD;YAED,uCAAuC;YACvC,MAAM,WAAW,GAAG,IAAI,WAAW,CAAC,UAAU,CAAC,CAAC;YAChD,MAAM,eAAe,GAAG,IAAI,UAAU,CAAC,WAAW,CAAC,CAAC;YACpD,IAAI,iBAAiB,GAAG,CAAC,CAAC;YAC1B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,CAAC,EAAE,EAAE;gBACnC,MAAM,MAAM,GAAG,IAAI,UAAU,CAAC,OAAO,CAAC,iBAAiB,GAAG,CAAC,CAAC,CAAC,CAAC;gBAC9D,eAAe,CAAC,GAAG,CAAC,MAAM,EAAE,iBAAiB,CAAC,CAAC;gBAC/C,iBAAiB,IAAI,MAAM,CAAC,UAAU,CAAC;aACxC;YAED,MAAM,cAAc,GAAG,mBAAmB,CAAC,CAAC,CAAC,CAAC;YAC9C,cAAc,CAAC,OAAO,CAAC,YAAY,CAAC,EAAE;gBACpC,MAAM,UAAU,GAAG,WAAW,CAAC,KAAK,CAChC,YAAY,CAAC,WAAW,EACxB,YAAY,CAAC,WAAW,GAAG,YAAY,CAAC,SAAS,CAAC,CAAC;gBACvD,MAAM,eAAe,GACjB,aAAa,CAAC,UAAU,EAAE,CAAC,YAAY,CAAC,aAAa,CAAC,CAAC,CAAC;gBAC5D,KAAK,MAAM,IAAI,IAAI,eAAe,EAAE;oBAClC,gBAAgB,CAAC,IAAI,CAAC,GAAG,eAAe,CAAC,IAAI,CAAC,CAAC;iBAChD;YACH,CAAC,CAAC,CAAC;YAEH,iBAAiB,IAAI,UAAU,CAAC;QAClC,CAAC,CAAC,CAAC;QAEH,OAAO,gBAAgB,CAAC;IAC1B,CAAC,CAAC;AACJ,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {env} from '../environment';\n\nimport {NamedTensorMap} from '../tensor_types';\nimport * as util from '../util';\nimport {decodeWeights} from './io_utils';\nimport {monitorPromisesProgress} from './progress';\nimport {DTYPE_VALUE_SIZE_MAP, LoadOptions, WeightsManifestConfig, WeightsManifestEntry} from './types';\n\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nexport async function loadWeightsAsArrayBuffer(\n    fetchURLs: string[], loadOptions?: LoadOptions): Promise<ArrayBuffer[]> {\n  if (loadOptions == null) {\n    loadOptions = {};\n  }\n\n  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch :\n                                                    loadOptions.fetchFunc;\n\n  // Create the requests for all of the weights in parallel.\n  const requests = fetchURLs.map(\n      fetchURL =>\n          fetchFunc(fetchURL, loadOptions.requestInit, {isBinary: true}));\n\n  const fetchStartFraction = 0;\n  const fetchEndFraction = 0.5;\n\n  const responses = loadOptions.onProgress == null ?\n      await Promise.all(requests) :\n      await monitorPromisesProgress(\n          requests, loadOptions.onProgress, fetchStartFraction,\n          fetchEndFraction);\n\n  const bufferPromises = responses.map(response => response.arrayBuffer());\n\n  const bufferStartFraction = 0.5;\n  const bufferEndFraction = 1;\n\n  const buffers = loadOptions.onProgress == null ?\n      await Promise.all(bufferPromises) :\n      await monitorPromisesProgress(\n          bufferPromises, loadOptions.onProgress, bufferStartFraction,\n          bufferEndFraction);\n  return buffers;\n}\n\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nexport async function loadWeights(\n    manifest: WeightsManifestConfig, filePathPrefix = '',\n    weightNames?: string[],\n    requestInit?: RequestInit): Promise<NamedTensorMap> {\n  // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n  // single weight from a group, the whole group will be fetched. At a future\n  // date, we should support fetching only the individual shards within a\n  // group that are needed to reconstruct the requested weight.\n  // TODO(cais): Use `decodeWeights` for implementation.\n\n  const fetchWeights = (fetchUrls: string[]) =>\n      loadWeightsAsArrayBuffer(fetchUrls, {requestInit});\n  const loadWeights = weightsLoaderFactory(fetchWeights);\n\n  return loadWeights(manifest, filePathPrefix, weightNames);\n}\n\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nexport function weightsLoaderFactory(\n    fetchWeightsFunction: (fetchUrls: string[]) => Promise<ArrayBuffer[]>):\n    (manifest: WeightsManifestConfig, filePathPrefix?: string,\n     weightNames?: string[]) => Promise<NamedTensorMap> {\n  return async(\n             manifest: WeightsManifestConfig, filePathPrefix = '',\n             weightNames?: string[]): Promise<NamedTensorMap> => {\n    // Collect all the groups, weights, and their relative offsets to be\n    // fetched.\n    const groupIndicesToFetchMap = manifest.map(() => false);\n    const groupWeightsToFetch: {\n      [group: number]: Array<{\n        manifestEntry: WeightsManifestEntry; groupOffset: number;\n        sizeBytes: number;\n      }>\n    } = {};\n    const weightsFound =\n        weightNames != null ? weightNames.map(() => false) : [];\n    const allManifestWeightNames: string[] = [];\n    manifest.forEach((manifestGroupConfig, groupIndex) => {\n      let groupOffset = 0;\n      manifestGroupConfig.weights.forEach(weightsEntry => {\n        const rawDtype = ('quantization' in weightsEntry) ?\n            weightsEntry.quantization.dtype :\n            weightsEntry.dtype;\n\n        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] *\n            util.sizeFromShape(weightsEntry.shape);\n\n        const enqueueWeightsForFetchingFn = () => {\n          groupIndicesToFetchMap[groupIndex] = true;\n          if (groupWeightsToFetch[groupIndex] == null) {\n            groupWeightsToFetch[groupIndex] = [];\n          }\n\n          groupWeightsToFetch[groupIndex].push({\n            manifestEntry: weightsEntry,\n            groupOffset,\n            sizeBytes: weightsBytes\n          });\n        };\n\n        if (weightNames != null) {\n          weightNames.forEach((weightName, weightIndex) => {\n            if (weightName === weightsEntry.name) {\n              enqueueWeightsForFetchingFn();\n              weightsFound[weightIndex] = true;\n            }\n          });\n        } else {\n          enqueueWeightsForFetchingFn();\n        }\n\n        allManifestWeightNames.push(weightsEntry.name);\n        groupOffset += weightsBytes;\n      });\n    });\n\n    if (!weightsFound.every(found => found)) {\n      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);\n      throw new Error(\n          `Could not find weights in manifest with names: ` +\n          `${weightsNotFound.join(', ')}. \\n` +\n          `Manifest JSON has weights with names: ` +\n          `${allManifestWeightNames.join(', ')}.`);\n    }\n\n    // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n    // IDs.\n    const groupIndicesToFetch =\n        groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {\n          if (shouldFetch) {\n            accumulator.push(i);\n          }\n          return accumulator;\n        }, []);\n\n    const fetchUrls: string[] = [];\n    groupIndicesToFetch.forEach(i => {\n      manifest[i].paths.forEach(filepath => {\n        const fetchUrl = filePathPrefix +\n            (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n        fetchUrls.push(fetchUrl);\n      });\n    });\n    const buffers = await fetchWeightsFunction(fetchUrls);\n\n    const weightsTensorMap: NamedTensorMap = {};\n    let bufferIndexOffset = 0;\n    groupIndicesToFetch.forEach(i => {\n      const numBuffers = manifest[i].paths.length;\n\n      let groupBytes = 0;\n      for (let i = 0; i < numBuffers; i++) {\n        groupBytes += buffers[bufferIndexOffset + i].byteLength;\n      }\n\n      // Create a buffer for the whole group.\n      const groupBuffer = new ArrayBuffer(groupBytes);\n      const groupByteBuffer = new Uint8Array(groupBuffer);\n      let groupBufferOffset = 0;\n      for (let i = 0; i < numBuffers; i++) {\n        const buffer = new Uint8Array(buffers[bufferIndexOffset + i]);\n        groupByteBuffer.set(buffer, groupBufferOffset);\n        groupBufferOffset += buffer.byteLength;\n      }\n\n      const weightsEntries = groupWeightsToFetch[i];\n      weightsEntries.forEach(weightsEntry => {\n        const byteBuffer = groupBuffer.slice(\n            weightsEntry.groupOffset,\n            weightsEntry.groupOffset + weightsEntry.sizeBytes);\n        const nameToTensorMap =\n            decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n        for (const name in nameToTensorMap) {\n          weightsTensorMap[name] = nameToTensorMap[name];\n        }\n      });\n\n      bufferIndexOffset += numBuffers;\n    });\n\n    return weightsTensorMap;\n  };\n}\n"]}