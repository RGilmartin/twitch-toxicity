{"version":3,"file":"engine.js","sourceRoot":"","sources":["../src/engine.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AAEH,OAAO,EAA+B,aAAa,EAAC,MAAM,oBAAoB,CAAC;AAC/E,OAAO,EAAC,WAAW,EAAE,oBAAoB,EAAC,MAAM,eAAe,CAAC;AAChE,OAAO,EAAC,kBAAkB,EAAC,MAAM,eAAe,CAAC;AACjD,OAAO,EAAC,GAAG,EAAE,IAAI,EAAE,QAAQ,EAAC,MAAM,gBAAgB,CAAC;AACnD,OAAO,EAAC,WAAW,EAAE,SAAS,EAAE,oBAAoB,EAAqC,MAAM,mBAAmB,CAAC;AACnH,OAAO,EAAgB,QAAQ,EAAC,MAAM,YAAY,CAAC;AACnD,OAAO,EAAC,sBAAsB,EAAE,oBAAoB,EAAW,MAAM,QAAQ,CAAC;AAC9E,OAAO,EAAS,gBAAgB,EAAE,MAAM,EAAiB,QAAQ,EAAC,MAAM,UAAU,CAAC;AAEnF,OAAO,EAAC,qBAAqB,EAAC,MAAM,eAAe,CAAC;AAEpD,OAAO,KAAK,IAAI,MAAM,QAAQ,CAAC;AAC/B,OAAO,EAAC,oBAAoB,EAAE,kBAAkB,EAAE,GAAG,EAAE,aAAa,EAAC,MAAM,QAAQ,CAAC;AAuEpF,SAAS,4BAA4B,CAEjC,gBACgC;IAElC,OAAQ,gBAAkD,CAAC,UAAU,IAAI,IAAI,CAAC;AAChF,CAAC;AAED,MAAM,WAAW;IAAjB;QACE,uCAAuC;QACvC,wBAAmB,GAAqB,EAAE,CAAC;QAE3C,mBAAc,GAAG,CAAC,CAAC;QACnB,aAAQ,GAAG,CAAC,CAAC;QACb,eAAU,GAAG,CAAC,CAAC;QACf,qBAAgB,GAAG,CAAC,CAAC;QACrB,mBAAc,GAAG,CAAC,CAAC;QAGnB,oEAAoE;QACpE,yEAAyE;QACzE,2EAA2E;QAC3E,kBAAa,GAAG,CAAC,CAAC;QAClB,8EAA8E;QAC9E,gBAAgB;QAChB,gBAAW,GAAG,CAAC,CAAC;QAIhB,eAAU,GAAiB,EAAE,CAAC;QAC9B;;;WAGG;QACH,sBAAiB,GAAa,EAAE,CAAC;QACjC,gBAAW,GAAG,CAAC,CAAC;QAEhB,eAAU,GAAG,IAAI,OAAO,EAKpB,CAAC;QAEL,cAAS,GAAG,KAAK,CAAC;QAClB,kBAAa,GAAgB;YAC3B,QAAQ,EAAE,CAAC;YACX,UAAU,EAAE,CAAC;YACb,SAAS,EAAE,CAAC;YACZ,OAAO,EAAE,EAAE;YACX,MAAM,EAAE,IAAI;YACZ,IAAI,WAAW;gBAET,OAAO,KAAK,CAAC,IAAI,CAAC,IAAI,GAAG,CAAC,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC5D,CAAC;SACN,CAAC;IAOJ,CAAC;IALC,OAAO;QACL,KAAK,MAAM,YAAY,IAAI,IAAI,CAAC,mBAAmB,EAAE;YACnD,IAAI,CAAC,mBAAmB,CAAC,YAAY,CAAC,CAAC,OAAO,EAAE,CAAC;SAClD;IACH,CAAC;CACF;AAED,MAAM,OAAO,MAAM;IAgBjB,YAAmB,GAAgB;QAAhB,QAAG,GAAH,GAAG,CAAa;QAbnC,aAAQ,GAAkC,EAAE,CAAC;QAC7C,oBAAe,GAKX,EAAE,CAAC;QAKC,yBAAoB,GAAG,CAAC,CAAC;QAG/B,IAAI,CAAC,KAAK,GAAG,IAAI,WAAW,EAAE,CAAC;IACjC,CAAC;IAED,KAAK,CAAC,KAAK;QACT,IAAI,IAAI,CAAC,kBAAkB,IAAI,IAAI,EAAE;YACnC,OAAO,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,GAAG,EAAE,GAAE,CAAC,CAAC,CAAC;SAC/C;QACD,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,EAAE;YAChC,OAAO;SACR;QACD,MAAM,cAAc,GAAG,IAAI,CAAC,iBAAiB,EAAE,CAAC;QAEhD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,cAAc,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YAC9C,MAAM,WAAW,GAAG,cAAc,CAAC,CAAC,CAAC,CAAC;YACtC,MAAM,OAAO,GAAG,MAAM,IAAI,CAAC,iBAAiB,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC;YAClE,IAAI,OAAO,EAAE;gBACX,MAAM,IAAI,CAAC,UAAU,CAAC,WAAW,CAAC,CAAC;gBACnC,OAAO;aACR;SACF;QAED,MAAM,IAAI,KAAK,CACX,iEAAiE;YACjE,SAAS,CAAC,CAAC;IACjB,CAAC;IAED,IAAI,OAAO;QACT,IAAI,IAAI,CAAC,kBAAkB,IAAI,IAAI,EAAE;YACnC,MAAM,IAAI,KAAK,CACX,YAAY,IAAI,CAAC,WAAW,uCAAuC;gBACnE,mEAAmE;gBACnE,eAAe,CAAC,CAAC;SACtB;QACD,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,EAAE;YAChC,MAAM,EAAC,IAAI,EAAE,SAAS,EAAC,GAAG,IAAI,CAAC,+BAA+B,EAAE,CAAC;YACjE,IAAI,SAAS,EAAE;gBACb,MAAM,IAAI,KAAK,CACX,iCAAiC,IAAI,qBAAqB;oBAC1D,gDAAgD;oBAChD,oDAAoD,CAAC,CAAC;aAC3D;YACD,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,CAAC;SACvB;QACD,OAAO,IAAI,CAAC,eAAe,CAAC;IAC9B,CAAC;IAED,YAAY;QACV,OAAO,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;IAC3C,CAAC;IAED,WAAW,CAAC,WAAmB;QAC7B,IAAI,CAAC,CAAC,WAAW,IAAI,IAAI,CAAC,QAAQ,CAAC,EAAE;YACnC,0EAA0E;YAC1E,mCAAmC;YACnC,IAAI,WAAW,IAAI,IAAI,CAAC,eAAe,EAAE;gBACvC,MAAM,EAAC,SAAS,EAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC,WAAW,CAAC,CAAC;gBACxD,IAAI,SAAS,EAAE;oBACb,4BAA4B;oBAC5B,OAAO,IAAI,CAAC;iBACb;aACF;iBAAM;gBACL,OAAO,IAAI,CAAC;aACb;SACF;QACD,OAAO,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,CAAC;IACpC,CAAC;IAED,kBAAkB,CAAC,WAAmB;QAEpC,IAAI,CAAC,CAAC,WAAW,IAAI,IAAI,CAAC,eAAe,CAAC,EAAE;YAC1C,OAAO,IAAI,CAAC;SACb;QACD,OAAO,IAAI,CAAC,eAAe,CAAC,WAAW,CAAC,CAAC,OAAO,CAAC;IACnD,CAAC;IAED,eAAe,CACX,WAAmB,EACnB,OAAqD,EACrD,QAAQ,GAAG,CAAC;QACd,IAAI,WAAW,IAAI,IAAI,CAAC,eAAe,EAAE;YACvC,OAAO,CAAC,IAAI,CACR,GAAG,WAAW,mCAAmC;gBACjD,mCAAmC,CAAC,CAAC;YACzC,OAAO,KAAK,CAAC;SACd;QACD,IAAI,CAAC,eAAe,CAAC,WAAW,CAAC,GAAG,EAAC,OAAO,EAAE,QAAQ,EAAC,CAAC;QACxD,OAAO,IAAI,CAAC;IACd,CAAC;IAED,KAAK,CAAC,UAAU,CAAC,WAAmB;QAClC,IAAI,IAAI,CAAC,eAAe,CAAC,WAAW,CAAC,IAAI,IAAI,EAAE;YAC7C,MAAM,IAAI,KAAK,CAAC,iBAAiB,WAAW,yBAAyB,CAAC,CAAC;SACxE;QACD,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;QAC/B,IAAI,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,IAAI,IAAI,EAAE;YACtC,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;YAC5B,MAAM,EAAC,OAAO,EAAE,SAAS,EAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC,WAAW,CAAC,CAAC;YACjE,MAAM,MAAM,GAAG,SAAS,CAAC,CAAC,CAAC,MAAM,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC;YACnD,IAAI,CAAC,MAAM,EAAE;gBACX,OAAO,KAAK,CAAC;aACd;SACF;QACD,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,CAAC;QAClD,IAAI,CAAC,sBAAsB,EAAE,CAAC;QAC9B,sBAAsB;QACtB,IAAI,CAAC,QAAQ,GAAG,IAAI,QAAQ,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAEnD,OAAO,IAAI,CAAC;IACd,CAAC;IAEO,sBAAsB;QAC5B,MAAM,OAAO,GAAG,oBAAoB,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;QACvD,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YACvB,IAAI,MAAM,CAAC,SAAS,IAAI,IAAI,EAAE;gBAC5B,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;aACxC;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAEO,wBAAwB,CAAC,WAAmB;QAClD,MAAM,OAAO,GAAG,oBAAoB,CAAC,WAAW,CAAC,CAAC;QAClD,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YACvB,IAAI,MAAM,CAAC,WAAW,IAAI,IAAI,EAAE;gBAC9B,MAAM,CAAC,WAAW,CAAC,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,CAAC,CAAC;aAChD;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;;;;OAKG;IACK,iBAAiB,CAAC,WAAmB;QAE3C,MAAM,oBAAoB,GAAG,IAAI,CAAC,eAAe,CAAC,WAAW,CAAC,CAAC;QAC/D,IAAI,oBAAoB,IAAI,IAAI,EAAE;YAChC,MAAM,IAAI,KAAK,CACX,6BAA6B,WAAW,0BAA0B,CAAC,CAAC;SACzE;QAED,IAAI;YACF,MAAM,OAAO,GAAG,oBAAoB,CAAC,OAAO,EAAE,CAAC;YAC/C;;;;6CAIiC;YACjC,IAAI,OAAO,IAAI,CAAC,CAAC,OAAO,YAAY,aAAa,CAAC;gBAC9C,OAAO,OAAO,CAAC,IAAI,KAAK,UAAU,EAAE;gBACtC,MAAM,SAAS,GAAG,EAAE,IAAI,CAAC,oBAAoB,CAAC;gBAC9C,MAAM,OAAO,GACT,OAAO;qBACF,IAAI,CAAC,eAAe,CAAC,EAAE;oBACtB,6DAA6D;oBAC7D,IAAI,SAAS,GAAG,IAAI,CAAC,oBAAoB,EAAE;wBACzC,OAAO,KAAK,CAAC;qBACd;oBACD,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,GAAG,eAAe,CAAC;oBAC7C,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC;oBAC/B,OAAO,IAAI,CAAC;gBACd,CAAC,CAAC;qBACD,KAAK,CAAC,GAAG,CAAC,EAAE;oBACX,6DAA6D;oBAC7D,IAAI,SAAS,GAAG,IAAI,CAAC,oBAAoB,EAAE;wBACzC,OAAO,KAAK,CAAC;qBACd;oBACD,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC;oBAC/B,OAAO,CAAC,IAAI,CACR,6BAA6B,WAAW,SAAS,CAAC,CAAC;oBACvD,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,KAAK,IAAI,GAAG,CAAC,OAAO,CAAC,CAAC;oBACvC,OAAO,KAAK,CAAC;gBACf,CAAC,CAAC,CAAC;gBACX,IAAI,CAAC,kBAAkB,GAAG,OAAO,CAAC;gBAClC,OAAO,EAAC,OAAO,EAAE,SAAS,EAAE,IAAI,EAAC,CAAC;aACnC;iBAAM;gBACL,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,GAAG,OAAwB,CAAC;gBACtD,OAAO,EAAC,OAAO,EAAE,IAAI,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC;aAC1C;SACF;QAAC,OAAO,GAAG,EAAE;YACZ,OAAO,CAAC,IAAI,CAAC,6BAA6B,WAAW,SAAS,CAAC,CAAC;YAChE,OAAO,CAAC,IAAI,CAAC,GAAG,CAAC,KAAK,IAAI,GAAG,CAAC,OAAO,CAAC,CAAC;YACvC,OAAO,EAAC,OAAO,EAAE,KAAK,EAAE,SAAS,EAAE,KAAK,EAAC,CAAC;SAC3C;IACH,CAAC;IAED,aAAa,CAAC,WAAmB;QAC/B,IAAI,CAAC,CAAC,WAAW,IAAI,IAAI,CAAC,eAAe,CAAC,EAAE;YAC1C,MAAM,IAAI,KAAK,CAAC,GAAG,WAAW,gCAAgC,CAAC,CAAC;SACjE;QACD,IAAI,IAAI,CAAC,WAAW,KAAK,WAAW,IAAI,IAAI,CAAC,kBAAkB,IAAI,IAAI,EAAE;YACvE,uEAAuE;YACvE,YAAY;YACZ,IAAI,CAAC,oBAAoB,EAAE,CAAC;SAC7B;QAED,IAAI,WAAW,IAAI,IAAI,CAAC,QAAQ,EAAE;YAChC,IAAI,CAAC,wBAAwB,CAAC,WAAW,CAAC,CAAC;YAC3C,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,CAAC,OAAO,EAAE,CAAC;YACrC,OAAO,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,CAAC;SACnC;QAED,OAAO,IAAI,CAAC,eAAe,CAAC,WAAW,CAAC,CAAC;QAEzC,qCAAqC;QACrC,IAAI,IAAI,CAAC,WAAW,KAAK,WAAW,EAAE;YACpC,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC;YAC/B,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;YACxB,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;SAC7B;IACH,CAAC;IAEO,iBAAiB;QACvB,IAAI,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YAClD,MAAM,IAAI,KAAK,CAAC,+BAA+B,CAAC,CAAC;SAClD;QACD,OAAO,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC,IAAI,CAAC,CAAC,CAAS,EAAE,CAAS,EAAE,EAAE;YACrE,gCAAgC;YAChC,OAAO,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,QAAQ;gBACnC,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC;QACvC,CAAC,CAAC,CAAC;IACL,CAAC;IAEO,+BAA+B;QAErC,MAAM,cAAc,GAAG,IAAI,CAAC,iBAAiB,EAAE,CAAC;QAEhD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,cAAc,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YAC9C,MAAM,WAAW,GAAG,cAAc,CAAC,CAAC,CAAC,CAAC;YACtC,MAAM,EAAC,OAAO,EAAE,SAAS,EAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC,WAAW,CAAC,CAAC;YACjE,IAAI,SAAS,IAAI,OAAO,EAAE;gBACxB,OAAO,EAAC,IAAI,EAAE,WAAW,EAAE,SAAS,EAAC,CAAC;aACvC;SACF;QACD,MAAM,IAAI,KAAK,CACX,iEAAiE;YACjE,SAAS,CAAC,CAAC;IACjB,CAAC;IAED,QAAQ,CAAC,OAAsB,EAAE,MAAc;QAC7C,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;QAC/C,MAAM,UAAU,GAAG,IAAI,CAAC,OAAO,CAAC;QAChC,MAAM,MAAM,GAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;QACrC,MAAM,QAAQ,GAAG,UAAU,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;QAC7C,gEAAgE;QAChE,WAAW;QACX,UAAU,CAAC,WAAW,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;QACrC,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;QACvB,OAAO,CAAC,IAAI,CAAC,MAAM,EAAE,MAAM,EAAE,IAAI,CAAC,KAAK,EAAE,IAAI,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;QAC/D,IAAI,IAAI,CAAC,sBAAsB,EAAE,EAAE;YACjC,mEAAmE;YACnE,uBAAuB;YACvB,IAAI,CAAC,KAAK,CAAC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,iBAAiB,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC;SACzE;IACH,CAAC;IAED,IAAI,CAA4B,QAA2B,EAAE,EAAe;QAE1E,IAAI,IAAI,GAAW,IAAI,CAAC;QACxB,IAAI,EAAE,IAAI,IAAI,EAAE;YACd,+BAA+B;YAC/B,IAAI,OAAO,QAAQ,KAAK,UAAU,EAAE;gBAClC,MAAM,IAAI,KAAK,CAAC,qCAAqC,CAAC,CAAC;aACxD;YACD,EAAE,GAAG,QAAQ,CAAC;SACf;aAAM;YACL,2BAA2B;YAC3B,IAAI,OAAO,QAAQ,KAAK,QAAQ,IAAI,CAAC,CAAC,QAAQ,YAAY,MAAM,CAAC,EAAE;gBACjE,MAAM,IAAI,KAAK,CACX,sDAAsD;oBACtD,4BAA4B,CAAC,CAAC;aACnC;YACD,IAAI,OAAO,EAAE,KAAK,UAAU,EAAE;gBAC5B,MAAM,IAAI,KAAK,CACX,oDAAoD;oBACpD,8BAA8B,CAAC,CAAC;aACrC;YACD,IAAI,GAAG,QAAkB,CAAC;YAC1B,+DAA+D;YAC/D,aAAa;SACd;QACD,IAAI,MAAS,CAAC;QACd,OAAO,IAAI,CAAC,SAAS,CACjB,GAAG,EAAE,CAAC,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,EAAE,GAAG,EAAE,CAAC,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,EAAE,GAAG,EAAE;YAC7D,MAAM,GAAG,EAAE,EAAE,CAAC;YACd,IAAI,MAAM,YAAY,OAAO,EAAE;gBAC7B,OAAO,CAAC,KAAK,CAAC,yCAAyC,CAAC,CAAC;aAC1D;YACD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACT,CAAC;IAEO,SAAS,CAAI,KAAiB,EAAE,GAAe,EAAE,CAAU;QACjE,KAAK,EAAE,CAAC;QACR,IAAI;YACF,MAAM,GAAG,GAAG,CAAC,EAAE,CAAC;YAChB,GAAG,EAAE,CAAC;YACN,OAAO,GAAG,CAAC;SACZ;QAAC,OAAO,EAAE,EAAE;YACX,GAAG,EAAE,CAAC;YACN,MAAM,EAAE,CAAC;SACV;IACH,CAAC;IAGO,YAAY;QAClB,OAAO,MAAM,CAAC,YAAY,EAAE,CAAC;IAC/B,CAAC;IAGO,cAAc;QACpB,OAAO,MAAM,CAAC,cAAc,EAAE,CAAC;IACjC,CAAC;IAED;;;;;OAKG;IACK,KAAK,CAAC,CAAS;QACrB,MAAM,CAAC,GAAW,MAAM,CAAC,SAAS,CAAC,QAAQ,EAAE,EAAC,CAAC,EAAyB,CAAC,CAAC;QAC1E,MAAM,MAAM,GAAG,EAAC,CAAC,EAAC,CAAC;QACnB,MAAM,IAAI,GAAG,CAAC,EAAU,EAAE,EAAE,CAAC,CAAC;YAC5B,CAAC,EAAE,GAAG,EAAE;gBACN,MAAM,KAAK,GAAG,SAAS,CAAC;gBACxB,MAAM,UAAU,GAAG,EAAC,CAAC,EAAE,EAAE,EAAC,CAAC;gBAC3B,MAAM,KAAK,GAAG,EAAC,KAAK,EAAC,CAAC;gBAEtB,OAAO,MAAM,CAAC,SAAS,CACZ,IAAI,EAAE,UAAkC;gBACxC,0DAA0D;gBAC1D,KAA2B,CAAW,CAAC;YACpD,CAAC;SACF,CAAC,CAAC;QACH,MAAM,KAAK,GAAa,EAAE,CAAC;QAC3B,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,IAAI,EAAE,MAAM,EAAE,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE,EAAE,CAAC,CAAC;QAC5E,OAAO,CAAC,CAAC;IACX,CAAC;IAED;;;;;;;;;;;;OAYG;IACH,SAAS,CACL,UAAkB,EAAE,MAAsB,EAAE,KAAoB;QAClE,MAAM,SAAS,GAAG,SAAS,CAAC,UAAU,EAAE,IAAI,CAAC,WAAW,CAAC,IAAI,IAAI,CAAC;QAClE,IAAI,CAAC,SAAS,EAAE;YACd,MAAM,IAAI,KAAK,CAAC,WAAW,UAAU,iCACjC,IAAI,CAAC,WAAW,GAAG,CAAC,CAAC;SAC1B;QACD,OAAO,IAAI,CAAC,aAAa,CAAC,EAAC,UAAU,EAAE,MAAM,EAAE,KAAK,EAAC,CAAC,CAAC;IACzD,CAAC;IAEO,sBAAsB;QAC5B,OAAO,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;IACrC,CAAC;IAEO,qBAAqB,CACzB,UAAkB,EAAE,gBAAwB,EAC5C,QAAsB;QACxB,MAAM,eAAe,GAAG,IAAI,CAAC,OAAO,CAAC,UAAU,EAAE,CAAC;QAElD,yEAAyE;QACzE,IAAI,gBAAgB,GAAG,CAAC,CAAC;QACzB,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;YACtB,+DAA+D;YAC/D,oEAAoE;YACpE,gBAAgB,IAAI,CAAC,IAAI,CAAC,KAAK,KAAK,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC3D,CAAC,CAAC,CAAC;QAEH,yEAAyE;QACzE,4EAA4E;QAC5E,sEAAsE;QACtE,2EAA2E;QAC3E,+BAA+B;QAC/B,MAAM,QAAQ,GACV,IAAI,CAAC,KAAK,CAAC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,iBAAiB,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAC1E,MAAM,aAAa,GACf,eAAe,GAAG,gBAAgB,GAAG,gBAAgB,GAAG,QAAQ,CAAC;QACrE,IAAI,aAAa,GAAG,CAAC,EAAE;YACrB,MAAM,IAAI,KAAK,CACX,YAAY,IAAI,CAAC,WAAW,gCAAgC;gBAC5D,IAAI,aAAa,6BAA6B,UAAU,GAAG,CAAC,CAAC;SAClE;IACH,CAAC;IAED;;;;OAIG;IACK,aAAa,CACjB,YACgC;QAClC,IAAI,OAAiB,CAAC;QACtB,IAAI,KAAK,GAAa,EAAE,CAAC;QACzB,MAAM,QAAQ,GAAG,IAAI,CAAC,QAAQ,EAAE,CAAC;QAEjC,MAAM,iBAAiB,GAAG,IAAI,CAAC,KAAK,CAAC,QAAQ,CAAC;QAC9C,MAAM,kBAAkB,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC;QAEjD,IAAI,IAAI,CAAC,sBAAsB,EAAE,EAAE;YACjC,IAAI,CAAC,KAAK,CAAC,iBAAiB,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SACtC;QAED,IAAI,UAA0B,CAAC;QAC/B,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;YAC5B,uEAAuE;YACvE,+CAA+C;YAC/C,oEAAoE;YACpE,mDAAmD;YACnD,iDAAiD;YACjD,IAAI,CAAC,OAAO,CAAC;SACd;QAED,IAAI,GAA4B,CAAC;QAEjC,MAAM,iBAAiB,GAAG,4BAA4B,CAAC,YAAY,CAAC,CAAC,CAAC;YAClE,YAAY,CAAC,UAAU,CAAC,CAAC;YACzB,IAAI,CAAC,KAAK,CAAC,WAAW,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC;QAEtE,qEAAqE;QACrE,sEAAsE;QACtE,kEAAkE;QAElE,IAAI,4BAA4B,CAAC,YAAY,CAAC,EAAE;YAC9C,MAAM,EAAC,UAAU,EAAE,MAAM,EAAE,KAAK,EAAC,GAAG,YAAY,CAAC;YACjD,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBAC5B,uEAAuE;gBACvE,+CAA+C;gBAC/C,oEAAoE;gBACpE,mDAAmD;gBACnD,iDAAiD;gBACjD,IAAI,CAAC,OAAO,CAAC;aACd;YACD,MAAM,MAAM,GAAG,SAAS,CAAC,UAAU,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC;YACvD,IAAI,CAAC,MAAM,CACP,MAAM,IAAI,IAAI,EACd,GAAG,EAAE,CAAC,kCAAkC,UAAU,kBAC9C,IAAI,CAAC,WAAW,GAAG,CAAC,CAAC;YAE7B,UAAU,GAAG,GAAG,EAAE;gBAChB,MAAM,gBAAgB,GAAG,IAAI,CAAC,OAAO,CAAC,UAAU,EAAE,CAAC;gBACnD,GAAG,GAAG,MAAM,CAAC,UAAU,CAAC,EAAC,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE,IAAI,CAAC,OAAO,EAAC,CAAC,CAAC;gBAChE,MAAM,QAAQ,GAAG,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;gBAClD,IAAI,IAAI,CAAC,sBAAsB,EAAE,EAAE;oBACjC,IAAI,CAAC,qBAAqB,CAAC,UAAU,EAAE,gBAAgB,EAAE,QAAQ,CAAC,CAAC;iBACpE;gBAED,MAAM,UAAU,GAAG,QAAQ,CAAC,GAAG,CAAC,CAAC,OAA0B,EAAE,EAAE;oBAC7D,gEAAgE;oBAChE,gEAAgE;oBAChE,4CAA4C;oBAC5C,IAAK,OAAkB,CAAC,IAAI,IAAI,IAAI,EAAE;wBACpC,OAAO,OAAiB,CAAC;qBAC1B;oBACD,MAAM,EAAC,MAAM,EAAE,KAAK,EAAE,KAAK,EAAC,GAAG,OAAqB,CAAC;oBACrD,OAAO,IAAI,CAAC,oBAAoB,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;gBACzD,CAAC,CAAC,CAAC;gBAEH,wCAAwC;gBAExC,sEAAsE;gBACtE,sEAAsE;gBACtE,wCAAwC;gBACxC,IAAI,QAAQ,EAAE;oBACZ,MAAM,aAAa,GACf,IAAI,CAAC,qBAAqB,CAAC,UAAU,EAAE,MAAM,EAAE,UAAU,CAAC,CAAC;oBAC/D,KAAK,GAAG,IAAI,CAAC,0BAA0B,CAAC,aAAa,CAAC,CAAC;iBACxD;gBACD,OAAO,UAAU,CAAC;YACpB,CAAC,CAAC;SACH;aAAM;YACL,MAAM,EAAC,WAAW,EAAC,GAAG,YAAY,CAAC;YACnC,2BAA2B;YAC3B,MAAM,QAAQ,GAAiB,CAAC,OAAO,EAAE,EAAE;gBACzC,sEAAsE;gBACtE,qEAAqE;gBACrE,oBAAoB;gBACpB,IAAI,CAAC,QAAQ,EAAE;oBACb,OAAO;iBACR;gBACD,KAAK,GAAG,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;YAC/D,CAAC,CAAC;YAEF,UAAU,GAAG,GAAG,EAAE;gBAChB,MAAM,gBAAgB,GAAG,IAAI,CAAC,OAAO,CAAC,UAAU,EAAE,CAAC;gBACnD,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,WAAW,CAAC,IAAI,CAAC,OAAO,EAAE,QAAQ,CAAC,CAAC,CAAC;gBAC3D,MAAM,IAAI,GAAG,CAAC,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAa,CAAC;gBAC5D,IAAI,IAAI,CAAC,sBAAsB,EAAE,EAAE;oBACjC,sEAAsE;oBACtE,IAAI,CAAC,qBAAqB,CAAC,iBAAiB,EAAE,gBAAgB,EAAE,IAAI,CAAC,CAAC;iBACvE;gBACD,OAAO,IAAI,CAAC;YACd,CAAC,CAAC;SACH;QAED,EAAE;QACF,+CAA+C;QAC/C,EAAE;QACF,MAAM,EAAC,MAAM,EAAE,KAAK,EAAC,GAAG,YAAY,CAAC;QACrC,MAAM,aAAa,GAAG,4BAA4B,CAAC,YAAY,CAAC,CAAC,CAAC;YAC9D,IAAI,CAAC,CAAC;YACN,YAAY,CAAC,aAAa,CAAC;QAE/B,IAAI,aAA4B,CAAC;QACjC,IAAI,CAAC,SAAS;QACV,kDAAkD;QAClD,GAAG,EAAE,CAAC,IAAI,CAAC,KAAK,CAAC,WAAW,EAAE,EAAE,GAAG,EAAE,CAAC,IAAI,CAAC,KAAK,CAAC,WAAW,EAAE,EAAE,GAAG,EAAE;YACnE,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,SAAS,EAAE;gBACvD,OAAO,GAAG,UAAU,EAAE,CAAC;aACxB;iBAAM;gBACL,aAAa,GAAG,IAAI,CAAC,QAAQ,CAAC,aAAa,CACvC,iBAAiB,EAAE,MAAM,EAAE,GAAG,EAAE,CAAC,UAAU,EAAE,CAAC,CAAC;gBACnD,IAAI,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE;oBAC7B,IAAI,CAAC,QAAQ,CAAC,gBAAgB,CAAC,aAAa,CAAC,CAAC;iBAC/C;gBACD,OAAO,GAAG,aAAa,CAAC,OAAO,CAAC;aACjC;QACH,CAAC,CAAC,CAAC;QAEP,IAAI,QAAQ,EAAE;YACZ,IAAI,CAAC,WAAW,CACZ,iBAAiB,EAAE,MAAM,EAAE,OAAO,EAAE,aAAa,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;SACtE;QAED,IAAI,IAAI,CAAC,KAAK,CAAC,SAAS,EAAE;YACxB,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,OAAO,CAAC,IAAI,CAAC;gBACpC,IAAI,EAAE,iBAAiB;gBACvB,UAAU,EAAE,IAAI,CAAC,KAAK,CAAC,QAAQ,GAAG,iBAAiB;gBACnD,kBAAkB,EAAE,IAAI,CAAC,KAAK,CAAC,QAAQ;gBACvC,YAAY,EAAE,IAAI,CAAC,KAAK,CAAC,UAAU,GAAG,kBAAkB;gBACxD,oBAAoB,EAAE,IAAI,CAAC,KAAK,CAAC,UAAU;gBAC3C,WAAW,EAAE,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAChC,GAAG,CAAC,EAAE,CAAC,MAAM,CAAC,GAAG,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC;gBAC1D,YAAY,EAAE,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,KAAK,CAAC;gBAC7C,YAAY,EAAE,aAAa,CAAC,MAAM;gBAClC,SAAS,EAAE,aAAa,CAAC,SAAS;aACnC,CAAC,CAAC;SACJ;QACD,OAAO,CAAC,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAM,CAAC;IAC1D,CAAC;IAED;;;;OAIG;IACK,0BAA0B,CAAC,OAAiB;QAClD,MAAM,KAAK,GAAG,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;QACnE,OAAO,KAAK,CAAC;IACf,CAAC;IAED;;;;;;OAMG;IACK,qBAAqB,CACzB,UAAkB,EAAE,MAAsB,EAC1C,OAAiB;QACnB,MAAM,UAAU,GAAG,WAAW,CAAC,UAAU,CAAC,CAAC;QAC3C,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,MAAM,YAAY,GAAa,UAAU,CAAC,YAAY,IAAI,EAAE,CAAC;YAC7D,MAAM,aAAa,GAAc,UAAU,CAAC,aAAa,IAAI,EAAE,CAAC;YAEhE,wEAAwE;YACxE,2CAA2C;YAC3C,IAAI,kBAA4B,CAAC;YACjC,IAAI,UAAU,CAAC,aAAa,EAAE;gBAC5B,IAAI,CAAC,MAAM,CACP,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EACrB,GAAG,EAAE,CAAC,wDAAwD,CAAC,CAAC;gBAEpE,kBAAkB,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,EAAE,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;aACpE;iBAAM;gBACL,kBAAkB,GAAG,YAAY,CAAC,GAAG,CAAC,CAAC,SAAS,EAAE,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC;aACzE;YAED,MAAM,mBAAmB,GACrB,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC,CAAC;YAE/C,OAAO,kBAAkB,CAAC,MAAM,CAAC,mBAAmB,CAAC,CAAC;SACvD;QACD,2EAA2E;QAC3E,yEAAyE;QACzE,mBAAmB;QACnB,EAAE;QACF,yEAAyE;QACzE,uCAAuC;QACvC,OAAO,EAAE,CAAC;IACZ,CAAC;IAED;;;;OAIG;IACH,UAAU,CACN,MAAkB,EAAE,KAAe,EAAE,KAAe,EACpD,OAAuB;QACzB,IAAI,MAAM,IAAI,IAAI,EAAE;YAClB,MAAM,IAAI,KAAK,CAAC,+CAA+C,CAAC,CAAC;SAClE;QACD,KAAK,GAAG,KAAK,IAAI,SAAS,CAAC;QAC3B,OAAO,GAAG,OAAO,IAAI,IAAI,CAAC,OAAO,CAAC;QAClC,IAAI,WAAW,GAAG,MAAuB,CAAC;QAC1C,IAAI,KAAK,KAAK,QAAQ,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,EAAE;YAClD,WAAW,GAAI,MAAmB,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;SACnE;QACD,MAAM,MAAM,GAAG,OAAO,CAAC,KAAK,CAAC,WAAW,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;QACxD,MAAM,CAAC,GAAG,IAAI,MAAM,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,EAAE,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;QAChE,IAAI,CAAC,WAAW,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;QAE7B,kCAAkC;QAClC,IAAI,KAAK,KAAK,QAAQ,EAAE;YACtB,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;YAC/C,MAAM,QAAQ,GAAG,oBAAoB,CAAC,WAA2B,CAAC,CAAC;YACnE,IAAI,CAAC,KAAK,CAAC,QAAQ,IAAI,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC;YAC7C,IAAI,CAAC,KAAK,GAAG,QAAQ,CAAC;SACvB;QACD,OAAO,CAAC,CAAC;IACX,CAAC;IAED;;;;OAIG;IACH,oBAAoB,CAChB,MAAc,EAAE,KAAe,EAAE,KAAe,EAChD,OAAuB;QACzB,KAAK,GAAG,KAAK,IAAI,SAAS,CAAC;QAC3B,MAAM,CAAC,GAAG,IAAI,MAAM,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,EAAE,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;QAChE,IAAI,CAAC,WAAW,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;QAC7B,OAAO,CAAC,CAAC;IACX,CAAC;IAED,YAAY,CACR,YAAoB,EAAE,SAAS,GAAG,IAAI,EAAE,IAAa,EACrD,KAAgB;QAClB,IAAI,GAAG,IAAI,IAAI,IAAI,CAAC,cAAc,EAAE,CAAC,QAAQ,EAAE,CAAC;QAChD,IAAI,KAAK,IAAI,IAAI,IAAI,KAAK,KAAK,YAAY,CAAC,KAAK,EAAE;YACjD,YAAY,GAAG,YAAY,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SACzC;QACD,MAAM,CAAC,GAAG,IAAI,QAAQ,CAAC,YAAY,EAAE,SAAS,EAAE,IAAI,EAAE,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;QAC3E,IAAI,IAAI,CAAC,KAAK,CAAC,mBAAmB,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,IAAI,EAAE;YAClD,MAAM,IAAI,KAAK,CAAC,sBAAsB,CAAC,CAAC,IAAI,yBAAyB,CAAC,CAAC;SACxE;QACD,IAAI,CAAC,KAAK,CAAC,mBAAmB,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC3C,IAAI,CAAC,MAAM,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;QAC7B,OAAO,CAAC,CAAC;IACX,CAAC;IAED,WAAW,CAAC,CAAS,EAAE,OAAsB;QAC3C,IAAI,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC;QACxB,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;YACxB,IAAI,CAAC,KAAK,CAAC,gBAAgB,EAAE,CAAC;SAC/B;QACD,uEAAuE;QACvE,kDAAkD;QAClD,IAAI,KAAK,GAAG,CAAC,CAAC;QACd,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;YACnD,KAAK,GAAG,CAAC,CAAC,IAAI,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;SAChD;QACD,IAAI,CAAC,KAAK,CAAC,QAAQ,IAAI,KAAK,CAAC;QAE7B,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,EAAE;YACxC,IAAI,CAAC,KAAK,CAAC,cAAc,EAAE,CAAC;YAC5B,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,EAAE;gBAClC,OAAO,EAAE,OAAO,IAAI,IAAI,CAAC,OAAO;gBAChC,KAAK,EAAE,CAAC,CAAC,KAAK;gBACd,KAAK,EAAE,CAAC,CAAC,KAAK;gBACd,KAAK;aACN,CAAC,CAAC;SACJ;QAED,IAAI,CAAC,CAAC,CAAC,YAAY,QAAQ,CAAC,EAAE;YAC5B,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;SACf;IACH,CAAC;IAED,6EAA6E;IAC7E,WAAW;IACX,6EAA6E;IAC7E,8EAA8E;IAC9E,kDAAkD;IAClD,MAAM,CAAC,CAAS,EAAE,OAAsB;QACtC,IAAI,CAAC,WAAW,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;QAC7B,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;IAChC,CAAC;IAED,YAAY,CAAC,MAAc,EAAE,OAAsB;QACjD,IAAI,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,MAAM,CAAC;YACjC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,OAAO,KAAK,OAAO,EAAE;YACzD,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YACrC,IAAI,CAAC,KAAK,CAAC,cAAc,EAAE,CAAC;SAC7B;IACH,CAAC;IACD,aAAa,CAAC,CAAS;QACrB,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,EAAE;YACxC,OAAO;SACR;QACD,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;QAEjD,IAAI,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC;QACxB,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;YACxB,IAAI,CAAC,KAAK,CAAC,gBAAgB,EAAE,CAAC;YAC9B,IAAI,CAAC,KAAK,CAAC,QAAQ,IAAI,IAAI,CAAC,KAAK,CAAC;SACnC;QACD,qEAAqE;QACrE,cAAc;QACd,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW,IAAI,CAAC,CAAC,KAAK,KAAK,QAAQ,EAAE;YACnD,MAAM,KAAK,GAAG,CAAC,CAAC,IAAI,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;YACrD,IAAI,CAAC,KAAK,CAAC,QAAQ,IAAI,KAAK,CAAC;SAC9B;QAED,0EAA0E;QAC1E,IAAI,IAAI,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,MAAM,CAAC,EAAE;YACtC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,MAAM,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;SAC3C;QAED,kEAAkE;QAClE,wEAAwE;QACxE,yBAAyB;IAC3B,CAAC;IAED,gBAAgB;QACd,KAAK,MAAM,OAAO,IAAI,IAAI,CAAC,KAAK,CAAC,mBAAmB,EAAE;YACpD,MAAM,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,mBAAmB,CAAC,OAAO,CAAC,CAAC;YAClD,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;SACzB;IACH,CAAC;IAED,eAAe,CAAC,CAAW;QACzB,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,CAAC;QACtB,IAAI,IAAI,CAAC,KAAK,CAAC,mBAAmB,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,IAAI,EAAE;YAClD,OAAO,IAAI,CAAC,KAAK,CAAC,mBAAmB,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;SAC/C;IACH,CAAC;IAED,MAAM;QACJ,MAAM,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAgB,CAAC;QACjD,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC;QACxC,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,KAAK,CAAC,cAAc,CAAC;QAChD,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC,QAAQ,CAAC;QACpC,IAAI,IAAI,CAAC,KAAK,CAAC,gBAAgB,GAAG,CAAC,EAAE;YACnC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC;YACvB,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;gBACxB,IAAI,CAAC,OAAO,GAAG,EAAE,CAAC;aACnB;YACD,IAAI,CAAC,OAAO,CAAC,IAAI,CACb,gDAAgD;gBAChD,yBAAyB,CAAC,CAAC;SAChC;QACD,OAAO,IAAI,CAAC;IACd,CAAC;IAED,KAAK,CAAC,OAAO,CAAC,KAAyD;QAErE,IAAI,CAAC,KAAK,CAAC,SAAS,GAAG,IAAI,CAAC;QAE5B,MAAM,UAAU,GAAG,IAAI,CAAC,KAAK,CAAC,QAAQ,CAAC;QACvC,MAAM,eAAe,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC;QAE9C,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,OAAO,GAAG,EAAE,CAAC;QACtC,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,MAAM,GAAG,MAAM,KAAK,EAAE,CAAC;QAEhD,IAAI,CAAC,KAAK,CAAC,SAAS,GAAG,KAAK,CAAC;QAE7B,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,SAAS,GAAG,IAAI,CAAC,GAAG,CACzC,GAAG,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,kBAAkB,CAAC,CAAC,CAAC;QACxE,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC,QAAQ,GAAG,UAAU,CAAC;QACrE,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,UAAU;YAC/B,IAAI,CAAC,KAAK,CAAC,UAAU,GAAG,eAAe,CAAC;QAC5C,KAAK,MAAM,MAAM,IAAI,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,OAAO,EAAE;YACrD,MAAM,CAAC,YAAY,GAAG,MAAM,MAAM,CAAC,YAAY,CAAC;YAChD,MAAM,CAAC,SAAS,GAAG,MAAM,MAAM,CAAC,SAAS,CAAC;SAC3C;QACD,OAAO,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC;IAClC,CAAC;IAED,QAAQ;QACN,OAAO,IAAI,CAAC,KAAK,CAAC,aAAa,GAAG,CAAC,IAAI,IAAI,CAAC,KAAK,CAAC,WAAW,KAAK,CAAC,CAAC;IACtE,CAAC;IAEO,WAAW,CACf,UAAkB,EAAE,MAAsB,EAAE,OAAiB,EAC7D,aAAuB,EAAE,KAAe,EAAE,KAAmB;QAC/D,MAAM,QAAQ,GACV,EAAC,EAAE,EAAE,IAAI,CAAC,KAAK,CAAC,cAAc,EAAE,EAAE,UAAU,EAAE,MAAM,EAAE,OAAO,EAAE,KAAK,EAAC,CAAC;QAE1E,MAAM,UAAU,GAAG,WAAW,CAAC,UAAU,CAAC,CAAC;QAC3C,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,aAAa,GAAG,UAAU,CAAC,QAAQ,CAAC;SACrC;QACD,IAAI,aAAa,IAAI,IAAI,EAAE;YACzB,QAAQ,CAAC,QAAQ,GAAG,CAAC,GAAa,EAAE,EAAE;gBACpC,sEAAsE;gBACtE,0DAA0D;gBAC1D,GAAG,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE,EAAE;oBACtB,IAAI,EAAE,IAAI,IAAI,EAAE;wBACd,MAAM,MAAM,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;wBAC1B,MAAM,IAAI,GAAG,IAAI,CAAC,mBAAmB,CAAC,MAAM,CAAC,IAAI,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC;wBACjE,OAAO,IAAI,CAAC,UAAU,CAAC,IAAI,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC;qBAC1D;oBACD,OAAO,EAAE,CAAC;gBACZ,CAAC,CAAC,CAAC;gBACH,mEAAmE;gBACnE,kDAAkD;gBAClD,OAAO,aAAa,CAAC,GAAG,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;YACpE,CAAC,CAAC;SACH;QACD,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;IACvC,CAAC;IAED,IAAI,CAAmB,MAAS;QAC9B,MAAM,CAAC,IAAI,GAAG,IAAI,CAAC;QACnB,OAAO,MAAM,CAAC;IAChB,CAAC;IAEO,SAAS;QACf,IAAI,IAAI,CAAC,KAAK,CAAC,aAAa,KAAK,CAAC,EAAE;YAClC,IAAI,CAAC,KAAK,CAAC,UAAU,GAAG,EAAE,CAAC;SAC5B;QACD,IAAI,CAAC,KAAK,CAAC,aAAa,EAAE,CAAC;IAC7B,CAAC;IAEO,OAAO;QACb,IAAI,CAAC,KAAK,CAAC,aAAa,EAAE,CAAC;IAC7B,CAAC;IAED;;;OAGG;IACH,UAAU,CAAC,IAAa;QACtB,MAAM,SAAS,GAAe;YAC5B,KAAK,EAAE,EAAE;YACT,IAAI,EAAE,eAAe;YACrB,EAAE,EAAE,IAAI,CAAC,KAAK,CAAC,WAAW,EAAE;SAC7B,CAAC;QACF,IAAI,IAAI,EAAE;YACR,SAAS,CAAC,IAAI,GAAG,IAAI,CAAC;SACvB;QACD,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QACtC,IAAI,CAAC,KAAK,CAAC,WAAW,GAAG,SAAS,CAAC;IACrC,CAAC;IAED;;;OAGG;IACH,QAAQ,CAAC,MAAwB;QAC/B,MAAM,sBAAsB,GAAG,qBAAqB,CAAC,MAAM,CAAC,CAAC;QAC7D,MAAM,yBAAyB,GAC3B,IAAI,GAAG,CAAC,sBAAsB,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAEnD,4CAA4C;QAC5C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,KAAK,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;YAC5D,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAC/C,IAAI,CAAC,MAAM,CAAC,IAAI,IAAI,CAAC,yBAAyB,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;gBAC7D,MAAM,CAAC,OAAO,EAAE,CAAC;aAClB;SACF;QAED,MAAM,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,EAAE,CAAC;QAC7C,IAAI,CAAC,KAAK,CAAC,WAAW,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,MAAM,KAAK,CAAC,CAAC,CAAC;YACzD,IAAI,CAAC,CAAC;YACN,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAE5D,gDAAgD;QAChD,sBAAsB,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YACtC,uEAAuE;YACvE,iBAAiB;YACjB,IAAI,CAAC,MAAM,CAAC,IAAI,IAAI,MAAM,CAAC,OAAO,KAAK,QAAQ,CAAC,EAAE,EAAE;gBAClD,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;aACpB;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;;;;OAKG;IACH,SAAS,CACL,CAAU,EAAE,EAAY,EAAE,EAAM,EAChC,gBAAgB,GAAG,KAAK;QAC1B,IAAI,CAAC,MAAM,CACP,EAAE,CAAC,MAAM,GAAG,CAAC,EAAE,GAAG,EAAE,CAAC,2CAA2C,CAAC,CAAC;QACtE,IAAI,EAAE,IAAI,IAAI,IAAI,EAAE,CAAC,KAAK,KAAK,SAAS,EAAE;YACxC,MAAM,IAAI,KAAK,CAAC,0CAA0C,EAAE,CAAC,KAAK,GAAG,CAAC,CAAC;SACxE;QAED,MAAM,CAAC,GAAG,IAAI,CAAC,SAAS,CACpB,GAAG,EAAE,CAAC,IAAI,CAAC,SAAS,EAAE,EAAE,GAAG,EAAE,CAAC,IAAI,CAAC,OAAO,EAAE,EAC5C,GAAG,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC;QAEnC,IAAI,CAAC,MAAM,CACP,CAAC,YAAY,MAAM,EACnB,GAAG,EAAE,CAAC,gDAAgD,CAAC,CAAC;QAC5D,kDAAkD;QAClD,MAAM,YAAY,GAAG,oBAAoB,CAAC,IAAI,CAAC,KAAK,CAAC,UAAU,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;QACxE,IAAI,CAAC,gBAAgB,IAAI,YAAY,CAAC,MAAM,KAAK,CAAC,IAAI,EAAE,CAAC,MAAM,GAAG,CAAC,EAAE;YACnE,MAAM,IAAI,KAAK,CACX,iEAAiE;gBACjE,iEAAiE;gBACjE,OAAO,CAAC,CAAC;SACd;QAED,OAAO,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE,GAAG,EAAE;YAChC,MAAM,sBAAsB,GAAiC,EAAE,CAAC;YAChE,sBAAsB,CAAC,CAAC,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC;YAEjE,iDAAiD;YACjD,sBAAsB,CAClB,sBAAsB,EAAE,YAAY;YACpC,+DAA+D;YAC/D,CAAC,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,CAAoB,CAAC;YACpC,gEAAgE;YAChE,GAAG,CAAC,CAAC;YACT,MAAM,KAAK,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,sBAAsB,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;YAExD,IAAI,IAAI,CAAC,KAAK,CAAC,aAAa,KAAK,CAAC,EAAE;gBAClC,8DAA8D;gBAC9D,6BAA6B;gBAC7B,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;oBACnC,KAAK,MAAM,MAAM,IAAI,IAAI,CAAC,KAAK,EAAE;wBAC/B,MAAM,CAAC,OAAO,EAAE,CAAC;qBAClB;gBACH,CAAC,CAAC,CAAC;gBACH,IAAI,CAAC,KAAK,CAAC,UAAU,GAAG,IAAI,CAAC;aAC9B;YACD,OAAO,EAAC,KAAK,EAAE,CAAC,EAAE,KAAK,EAAC,CAAC;QAC3B,CAAC,CAAC,CAAC;IACL,CAAC;IAED,UAAU,CAAmB,CAAwB;QAEnD,IAAI,CAAC,MAAM,CACP,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,EAClB,GAAG,EAAE,CAAC,mDAAmD,CAAC,CAAC;QAC/D,OAAO,CAAC,GAAG,MAAgB,EAAK,EAAE;YAChC,IAAI,CAAC,MAAM,CACP,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,YAAY,MAAM,CAAC,EACtC,GAAG,EAAE,CAAC,2DAA2D;gBAC7D,SAAS,CAAC,CAAC;YAEnB,IAAI,GAGH,CAAC;YACF,MAAM,QAAQ,GAAmB,EAAE,CAAC;YACpC,MAAM,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE,CAAC,EAAE,EAAE;gBAC1B,QAAQ,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC;YACtB,CAAC,CAAC,CAAC;YAEH,MAAM,WAAW,GAAmB,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE;gBAC9C,GAAG,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,MAAM,EAAE,IAAI,CAAC,CAAC,CAAC;gBAC9B,IAAI,CAAC,MAAM,CACP,GAAG,CAAC,KAAK,YAAY,MAAM,EAC3B,GAAG,EAAE,CAAC,wDAAwD;oBAC1D,sCAAsC,CAAC,CAAC;gBAChD,IAAI,CAAC,MAAM,CACP,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,QAAQ,CAAC,EAC7B,GAAG,EAAE,CAAC,wDAAwD;oBAC1D,4CAA4C,CAAC,CAAC;gBACtD,OAAO,GAAG,CAAC,KAAK,CAAC;YACnB,CAAC,CAAC;YAEF,MAAM,aAAa,GAAG,CAAC,EAAK,EAAE,KAAe,EAAE,EAAE;gBAC/C,MAAM,OAAO,GAAG,GAAG,CAAC,QAAQ,CAAC,EAAE,EAAE,KAAK,CAAC,CAAC;gBACxC,MAAM,KAAK,GAAa,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC;gBACrE,IAAI,CAAC,MAAM,CACP,KAAK,CAAC,MAAM,KAAK,MAAM,CAAC,MAAM,EAC9B,GAAG,EAAE,CAAC,wDAAwD;oBAC1D,yDAAyD;oBACzD,wDAAwD,CAAC,CAAC;gBAClE,IAAI,CAAC,MAAM,CACP,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,YAAY,MAAM,CAAC,EACrC,GAAG,EAAE,CAAC,wDAAwD;oBAC1D,yDAAyD;oBACzD,yBAAyB,CAAC,CAAC;gBACnC,MAAM,OAAO,GAAkC,EAAE,CAAC;gBAClD,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,EAAE,EAAE;oBACxB,OAAO,CAAC,CAAC,CAAC,GAAG,GAAG,EAAE,CAAC,IAAI,CAAC;gBAC1B,CAAC,CAAC,CAAC;gBACH,OAAO,OAAO,CAAC;YACjB,CAAC,CAAC;YAEF,OAAO,IAAI,CAAC,aAAa,CAAC;gBACxB,WAAW;gBACX,aAAa;gBACb,MAAM,EAAE,QAAQ;aACjB,CAAC,CAAC;QACL,CAAC,CAAC;IACJ,CAAC;IAED,QAAQ,CAAC,MAAc;QACrB,yCAAyC;QACzC,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;QAC/C,OAAO,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;IACvC,CAAC;IACD,IAAI,CAAC,MAAc;QACjB,yCAAyC;QACzC,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC;QAC/C,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IACnC,CAAC;IAED,KAAK,CAAC,IAAI,CAAC,KAAiB;QAC1B,MAAM,KAAK,GAAG,GAAG,EAAE,CAAC;QACpB,MAAM,UAAU,GAAG,MAAM,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAe,CAAC;QAChE,UAAU,CAAC,MAAM,GAAG,GAAG,EAAE,GAAG,KAAK,CAAC;QAClC,OAAO,UAAU,CAAC;IACpB,CAAC;IAED;;;;;OAKG;IACK,KAAK,CAAmB,MAAS;QACvC,IAAI,IAAI,CAAC,KAAK,CAAC,WAAW,IAAI,IAAI,EAAE;YAClC,MAAM,CAAC,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,EAAE,CAAC;YAC3C,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;SAC3C;QAED,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,IAAI,mBAAmB;QACrB,OAAO,IAAI,CAAC,KAAK,CAAC,mBAAmB,CAAC;IACxC,CAAC;IAED;;;OAGG;IACH,KAAK;QACH,qCAAqC;QACrC,IAAI,CAAC,oBAAoB,EAAE,CAAC;QAE5B,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE,CAAC;QACrB,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,CAAC;QACjB,IAAI,CAAC,KAAK,GAAG,IAAI,WAAW,EAAE,CAAC;QAE/B,KAAK,MAAM,WAAW,IAAI,IAAI,CAAC,QAAQ,EAAE;YACvC,IAAI,CAAC,wBAAwB,CAAC,WAAW,CAAC,CAAC;YAC3C,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,CAAC,OAAO,EAAE,CAAC;YACrC,OAAO,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,CAAC;SACnC;QACD,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;QACxB,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAC;IACjC,CAAC;;AA7vBc,mBAAY,GAAG,CAAC,CAAC;AAKjB,qBAAc,GAAG,CAAC,CAAC;AA2vBpC,SAAS,IAAI,CAAC,KAAe;IAC3B,MAAM,MAAM,GAAG,kBAAkB,CAAC,aAAa,CAAC,KAAK,CAAC,EAAE,SAAS,CAAC,CAAC;IACnE,OAAO,MAAM,CAAC,UAAU,CAAC,MAAM,EAAE,KAAK,EAAE,SAAS,CAAC,CAAC;AACrD,CAAC;AAED,MAAM,UAAU,eAAe;IAC7B,MAAM,EAAE,GAAG,kBAAkB,EAA+B,CAAC;IAC7D,IAAI,EAAE,CAAC,SAAS,IAAI,IAAI,EAAE;QACxB,MAAM,WAAW,GAAG,IAAI,WAAW,CAAC,EAAE,CAAC,CAAC;QACxC,EAAE,CAAC,SAAS,GAAG,IAAI,MAAM,CAAC,WAAW,CAAC,CAAC;KACxC;IACD,oBAAoB,CAAC,EAAE,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC;IAEvC,0EAA0E;IAC1E,gBAAgB;IAChB,gBAAgB,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC;IACrC,OAAO,EAAE,CAAC,SAAS,CAAC;AACtB,CAAC;AAED,MAAM,CAAC,MAAM,MAAM,GAAG,eAAe,EAAE,CAAC;AAExC;;;;;GAKG;AACH,MAAM,UAAU,GAAG,CAAC,CAAS,EAAE,CAAS;IACtC,oEAAoE;IACpE,MAAM,MAAM,GAAG,EAAC,CAAC,EAAE,CAAC,EAAC,CAAC;IACtB,OAAO,MAAM,CAAC,SAAS,CAAC,GAAG,EAAE,MAA8B,CAAC,CAAC;AAC/D,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendTimingInfo, DataMover, KernelBackend} from './backends/backend';\nimport {Environment, setEnvironmentGlobal} from './environment';\nimport {getGlobalNamespace} from './global_util';\nimport {Add, Cast, Identity} from './kernel_names';\nimport {getGradient, getKernel, getKernelsForBackend, GradFunc, NamedAttrMap, TensorInfo} from './kernel_registry';\nimport {KernelProfile, Profiler} from './profiler';\nimport {backpropagateGradients, getFilteredNodesXToY, TapeNode} from './tape';\nimport {DataId, setTensorTracker, Tensor, TensorTracker, Variable} from './tensor';\nimport {GradSaveFunc, NamedTensorMap, NamedVariableMap, TensorContainer} from './tensor_types';\nimport {getTensorsInContainer} from './tensor_util';\nimport {BackendValues, DataType, DataValues} from './types';\nimport * as util from './util';\nimport {bytesFromStringArray, makeOnesTypedArray, now, sizeFromShape} from './util';\n\n/**\n * A function that computes an output. The save function is for saving tensors\n * computed in the forward pass, that we need in the backward pass.\n */\nexport type ForwardFunc<T> = (backend: KernelBackend, save?: GradSaveFunc) => T;\n\n/**\n * @docalias (a: Tensor, b: Tensor,..., save?: Function) => {\n *   value: Tensor,\n *   gradFunc: (dy: Tensor, saved?: NamedTensorMap) => Tensor | Tensor[]\n * }\n */\nexport type CustomGradientFunc<T extends Tensor> =\n    (...inputs: Array<Tensor|GradSaveFunc>) => {\n      value: T;\n      gradFunc: (dy: T, saved: Tensor[]) => Tensor | Tensor[];\n    };\n\nexport type MemoryInfo = {\n  numTensors: number; numDataBuffers: number; numBytes: number;\n  unreliable?: boolean; reasons: string[];\n};\n\ntype KernelInfo = {\n  name: string; bytesAdded: number; totalBytesSnapshot: number;\n  tensorsAdded: number;\n  totalTensorsSnapshot: number;\n  inputShapes: number[][];\n  outputShapes: number[][];\n  kernelTimeMs: number | {error: string} | Promise<number|{error: string}>;\n  extraInfo: string | Promise<string>;\n};\n\nexport type ProfileInfo = {\n  newBytes: number; newTensors: number; peakBytes: number;\n  kernels: KernelInfo[];\n  result: TensorContainer;\n  kernelNames: string[];\n};\n\nexport interface TimingInfo extends BackendTimingInfo {\n  wallMs: number;\n}\n\n/** @docalias Function */\nexport type ScopeFn<T extends TensorContainer> = () => T;\n\ninterface ScopeState {\n  track: Tensor[];\n  name: string;\n  id: number;\n}\n\ninterface RegisteredKernelInvocation<I extends NamedTensorMap> {\n  kernelName: string;\n  inputs: I;\n  attrs?: NamedAttrMap;\n}\n\ninterface CustomGradKernelInvocation<T extends Tensor|Tensor[],\n                                               I extends NamedTensorMap> {\n  forwardFunc: ForwardFunc<T>;\n  backwardsFunc: (dy: T, saved: Tensor[]) => {\n    [P in keyof I]: () => I[P]\n  };\n  inputs: I;\n  attrs?: NamedAttrMap;\n}\n\nfunction isRegisteredKernelInvocation<T extends Tensor|Tensor[],\n                                                I extends NamedTensorMap>(\n    kernelInvocation: RegisteredKernelInvocation<I>|\n    CustomGradKernelInvocation<T, I>):\n    kernelInvocation is RegisteredKernelInvocation<I> {\n  return (kernelInvocation as RegisteredKernelInvocation<I>).kernelName != null;\n}\n\nclass EngineState {\n  // Public since optimizers will use it.\n  registeredVariables: NamedVariableMap = {};\n\n  nextTapeNodeId = 0;\n  numBytes = 0;\n  numTensors = 0;\n  numStringTensors = 0;\n  numDataBuffers = 0;\n\n  activeTape: TapeNode[];\n  // Number of nested tf.grad() statements when computing higher-order\n  // gradients. E.g. `1` for first-order gradients and `2` for second-order\n  // gradients. Used to track if the tape should be removed after a backprop.\n  gradientDepth = 0;\n  // Number of nested kernel calls. When kernel depth is greater than 1, we turn\n  // off the tape.\n  kernelDepth = 0;\n\n  // Keep Tensors that parallel the tapes.\n  activeScope: ScopeState;\n  scopeStack: ScopeState[] = [];\n  /**\n   * Keeps track of the number of data moves during a kernel execution. We\n   * maintain a stack since kernels can call other kernels, recursively.\n   */\n  numDataMovesStack: number[] = [];\n  nextScopeId = 0;\n\n  tensorInfo = new WeakMap<DataId, {\n    backend: KernelBackend,\n    bytes: number,\n    dtype: DataType,\n    shape: number[]\n  }>();\n\n  profiling = false;\n  activeProfile: ProfileInfo = {\n    newBytes: 0,\n    newTensors: 0,\n    peakBytes: 0,\n    kernels: [],\n    result: null,\n    get kernelNames():\n        string[] {\n          return Array.from(new Set(this.kernels.map(k => k.name)));\n        }\n  };\n\n  dispose() {\n    for (const variableName in this.registeredVariables) {\n      this.registeredVariables[variableName].dispose();\n    }\n  }\n}\n\nexport class Engine implements TensorTracker, DataMover {\n  state: EngineState;\n  backendName: string;\n  registry: {[id: string]: KernelBackend} = {};\n  registryFactory: {\n    [id: string]: {\n      factory: () => KernelBackend | Promise<KernelBackend>,\n      priority: number\n    }\n  } = {};\n\n  private profiler: Profiler;\n  private backendInstance: KernelBackend;\n  private pendingBackendInit: Promise<boolean>;\n  private pendingBackendInitId = 0;\n\n  constructor(public ENV: Environment) {\n    this.state = new EngineState();\n  }\n\n  async ready(): Promise<void> {\n    if (this.pendingBackendInit != null) {\n      return this.pendingBackendInit.then(() => {});\n    }\n    if (this.backendInstance != null) {\n      return;\n    }\n    const sortedBackends = this.getSortedBackends();\n\n    for (let i = 0; i < sortedBackends.length; i++) {\n      const backendName = sortedBackends[i];\n      const success = await this.initializeBackend(backendName).success;\n      if (success) {\n        await this.setBackend(backendName);\n        return;\n      }\n    }\n\n    throw new Error(\n        `Could not initialize any backends, all backend initializations ` +\n        `failed.`);\n  }\n\n  get backend(): KernelBackend {\n    if (this.pendingBackendInit != null) {\n      throw new Error(\n          `Backend '${this.backendName}' has not yet been initialized. Make ` +\n          `sure to await tf.ready() or await tf.setBackend() before calling ` +\n          `other methods`);\n    }\n    if (this.backendInstance == null) {\n      const {name, asyncInit} = this.initializeBackendsAndReturnBest();\n      if (asyncInit) {\n        throw new Error(\n            `The highest priority backend '${name}' has not yet been ` +\n            `initialized. Make sure to await tf.ready() or ` +\n            `await tf.setBackend() before calling other methods`);\n      }\n      this.setBackend(name);\n    }\n    return this.backendInstance;\n  }\n\n  backendNames(): string[] {\n    return Object.keys(this.registryFactory);\n  }\n\n  findBackend(backendName: string): KernelBackend {\n    if (!(backendName in this.registry)) {\n      // If the backend hasn't been initialized but we have a registry entry for\n      // it, initialize it and return it.\n      if (backendName in this.registryFactory) {\n        const {asyncInit} = this.initializeBackend(backendName);\n        if (asyncInit) {\n          // Backend is not ready yet.\n          return null;\n        }\n      } else {\n        return null;\n      }\n    }\n    return this.registry[backendName];\n  }\n\n  findBackendFactory(backendName: string):\n      () => KernelBackend | Promise<KernelBackend> {\n    if (!(backendName in this.registryFactory)) {\n      return null;\n    }\n    return this.registryFactory[backendName].factory;\n  }\n\n  registerBackend(\n      backendName: string,\n      factory: () => KernelBackend | Promise<KernelBackend>,\n      priority = 1): boolean {\n    if (backendName in this.registryFactory) {\n      console.warn(\n          `${backendName} backend was already registered. ` +\n          `Reusing existing backend factory.`);\n      return false;\n    }\n    this.registryFactory[backendName] = {factory, priority};\n    return true;\n  }\n\n  async setBackend(backendName: string): Promise<boolean> {\n    if (this.registryFactory[backendName] == null) {\n      throw new Error(`Backend name '${backendName}' not found in registry`);\n    }\n    this.backendName = backendName;\n    if (this.registry[backendName] == null) {\n      this.backendInstance = null;\n      const {success, asyncInit} = this.initializeBackend(backendName);\n      const result = asyncInit ? await success : success;\n      if (!result) {\n        return false;\n      }\n    }\n    this.backendInstance = this.registry[backendName];\n    this.setupRegisteredKernels();\n    // Reset the profiler.\n    this.profiler = new Profiler(this.backendInstance);\n\n    return true;\n  }\n\n  private setupRegisteredKernels(): void {\n    const kernels = getKernelsForBackend(this.backendName);\n    kernels.forEach(kernel => {\n      if (kernel.setupFunc != null) {\n        kernel.setupFunc(this.backendInstance);\n      }\n    });\n  }\n\n  private disposeRegisteredKernels(backendName: string): void {\n    const kernels = getKernelsForBackend(backendName);\n    kernels.forEach(kernel => {\n      if (kernel.disposeFunc != null) {\n        kernel.disposeFunc(this.registry[backendName]);\n      }\n    });\n  }\n\n  /**\n   * Initializes a backend by looking up the backend name in the factory\n   * registry and calling the factory method. Returns a boolean representing\n   * whether the initialization of the backend suceeded. Throws an error if\n   * there is no backend in the factory registry.\n   */\n  private initializeBackend(backendName: string):\n      {success: boolean|Promise<boolean>, asyncInit: boolean} {\n    const registryFactoryEntry = this.registryFactory[backendName];\n    if (registryFactoryEntry == null) {\n      throw new Error(\n          `Cannot initialize backend ${backendName}, no registration found.`);\n    }\n\n    try {\n      const backend = registryFactoryEntry.factory();\n      /* Test if the factory returns a promise.\n      Done in a more liberal way than\n      previous 'Promise.resolve(backend)===backend'\n      as we needed to account for custom Promise\n      implementations (e.g. Angular) */\n      if (backend && !(backend instanceof KernelBackend) &&\n          typeof backend.then === 'function') {\n        const promiseId = ++this.pendingBackendInitId;\n        const success =\n            backend\n                .then(backendInstance => {\n                  // Outdated promise. Another backend was set in the meantime.\n                  if (promiseId < this.pendingBackendInitId) {\n                    return false;\n                  }\n                  this.registry[backendName] = backendInstance;\n                  this.pendingBackendInit = null;\n                  return true;\n                })\n                .catch(err => {\n                  // Outdated promise. Another backend was set in the meantime.\n                  if (promiseId < this.pendingBackendInitId) {\n                    return false;\n                  }\n                  this.pendingBackendInit = null;\n                  console.warn(\n                      `Initialization of backend ${backendName} failed`);\n                  console.warn(err.stack || err.message);\n                  return false;\n                });\n        this.pendingBackendInit = success;\n        return {success, asyncInit: true};\n      } else {\n        this.registry[backendName] = backend as KernelBackend;\n        return {success: true, asyncInit: false};\n      }\n    } catch (err) {\n      console.warn(`Initialization of backend ${backendName} failed`);\n      console.warn(err.stack || err.message);\n      return {success: false, asyncInit: false};\n    }\n  }\n\n  removeBackend(backendName: string): void {\n    if (!(backendName in this.registryFactory)) {\n      throw new Error(`${backendName} backend not found in registry`);\n    }\n    if (this.backendName === backendName && this.pendingBackendInit != null) {\n      // There is a pending promise of the backend we want to remove. Make it\n      // obsolete.\n      this.pendingBackendInitId++;\n    }\n\n    if (backendName in this.registry) {\n      this.disposeRegisteredKernels(backendName);\n      this.registry[backendName].dispose();\n      delete this.registry[backendName];\n    }\n\n    delete this.registryFactory[backendName];\n\n    // Unset the backend if it is active.\n    if (this.backendName === backendName) {\n      this.pendingBackendInit = null;\n      this.backendName = null;\n      this.backendInstance = null;\n    }\n  }\n\n  private getSortedBackends(): string[] {\n    if (Object.keys(this.registryFactory).length === 0) {\n      throw new Error('No backend found in registry.');\n    }\n    return Object.keys(this.registryFactory).sort((a: string, b: string) => {\n      // Highest priority comes first.\n      return this.registryFactory[b].priority -\n          this.registryFactory[a].priority;\n    });\n  }\n\n  private initializeBackendsAndReturnBest():\n      {name: string, asyncInit: boolean} {\n    const sortedBackends = this.getSortedBackends();\n\n    for (let i = 0; i < sortedBackends.length; i++) {\n      const backendName = sortedBackends[i];\n      const {success, asyncInit} = this.initializeBackend(backendName);\n      if (asyncInit || success) {\n        return {name: backendName, asyncInit};\n      }\n    }\n    throw new Error(\n        `Could not initialize any backends, all backend initializations ` +\n        `failed.`);\n  }\n\n  moveData(backend: KernelBackend, dataId: DataId) {\n    const info = this.state.tensorInfo.get(dataId);\n    const srcBackend = info.backend;\n    const values = this.readSync(dataId);\n    const refCount = srcBackend.refCount(dataId);\n    // Delete the tensor from the old backend and move it to the new\n    // backend.\n    srcBackend.disposeData(dataId, true);\n    info.backend = backend;\n    backend.move(dataId, values, info.shape, info.dtype, refCount);\n    if (this.shouldCheckForMemLeaks()) {\n      // Track the number of moves during a kernel execution to correctly\n      // detect memory leaks.\n      this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n    }\n  }\n\n  tidy<T extends TensorContainer>(nameOrFn: string|ScopeFn<T>, fn?: ScopeFn<T>):\n      T {\n    let name: string = null;\n    if (fn == null) {\n      // Called with only 1 argument.\n      if (typeof nameOrFn !== 'function') {\n        throw new Error('Please provide a function to tidy()');\n      }\n      fn = nameOrFn;\n    } else {\n      // Called with 2 arguments.\n      if (typeof nameOrFn !== 'string' && !(nameOrFn instanceof String)) {\n        throw new Error(\n            'When calling with two arguments, the first argument ' +\n            'to tidy() must be a string');\n      }\n      if (typeof fn !== 'function') {\n        throw new Error(\n            'When calling with two arguments, the 2nd argument ' +\n            'to tidy() must be a function');\n      }\n      name = nameOrFn as string;\n      // TODO(nsthorat,smilkov): Do operation logging and performance\n      // profiling.\n    }\n    let result: T;\n    return this.scopedRun(\n        () => this.startScope(name), () => this.endScope(result), () => {\n          result = fn();\n          if (result instanceof Promise) {\n            console.error('Cannot return a Promise inside of tidy.');\n          }\n          return result;\n        });\n  }\n\n  private scopedRun<T>(start: () => void, end: () => void, f: () => T): T {\n    start();\n    try {\n      const res = f();\n      end();\n      return res;\n    } catch (ex) {\n      end();\n      throw ex;\n    }\n  }\n\n  private static nextTensorId = 0;\n  private nextTensorId(): number {\n    return Engine.nextTensorId++;\n  }\n\n  private static nextVariableId = 0;\n  private nextVariableId(): number {\n    return Engine.nextVariableId++;\n  }\n\n  /**\n   * This method is called instead of the public-facing tensor.clone() when\n   * saving a tensor for backwards pass. It makes sure to add the clone\n   * operation to the tape regardless of being called inside a kernel\n   * execution.\n   */\n  private clone(x: Tensor): Tensor {\n    const y: Tensor = ENGINE.runKernel(Identity, {x} as {} as NamedTensorMap);\n    const inputs = {x};\n    const grad = (dy: Tensor) => ({\n      x: () => {\n        const dtype = 'float32';\n        const gradInputs = {x: dy};\n        const attrs = {dtype};\n\n        return ENGINE.runKernel(\n                   Cast, gradInputs as {} as NamedTensorMap,\n                   // tslint:disable-next-line: no-unnecessary-type-assertion\n                   attrs as {} as NamedAttrMap) as Tensor;\n      }\n    });\n    const saved: Tensor[] = [];\n    this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});\n    return y;\n  }\n\n  /**\n   * Execute a kernel with the given name and return the output tensor.\n   *\n   * @param kernelName The name of the kernel to execute.\n   * @param inputs A map of input names to tensors.\n   * @param attrs A map of attribute names to their values. An attribute is a\n   *     primitive (non-tensor) input to the kernel.\n   * @param inputsToSave A list of tensors, inputs to save for the backprop\n   *     computation.\n   * @param outputsToSave A list of booleans, specifying which output to save\n   *     for the backprop computation. These are booleans since the output\n   * tensors are not visible to the user.\n   */\n  runKernel<T extends Tensor|Tensor[]>(\n      kernelName: string, inputs: NamedTensorMap, attrs?: NamedAttrMap): T {\n    const hasKernel = getKernel(kernelName, this.backendName) != null;\n    if (!hasKernel) {\n      throw new Error(`Kernel '${kernelName}' not registered for backend '${\n          this.backendName}'`);\n    }\n    return this.runKernelFunc({kernelName, inputs, attrs});\n  }\n\n  private shouldCheckForMemLeaks(): boolean {\n    return this.ENV.getBool('IS_TEST');\n  }\n\n  private checkKernelForMemLeak(\n      kernelName: string, numDataIdsBefore: number,\n      outInfos: TensorInfo[]): void {\n    const numDataIdsAfter = this.backend.numDataIds();\n\n    // Count the number of data ids associated with the result of the kernel.\n    let numOutputDataIds = 0;\n    outInfos.forEach(info => {\n      // Complex numbers allocate 3 data ids, one for 'real', one for\n      // 'imaginary', and one for the container that holds the former two.\n      numOutputDataIds += (info.dtype === 'complex64' ? 3 : 1);\n    });\n\n    // Account for the number of moves during kernel execution. A \"data move\"\n    // can happen in the middle of a kernel execution, placing a new (key,value)\n    // pair in the data storage. Since data moves have net zero effect (we\n    // always remove the data from the old backend), we have to cancel them out\n    // when detecting memory leaks.\n    const numMoves =\n        this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n    const dataIdsLeaked =\n        numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;\n    if (dataIdsLeaked > 0) {\n      throw new Error(\n          `Backend '${this.backendName}' has an internal memory leak ` +\n          `(${dataIdsLeaked} data ids) after running '${kernelName}'`);\n    }\n  }\n\n  /**\n   * Internal helper method to execute a kernel Func\n   *\n   * Use `runKernel` to execute kernels from outside of engine.\n   */\n  private runKernelFunc<T extends Tensor|Tensor[], I extends NamedTensorMap>(\n      kernelParams: RegisteredKernelInvocation<I>|\n      CustomGradKernelInvocation<T, I>): T {\n    let outputs: Tensor[];\n    let saved: Tensor[] = [];\n    const isTapeOn = this.isTapeOn();\n\n    const startingBytecount = this.state.numBytes;\n    const startingNumTensors = this.state.numTensors;\n\n    if (this.shouldCheckForMemLeaks()) {\n      this.state.numDataMovesStack.push(0);\n    }\n\n    let kernelFunc: () => Tensor[];\n    if (this.backendName == null) {\n      // backend has not been initialized yet (backend initialization is lazy\n      // can be deferred until an op/ kernel is run).\n      // The below getter has side effects that will try to initialize the\n      // backend and set properties like this.backendName\n      // tslint:disable-next-line: no-unused-expression\n      this.backend;\n    }\n\n    let out: TensorInfo|TensorInfo[];\n\n    const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ?\n        kernelParams.kernelName :\n        this.state.activeScope != null ? this.state.activeScope.name : '';\n\n    // Create the kernelFunc from either a registered kernel OR passed in\n    // forward/backward functions (used by custom grad). In this context a\n    // kernelFunc wraps a kernel implementation with some bookkeeping.\n\n    if (isRegisteredKernelInvocation(kernelParams)) {\n      const {kernelName, inputs, attrs} = kernelParams;\n      if (this.backendName == null) {\n        // backend has not been initialized yet (backend initialization is lazy\n        // can be deferred until an op/ kernel is run).\n        // The below getter has side effects that will try to initialize the\n        // backend and set properties like this.backendName\n        // tslint:disable-next-line: no-unused-expression\n        this.backend;\n      }\n      const kernel = getKernel(kernelName, this.backendName);\n      util.assert(\n          kernel != null,\n          () => `Cannot find registered kernel '${kernelName}' for backend '${\n              this.backendName}'`);\n\n      kernelFunc = () => {\n        const numDataIdsBefore = this.backend.numDataIds();\n        out = kernel.kernelFunc({inputs, attrs, backend: this.backend});\n        const outInfos = Array.isArray(out) ? out : [out];\n        if (this.shouldCheckForMemLeaks()) {\n          this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);\n        }\n\n        const outTensors = outInfos.map((outInfo: TensorInfo|Tensor) => {\n          // todo (yassogba) remove this option (Tensor) when node backend\n          // methods have been modularized and they all return tensorInfo.\n          // TensorInfos do not have a rank attribute.\n          if ((outInfo as Tensor).rank != null) {\n            return outInfo as Tensor;\n          }\n          const {dataId, shape, dtype} = outInfo as TensorInfo;\n          return this.makeTensorFromDataId(dataId, shape, dtype);\n        });\n\n        // Save any required inputs and outputs.\n\n        // Do not save unless we are recording to the tape. Otherwise it would\n        // cause a mem leak since there would be no backprop for these tensors\n        // (which would otherwise dispose them).\n        if (isTapeOn) {\n          const tensorsToSave =\n              this.getTensorsForGradient(kernelName, inputs, outTensors);\n          saved = this.saveTensorsForBackwardMode(tensorsToSave);\n        }\n        return outTensors;\n      };\n    } else {\n      const {forwardFunc} = kernelParams;\n      // Running a customGrad op.\n      const saveFunc: GradSaveFunc = (tensors) => {\n        // Do not save unless we are recording to the tape. Otherwise it would\n        // cause a mem leak since we would never run backprop, which disposes\n        // the kept tensors.\n        if (!isTapeOn) {\n          return;\n        }\n        saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n      };\n\n      kernelFunc = () => {\n        const numDataIdsBefore = this.backend.numDataIds();\n        out = this.tidy(() => forwardFunc(this.backend, saveFunc));\n        const outs = (Array.isArray(out) ? out : [out]) as Tensor[];\n        if (this.shouldCheckForMemLeaks()) {\n          // Scope name is used to print a more helpful error message if needed.\n          this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);\n        }\n        return outs;\n      };\n    }\n\n    //\n    // Run the kernelFunc. Optionally profiling it.\n    //\n    const {inputs, attrs} = kernelParams;\n    const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ?\n        null :\n        kernelParams.backwardsFunc;\n\n    let kernelProfile: KernelProfile;\n    this.scopedRun(\n        // Stop recording to a tape when running a kernel.\n        () => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {\n          if (!this.ENV.getBool('DEBUG') && !this.state.profiling) {\n            outputs = kernelFunc();\n          } else {\n            kernelProfile = this.profiler.profileKernel(\n                kernelOrScopeName, inputs, () => kernelFunc());\n            if (this.ENV.getBool('DEBUG')) {\n              this.profiler.logKernelProfile(kernelProfile);\n            }\n            outputs = kernelProfile.outputs;\n          }\n        });\n\n    if (isTapeOn) {\n      this.addTapeNode(\n          kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);\n    }\n\n    if (this.state.profiling) {\n      this.state.activeProfile.kernels.push({\n        name: kernelOrScopeName,\n        bytesAdded: this.state.numBytes - startingBytecount,\n        totalBytesSnapshot: this.state.numBytes,\n        tensorsAdded: this.state.numTensors - startingNumTensors,\n        totalTensorsSnapshot: this.state.numTensors,\n        inputShapes: Object.keys(inputs).map(\n            key => inputs[key] != null ? inputs[key].shape : null),\n        outputShapes: outputs.map(item => item.shape),\n        kernelTimeMs: kernelProfile.timeMs,\n        extraInfo: kernelProfile.extraInfo\n      });\n    }\n    return (Array.isArray(out) ? outputs : outputs[0]) as T;\n  }\n\n  /**\n   * Saves tensors used in forward mode for use in backward mode.\n   *\n   * @param tensors the list of tensors to save.\n   */\n  private saveTensorsForBackwardMode(tensors: Tensor[]): Tensor[] {\n    const saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n    return saved;\n  }\n\n  /**\n   * Returns a list of tensors to save for a given gradient calculation.\n   *\n   * @param kernelName name of kernel to look up gradient for.\n   * @param inputs a map of input tensors.\n   * @param outputs an array of output tensors from forward mode of kernel.\n   */\n  private getTensorsForGradient(\n      kernelName: string, inputs: NamedTensorMap,\n      outputs: Tensor[]): Tensor[]|null {\n    const gradConfig = getGradient(kernelName);\n    if (gradConfig != null) {\n      const inputsToSave: string[] = gradConfig.inputsToSave || [];\n      const outputsToSave: boolean[] = gradConfig.outputsToSave || [];\n\n      // If saveAllInputs is true, all inputs will be saved. Otherwise, inputs\n      // specified in inputsToSave will be saved.\n      let inputTensorsToSave: Tensor[];\n      if (gradConfig.saveAllInputs) {\n        util.assert(\n            Array.isArray(inputs),\n            () => 'saveAllInputs is true, expected inputs to be an array.');\n\n        inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);\n      } else {\n        inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);\n      }\n\n      const outputTensorsToSave: Tensor[] =\n          outputs.filter((_, i) => outputsToSave[i]);\n\n      return inputTensorsToSave.concat(outputTensorsToSave);\n    }\n    // We return an empty list rather than throw an error because the kernel we\n    // are looking up may not actually be relevant to backproping through the\n    // overall function\n    //\n    // See 'does not error if irrelevant (pruned) ops are missing grads' test\n    // in gradients_test.ts for an example.\n    return [];\n  }\n\n  /**\n   * Internal method used by public APIs for tensor creation. Makes a new\n   * tensor with the provided shape, dtype and values. It always\n   * creates a new data id and writes the values to the underlying backend.\n   */\n  makeTensor(\n      values: DataValues, shape: number[], dtype: DataType,\n      backend?: KernelBackend): Tensor {\n    if (values == null) {\n      throw new Error('Values passed to engine.makeTensor() are null');\n    }\n    dtype = dtype || 'float32';\n    backend = backend || this.backend;\n    let backendVals = values as BackendValues;\n    if (dtype === 'string' && util.isString(values[0])) {\n      backendVals = (values as string[]).map(d => util.encodeString(d));\n    }\n    const dataId = backend.write(backendVals, shape, dtype);\n    const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n    this.trackTensor(t, backend);\n\n    // Count bytes for string tensors.\n    if (dtype === 'string') {\n      const info = this.state.tensorInfo.get(dataId);\n      const newBytes = bytesFromStringArray(backendVals as Uint8Array[]);\n      this.state.numBytes += newBytes - info.bytes;\n      info.bytes = newBytes;\n    }\n    return t;\n  }\n\n  /**\n   * Internal method used by backends. Makes a new tensor\n   * that is a wrapper around an existing data id. It doesn't create\n   * a new data id, only increments the ref count used in memory tracking.\n   */\n  makeTensorFromDataId(\n      dataId: DataId, shape: number[], dtype: DataType,\n      backend?: KernelBackend): Tensor {\n    dtype = dtype || 'float32';\n    const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n    this.trackTensor(t, backend);\n    return t;\n  }\n\n  makeVariable(\n      initialValue: Tensor, trainable = true, name?: string,\n      dtype?: DataType): Variable {\n    name = name || this.nextVariableId().toString();\n    if (dtype != null && dtype !== initialValue.dtype) {\n      initialValue = initialValue.cast(dtype);\n    }\n    const v = new Variable(initialValue, trainable, name, this.nextTensorId());\n    if (this.state.registeredVariables[v.name] != null) {\n      throw new Error(`Variable with name ${v.name} was already registered`);\n    }\n    this.state.registeredVariables[v.name] = v;\n    this.incRef(v, this.backend);\n    return v;\n  }\n\n  trackTensor(a: Tensor, backend: KernelBackend): void {\n    this.state.numTensors++;\n    if (a.dtype === 'string') {\n      this.state.numStringTensors++;\n    }\n    // Bytes for complex numbers are counted by their components. Bytes for\n    // string tensors are counted when writing values.\n    let bytes = 0;\n    if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n      bytes = a.size * util.bytesPerElement(a.dtype);\n    }\n    this.state.numBytes += bytes;\n\n    if (!this.state.tensorInfo.has(a.dataId)) {\n      this.state.numDataBuffers++;\n      this.state.tensorInfo.set(a.dataId, {\n        backend: backend || this.backend,\n        dtype: a.dtype,\n        shape: a.shape,\n        bytes\n      });\n    }\n\n    if (!(a instanceof Variable)) {\n      this.track(a);\n    }\n  }\n\n  // Track the tensor by dataId and increase the refCount for the dataId in the\n  // backend.\n  // TODO(pyu10055): This is currently used by makeVariable method, to increase\n  // refCount on the backend for the dataId. It can potentially be replaced with\n  // Identity op indead of calling backend directly.\n  incRef(a: Tensor, backend: KernelBackend): void {\n    this.trackTensor(a, backend);\n    this.backend.incRef(a.dataId);\n  }\n\n  removeDataId(dataId: DataId, backend: KernelBackend) {\n    if (this.state.tensorInfo.has(dataId) &&\n        this.state.tensorInfo.get(dataId).backend === backend) {\n      this.state.tensorInfo.delete(dataId);\n      this.state.numDataBuffers--;\n    }\n  }\n  disposeTensor(a: Tensor): void {\n    if (!this.state.tensorInfo.has(a.dataId)) {\n      return;\n    }\n    const info = this.state.tensorInfo.get(a.dataId);\n\n    this.state.numTensors--;\n    if (a.dtype === 'string') {\n      this.state.numStringTensors--;\n      this.state.numBytes -= info.bytes;\n    }\n    // Don't count bytes for complex numbers as they are counted by their\n    // components.\n    if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n      const bytes = a.size * util.bytesPerElement(a.dtype);\n      this.state.numBytes -= bytes;\n    }\n\n    // Remove the reference to dataId if backend dispose the data successfully\n    if (info.backend.disposeData(a.dataId)) {\n      this.removeDataId(a.dataId, info.backend);\n    }\n\n    // TODO(nsthorat): Construct an error and save the stack trace for\n    // debugging when in debug mode. Creating a stack trace is too expensive\n    // to do unconditionally.\n  }\n\n  disposeVariables(): void {\n    for (const varName in this.state.registeredVariables) {\n      const v = this.state.registeredVariables[varName];\n      this.disposeVariable(v);\n    }\n  }\n\n  disposeVariable(v: Variable): void {\n    this.disposeTensor(v);\n    if (this.state.registeredVariables[v.name] != null) {\n      delete this.state.registeredVariables[v.name];\n    }\n  }\n\n  memory(): MemoryInfo {\n    const info = this.backend.memory() as MemoryInfo;\n    info.numTensors = this.state.numTensors;\n    info.numDataBuffers = this.state.numDataBuffers;\n    info.numBytes = this.state.numBytes;\n    if (this.state.numStringTensors > 0) {\n      info.unreliable = true;\n      if (info.reasons == null) {\n        info.reasons = [];\n      }\n      info.reasons.push(\n          'Memory usage by string tensors is approximate ' +\n          '(2 bytes per character)');\n    }\n    return info;\n  }\n\n  async profile(query: () => (TensorContainer | Promise<TensorContainer>)):\n      Promise<ProfileInfo> {\n    this.state.profiling = true;\n\n    const startBytes = this.state.numBytes;\n    const startNumTensors = this.state.numTensors;\n\n    this.state.activeProfile.kernels = [];\n    this.state.activeProfile.result = await query();\n\n    this.state.profiling = false;\n\n    this.state.activeProfile.peakBytes = Math.max(\n        ...this.state.activeProfile.kernels.map(d => d.totalBytesSnapshot));\n    this.state.activeProfile.newBytes = this.state.numBytes - startBytes;\n    this.state.activeProfile.newTensors =\n        this.state.numTensors - startNumTensors;\n    for (const kernel of this.state.activeProfile.kernels) {\n      kernel.kernelTimeMs = await kernel.kernelTimeMs;\n      kernel.extraInfo = await kernel.extraInfo;\n    }\n    return this.state.activeProfile;\n  }\n\n  isTapeOn(): boolean {\n    return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;\n  }\n\n  private addTapeNode(\n      kernelName: string, inputs: NamedTensorMap, outputs: Tensor[],\n      gradientsFunc: GradFunc, saved: Tensor[], attrs: NamedAttrMap): void {\n    const tapeNode: TapeNode =\n        {id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved};\n\n    const gradConfig = getGradient(kernelName);\n    if (gradConfig != null) {\n      gradientsFunc = gradConfig.gradFunc;\n    }\n    if (gradientsFunc != null) {\n      tapeNode.gradient = (dys: Tensor[]) => {\n        // TODO(smilkov): To optimize back-prop, pass dys that are not used in\n        // the backprop graph to the user as null instead of zeros\n        dys = dys.map((dy, i) => {\n          if (dy == null) {\n            const output = outputs[i];\n            const vals = util.makeZerosTypedArray(output.size, output.dtype);\n            return this.makeTensor(vals, output.shape, output.dtype);\n          }\n          return dy;\n        });\n        // Grad functions of ops with single outputs expect a dy, while ops\n        // with multiple outputs expect dys (array of dy).\n        return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);\n      };\n    }\n    this.state.activeTape.push(tapeNode);\n  }\n\n  keep<T extends Tensor>(result: T): T {\n    result.kept = true;\n    return result;\n  }\n\n  private startTape() {\n    if (this.state.gradientDepth === 0) {\n      this.state.activeTape = [];\n    }\n    this.state.gradientDepth++;\n  }\n\n  private endTape() {\n    this.state.gradientDepth--;\n  }\n\n  /**\n   * Start a scope. Use this with endScope() to achieve the same functionality\n   * as scope() without the need for a function closure.\n   */\n  startScope(name?: string) {\n    const scopeInfo: ScopeState = {\n      track: [],\n      name: 'unnamed scope',\n      id: this.state.nextScopeId++\n    };\n    if (name) {\n      scopeInfo.name = name;\n    }\n    this.state.scopeStack.push(scopeInfo);\n    this.state.activeScope = scopeInfo;\n  }\n\n  /**\n   * End a scope. Use this with startScope() to achieve the same functionality\n   * as scope() without the need for a function closure.\n   */\n  endScope(result?: TensorContainer) {\n    const tensorsToTrackInParent = getTensorsInContainer(result);\n    const tensorsToTrackInParentSet =\n        new Set(tensorsToTrackInParent.map(t => t.id));\n\n    // Dispose the arrays tracked in this scope.\n    for (let i = 0; i < this.state.activeScope.track.length; i++) {\n      const tensor = this.state.activeScope.track[i];\n      if (!tensor.kept && !tensorsToTrackInParentSet.has(tensor.id)) {\n        tensor.dispose();\n      }\n    }\n\n    const oldScope = this.state.scopeStack.pop();\n    this.state.activeScope = this.state.scopeStack.length === 0 ?\n        null :\n        this.state.scopeStack[this.state.scopeStack.length - 1];\n\n    // Track the current result in the parent scope.\n    tensorsToTrackInParent.forEach(tensor => {\n      // Only track the tensor if was allocated in the inner scope and is not\n      // globally kept.\n      if (!tensor.kept && tensor.scopeId === oldScope.id) {\n        this.track(tensor);\n      }\n    });\n  }\n\n  /**\n   * Returns gradients of `f` with respect to each of the `xs`. The gradients\n   * returned are of the same length as `xs`, but some might be null if `f`\n   * was not a function of that `x`. It also takes optional dy to multiply the\n   * gradient, which defaults to `1`.\n   */\n  gradients<T extends Tensor>(\n      f: () => T, xs: Tensor[], dy?: T,\n      allowNoGradients = false): {value: T, grads: Tensor[]} {\n    util.assert(\n        xs.length > 0, () => 'gradients() received an empty list of xs.');\n    if (dy != null && dy.dtype !== 'float32') {\n      throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);\n    }\n\n    const y = this.scopedRun(\n        () => this.startTape(), () => this.endTape(),\n        () => this.tidy('forward', f));\n\n    util.assert(\n        y instanceof Tensor,\n        () => 'The result y returned by f() must be a tensor.');\n    // Filter out the nodes that don't connect x => y.\n    const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);\n    if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {\n      throw new Error(\n          'Cannot compute gradient of y=f(x) with respect to x. Make sure ' +\n          'that the f you passed encloses all operations that lead from x ' +\n          'to y.');\n    }\n\n    return this.tidy('backward', () => {\n      const accumulatedGradientMap: {[tensorId: number]: Tensor} = {};\n      accumulatedGradientMap[y.id] = (dy == null) ? ones(y.shape) : dy;\n\n      // Backprop gradients through the filtered nodes.\n      backpropagateGradients(\n          accumulatedGradientMap, filteredTape,\n          // Pass the tidy function to avoid circular dep with `tape.ts`.\n          f => this.tidy(f as ScopeFn<Tensor>),\n          // Pass an add function to avoide a circular dep with `tape.ts`.\n          add);\n      const grads = xs.map(x => accumulatedGradientMap[x.id]);\n\n      if (this.state.gradientDepth === 0) {\n        // This means that we are not computing higher-order gradients\n        // and can clean up the tape.\n        this.state.activeTape.forEach(node => {\n          for (const tensor of node.saved) {\n            tensor.dispose();\n          }\n        });\n        this.state.activeTape = null;\n      }\n      return {value: y, grads};\n    });\n  }\n\n  customGrad<T extends Tensor>(f: CustomGradientFunc<T>):\n      (...args: Array<Tensor|GradSaveFunc>) => T {\n    util.assert(\n        util.isFunction(f),\n        () => 'The f passed in customGrad(f) must be a function.');\n    return (...inputs: Tensor[]): T => {\n      util.assert(\n          inputs.every(t => t instanceof Tensor),\n          () => 'The args passed in customGrad(f)(x1, x2,...) must all be ' +\n              'tensors');\n\n      let res: {\n        value: T,\n        gradFunc: (dy: T, saved: Tensor[]) => Tensor | Tensor[],\n      };\n      const inputMap: NamedTensorMap = {};\n      inputs.forEach((input, i) => {\n        inputMap[i] = input;\n      });\n\n      const forwardFunc: ForwardFunc<T> = (_, save) => {\n        res = f(...[...inputs, save]);\n        util.assert(\n            res.value instanceof Tensor,\n            () => 'The function f passed in customGrad(f) must return an ' +\n                'object where `obj.value` is a tensor');\n        util.assert(\n            util.isFunction(res.gradFunc),\n            () => 'The function f passed in customGrad(f) must return an ' +\n                'object where `obj.gradFunc` is a function.');\n        return res.value;\n      };\n\n      const backwardsFunc = (dy: T, saved: Tensor[]) => {\n        const gradRes = res.gradFunc(dy, saved);\n        const grads: Tensor[] = Array.isArray(gradRes) ? gradRes : [gradRes];\n        util.assert(\n            grads.length === inputs.length,\n            () => 'The function f passed in customGrad(f) must return an ' +\n                'object where `obj.gradFunc` is a function that returns ' +\n                'the same number of tensors as inputs passed to f(...).');\n        util.assert(\n            grads.every(t => t instanceof Tensor),\n            () => 'The function f passed in customGrad(f) must return an ' +\n                'object where `obj.gradFunc` is a function that returns ' +\n                'a list of only tensors.');\n        const gradMap: {[key: string]: () => Tensor} = {};\n        grads.forEach((grad, i) => {\n          gradMap[i] = () => grad;\n        });\n        return gradMap;\n      };\n\n      return this.runKernelFunc({\n        forwardFunc,\n        backwardsFunc,\n        inputs: inputMap,\n      });\n    };\n  }\n\n  readSync(dataId: DataId): BackendValues {\n    // Route the read to the correct backend.\n    const info = this.state.tensorInfo.get(dataId);\n    return info.backend.readSync(dataId);\n  }\n  read(dataId: DataId): Promise<BackendValues> {\n    // Route the read to the correct backend.\n    const info = this.state.tensorInfo.get(dataId);\n    return info.backend.read(dataId);\n  }\n\n  async time(query: () => void): Promise<TimingInfo> {\n    const start = now();\n    const timingInfo = await this.backend.time(query) as TimingInfo;\n    timingInfo.wallMs = now() - start;\n    return timingInfo;\n  }\n\n  /**\n   * Tracks a Tensor in the current scope to be automatically cleaned up\n   * when the current scope ends, and returns the value.\n   *\n   * @param result The Tensor to track in the current scope.\n   */\n  private track<T extends Tensor>(result: T): T {\n    if (this.state.activeScope != null) {\n      result.scopeId = this.state.activeScope.id;\n      this.state.activeScope.track.push(result);\n    }\n\n    return result;\n  }\n\n  get registeredVariables(): NamedVariableMap {\n    return this.state.registeredVariables;\n  }\n\n  /**\n   * Resets the engine state. Removes all backends but does not remove\n   * registered backend factories.\n   */\n  reset(): void {\n    // Make any pending promise obsolete.\n    this.pendingBackendInitId++;\n\n    this.state.dispose();\n    this.ENV.reset();\n    this.state = new EngineState();\n\n    for (const backendName in this.registry) {\n      this.disposeRegisteredKernels(backendName);\n      this.registry[backendName].dispose();\n      delete this.registry[backendName];\n    }\n    this.backendName = null;\n    this.backendInstance = null;\n    this.pendingBackendInit = null;\n  }\n}\n\nfunction ones(shape: number[]): Tensor {\n  const values = makeOnesTypedArray(sizeFromShape(shape), 'float32');\n  return ENGINE.makeTensor(values, shape, 'float32');\n}\n\nexport function getOrMakeEngine(): Engine {\n  const ns = getGlobalNamespace() as {} as {_tfengine: Engine};\n  if (ns._tfengine == null) {\n    const environment = new Environment(ns);\n    ns._tfengine = new Engine(environment);\n  }\n  setEnvironmentGlobal(ns._tfengine.ENV);\n\n  // Tell the current tensor interface that the global engine is responsible\n  // for tracking.\n  setTensorTracker(() => ns._tfengine);\n  return ns._tfengine;\n}\n\nexport const ENGINE = getOrMakeEngine();\n\n/**\n * A implementation of the add op for use within engine and tape.\n *\n * This allows us to avoid a circular dependency between add.ts and engine.\n * It is exported to be available in tape tests.\n */\nexport function add(a: Tensor, b: Tensor): Tensor {\n  // We duplicate Add here to avoid a circular dependency with add.ts.\n  const inputs = {a, b};\n  return ENGINE.runKernel(Add, inputs as {} as NamedTensorMap);\n}\n"]}