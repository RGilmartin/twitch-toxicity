{"version":3,"file":"log_loss_test.js","sourceRoot":"","sources":["../../../src/ops/losses/log_loss_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AACH,OAAO,KAAK,EAAE,MAAM,aAAa,CAAC;AAClC,OAAO,EAAC,QAAQ,EAAE,iBAAiB,EAAC,MAAM,oBAAoB,CAAC;AAC/D,OAAO,EAAC,iBAAiB,EAAC,MAAM,iBAAiB,CAAC;AAElD,iBAAiB,CAAC,SAAS,EAAE,QAAQ,EAAE,GAAG,EAAE;IAC1C,EAAE,CAAC,IAAI,EAAE,KAAK,IAAI,EAAE;QAClB,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAEjD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;QAEjD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,QAAQ,CAAC,CAAC;IAC9C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QAEnD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;QAEjD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,GAAG,CAAC,CAAC;IACzC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kDAAkD,EAAE,KAAK,IAAI,EAAE;QAChE,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QACjD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,EAAE,WAAW,EAAE,OAAO,CAAC,CAAC;QAE1D,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,SAAS,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QACjD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CACvB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,UAAU,EAAE,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;IACzE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qBAAqB,EAAE,KAAK,IAAI,EAAE;QACnC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAEjD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CACvB,MAAM,EAAE,WAAW,EAAE,SAAS,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAElE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,QAAQ,CAAC,CAAC;IAC9C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QACjD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CACvB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,SAAS,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,IAAI,EAAE,KAAK,IAAI,EAAE;QAClB,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE1E,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;QAEjD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kDAAkD,EAAE,KAAK,IAAI,EAAE;QAChE,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CAAC,MAAM,EAAE,WAAW,EAAE,OAAO,CAAC,CAAC;QAE1D,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,SAAS,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CACvB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,SAAS,EAAE,EAAE,EAAE,SAAS,EAAE,EAAE,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC,CAAC;IAC5E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qBAAqB,EAAE,KAAK,IAAI,EAAE;QACnC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE1E,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CACvB,MAAM,EAAE,WAAW,EAAE,SAAS,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAElE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CACvB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,wDAAwD,CAAC;QACnE,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,OAAO,CACnB,EAAe,EAAE,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aAC7D,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,IAAI,MAAM,CAChB,iDAAiD;YACjD,kBAAkB,CAAC,CAAC;QACxB,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,OAAO,CACnB,MAAM,EAAE,EAAe,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aACxD,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE1E,MAAM,CAAC,GAAG,yDAAyD,CAAC;QACpE,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,OAAO,CACnB,MAAM,EAAE,WAAW,EAAE,EAAe,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aAC5D,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8BAA8B,EAAE,KAAK,IAAI,EAAE;QAC5C,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QACzB,MAAM,WAAW,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;QACpC,MAAM,OAAO,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;QAEhC,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,OAAO,CACvB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,UAAU,EAAE,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;IACzE,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '../../index';\nimport {ALL_ENVS, describeWithFlags} from '../../jasmine_util';\nimport {expectArraysClose} from '../../test_util';\n\ndescribeWithFlags('logLoss', ALL_ENVS, () => {\n  it('1D', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n\n    const y = tf.losses.logLoss(labels, predictions);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 2.668788);\n  });\n\n  it('1D - Check for negative values', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, -0.6, -0.1]);\n\n    const y = tf.losses.logLoss(labels, predictions);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), NaN);\n  });\n\n  it('1D - weighted - Reduction.SUM_BY_NONZERO_WEIGHTS', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.logLoss(labels, predictions, weights);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.7168596);\n  });\n\n  it('1D - weighted - Reduction.NONE', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.logLoss(\n        labels, predictions, weights, undefined, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([3]);\n    expectArraysClose(await y.data(), [0.12039725, 0.02107204, 2.0091095]);\n  });\n\n  it('1D - Reduction.MEAN', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n\n    const y = tf.losses.logLoss(\n        labels, predictions, undefined, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 2.668788);\n  });\n\n  it('1D - weighted - Reduction.MEAN', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.logLoss(\n        labels, predictions, weights, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 3.5842977);\n  });\n\n  it('2D', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n\n    const y = tf.losses.logLoss(labels, predictions);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.60019904);\n  });\n\n  it('2D - weighted - Reduction.SUM_BY_NONZERO_WEIGHTS', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n    const weights = tf.tensor2d([3, 0, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.logLoss(labels, predictions, weights);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 1.8866577);\n  });\n\n  it('2D - weighted - Reduction.NONE', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n    const weights = tf.tensor2d([3, 0, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.logLoss(\n        labels, predictions, weights, undefined, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([2, 3]);\n    expectArraysClose(\n        await y.data(), [2.9527497, 0., 1.8451363, 0., 1.3829476, 1.3657978]);\n  });\n\n  it('2D - Reduction.MEAN', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n\n    const y = tf.losses.logLoss(\n        labels, predictions, undefined, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.60019904);\n  });\n\n  it('2D - weighted - Reduction.MEAN', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n    const weights = tf.tensor2d([3, 0, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.logLoss(\n        labels, predictions, weights, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.53904504);\n  });\n\n  it('throws when passed label as a non-tensor', () => {\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n    const weights = tf.tensor2d([3, 6, 5, 0, 4, 2], [2, 3]);\n\n    const e = /Argument 'labels' passed to 'logLoss' must be a Tensor/;\n    expect(\n        () => tf.losses.logLoss(\n            {} as tf.Tensor, predictions, weights, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('throws when passed label as a non-tensor', () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const weights = tf.tensor2d([3, 6, 5, 0, 4, 2], [2, 3]);\n\n    const e = new RegExp(\n        'Argument \\'predictions\\' passed to \\'logLoss\\' ' +\n        'must be a Tensor');\n    expect(\n        () => tf.losses.logLoss(\n            labels, {} as tf.Tensor, weights, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('throws when passed weights as a non-tensor', () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n\n    const e = /Argument 'weights' passed to 'logLoss' must be a Tensor/;\n    expect(\n        () => tf.losses.logLoss(\n            labels, predictions, {} as tf.Tensor, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('accepts a tensor-like object', async () => {\n    const labels = [1, 2, 3];\n    const predictions = [0.3, 0.6, 0.1];\n    const weights = [0.1, 0.2, 0.3];\n\n    const y = tf.losses.logLoss(\n        labels, predictions, weights, undefined, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([3]);\n    expectArraysClose(await y.data(), [0.12039725, 0.02107204, 2.0091095]);\n  });\n});\n"]}