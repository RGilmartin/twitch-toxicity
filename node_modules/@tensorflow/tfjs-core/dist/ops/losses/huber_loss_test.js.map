{"version":3,"file":"huber_loss_test.js","sourceRoot":"","sources":["../../../src/ops/losses/huber_loss_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AACH,OAAO,KAAK,EAAE,MAAM,aAAa,CAAC;AAClC,OAAO,EAAC,QAAQ,EAAE,iBAAiB,EAAC,MAAM,oBAAoB,CAAC;AAC/D,OAAO,EAAC,iBAAiB,EAAC,MAAM,iBAAiB,CAAC;AAElD,iBAAiB,CAAC,WAAW,EAAE,QAAQ,EAAE,GAAG,EAAE;IAC5C,EAAE,CAAC,IAAI,EAAE,KAAK,IAAI,EAAE;QAClB,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAEjD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;QAEnD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,SAAS,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,YAAY,EAAE,KAAK,IAAI,EAAE;QAC1B,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,GAAG,CAAC;QAElB,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,EAAE,WAAW,EAAE,SAAS,EAAE,KAAK,CAAC,CAAC;QAErE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kDAAkD,EAAE,KAAK,IAAI,EAAE;QAChE,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QACjD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,EAAE,WAAW,EAAE,OAAO,CAAC,CAAC;QAE5D,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QACjD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CACzB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,MAAM,EAAE,UAAU,EAAE,IAAI,CAAC,CAAC,CAAC;IAChE,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qBAAqB,EAAE,KAAK,IAAI,EAAE;QACnC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAEjD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CACzB,MAAM,EAAE,WAAW,EAAE,SAAS,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAElE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,SAAS,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QACjD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CACzB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,SAAS,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,IAAI,EAAE,KAAK,IAAI,EAAE;QAClB,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE1E,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;QAEnD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,OAAO,CAAC,CAAC;IAC7C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kDAAkD,EAAE,KAAK,IAAI,EAAE;QAChE,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,MAAM,EAAE,WAAW,EAAE,OAAO,CAAC,CAAC;QAE5D,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,WAAW,CAAC,CAAC;IACjD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CACzB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,EAAE,EAAE,KAAK,EAAE,EAAE,EAAE,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qBAAqB,EAAE,KAAK,IAAI,EAAE;QACnC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE1E,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CACzB,MAAM,EAAE,WAAW,EAAE,SAAS,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAElE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,OAAO,CAAC,CAAC;IAC7C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CACzB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,WAAW,CAAC,CAAC;IACjD,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1E,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,0DAA0D,CAAC;QACrE,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,SAAS,CACrB,EAAe,EAAE,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aAC7D,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,IAAI,MAAM,CAChB,mDAAmD;YACnD,kBAAkB,CAAC,CAAC;QACxB,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,SAAS,CACrB,MAAM,EAAE,EAAe,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aACxD,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,IAAI,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAE1E,MAAM,CAAC,GAAG,2DAA2D,CAAC;QACtE,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,SAAS,CACrB,MAAM,EAAE,WAAW,EAAE,EAAe,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aAC5D,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8BAA8B,EAAE,KAAK,IAAI,EAAE;QAC5C,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QACzB,MAAM,WAAW,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;QACpC,MAAM,OAAO,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;QAEhC,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,SAAS,CACzB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEhE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,MAAM,EAAE,UAAU,EAAE,IAAI,CAAC,CAAC,CAAC;IAChE,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '../../index';\nimport {ALL_ENVS, describeWithFlags} from '../../jasmine_util';\nimport {expectArraysClose} from '../../test_util';\n\ndescribeWithFlags('huberLoss', ALL_ENVS, () => {\n  it('1D', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n\n    const y = tf.losses.huberLoss(labels, predictions);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 1.1816667);\n  });\n\n  it('1D - delta', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n    const delta = 0.4;\n\n    const y = tf.losses.huberLoss(labels, predictions, undefined, delta);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.58666664);\n  });\n\n  it('1D - weighted - Reduction.SUM_BY_NONZERO_WEIGHTS', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.huberLoss(labels, predictions, weights);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.30816665);\n  });\n\n  it('1D - weighted - Reduction.NONE', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.huberLoss(\n        labels, predictions, weights, undefined, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([3]);\n    expectArraysClose(await y.data(), [0.0245, 0.17999999, 0.72]);\n  });\n\n  it('1D - Reduction.MEAN', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n\n    const y = tf.losses.huberLoss(\n        labels, predictions, undefined, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 1.1816667);\n  });\n\n  it('1D - weighted - Reduction.MEAN', async () => {\n    const labels = tf.tensor1d([1, 2, 3]);\n    const predictions = tf.tensor1d([0.3, 0.6, 0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.huberLoss(\n        labels, predictions, weights, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 1.5408332);\n  });\n\n  it('2D', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n\n    const y = tf.losses.huberLoss(labels, predictions);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.01795);\n  });\n\n  it('2D - weighted - Reduction.SUM_BY_NONZERO_WEIGHTS', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n    const weights = tf.tensor2d([3, 0, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.huberLoss(labels, predictions, weights);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.040875003);\n  });\n\n  it('2D - weighted - Reduction.NONE', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n    const weights = tf.tensor2d([3, 0, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.huberLoss(\n        labels, predictions, weights, undefined, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([2, 3]);\n    expectArraysClose(await y.data(), [0.135, 0., 0.001, 0., 0.005, 0.0225]);\n  });\n\n  it('2D - Reduction.MEAN', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n\n    const y = tf.losses.huberLoss(\n        labels, predictions, undefined, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.01795);\n  });\n\n  it('2D - weighted - Reduction.MEAN', async () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n    const weights = tf.tensor2d([3, 0, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.huberLoss(\n        labels, predictions, weights, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(await y.data(), 0.011678572);\n  });\n\n  it('throws when passed label as a non-tensor', () => {\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n    const weights = tf.tensor2d([3, 6, 5, 0, 4, 2], [2, 3]);\n\n    const e = /Argument 'labels' passed to 'huberLoss' must be a Tensor/;\n    expect(\n        () => tf.losses.huberLoss(\n            {} as tf.Tensor, predictions, weights, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('throws when passed label as a non-tensor', () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const weights = tf.tensor2d([3, 6, 5, 0, 4, 2], [2, 3]);\n\n    const e = new RegExp(\n        'Argument \\'predictions\\' passed to \\'huberLoss\\' ' +\n        'must be a Tensor');\n    expect(\n        () => tf.losses.huberLoss(\n            labels, {} as tf.Tensor, weights, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('throws when passed weights as a non-tensor', () => {\n    const labels = tf.tensor2d([0.4, 0.8, 0.12, 0.8, 0.1, 0.3], [2, 3]);\n    const predictions = tf.tensor2d([0.1, 0.7, 0.1, 0.5, 0.05, 0.15], [2, 3]);\n\n    const e = /Argument 'weights' passed to 'huberLoss' must be a Tensor/;\n    expect(\n        () => tf.losses.huberLoss(\n            labels, predictions, {} as tf.Tensor, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('accepts a tensor-like object', async () => {\n    const labels = [1, 2, 3];\n    const predictions = [0.3, 0.6, 0.1];\n    const weights = [0.1, 0.2, 0.3];\n\n    const y = tf.losses.huberLoss(\n        labels, predictions, weights, undefined, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([3]);\n    expectArraysClose(await y.data(), [0.0245, 0.17999999, 0.72]);\n  });\n});\n"]}