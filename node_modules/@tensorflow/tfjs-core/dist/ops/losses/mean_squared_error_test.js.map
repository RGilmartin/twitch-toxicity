{"version":3,"file":"mean_squared_error_test.js","sourceRoot":"","sources":["../../../src/ops/losses/mean_squared_error_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AACH,OAAO,KAAK,EAAE,MAAM,aAAa,CAAC;AAClC,OAAO,EAAC,QAAQ,EAAE,iBAAiB,EAAC,MAAM,oBAAoB,CAAC;AAC/D,OAAO,EAAC,iBAAiB,EAAC,MAAM,iBAAiB,CAAC;AAElD,iBAAiB,CAAC,kBAAkB,EAAE,QAAQ,EAAE,GAAG,EAAE;IACnD,EAAE,CAAC,IAAI,EAAE,KAAK,IAAI,EAAE;QAClB,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;QAEzD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EACd,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YACnD,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;YACzB,CAAC,CAAC,CAAC;IACb,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kDAAkD,EAAE,KAAK,IAAI,EAAE;QAChE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QAC7C,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAAC,KAAK,EAAE,WAAW,EAAE,OAAO,CAAC,CAAC;QAElE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EACd,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,GAAG,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG;YAC/D,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC;YAC/B,CAAC,CAAC,CAAC;IACb,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QAC7C,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAChC,KAAK,EAAE,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEpD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE;YAChC,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG;YAC9D,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG;SAClC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qBAAqB,EAAE,KAAK,IAAI,EAAE;QACnC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAChC,KAAK,EAAE,WAAW,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEtD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EACd,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YACnD,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;YACzB,CAAC,CAAC,CAAC;IACb,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC;QAC7C,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC,CAAC;QAE7C,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAChC,KAAK,EAAE,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEpD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EACd,CAAC,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC;YACnE,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC;YACjC,GAAG,CAAC,CAAC;IACf,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,IAAI,EAAE,KAAK,IAAI,EAAE;QAClB,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;QAEzD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EACd,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC;YAC3D,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;YACjD,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;YACf,CAAC,CAAC,CAAC;IACb,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kDAAkD,EAAE,KAAK,IAAI,EAAE;QAChE,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAAC,KAAK,EAAE,WAAW,EAAE,OAAO,CAAC,CAAC;QAElE,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EACd,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC;YAC7C,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;YACrD,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YACjD,CAAC,CAAC,CAAC;IACb,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAChC,KAAK,EAAE,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEpD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChC,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE;YAChC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC;YACrE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;YACxD,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC;SACtB,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qBAAqB,EAAE,KAAK,IAAI,EAAE;QACnC,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAChC,KAAK,EAAE,WAAW,EAAE,SAAS,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEtD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EACd,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC;YAC3D,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC;YACjD,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;YACf,CAAC,CAAC,CAAC;IACb,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,gCAAgC,EAAE,KAAK,IAAI,EAAE;QAC9C,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAChC,KAAK,EAAE,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEpD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;QAC5B,iBAAiB,CACb,MAAM,CAAC,CAAC,IAAI,EAAE,EACd,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC;YAC7C,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;YACrD,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YACjD,EAAE,CAAC,CAAC;IACd,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,iEAAiE,CAAC;QAC5E,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAC5B,EAAe,EAAE,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aAC7D,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACxD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GAAG,IAAI,MAAM,CAChB,0DAA0D;YAC1D,kBAAkB,CAAC,CAAC;QACxB,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAC5B,KAAK,EAAE,EAAe,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aACvD,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,MAAM,WAAW,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAExD,MAAM,CAAC,GACH,kEAAkE,CAAC;QACvE,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAC5B,KAAK,EAAE,WAAW,EAAE,EAAe,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;aAC3D,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8BAA8B,EAAE,KAAK,IAAI,EAAE;QAC5C,MAAM,WAAW,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAC9B,MAAM,KAAK,GAAG,CAAC,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,CAAC,CAAC;QAChC,MAAM,OAAO,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAAC;QAEhC,MAAM,CAAC,GAAG,EAAE,CAAC,MAAM,CAAC,gBAAgB,CAChC,KAAK,EAAE,WAAW,EAAE,OAAO,EAAE,EAAE,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAEpD,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7B,iBAAiB,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE;YAChC,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,GAAG,GAAG,EAAE,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG;YAC9D,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG;SAClC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '../../index';\nimport {ALL_ENVS, describeWithFlags} from '../../jasmine_util';\nimport {expectArraysClose} from '../../test_util';\n\ndescribeWithFlags('meanSquaredError', ALL_ENVS, () => {\n  it('1D', async () => {\n    const predictions = tf.tensor1d([1, 2, 3]);\n    const label = tf.tensor1d([0.3, -0.6, -0.1]);\n\n    const y = tf.losses.meanSquaredError(label, predictions);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(\n        await y.data(),\n        ((1 - 0.3) * (1 - 0.3) + (2 - (-0.6)) * (2 - (-0.6)) +\n         (3 - (-0.1)) * (3 - (-0.1))) /\n            3);\n  });\n\n  it('1D - weighted - Reduction.SUM_BY_NONZERO_WEIGHTS', async () => {\n    const predictions = tf.tensor1d([1, 2, 3]);\n    const label = tf.tensor1d([0.3, -0.6, -0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.meanSquaredError(label, predictions, weights);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(\n        await y.data(),\n        ((1 - 0.3) * (1 - 0.3) * 0.1 + (2 - (-0.6)) * (2 - (-0.6)) * 0.2 +\n         (3 - (-0.1)) * (3 - (-0.1)) * 0.3) /\n            3);\n  });\n\n  it('1D - weighted - Reduction.NONE', async () => {\n    const predictions = tf.tensor1d([1, 2, 3]);\n    const label = tf.tensor1d([0.3, -0.6, -0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.meanSquaredError(\n        label, predictions, weights, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([3]);\n    expectArraysClose(await y.data(), [\n      (1 - 0.3) * (1 - 0.3) * 0.1, (2 - (-0.6)) * (2 - (-0.6)) * 0.2,\n      (3 - (-0.1)) * (3 - (-0.1)) * 0.3\n    ]);\n  });\n\n  it('1D - Reduction.MEAN', async () => {\n    const predictions = tf.tensor1d([1, 2, 3]);\n    const label = tf.tensor1d([0.3, -0.6, -0.1]);\n\n    const y = tf.losses.meanSquaredError(\n        label, predictions, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(\n        await y.data(),\n        ((1 - 0.3) * (1 - 0.3) + (2 - (-0.6)) * (2 - (-0.6)) +\n         (3 - (-0.1)) * (3 - (-0.1))) /\n            3);\n  });\n\n  it('1D - weighted - Reduction.MEAN', async () => {\n    const predictions = tf.tensor1d([1, 2, 3]);\n    const label = tf.tensor1d([0.3, -0.6, -0.1]);\n    const weights = tf.tensor1d([0.1, 0.2, 0.3]);\n\n    const y = tf.losses.meanSquaredError(\n        label, predictions, weights, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(\n        await y.data(),\n        (((1 - 0.3) * (1 - 0.3) * 0.1) + ((2 - (-0.6)) * (2 - (-0.6)) * 0.2) +\n         ((3 - (-0.1)) * (3 - (-0.1)) * 0.3)) /\n            0.6);\n  });\n\n  it('2D', async () => {\n    const predictions = tf.tensor2d([4, 8, 12, 8, 1, 3], [2, 3]);\n    const label = tf.tensor2d([1, 9, 2, -5, -2, 6], [2, 3]);\n\n    const y = tf.losses.meanSquaredError(label, predictions);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(\n        await y.data(),\n        ((4 - 1) * (4 - 1) + (8 - 9) * (8 - 9) + (12 - 2) * (12 - 2) +\n         (8 - (-5)) * (8 - (-5)) + (1 - (-2)) * (1 - (-2)) +\n         (3 - 6) * (3 - 6)) /\n            6);\n  });\n\n  it('2D - weighted - Reduction.SUM_BY_NONZERO_WEIGHTS', async () => {\n    const predictions = tf.tensor2d([4, 8, 12, 8, 1, 3], [2, 3]);\n    const label = tf.tensor2d([1, 9, 2, -5, -2, 6], [2, 3]);\n    const weights = tf.tensor2d([3, 0, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.meanSquaredError(label, predictions, weights);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(\n        await y.data(),\n        ((4 - 1) * (4 - 1) * 3 + (8 - 9) * (8 - 9) * 0 +\n         (12 - 2) * (12 - 2) * 5 + (8 - (-5)) * (8 - (-5)) * 0 +\n         (1 - (-2)) * (1 - (-2)) * 4 + (3 - 6) * (3 - 6) * 2) /\n            4);\n  });\n\n  it('2D - weighted - Reduction.NONE', async () => {\n    const predictions = tf.tensor2d([4, 8, 12, 8, 1, 3], [2, 3]);\n    const label = tf.tensor2d([1, 9, 2, -5, -2, 6], [2, 3]);\n    const weights = tf.tensor2d([3, 6, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.meanSquaredError(\n        label, predictions, weights, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([2, 3]);\n    expectArraysClose(await y.data(), [\n      (4 - 1) * (4 - 1) * 3, (8 - 9) * (8 - 9) * 6, (12 - 2) * (12 - 2) * 5,\n      (8 - (-5)) * (8 - (-5)) * 0, (1 - (-2)) * (1 - (-2)) * 4,\n      (3 - 6) * (3 - 6) * 2\n    ]);\n  });\n\n  it('2D - Reduction.MEAN', async () => {\n    const predictions = tf.tensor2d([4, 8, 12, 8, 1, 3], [2, 3]);\n    const label = tf.tensor2d([1, 9, 2, -5, -2, 6], [2, 3]);\n\n    const y = tf.losses.meanSquaredError(\n        label, predictions, undefined, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(\n        await y.data(),\n        ((4 - 1) * (4 - 1) + (8 - 9) * (8 - 9) + (12 - 2) * (12 - 2) +\n         (8 - (-5)) * (8 - (-5)) + (1 - (-2)) * (1 - (-2)) +\n         (3 - 6) * (3 - 6)) /\n            6);\n  });\n\n  it('2D - weighted - Reduction.MEAN', async () => {\n    const predictions = tf.tensor2d([4, 8, 12, 8, 1, 3], [2, 3]);\n    const label = tf.tensor2d([1, 9, 2, -5, -2, 6], [2, 3]);\n    const weights = tf.tensor2d([3, 6, 5, 0, 4, 2], [2, 3]);\n\n    const y = tf.losses.meanSquaredError(\n        label, predictions, weights, tf.Reduction.MEAN);\n\n    expect(y.shape).toEqual([]);\n    expectArraysClose(\n        await y.data(),\n        ((4 - 1) * (4 - 1) * 3 + (8 - 9) * (8 - 9) * 6 +\n         (12 - 2) * (12 - 2) * 5 + (8 - (-5)) * (8 - (-5)) * 0 +\n         (1 - (-2)) * (1 - (-2)) * 4 + (3 - 6) * (3 - 6) * 2) /\n            20);\n  });\n\n  it('throws when passed label as a non-tensor', () => {\n    const predictions = tf.tensor2d([4, 8, 12, 8, 1, 3], [2, 3]);\n    const weights = tf.tensor2d([3, 6, 5, 0, 4, 2], [2, 3]);\n\n    const e = /Argument 'labels' passed to 'meanSquaredError' must be a Tensor/;\n    expect(\n        () => tf.losses.meanSquaredError(\n            {} as tf.Tensor, predictions, weights, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('throws when passed label as a non-tensor', () => {\n    const label = tf.tensor2d([1, 9, 2, -5, -2, 6], [2, 3]);\n    const weights = tf.tensor2d([3, 6, 5, 0, 4, 2], [2, 3]);\n\n    const e = new RegExp(\n        'Argument \\'predictions\\' passed to \\'meanSquaredError\\' ' +\n        'must be a Tensor');\n    expect(\n        () => tf.losses.meanSquaredError(\n            label, {} as tf.Tensor, weights, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('throws when passed weights as a non-tensor', () => {\n    const predictions = tf.tensor2d([4, 8, 12, 8, 1, 3], [2, 3]);\n    const label = tf.tensor2d([1, 9, 2, -5, -2, 6], [2, 3]);\n\n    const e =\n        /Argument 'weights' passed to 'meanSquaredError' must be a Tensor/;\n    expect(\n        () => tf.losses.meanSquaredError(\n            label, predictions, {} as tf.Tensor, tf.Reduction.MEAN))\n        .toThrowError(e);\n  });\n\n  it('accepts a tensor-like object', async () => {\n    const predictions = [1, 2, 3];\n    const label = [0.3, -0.6, -0.1];\n    const weights = [0.1, 0.2, 0.3];\n\n    const y = tf.losses.meanSquaredError(\n        label, predictions, weights, tf.Reduction.NONE);\n\n    expect(y.shape).toEqual([3]);\n    expectArraysClose(await y.data(), [\n      (1 - 0.3) * (1 - 0.3) * 0.1, (2 - (-0.6)) * (2 - (-0.6)) * 0.2,\n      (3 - (-0.1)) * (3 - (-0.1)) * 0.3\n    ]);\n  });\n});\n"]}