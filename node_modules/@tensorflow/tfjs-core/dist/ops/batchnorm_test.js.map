{"version":3,"file":"batchnorm_test.js","sourceRoot":"","sources":["../../src/ops/batchnorm_test.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AAEH,OAAO,KAAK,EAAE,MAAM,UAAU,CAAC;AAC/B,OAAO,EAAC,QAAQ,EAAE,iBAAiB,EAAC,MAAM,iBAAiB,CAAC;AAC5D,OAAO,EAAC,iBAAiB,EAAC,MAAM,cAAc,CAAC;AAE/C,iBAAiB,CAAC,aAAa,EAAE,QAAQ,EAAE,GAAG,EAAE;IAC9C,EAAE,CAAC,iDAAiD,EAAE,KAAK,IAAI,EAAE;QAC/D,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,eAAe,CAAC,CAAC;QAEjE,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,KAAK,EAAE,CAAC;QAC3B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,KAAK,EAAE,CAAC;QACjC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,KAAK,EAAE,CAAC;QACzC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACxE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACxE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACxE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACzE,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,KAAK,IAAI,EAAE;QACtD,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,SAAS,EAAE,MAAM,EAAE,eAAe,CAAC,CAAC;QAC9D,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,MAAM,KAAK,GAAG,MAAM,MAAM,CAAC,MAAM,EAAE,CAAC;QAEpC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBAC5C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBAC5C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBAC5C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBAC5C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uCAAuC,EAAE,KAAK,IAAI,EAAE;QACrD,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEpC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,OAAO,EAAE,SAAS,EAAE,eAAe,CAAC,CAAC;QAC/D,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,MAAM,EAAE,CAAC;QAEtC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;oBACjC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;oBACjC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;oBACjC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;oBACjC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACrD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,6BAA6B,EAAE,KAAK,IAAI,EAAE;QAC3C,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEnC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,OAAO,EAAE,MAAM,EAAE,eAAe,CAAC,CAAC;QAC3E,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,MAAM,KAAK,GAAG,MAAM,MAAM,CAAC,MAAM,EAAE,CAAC;QACpC,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,MAAM,EAAE,CAAC;QAEtC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;oBAC5C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;oBAC5C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;oBAC5C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;oBAC5C,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACrD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8BAA8B,EAAE,KAAK,IAAI,EAAE;QAC5C,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC,CAAE,UAAU;QAChD,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACxB,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACtB,MAAM,KAAK,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAErB,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC;QAEtE,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAChC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAChC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAChC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAChC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,uCAAuC,EAAE,KAAK,IAAI,EAAE;QACrD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAElC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,KAAK,GAAG,EAAE,CAAC,IAAI,CACjB,CAAC,CAAc,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAC9B,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;QACnE,iBAAiB,CAAC,MAAM,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QACxE,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,QAAQ,GAAG,EAAE,CAAC,IAAI,CACpB,CAAC,IAAiB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACjC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;QACtE,iBAAiB,CAAC,MAAM,QAAQ,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,YAAY,GAAG,EAAE,CAAC,IAAI,CACxB,CAAC,QAAqB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACrC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,QAAQ,EAAE,EAAE,CAAC,CAAC;QAC1E,iBAAiB,CAAC,MAAM,YAAY,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC;QAC9D,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,UAAU,GAAG,EAAE,CAAC,IAAI,CACtB,CAAC,MAAmB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACnC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC;QACxE,iBAAiB,CAAC,MAAM,UAAU,CAAC,IAAI,EAAE,EAAE,MAAM,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC,CAAC;QAC3E,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,SAAS,GAAG,EAAE,CAAC,IAAI,CACrB,CAAC,KAAkB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAClC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC;QACvE,iBAAiB,CAAC,MAAM,SAAS,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC;QAC7D,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4DAA4D,EAAE,KAAK,IAAI,EAAE;QAC1E,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEvD,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvD,MAAM,KAAK,GAAG,EAAE,CAAC,IAAI,CACjB,CAAC,CAAc,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAC9B,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;QACnE,iBAAiB,CAAC,MAAM,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QACxE,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,QAAQ,GAAG,EAAE,CAAC,IAAI,CACpB,CAAC,IAAiB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACjC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;QACtE,iBAAiB,CAAC,MAAM,QAAQ,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACvE,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,YAAY,GAAG,EAAE,CAAC,IAAI,CACxB,CAAC,QAAqB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACrC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,QAAQ,EAAE,EAAE,CAAC,CAAC;QAC1E,iBAAiB,CAAC,MAAM,YAAY,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QAC3E,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,UAAU,GAAG,EAAE,CAAC,IAAI,CACtB,CAAC,MAAmB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACnC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC;QACxE,iBAAiB,CAAC,MAAM,UAAU,CAAC,IAAI,EAAE,EAAE,MAAM,EAAE,CAAC,IAAI,EAAE,CAAC,CAAC;QAC5D,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/C,MAAM,SAAS,GAAG,EAAE,CAAC,IAAI,CACrB,CAAC,KAAkB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAClC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC;QACvE,iBAAiB,CAAC,MAAM,SAAS,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QAC5E,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,iBAAiB,CAAC,aAAa,EAAE,QAAQ,EAAE,GAAG,EAAE;IAC9C,EAAE,CAAC,+CAA+C,EAAE,KAAK,IAAI,EAAE;QAC7D,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,eAAe,CAAC,CAAC;QACjE,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;gBAC9B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;gBAC9B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;gBAC9B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;gBAC9B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,sCAAsC,EAAE,KAAK,IAAI,EAAE;QACpD,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,SAAS,EAAE,MAAM,EAAE,eAAe,CAAC,CAAC;QAE9D,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,MAAM,KAAK,GAAG,MAAM,MAAM,CAAC,MAAM,EAAE,CAAC;QACpC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBACzC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBACzC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBACzC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBACzC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qCAAqC,EAAE,KAAK,IAAI,EAAE;QACnD,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEpC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,OAAO,EAAE,SAAS,EAAE,eAAe,CAAC,CAAC;QAE/D,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,MAAM,EAAE,CAAC;QACtC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;oBAC9B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;oBAC9B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;oBAC9B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;oBAC9B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACrD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2BAA2B,EAAE,KAAK,IAAI,EAAE;QACzC,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEnC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,OAAO,EAAE,MAAM,EAAE,eAAe,CAAC,CAAC;QAC3E,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,MAAM,EAAE,CAAC;QACtC,MAAM,KAAK,GAAG,MAAM,MAAM,CAAC,MAAM,EAAE,CAAC;QAEpC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;oBACzC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;oBACzC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;oBACzC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;gBACT,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;oBACzC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACrD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8BAA8B,EAAE,KAAK,IAAI,EAAE;QAC5C,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAE,QAAQ;QAC1C,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACxB,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACtB,MAAM,KAAK,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAErB,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC;QAEtE,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC7B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC7B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC7B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC7B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,iDAAiD,EAAE,KAAK,IAAI,EAAE;QAC/D,MAAM,KAAK,GAA6B,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;QAClD,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,KAAK,CAAC,CAAC;QAC7C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;QAC/C,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;QACnD,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;QACjD,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;QAEhD,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,OAAO,EAAE,MAAM,EAAE,eAAe,CAAC,CAAC;QAE3E,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,MAAM,EAAE,CAAC;QACtC,MAAM,KAAK,GAAG,MAAM,MAAM,CAAC,MAAM,EAAE,CAAC;QACpC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;gBACf,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;oBACrD,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,eAAe,CAAC;YAC1D,MAAM,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;gBACf,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;oBACrD,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,eAAe,CAAC;YAC1D,MAAM,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;gBACf,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;oBACrD,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,eAAe,CAAC;YAC1D,MAAM,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;gBACf,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;oBACrD,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,GAAG,eAAe,CAAC;SAC3D,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qCAAqC,EAAE,KAAK,IAAI,EAAE;QACnD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChD,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAElC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChD,MAAM,KAAK,GAAG,EAAE,CAAC,IAAI,CACjB,CAAC,CAAc,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAC9B,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;QACnE,iBAAiB,CAAC,MAAM,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACpE,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,QAAQ,GAAG,EAAE,CAAC,IAAI,CACpB,CAAC,IAAiB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACjC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;QACtE,iBAAiB,CAAC,MAAM,QAAQ,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,YAAY,GAAG,EAAE,CAAC,IAAI,CACxB,CAAC,QAAqB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACrC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,QAAQ,EAAE,EAAE,CAAC,CAAC;QAC1E,iBAAiB,CAAC,MAAM,YAAY,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACxC,MAAM,UAAU,GAAG,EAAE,CAAC,IAAI,CACtB,CAAC,MAAmB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACnC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC;QACxE,iBAAiB,CAAC,MAAM,UAAU,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,SAAS,GAAG,EAAE,CAAC,IAAI,CACrB,CAAC,KAAkB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAClC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC;QACvE,iBAAiB,CAAC,MAAM,SAAS,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4DAA4D,EAAE,KAAK,IAAI,EAAE;QAC1E,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpD,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEpD,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChD,MAAM,KAAK,GAAG,EAAE,CAAC,IAAI,CACjB,CAAC,CAAc,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAC9B,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;QACnE,iBAAiB,CAAC,MAAM,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACpE,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,QAAQ,GAAG,EAAE,CAAC,IAAI,CACpB,CAAC,IAAiB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACjC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;QACtE,iBAAiB,CAAC,MAAM,QAAQ,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QAC3E,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC1C,MAAM,YAAY,GAAG,EAAE,CAAC,IAAI,CACxB,CAAC,QAAqB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACrC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,QAAQ,EAAE,EAAE,CAAC,CAAC;QAC1E,iBAAiB,CACb,MAAM,YAAY,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QACjE,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,UAAU,GAAG,EAAE,CAAC,IAAI,CACtB,CAAC,MAAmB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACnC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC;QACxE,iBAAiB,CAAC,MAAM,UAAU,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC5C,MAAM,SAAS,GAAG,EAAE,CAAC,IAAI,CACrB,CAAC,KAAkB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAClC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC;QACvE,iBAAiB,CAAC,MAAM,SAAS,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACxE,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC7C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qCAAqC,EAAE,KAAK,IAAI,EAAE;QACnD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CACjB;YACE,UAAU,EAAE,UAAU,EAAE,CAAC,UAAU,EAAE,UAAU,EAAE,CAAC,UAAU;YAC5D,UAAU,EAAE,UAAU,EAAE,QAAQ,EAAE,UAAU,EAAE,UAAU,EAAE,CAAC,UAAU;YACrE,UAAU,EAAE,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU;YAC3D,UAAU,EAAE,UAAU;SACvB,EACD,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACf,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,UAAU,EAAE,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QAC/D,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,UAAU,EAAE,CAAC,UAAU,EAAE,SAAS,CAAC,CAAC,CAAC;QACjE,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,SAAS,EAAE,SAAS,EAAE,UAAU,CAAC,CAAC,CAAC;QAC/D,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC;QAEtE,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,UAAU,EAAE,CAAC,UAAU,EAAE,SAAS,EAAE,CAAC,UAAU,EAAE,CAAC,UAAU,EAAE,UAAU;YACxE,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,CAAC,UAAU,EAAE,CAAC,UAAU,EAAE,UAAU;YACzE,UAAU,EAAE,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,SAAS;SACvE,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC;AAEH,iBAAiB,CAAC,aAAa,EAAE,QAAQ,EAAE,GAAG,EAAE;IAC9C,EAAE,CAAC,6CAA6C,EAAE,KAAK,IAAI,EAAE;QAC3D,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,eAAe,CAAC,CAAC;QAEjE,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;gBAC3B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;gBAC3B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;gBAC3B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;gBAC3B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,oCAAoC,EAAE,KAAK,IAAI,EAAE;QAClD,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,SAAS,EAAE,MAAM,EAAE,eAAe,CAAC,CAAC;QAE9D,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,MAAM,EAAE,CAAC;QAC5B,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,MAAM,EAAE,CAAC;QAClC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,MAAM,EAAE,CAAC;QAC1C,MAAM,KAAK,GAAG,MAAM,MAAM,CAAC,MAAM,EAAE,CAAC;QACpC,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBACtC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBACtC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBACtC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBACtC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,mCAAmC,EAAE,KAAK,IAAI,EAAE;QACjD,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEpC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GAAG,EAAE,CAAC,WAAW,CACzB,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,OAAO,EAAE,SAAS,EAAE,eAAe,CAAC,CAAC;QAE/D,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,KAAK,EAAE,CAAC;QACrC,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,KAAK,EAAE,CAAC;QACjC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,KAAK,EAAE,CAAC;QACzC,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,KAAK,EAAE,CAAC;QAE3B,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACtE,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACtE,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YACtE,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACvE,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,yBAAyB,EAAE,KAAK,IAAI,EAAE;QACvC,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,SAAS,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACtC,MAAM,OAAO,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEnC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,EAAE,EAAE,KAAK,EAAE,SAAS,EAAE,OAAO,EAAE,MAAM,EAAE,eAAe,CAAC,CAAC;QAE3E,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,KAAK,EAAE,CAAC;QACrC,MAAM,IAAI,GAAG,MAAM,KAAK,CAAC,KAAK,EAAE,CAAC;QACjC,MAAM,QAAQ,GAAG,MAAM,SAAS,CAAC,KAAK,EAAE,CAAC;QACzC,MAAM,KAAK,GAAG,MAAM,MAAM,CAAC,KAAK,EAAE,CAAC;QACnC,MAAM,CAAC,GAAG,MAAM,EAAE,CAAC,KAAK,EAAE,CAAC;QAE3B,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,mCAAmC,EAAE,KAAK,IAAI,EAAE;QACjD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAElC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,CAAC,KAAK,EAAE,QAAQ,EAAE,YAAY,EAAE,UAAU,EAAE,SAAS,CAAC,GAAG,EAAE,CAAC,KAAK,CACnE,CAAC,CAAc,EAAE,IAAiB,EAAE,QAAqB,EACxD,MAAmB,EAAE,KAAkB,EAAE,EAAE,CACxC,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CACtE,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,CAAC,EAAE,EAAE,CAAC,CAAC;QAC5C,iBAAiB,CAAC,MAAM,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACpE,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,iBAAiB,CAAC,MAAM,QAAQ,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACpC,iBAAiB,CAAC,MAAM,YAAY,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACxC,iBAAiB,CAAC,MAAM,UAAU,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtC,iBAAiB,CAAC,MAAM,SAAS,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,kCAAkC,EAAE,KAAK,IAAI,EAAE;QAChD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnC,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAElC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,CAAC,KAAK,EAAE,QAAQ,EAAE,YAAY,EAAE,UAAU,EAAE,SAAS,CAAC,GAAG,EAAE,CAAC,KAAK,CACnE,CAAC,CAAc,EAAE,IAAiB,EAAE,QAAqB,EACxD,MAAmB,EAAE,KAAkB,EAAE,EAAE,CACxC,EAAE,CAAC,WAAW,CACR,CAAC,CAAC,KAAK,EAAE,EAAE,IAAI,CAAC,KAAK,EAAE,EAAE,QAAQ,CAAC,KAAK,EAAE,EAAE,MAAM,CAAC,KAAK,EAAE,EACzD,KAAK,CAAC,KAAK,EAAE,EAAE,eAAe,CAAC;aAChC,KAAK,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,CAAC,EAAE,EAAE,CAAC,CAAC;QAC9D,iBAAiB,CAAC,MAAM,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACpE,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,iBAAiB,CAAC,MAAM,QAAQ,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACpC,iBAAiB,CAAC,MAAM,YAAY,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC;QAChE,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACxC,iBAAiB,CAAC,MAAM,UAAU,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACtC,iBAAiB,CAAC,MAAM,SAAS,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,MAAM,CAAC,CAAC,CAAC;QAC3D,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACvC,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4DAA4D,EAAE,KAAK,IAAI,EAAE;QAC1E,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChD,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjD,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAChD,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEjD,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,EAAE,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAM,KAAK,GAAG,EAAE,CAAC,IAAI,CACjB,CAAC,CAAc,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAC9B,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;QACnE,iBAAiB,CAAC,MAAM,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACpE,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,QAAQ,GAAG,EAAE,CAAC,IAAI,CACpB,CAAC,IAAiB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACjC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;QACtE,iBAAiB,CAAC,MAAM,QAAQ,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QAC3E,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACvC,MAAM,YAAY,GAAG,EAAE,CAAC,IAAI,CACxB,CAAC,QAAqB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACrC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,QAAQ,EAAE,EAAE,CAAC,CAAC;QAC1E,iBAAiB,CACb,MAAM,YAAY,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC;QACjE,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3C,MAAM,UAAU,GAAG,EAAE,CAAC,IAAI,CACtB,CAAC,MAAmB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CACnC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC;QACxE,iBAAiB,CAAC,MAAM,UAAU,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzD,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACzC,MAAM,SAAS,GAAG,EAAE,CAAC,IAAI,CACrB,CAAC,KAAkB,EAAE,EAAE,CAAC,EAAE,CAAC,WAAW,CAClC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC;QACvE,iBAAiB,CAAC,MAAM,SAAS,CAAC,IAAI,EAAE,EAAE,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC,CAAC;QACxE,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IAC1C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,sBAAsB,EAAE,GAAG,EAAE;QAC9B,MAAM,CAAC,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3B,MAAM,IAAI,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC9B,MAAM,QAAQ,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAClC,MAAM,KAAK,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC/B,MAAM,MAAM,GAAG,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEhC,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,KAAK,GAAG,EAAE,CAAC,KAAK,CAClB,CAAC,CAAc,EAAE,IAAiB,EAAE,QAAqB,EACxD,MAAmB,EAAE,KAAkB,EAAE,EAAE,CACxC,EAAE,CAAC,WAAW,CACR,CAAC,CAAC,KAAK,EAAE,EAAE,IAAI,CAAC,KAAK,EAAE,EAAE,QAAQ,CAAC,KAAK,EAAE,EAAE,MAAM,CAAC,KAAK,EAAE,EACzD,KAAK,CAAC,KAAK,EAAE,EAAE,eAAe,CAAC;aAChC,KAAK,EAAE,CAAC,CAAC;QACtB,MAAM,CAAC,KAAK,EAAE,QAAQ,EAAE,YAAY,EAAE,UAAU,EAAE,SAAS,CAAC,GACxD,KAAK,CAAC,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;QACrC,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAC3C,MAAM,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC;QACnD,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;QAC/C,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;IAC/C,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,qCAAqC,EAAE,KAAK,IAAI,EAAE;QACnD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CACjB;YACE,SAAS,EAAE,UAAU,EAAE,QAAQ,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU;YACnE,UAAU,EAAE,UAAU,EAAE,UAAU;SACnC,EACD,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACZ,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QAC/D,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QACnE,MAAM,MAAM,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QACjE,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QAChE,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC;QAEtE,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU;YACtE,UAAU,EAAE,UAAU,EAAE,UAAU;SACnC,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,sCAAsC,EAAE,GAAG,EAAE;QAC9C,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAErC,MAAM,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,SAAS,CAAC,EAAe,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;aACtD,YAAY,CAAC,qDAAqD,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,yCAAyC,EAAE,GAAG,EAAE;QACjD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAErC,MAAM,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,EAAE,EAAe,EAAE,QAAQ,CAAC,CAAC;aACnD,YAAY,CAAC,wDAAwD,CAAC,CAAC;IAC9E,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,6CAA6C,EAAE,GAAG,EAAE;QACrD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAEjC,MAAM,CAAC,GAAG,4DAA4D,CAAC;QACvE,MAAM,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,EAAE,IAAI,EAAE,EAAe,CAAC,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;IACvE,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,0CAA0C,EAAE,GAAG,EAAE;QAClD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,OAAO,GAAG,IAAI,CAAC;QAErB,MAAM,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,OAAO,EAAE,EAAe,CAAC,CAAC;aAClE,YAAY,CACT,yDAAyD,CAAC,CAAC;IACrE,CAAC,CAAC,CAAC;IACH,EAAE,CAAC,2CAA2C,EAAE,GAAG,EAAE;QACnD,MAAM,CAAC,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACnD,MAAM,IAAI,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACjC,MAAM,QAAQ,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QACrC,MAAM,OAAO,GAAG,IAAI,CAAC;QACrB,MAAM,KAAK,GAAG,EAAE,CAAC,QAAQ,CAAC,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,CAAC,CAAC;QAEhE,MAAM,CAAC,GAAG,0DAA0D,CAAC;QACrE,MAAM,CACF,GAAG,EAAE,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,EAAe,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;aACtE,YAAY,CAAC,CAAC,CAAC,CAAC;IACvB,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,8BAA8B,EAAE,KAAK,IAAI,EAAE;QAC5C,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;QAC5B,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACxB,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACtB,MAAM,KAAK,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAErB,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,MAAM,GACR,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC;QAEtE,iBAAiB,CAAC,MAAM,MAAM,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;YAChD,MAAM,CAAC,CAAC,CAAC;gBACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;oBAC1B,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAC;SACjD,CAAC,CAAC;IACL,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,wCAAwC,EAAE,GAAG,EAAE;QAChD,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACxB,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACtB,MAAM,KAAK,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAErB,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,CAAC,GAAG,GAAG,EAAE,CAAC,EAAE,CAAC,WAAW,CAC1B,CAAC,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EACvD,eAAe,CAAC,CAAC;QACrB,MAAM,CAAC,CAAC,CAAC,CAAC,YAAY,CAClB,oDAAoD,CAAC,CAAC;IAC5D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,2CAA2C,EAAE,GAAG,EAAE;QACnD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;QAC5B,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACxB,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACtB,MAAM,KAAK,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAErB,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,CAAC,GAAG,GAAG,EAAE,CACX,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC;QAC5E,MAAM,CAAC,CAAC,CAAC,CAAC,YAAY,CAClB,uDAAuD,CAAC,CAAC;IAC/D,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,+CAA+C,EAAE,GAAG,EAAE;QACvD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;QAC5B,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACpB,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACtB,MAAM,KAAK,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAErB,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,CAAC,GAAG,GAAG,EAAE,CACX,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,MAAM,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC;QACxE,MAAM,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,kDAAkD,CAAC,CAAC;IAC7E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,4CAA4C,EAAE,GAAG,EAAE;QACpD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;QAC5B,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACxB,MAAM,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAEtB,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,CAAC,GAAG,GAAG,EAAE,CACX,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,eAAe,CAAC,CAAC;QAC3E,MAAM,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,+CAA+C,CAAC,CAAC;IAC1E,CAAC,CAAC,CAAC;IAEH,EAAE,CAAC,6CAA6C,EAAE,GAAG,EAAE;QACrD,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;QAC5B,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACpB,MAAM,QAAQ,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACxB,MAAM,KAAK,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAErB,MAAM,eAAe,GAAG,IAAI,CAAC;QAE7B,MAAM,CAAC,GAAG,GAAG,EAAE,CACX,EAAE,CAAC,WAAW,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,KAAK,EAAE,eAAe,CAAC,CAAC;QAC1E,MAAM,CAAC,CAAC,CAAC,CAAC,YAAY,CAAC,gDAAgD,CAAC,CAAC;IAC3E,CAAC,CAAC,CAAC;AACL,CAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '../index';\nimport {ALL_ENVS, describeWithFlags} from '../jasmine_util';\nimport {expectArraysClose} from '../test_util';\n\ndescribeWithFlags('batchNorm4D', ALL_ENVS, () => {\n  it('simple batchnorm4D, no offset or scale, 2x1x1x2', async () => {\n    const xT = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm4d(\n        xT, meanT, varianceT, undefined, undefined, varianceEpsilon);\n\n    const x = await xT.array();\n    const mean = await meanT.array();\n    const variance = await varianceT.array();\n    expectArraysClose(await result.data(), [\n      (x[0][0][0][0] - mean[0]) * 1 / Math.sqrt(variance[0] + varianceEpsilon),\n      (x[0][0][0][1] - mean[1]) * 1 / Math.sqrt(variance[1] + varianceEpsilon),\n      (x[1][0][0][0] - mean[0]) * 1 / Math.sqrt(variance[0] + varianceEpsilon),\n      (x[1][0][0][1] - mean[1]) * 1 / Math.sqrt(variance[1] + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm4D, no offset, 2x1x1x2', async () => {\n    const xT = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const scaleT = tf.tensor1d([4, 5]);\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm4d(\n        xT, meanT, varianceT, undefined, scaleT, varianceEpsilon);\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    const scale = await scaleT.buffer();\n\n    expectArraysClose(await result.data(), [\n      (x.get(0, 0, 0, 0) - mean.get(0)) * scale.get(0) /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(0, 0, 0, 1) - mean.get(1)) * scale.get(1) /\n          Math.sqrt(variance.get(1) + varianceEpsilon),\n      (x.get(1, 0, 0, 0) - mean.get(0)) * scale.get(0) /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(1, 0, 0, 1) - mean.get(1)) * scale.get(1) /\n          Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm4D, no scale, 2x1x1x2', async () => {\n    const xT = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const offsetT = tf.tensor1d([4, 5]);\n\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm4d(\n        xT, meanT, varianceT, offsetT, undefined, varianceEpsilon);\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    const offset = await offsetT.buffer();\n\n    expectArraysClose(await result.data(), [\n      offset.get(0) +\n          (x.get(0, 0, 0, 0) - mean.get(0)) * 1 /\n              Math.sqrt(variance.get(0) + varianceEpsilon),\n      offset.get(1) +\n          (x.get(0, 0, 0, 1) - mean.get(1)) * 1 /\n              Math.sqrt(variance.get(1) + varianceEpsilon),\n      offset.get(0) +\n          (x.get(1, 0, 0, 0) - mean.get(0)) * 1 /\n              Math.sqrt(variance.get(0) + varianceEpsilon),\n      offset.get(1) +\n          (x.get(1, 0, 0, 1) - mean.get(1)) * 1 /\n              Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm4D, 2x1x1x2', async () => {\n    const xT = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const offsetT = tf.tensor1d([3, 4]);\n    const scaleT = tf.tensor1d([4, 5]);\n\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm4d(xT, meanT, varianceT, offsetT, scaleT, varianceEpsilon);\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    const scale = await scaleT.buffer();\n    const offset = await offsetT.buffer();\n\n    expectArraysClose(await result.data(), [\n      offset.get(0) +\n          (x.get(0, 0, 0, 0) - mean.get(0)) * scale.get(0) /\n              Math.sqrt(variance.get(0) + varianceEpsilon),\n      offset.get(1) +\n          (x.get(0, 0, 0, 1) - mean.get(1)) * scale.get(1) /\n              Math.sqrt(variance.get(1) + varianceEpsilon),\n      offset.get(0) +\n          (x.get(1, 0, 0, 0) - mean.get(0)) * scale.get(0) /\n              Math.sqrt(variance.get(0) + varianceEpsilon),\n      offset.get(1) +\n          (x.get(1, 0, 0, 1) - mean.get(1)) * scale.get(1) /\n              Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n\n  it('accepts a tensor-like object', async () => {\n    const x = [[[[2, 4]]], [[[9, 23]]]];  // 2x1x1x2\n    const mean = [1, 2];\n    const variance = [2, 3];\n    const offset = [3, 4];\n    const scale = [4, 5];\n\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm4d(x, mean, variance, offset, scale, varianceEpsilon);\n\n    expectArraysClose(await result.data(), [\n      offset[0] +\n          (x[0][0][0][0] - mean[0]) * scale[0] /\n              Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[0][0][0][1] - mean[1]) * scale[1] /\n              Math.sqrt(variance[1] + varianceEpsilon),\n      offset[0] +\n          (x[1][0][0][0] - mean[0]) * scale[0] /\n              Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[1][0][0][1] - mean[1]) * scale[1] /\n              Math.sqrt(variance[1] + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm4D gradients, 2x1x1x2', async () => {\n    const x = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const mean = tf.tensor1d([1, 2]);\n    const variance = tf.tensor1d([2, 3]);\n    const offset = tf.tensor1d([3, 4]);\n    const scale = tf.tensor1d([2, 5]);\n\n    const varianceEpsilon = .001;\n\n    const dy = tf.tensor4d([-1, -1, -1, -1], [2, 1, 1, 2]);\n    const gradX = tf.grad(\n        (x: tf.Tensor4D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(x, dy);\n    expectArraysClose(await gradX.data(), [-1.414, -2.887, -1.414, -2.887]);\n    expect(gradX.shape).toEqual([2, 1, 1, 2]);\n    const gradMean = tf.grad(\n        (mean: tf.Tensor1D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(mean, dy);\n    expectArraysClose(await gradMean.data(), [2.828, 5.773]);\n    expect(gradMean.shape).toEqual([2]);\n    const gradVariance = tf.grad(\n        (variance: tf.Tensor1D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(variance, dy);\n    expectArraysClose(await gradVariance.data(), [3.180, 11.060]);\n    expect(gradVariance.shape).toEqual([2]);\n    const gradOffset = tf.grad(\n        (offset: tf.Tensor1D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(offset, dy);\n    expectArraysClose(await gradOffset.data(), await dy.sum([0, 1, 2]).data());\n    expect(gradOffset.shape).toEqual([2]);\n    const gradScale = tf.grad(\n        (scale: tf.Tensor1D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(scale, dy);\n    expectArraysClose(await gradScale.data(), [-6.362, -13.277]);\n    expect(gradScale.shape).toEqual([2]);\n  });\n\n  it('batchnorm4D gradients, same shapes in x, mean and variance', async () => {\n    const x = tf.tensor4d([10, 20, 30, 40], [2, 1, 1, 2]);\n    const mean = tf.tensor4d([0, 5, 10, 15], [2, 1, 1, 2]);\n    const variance = tf.tensor4d([2, 4, 6, 8], [2, 1, 1, 2]);\n    const scale = tf.tensor4d([2, 5, 2, 5], [2, 1, 1, 2]);\n    const offset = tf.tensor4d([0, 0, 0, 0], [2, 1, 1, 2]);\n\n    const varianceEpsilon = .001;\n\n    const dy = tf.tensor4d([-1, -1, -1, -1], [2, 1, 1, 2]);\n    const gradX = tf.grad(\n        (x: tf.Tensor4D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(x, dy);\n    expectArraysClose(await gradX.data(), [-1.414, -2.500, -0.816, -1.768]);\n    expect(gradX.shape).toEqual([2, 1, 1, 2]);\n    const gradMean = tf.grad(\n        (mean: tf.Tensor4D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(mean, dy);\n    expectArraysClose(await gradMean.data(), [1.414, 2.500, 0.816, 1.768]);\n    expect(gradMean.shape).toEqual([2, 1, 1, 2]);\n    const gradVariance = tf.grad(\n        (variance: tf.Tensor4D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(variance, dy);\n    expectArraysClose(await gradVariance.data(), [3.533, 4.686, 1.360, 2.762]);\n    expect(gradVariance.shape).toEqual([2, 1, 1, 2]);\n    const gradOffset = tf.grad(\n        (offset: tf.Tensor4D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(offset, dy);\n    expectArraysClose(await gradOffset.data(), await dy.data());\n    expect(gradOffset.shape).toEqual([2, 1, 1, 2]);\n    const gradScale = tf.grad(\n        (scale: tf.Tensor4D) => tf.batchNorm4d(\n            x, mean, variance, offset, scale, varianceEpsilon))(scale, dy);\n    expectArraysClose(await gradScale.data(), [-7.069, -7.499, -8.164, -8.838]);\n    expect(gradScale.shape).toEqual([2, 1, 1, 2]);\n  });\n});\n\ndescribeWithFlags('batchNorm3D', ALL_ENVS, () => {\n  it('simple batchnorm3D, no offset or scale, 2x1x2', async () => {\n    const xT = tf.tensor3d([2, 4, 9, 23], [2, 1, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm3d(\n        xT, meanT, varianceT, undefined, undefined, varianceEpsilon);\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    expectArraysClose(await result.data(), [\n      (x.get(0, 0, 0) - mean.get(0)) * 1 /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(0, 0, 1) - mean.get(1)) * 1 /\n          Math.sqrt(variance.get(1) + varianceEpsilon),\n      (x.get(1, 0, 0) - mean.get(0)) * 1 /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(1, 0, 1) - mean.get(1)) * 1 /\n          Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm3D, no offset, 2x1x2', async () => {\n    const xT = tf.tensor3d([2, 4, 9, 23], [2, 1, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const scaleT = tf.tensor1d([4, 5]);\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm3d(\n        xT, meanT, varianceT, undefined, scaleT, varianceEpsilon);\n\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    const scale = await scaleT.buffer();\n    expectArraysClose(await result.data(), [\n      (x.get(0, 0, 0) - mean.get(0)) * scale.get(0) /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(0, 0, 1) - mean.get(1)) * scale.get(1) /\n          Math.sqrt(variance.get(1) + varianceEpsilon),\n      (x.get(1, 0, 0) - mean.get(0)) * scale.get(0) /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(1, 0, 1) - mean.get(1)) * scale.get(1) /\n          Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm3D, no scale, 2x1x2', async () => {\n    const xT = tf.tensor3d([2, 4, 9, 23], [2, 1, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const offsetT = tf.tensor1d([4, 5]);\n\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm3d(\n        xT, meanT, varianceT, offsetT, undefined, varianceEpsilon);\n\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    const offset = await offsetT.buffer();\n    expectArraysClose(await result.data(), [\n      offset.get(0) +\n          (x.get(0, 0, 0) - mean.get(0)) * 1 /\n              Math.sqrt(variance.get(0) + varianceEpsilon),\n      offset.get(1) +\n          (x.get(0, 0, 1) - mean.get(1)) * 1 /\n              Math.sqrt(variance.get(1) + varianceEpsilon),\n      offset.get(0) +\n          (x.get(1, 0, 0) - mean.get(0)) * 1 /\n              Math.sqrt(variance.get(0) + varianceEpsilon),\n      offset.get(1) +\n          (x.get(1, 0, 1) - mean.get(1)) * 1 /\n              Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm3D, 2x1x2', async () => {\n    const xT = tf.tensor3d([2, 4, 9, 23], [2, 1, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const offsetT = tf.tensor1d([3, 4]);\n    const scaleT = tf.tensor1d([4, 5]);\n\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm3d(xT, meanT, varianceT, offsetT, scaleT, varianceEpsilon);\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    const offset = await offsetT.buffer();\n    const scale = await scaleT.buffer();\n\n    expectArraysClose(await result.data(), [\n      offset.get(0) +\n          (x.get(0, 0, 0) - mean.get(0)) * scale.get(0) /\n              Math.sqrt(variance.get(0) + varianceEpsilon),\n      offset.get(1) +\n          (x.get(0, 0, 1) - mean.get(1)) * scale.get(1) /\n              Math.sqrt(variance.get(1) + varianceEpsilon),\n      offset.get(0) +\n          (x.get(1, 0, 0) - mean.get(0)) * scale.get(0) /\n              Math.sqrt(variance.get(0) + varianceEpsilon),\n      offset.get(1) +\n          (x.get(1, 0, 1) - mean.get(1)) * scale.get(1) /\n              Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n\n  it('accepts a tensor-like object', async () => {\n    const x = [[[2, 4]], [[9, 23]]];  // 2x1x2\n    const mean = [1, 2];\n    const variance = [2, 3];\n    const offset = [3, 4];\n    const scale = [4, 5];\n\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm3d(x, mean, variance, offset, scale, varianceEpsilon);\n\n    expectArraysClose(await result.data(), [\n      offset[0] +\n          (x[0][0][0] - mean[0]) * scale[0] /\n              Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[0][0][1] - mean[1]) * scale[1] /\n              Math.sqrt(variance[1] + varianceEpsilon),\n      offset[0] +\n          (x[1][0][0] - mean[0]) * scale[0] /\n              Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[1][0][1] - mean[1]) * scale[1] /\n              Math.sqrt(variance[1] + varianceEpsilon)\n    ]);\n  });\n\n  it('batchnorm3D, x,mean,var,offset,scale are all 3D', async () => {\n    const shape: [number, number, number] = [2, 1, 2];\n    const xT = tf.tensor3d([2, 4, 9, 23], shape);\n    const meanT = tf.tensor3d([1, 2, 3, 4], shape);\n    const varianceT = tf.tensor3d([2, 3, 4, 5], shape);\n    const offsetT = tf.tensor3d([3, 4, 5, 6], shape);\n    const scaleT = tf.tensor3d([4, 5, 6, 7], shape);\n\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm3d(xT, meanT, varianceT, offsetT, scaleT, varianceEpsilon);\n\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    const offset = await offsetT.buffer();\n    const scale = await scaleT.buffer();\n    expectArraysClose(await result.data(), [\n      offset.get(0, 0, 0) +\n          (x.get(0, 0, 0) - mean.get(0, 0, 0)) * scale.get(0, 0, 0) /\n              Math.sqrt(variance.get(0, 0, 0) + varianceEpsilon),\n      offset.get(0, 0, 1) +\n          (x.get(0, 0, 1) - mean.get(0, 0, 1)) * scale.get(0, 0, 1) /\n              Math.sqrt(variance.get(0, 0, 1) + varianceEpsilon),\n      offset.get(1, 0, 0) +\n          (x.get(1, 0, 0) - mean.get(1, 0, 0)) * scale.get(1, 0, 0) /\n              Math.sqrt(variance.get(1, 0, 0) + varianceEpsilon),\n      offset.get(1, 0, 1) +\n          (x.get(1, 0, 1) - mean.get(1, 0, 1)) * scale.get(1, 0, 1) /\n              Math.sqrt(variance.get(1, 0, 1) + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm3D gradients, 2x1x2', async () => {\n    const x = tf.tensor3d([2, 4, 9, 23], [2, 1, 2]);\n    const mean = tf.tensor1d([1, 2]);\n    const variance = tf.tensor1d([2, 3]);\n    const offset = tf.tensor1d([3, 4]);\n    const scale = tf.tensor1d([2, 5]);\n\n    const varianceEpsilon = .001;\n\n    const dy = tf.tensor3d([1, 1, 1, 1], [2, 1, 2]);\n    const gradX = tf.grad(\n        (x: tf.Tensor3D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(x, dy);\n    expectArraysClose(await gradX.data(), [1.414, 2.887, 1.414, 2.887]);\n    expect(gradX.shape).toEqual([2, 1, 2]);\n    const gradMean = tf.grad(\n        (mean: tf.Tensor1D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(mean, dy);\n    expectArraysClose(await gradMean.data(), [-2.828, -5.773]);\n    expect(gradMean.shape).toEqual([2]);\n    const gradVariance = tf.grad(\n        (variance: tf.Tensor1D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(variance, dy);\n    expectArraysClose(await gradVariance.data(), [-3.180, -11.060]);\n    expect(gradVariance.shape).toEqual([2]);\n    const gradOffset = tf.grad(\n        (offset: tf.Tensor1D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(offset, dy);\n    expectArraysClose(await gradOffset.data(), [2, 2]);\n    expect(gradOffset.shape).toEqual([2]);\n    const gradScale = tf.grad(\n        (scale: tf.Tensor1D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(scale, dy);\n    expectArraysClose(await gradScale.data(), [6.362, 13.277]);\n    expect(gradScale.shape).toEqual([2]);\n  });\n\n  it('batchnorm3D gradients, same shapes in x, mean and variance', async () => {\n    const x = tf.tensor3d([10, 20, 30, 40], [2, 1, 2]);\n    const mean = tf.tensor3d([0, 5, 10, 15], [2, 1, 2]);\n    const variance = tf.tensor3d([2, 4, 6, 8], [2, 1, 2]);\n    const scale = tf.tensor3d([2, 5, 2, 5], [2, 1, 2]);\n    const offset = tf.tensor3d([0, 0, 0, 0], [2, 1, 2]);\n\n    const varianceEpsilon = .001;\n\n    const dy = tf.tensor3d([1, 1, 1, 1], [2, 1, 2]);\n    const gradX = tf.grad(\n        (x: tf.Tensor3D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(x, dy);\n    expectArraysClose(await gradX.data(), [1.414, 2.500, 0.816, 1.768]);\n    expect(gradX.shape).toEqual([2, 1, 2]);\n    const gradMean = tf.grad(\n        (mean: tf.Tensor3D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(mean, dy);\n    expectArraysClose(await gradMean.data(), [-1.414, -2.500, -0.816, -1.768]);\n    expect(gradMean.shape).toEqual([2, 1, 2]);\n    const gradVariance = tf.grad(\n        (variance: tf.Tensor3D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(variance, dy);\n    expectArraysClose(\n        await gradVariance.data(), [-3.533, -4.686, -1.360, -2.762]);\n    expect(gradVariance.shape).toEqual([2, 1, 2]);\n    const gradOffset = tf.grad(\n        (offset: tf.Tensor3D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(offset, dy);\n    expectArraysClose(await gradOffset.data(), [1, 1, 1, 1]);\n    expect(gradOffset.shape).toEqual([2, 1, 2]);\n    const gradScale = tf.grad(\n        (scale: tf.Tensor3D) => tf.batchNorm3d(\n            x, mean, variance, offset, scale, varianceEpsilon))(scale, dy);\n    expectArraysClose(await gradScale.data(), [7.069, 7.499, 8.164, 8.838]);\n    expect(gradScale.shape).toEqual([2, 1, 2]);\n  });\n\n  it('batchnorm matches tensorflow, 2x3x3', async () => {\n    const x = tf.tensor3d(\n        [\n          0.49955603, 0.04158615, -1.09440524, 2.03854165, -0.61578344,\n          2.87533573, 1.18105987, 0.807462, 1.87888837, 2.26563962, -0.37040935,\n          1.35848753, -0.75347094, 0.15683117, 0.91925946, 0.34121279,\n          0.92717143, 1.89683965\n        ],\n        [2, 3, 3]);\n    const mean = tf.tensor1d([0.39745062, -0.48062894, 0.4847822]);\n    const variance = tf.tensor1d([0.32375343, 0.67117643, 1.08334653]);\n    const offset = tf.tensor1d([0.69398749, -1.29056387, 0.9429723]);\n    const scale = tf.tensor1d([-0.5607271, 0.9878457, 0.25181573]);\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm3d(x, mean, variance, offset, scale, varianceEpsilon);\n\n    expectArraysClose(await result.data(), [\n      0.59352049, -0.66135202, 0.5610874, -0.92077015, -1.45341019, 1.52106473,\n      -0.07704776, 0.26144429, 1.28010017, -1.14422404, -1.15776136, 1.15425493,\n      1.82644104, -0.52249442, 1.04803919, 0.74932291, 0.40568101, 1.2844412\n    ]);\n  });\n});\n\ndescribeWithFlags('batchNorm2D', ALL_ENVS, () => {\n  it('simple batchnorm2D, no offset or scale, 2x2', async () => {\n    const xT = tf.tensor2d([2, 4, 9, 23], [2, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm2d(\n        xT, meanT, varianceT, undefined, undefined, varianceEpsilon);\n\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    expectArraysClose(await result.data(), [\n      (x.get(0, 0) - mean.get(0)) * 1 /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(0, 1) - mean.get(1)) * 1 /\n          Math.sqrt(variance.get(1) + varianceEpsilon),\n      (x.get(1, 0) - mean.get(0)) * 1 /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(1, 1) - mean.get(1)) * 1 /\n          Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n  it('simple batchnorm2D, no offset, 2x2', async () => {\n    const xT = tf.tensor2d([2, 4, 9, 23], [2, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const scaleT = tf.tensor1d([4, 5]);\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm2d(\n        xT, meanT, varianceT, undefined, scaleT, varianceEpsilon);\n\n    const x = await xT.buffer();\n    const mean = await meanT.buffer();\n    const variance = await varianceT.buffer();\n    const scale = await scaleT.buffer();\n    expectArraysClose(await result.data(), [\n      (x.get(0, 0) - mean.get(0)) * scale.get(0) /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(0, 1) - mean.get(1)) * scale.get(1) /\n          Math.sqrt(variance.get(1) + varianceEpsilon),\n      (x.get(1, 0) - mean.get(0)) * scale.get(0) /\n          Math.sqrt(variance.get(0) + varianceEpsilon),\n      (x.get(1, 1) - mean.get(1)) * scale.get(1) /\n          Math.sqrt(variance.get(1) + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm2D, no scale, 2x2', async () => {\n    const xT = tf.tensor2d([2, 4, 9, 23], [2, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const offsetT = tf.tensor1d([4, 5]);\n\n    const varianceEpsilon = .001;\n\n    const result = tf.batchNorm2d(\n        xT, meanT, varianceT, offsetT, undefined, varianceEpsilon);\n\n    const offset = await offsetT.array();\n    const mean = await meanT.array();\n    const variance = await varianceT.array();\n    const x = await xT.array();\n\n    expectArraysClose(await result.data(), [\n      offset[0] +\n          (x[0][0] - mean[0]) * 1 / Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[0][1] - mean[1]) * 1 / Math.sqrt(variance[1] + varianceEpsilon),\n      offset[0] +\n          (x[1][0] - mean[0]) * 1 / Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[1][1] - mean[1]) * 1 / Math.sqrt(variance[1] + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm2D, 2x2', async () => {\n    const xT = tf.tensor2d([2, 4, 9, 23], [2, 2]);\n    const meanT = tf.tensor1d([1, 2]);\n    const varianceT = tf.tensor1d([2, 3]);\n    const offsetT = tf.tensor1d([3, 4]);\n    const scaleT = tf.tensor1d([4, 5]);\n\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm2d(xT, meanT, varianceT, offsetT, scaleT, varianceEpsilon);\n\n    const offset = await offsetT.array();\n    const mean = await meanT.array();\n    const variance = await varianceT.array();\n    const scale = await scaleT.array();\n    const x = await xT.array();\n\n    expectArraysClose(await result.data(), [\n      offset[0] +\n          (x[0][0] - mean[0]) * scale[0] /\n              Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[0][1] - mean[1]) * scale[1] /\n              Math.sqrt(variance[1] + varianceEpsilon),\n      offset[0] +\n          (x[1][0] - mean[0]) * scale[0] /\n              Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[1][1] - mean[1]) * scale[1] /\n              Math.sqrt(variance[1] + varianceEpsilon)\n    ]);\n  });\n\n  it('simple batchnorm2D gradients, 2x2', async () => {\n    const x = tf.tensor2d([2, 4, 9, 23], [2, 2]);\n    const mean = tf.tensor1d([1, 2]);\n    const variance = tf.tensor1d([2, 3]);\n    const offset = tf.tensor1d([3, 4]);\n    const scale = tf.tensor1d([2, 5]);\n\n    const varianceEpsilon = .001;\n\n    const dy = tf.tensor2d([1, 1, 1, 1], [2, 2]);\n    const [gradX, gradMean, gradVariance, gradOffset, gradScale] = tf.grads(\n        (x: tf.Tensor2D, mean: tf.Tensor1D, variance: tf.Tensor1D,\n         offset: tf.Tensor1D, scale: tf.Tensor1D) =>\n            tf.batchNorm2d(x, mean, variance, offset, scale, varianceEpsilon))(\n        [x, mean, variance, offset, scale], dy);\n    expectArraysClose(await gradX.data(), [1.414, 2.887, 1.414, 2.887]);\n    expect(gradX.shape).toEqual([2, 2]);\n    expectArraysClose(await gradMean.data(), [-2.828, -5.773]);\n    expect(gradMean.shape).toEqual([2]);\n    expectArraysClose(await gradVariance.data(), [-3.180, -11.060]);\n    expect(gradVariance.shape).toEqual([2]);\n    expectArraysClose(await gradOffset.data(), [2, 2]);\n    expect(gradOffset.shape).toEqual([2]);\n    expectArraysClose(await gradScale.data(), [6.362, 13.277]);\n    expect(gradScale.shape).toEqual([2]);\n  });\n\n  it('gradient with clones batchnorm2D', async () => {\n    const x = tf.tensor2d([2, 4, 9, 23], [2, 2]);\n    const mean = tf.tensor1d([1, 2]);\n    const variance = tf.tensor1d([2, 3]);\n    const offset = tf.tensor1d([3, 4]);\n    const scale = tf.tensor1d([2, 5]);\n\n    const varianceEpsilon = .001;\n\n    const dy = tf.tensor2d([1, 1, 1, 1], [2, 2]);\n    const [gradX, gradMean, gradVariance, gradOffset, gradScale] = tf.grads(\n        (x: tf.Tensor2D, mean: tf.Tensor1D, variance: tf.Tensor1D,\n         offset: tf.Tensor1D, scale: tf.Tensor1D) =>\n            tf.batchNorm2d(\n                  x.clone(), mean.clone(), variance.clone(), offset.clone(),\n                  scale.clone(), varianceEpsilon)\n                .clone())([x, mean, variance, offset, scale], dy);\n    expectArraysClose(await gradX.data(), [1.414, 2.887, 1.414, 2.887]);\n    expect(gradX.shape).toEqual([2, 2]);\n    expectArraysClose(await gradMean.data(), [-2.828, -5.773]);\n    expect(gradMean.shape).toEqual([2]);\n    expectArraysClose(await gradVariance.data(), [-3.180, -11.060]);\n    expect(gradVariance.shape).toEqual([2]);\n    expectArraysClose(await gradOffset.data(), [2, 2]);\n    expect(gradOffset.shape).toEqual([2]);\n    expectArraysClose(await gradScale.data(), [6.362, 13.277]);\n    expect(gradScale.shape).toEqual([2]);\n  });\n\n  it('batchnorm2D gradients, same shapes in x, mean and variance', async () => {\n    const x = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n    const mean = tf.tensor2d([0, 5, 10, 15], [2, 2]);\n    const variance = tf.tensor2d([2, 4, 6, 8], [2, 2]);\n    const scale = tf.tensor2d([2, 5, 2, 5], [2, 2]);\n    const offset = tf.tensor2d([0, 0, 0, 0], [2, 2]);\n\n    const varianceEpsilon = .001;\n\n    const dy = tf.tensor2d([1, 1, 1, 1], [2, 2]);\n    const gradX = tf.grad(\n        (x: tf.Tensor2D) => tf.batchNorm2d(\n            x, mean, variance, offset, scale, varianceEpsilon))(x, dy);\n    expectArraysClose(await gradX.data(), [1.414, 2.500, 0.816, 1.768]);\n    expect(gradX.shape).toEqual([2, 2]);\n    const gradMean = tf.grad(\n        (mean: tf.Tensor2D) => tf.batchNorm2d(\n            x, mean, variance, offset, scale, varianceEpsilon))(mean, dy);\n    expectArraysClose(await gradMean.data(), [-1.414, -2.500, -0.816, -1.768]);\n    expect(gradMean.shape).toEqual([2, 2]);\n    const gradVariance = tf.grad(\n        (variance: tf.Tensor2D) => tf.batchNorm2d(\n            x, mean, variance, offset, scale, varianceEpsilon))(variance, dy);\n    expectArraysClose(\n        await gradVariance.data(), [-3.533, -4.686, -1.360, -2.762]);\n    expect(gradVariance.shape).toEqual([2, 2]);\n    const gradOffset = tf.grad(\n        (offset: tf.Tensor2D) => tf.batchNorm2d(\n            x, mean, variance, offset, scale, varianceEpsilon))(offset, dy);\n    expectArraysClose(await gradOffset.data(), [1, 1, 1, 1]);\n    expect(gradOffset.shape).toEqual([2, 2]);\n    const gradScale = tf.grad(\n        (scale: tf.Tensor2D) => tf.batchNorm2d(\n            x, mean, variance, offset, scale, varianceEpsilon))(scale, dy);\n    expectArraysClose(await gradScale.data(), [7.069, 7.499, 8.164, 8.838]);\n    expect(gradScale.shape).toEqual([2, 2]);\n  });\n\n  it('gradient with clones', () => {\n    const x = tf.zeros([2, 2]);\n    const mean = tf.zeros([2, 2]);\n    const variance = tf.zeros([2, 2]);\n    const scale = tf.zeros([2, 2]);\n    const offset = tf.zeros([2, 2]);\n\n    const varianceEpsilon = .001;\n\n    const gradF = tf.grads(\n        (x: tf.Tensor2D, mean: tf.Tensor2D, variance: tf.Tensor2D,\n         offset: tf.Tensor2D, scale: tf.Tensor2D) =>\n            tf.batchNorm2d(\n                  x.clone(), mean.clone(), variance.clone(), offset.clone(),\n                  scale.clone(), varianceEpsilon)\n                .clone());\n    const [gradX, gradMean, gradVariance, gradOffset, gradScale] =\n        gradF([x, mean, variance, offset, scale]);\n    expect(gradX.shape).toEqual(x.shape);\n    expect(gradMean.shape).toEqual(mean.shape);\n    expect(gradVariance.shape).toEqual(variance.shape);\n    expect(gradOffset.shape).toEqual(offset.shape);\n    expect(gradScale.shape).toEqual(scale.shape);\n  });\n\n  it('batchnorm2D matches tensorflow, 3x3', async () => {\n    const x = tf.tensor2d(\n        [\n          0.3136892, 0.92389025, 0.594782, 0.05021042, 0.67545404, 0.93910035,\n          0.13277993, 0.96474269, 0.88608916\n        ],\n        [3, 3]);\n    const mean = tf.tensor1d([0.19526312, 0.74857256, 0.45166398]);\n    const variance = tf.tensor1d([0.22963001, 0.61521992, 0.46623685]);\n    const offset = tf.tensor1d([0.43098484, 0.77712237, 0.47916298]);\n    const scale = tf.tensor1d([0.62186907, 0.85673736, 0.19201061]);\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm2d(x, mean, variance, offset, scale, varianceEpsilon);\n\n    expectArraysClose(await result.data(), [\n      0.58433646, 0.96846228, 0.51936529, 0.24315402, 0.69732157, 0.61608542,\n      0.35007446, 1.01304821, 0.60119441\n    ]);\n  });\n\n  it('throws when passed x as a non-tensor', () => {\n    const mean = tf.tensor1d([1, 2]);\n    const variance = tf.tensor1d([2, 3]);\n\n    expect(() => tf.batchNorm({} as tf.Tensor, mean, variance))\n        .toThrowError(/Argument 'x' passed to 'batchNorm' must be a Tensor/);\n  });\n  it('throws when passed mean as a non-tensor', () => {\n    const x = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const variance = tf.tensor1d([2, 3]);\n\n    expect(() => tf.batchNorm(x, {} as tf.Tensor, variance))\n        .toThrowError(/Argument 'mean' passed to 'batchNorm' must be a Tensor/);\n  });\n  it('throws when passed variance as a non-tensor', () => {\n    const x = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const mean = tf.tensor1d([1, 2]);\n\n    const e = /Argument 'variance' passed to 'batchNorm' must be a Tensor/;\n    expect(() => tf.batchNorm(x, mean, {} as tf.Tensor)).toThrowError(e);\n  });\n  it('throws when passed scale as a non-tensor', () => {\n    const x = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const mean = tf.tensor1d([1, 2]);\n    const variance = tf.tensor1d([2, 3]);\n    const epsilon = .001;\n\n    expect(() => tf.batchNorm(x, mean, variance, epsilon, {} as tf.Tensor))\n        .toThrowError(\n            /Argument 'scale' passed to 'batchNorm' must be a Tensor/);\n  });\n  it('throws when passed offset as a non-tensor', () => {\n    const x = tf.tensor4d([2, 4, 9, 23], [2, 1, 1, 2]);\n    const mean = tf.tensor1d([1, 2]);\n    const variance = tf.tensor1d([2, 3]);\n    const epsilon = .001;\n    const scale = tf.tensor1d([0.62186907, 0.85673736, 0.19201061]);\n\n    const e = /Argument 'offset' passed to 'batchNorm' must be a Tensor/;\n    expect(\n        () => tf.batchNorm(x, mean, variance, {} as tf.Tensor, scale, epsilon))\n        .toThrowError(e);\n  });\n\n  it('accepts a tensor-like object', async () => {\n    const x = [[2, 4], [9, 23]];\n    const mean = [1, 2];\n    const variance = [2, 3];\n    const offset = [3, 4];\n    const scale = [4, 5];\n\n    const varianceEpsilon = .001;\n\n    const result =\n        tf.batchNorm2d(x, mean, variance, offset, scale, varianceEpsilon);\n\n    expectArraysClose(await result.data(), [\n      offset[0] +\n          (x[0][0] - mean[0]) * scale[0] /\n              Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[0][1] - mean[1]) * scale[1] /\n              Math.sqrt(variance[1] + varianceEpsilon),\n      offset[0] +\n          (x[1][0] - mean[0]) * scale[0] /\n              Math.sqrt(variance[0] + varianceEpsilon),\n      offset[1] +\n          (x[1][1] - mean[1]) * scale[1] /\n              Math.sqrt(variance[1] + varianceEpsilon)\n    ]);\n  });\n\n  it('throws error when x is a string tensor', () => {\n    const mean = [1, 2];\n    const variance = [2, 3];\n    const offset = [3, 4];\n    const scale = [4, 5];\n\n    const varianceEpsilon = .001;\n\n    const f = () => tf.batchNorm2d(\n        [['a', 'b'], ['c', 'd']], mean, variance, offset, scale,\n        varianceEpsilon);\n    expect(f).toThrowError(\n        /Argument 'x' passed to 'batchNorm' must be numeric/);\n  });\n\n  it('throws error when mean is a string tensor', () => {\n    const x = [[2, 4], [9, 23]];\n    const variance = [2, 3];\n    const offset = [3, 4];\n    const scale = [4, 5];\n\n    const varianceEpsilon = .001;\n\n    const f = () =>\n        tf.batchNorm2d(x, ['a', 'b'], variance, offset, scale, varianceEpsilon);\n    expect(f).toThrowError(\n        /Argument 'mean' passed to 'batchNorm' must be numeric/);\n  });\n\n  it('throws error when variance is a string tensor', () => {\n    const x = [[2, 4], [9, 23]];\n    const mean = [1, 2];\n    const offset = [3, 4];\n    const scale = [4, 5];\n\n    const varianceEpsilon = .001;\n\n    const f = () =>\n        tf.batchNorm2d(x, mean, ['a', 'b'], offset, scale, varianceEpsilon);\n    expect(f).toThrowError(/'variance' passed to 'batchNorm' must be numeric/);\n  });\n\n  it('throws error when scale is a string tensor', () => {\n    const x = [[2, 4], [9, 23]];\n    const mean = [1, 2];\n    const variance = [2, 3];\n    const offset = [3, 4];\n\n    const varianceEpsilon = .001;\n\n    const f = () =>\n        tf.batchNorm2d(x, mean, variance, offset, ['a', 'b'], varianceEpsilon);\n    expect(f).toThrowError(/'scale' passed to 'batchNorm' must be numeric/);\n  });\n\n  it('throws error when offset is a string tensor', () => {\n    const x = [[2, 4], [9, 23]];\n    const mean = [1, 2];\n    const variance = [2, 3];\n    const scale = [4, 5];\n\n    const varianceEpsilon = .001;\n\n    const f = () =>\n        tf.batchNorm2d(x, mean, variance, ['a', 'b'], scale, varianceEpsilon);\n    expect(f).toThrowError(/'offset' passed to 'batchNorm' must be numeric/);\n  });\n});\n"]}