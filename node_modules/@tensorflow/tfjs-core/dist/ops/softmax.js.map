{"version":3,"file":"softmax.js","sourceRoot":"","sources":["../../src/ops/softmax.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AAEH,OAAO,EAAC,MAAM,EAAC,MAAM,WAAW,CAAC;AACjC,OAAO,EAAC,OAAO,EAA8B,MAAM,iBAAiB,CAAC;AAIrE,OAAO,EAAC,eAAe,EAAC,MAAM,oBAAoB,CAAC;AAGnD,OAAO,EAAC,EAAE,EAAC,MAAM,aAAa,CAAC;AAE/B;;;;;;;;;;;;;;;;;;;;GAoBG;AACH,SAAS,QAAQ,CAAmB,MAAoB,EAAE,GAAG,GAAG,CAAC,CAAC;IAChE,MAAM,OAAO,GAAG,eAAe,CAAC,MAAM,EAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,CAAC,CAAC;IAExE,IAAI,GAAG,KAAK,CAAC,CAAC,EAAE;QACd,GAAG,GAAG,OAAO,CAAC,IAAI,GAAG,CAAC,CAAC;KACxB;IACD,IAAI,GAAG,KAAK,OAAO,CAAC,IAAI,GAAG,CAAC,EAAE;QAC5B,MAAM,KAAK,CACP,2DAA2D;YAC3D,mBAAmB,OAAO,CAAC,IAAI,gBAAgB,GAAG,EAAE,CAAC,CAAC;KAC3D;IAED,MAAM,MAAM,GAAkB,EAAC,MAAM,EAAE,OAAO,EAAC,CAAC;IAChD,MAAM,KAAK,GAAiB,EAAC,GAAG,EAAC,CAAC;IAElC,OAAO,MAAM,CAAC,SAAS,CACnB,OAAO,EAAE,MAA8B,EAAE,KAA2B,CAAC,CAAC;AAC5E,CAAC;AAED,MAAM,CAAC,MAAM,OAAO,GAAG,EAAE,CAAC,EAAC,QAAQ,EAAC,CAAC,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ENGINE} from '../engine';\nimport {Softmax, SoftmaxAttrs, SoftmaxInputs} from '../kernel_names';\nimport {NamedAttrMap} from '../kernel_registry';\nimport {Tensor} from '../tensor';\nimport {NamedTensorMap} from '../tensor_types';\nimport {convertToTensor} from '../tensor_util_env';\nimport {TensorLike} from '../types';\n\nimport {op} from './operation';\n\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction softmax_<T extends Tensor>(logits: T|TensorLike, dim = -1): T {\n  const $logits = convertToTensor(logits, 'logits', 'softmax', 'float32');\n\n  if (dim === -1) {\n    dim = $logits.rank - 1;\n  }\n  if (dim !== $logits.rank - 1) {\n    throw Error(\n        'Softmax along a non-last dimension is not yet supported. ' +\n        `Logits was rank ${$logits.rank} and dim was ${dim}`);\n  }\n\n  const inputs: SoftmaxInputs = {logits: $logits};\n  const attrs: SoftmaxAttrs = {dim};\n\n  return ENGINE.runKernel(\n      Softmax, inputs as {} as NamedTensorMap, attrs as {} as NamedAttrMap);\n}\n\nexport const softmax = op({softmax_});\n"]}