{"version":3,"file":"LogSoftmax_grad.js","sourceRoot":"","sources":["../../src/gradients/LogSoftmax_grad.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AAEH,OAAO,EAAC,UAAU,EAAkB,MAAM,iBAAiB,CAAC;AAE5D,OAAO,EAAC,GAAG,EAAC,MAAM,YAAY,CAAC;AAC/B,OAAO,EAAC,GAAG,EAAC,MAAM,YAAY,CAAC;AAC/B,OAAO,EAAC,GAAG,EAAC,MAAM,YAAY,CAAC;AAC/B,OAAO,EAAC,GAAG,EAAC,MAAM,YAAY,CAAC;AAG/B,MAAM,CAAC,MAAM,oBAAoB,GAAe;IAC9C,UAAU,EAAE,UAAU;IACtB,YAAY,EAAE,EAAE;IAChB,aAAa,EAAE,CAAC,IAAI,CAAC;IACrB,QAAQ,EAAE,CAAC,EAAU,EAAE,KAAe,EAAE,KAAmB,EAAE,EAAE;QAC7D,MAAM,CAAC,KAAK,CAAC,GAAG,KAAK,CAAC;QACtB,MAAM,EAAC,IAAI,EAAC,GAAG,KAA8B,CAAC;QAC9C,OAAO;YACL,MAAM,EAAE,GAAG,EAAE;gBACX,MAAM,QAAQ,GAAG,IAAI,CAAC;gBACtB,MAAM,OAAO,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC;gBAC3B,OAAO,GAAG,CAAC,EAAE,EAAE,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,IAAI,EAAE,QAAQ,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC;YACxD,CAAC;SACF,CAAC;IACJ,CAAC;CACF,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {LogSoftmax, LogSoftmaxAttrs} from '../kernel_names';\nimport {GradConfig, NamedAttrMap} from '../kernel_registry';\nimport {exp} from '../ops/exp';\nimport {mul} from '../ops/mul';\nimport {sub} from '../ops/sub';\nimport {sum} from '../ops/sum';\nimport {Tensor} from '../tensor';\n\nexport const logSoftmaxGradConfig: GradConfig = {\n  kernelName: LogSoftmax,\n  inputsToSave: [],\n  outputsToSave: [true],\n  gradFunc: (dy: Tensor, saved: Tensor[], attrs: NamedAttrMap) => {\n    const [value] = saved;\n    const {axis} = attrs as {} as LogSoftmaxAttrs;\n    return {\n      logits: () => {\n        const keepDims = true;\n        const softmax = exp(value);\n        return sub(dy, mul(sum(dy, axis, keepDims), softmax));\n      }\n    };\n  }\n};\n"]}