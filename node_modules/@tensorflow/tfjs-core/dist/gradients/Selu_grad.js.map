{"version":3,"file":"Selu_grad.js","sourceRoot":"","sources":["../../src/gradients/Selu_grad.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AACH,OAAO,EAAC,IAAI,EAAC,MAAM,iBAAiB,CAAC;AAErC,OAAO,EAAC,IAAI,EAAC,MAAM,aAAa,CAAC;AACjC,OAAO,EAAC,GAAG,EAAC,MAAM,YAAY,CAAC;AAC/B,OAAO,EAAC,OAAO,EAAC,MAAM,gBAAgB,CAAC;AACvC,OAAO,EAAC,GAAG,EAAC,MAAM,YAAY,CAAC;AAC/B,OAAO,EAAC,MAAM,EAAC,MAAM,eAAe,CAAC;AACrC,OAAO,EAAC,UAAU,EAAE,eAAe,EAAC,MAAM,kBAAkB,CAAC;AAC7D,OAAO,EAAC,KAAK,EAAC,MAAM,cAAc,CAAC;AAGnC,MAAM,CAAC,MAAM,cAAc,GAAe;IACxC,UAAU,EAAE,IAAI;IAChB,YAAY,EAAE,CAAC,GAAG,CAAC;IACnB,QAAQ,EAAE,CAAC,EAAU,EAAE,KAAe,EAAE,EAAE;QACxC,MAAM,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC;QAClB,OAAO;YACL,CAAC,EAAE,GAAG,EAAE;gBACN,MAAM,IAAI,GAAG,OAAO,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;gBAEnC,MAAM,UAAU,GAAG,MAAM,CAAC,eAAe,CAAC,CAAC;gBAC3C,MAAM,KAAK,GAAG,MAAM,CAAC,UAAU,CAAC,CAAC;gBAEjC,MAAM,kBAAkB,GAAG,GAAG,CAAC,EAAE,EAAE,KAAK,CAAC,CAAC;gBAC1C,MAAM,gBAAgB,GAClB,GAAG,CAAC,GAAG,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,GAAG,CAAC,IAAI,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC;gBAEtD,OAAO,KAAK,CAAC,IAAI,EAAE,kBAAkB,EAAE,gBAAgB,CAAC,CAAC;YAC3D,CAAC;SACF,CAAC;IACJ,CAAC;CACF,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Selu} from '../kernel_names';\nimport {GradConfig} from '../kernel_registry';\nimport {cast} from '../ops/cast';\nimport {exp} from '../ops/exp';\nimport {greater} from '../ops/greater';\nimport {mul} from '../ops/mul';\nimport {scalar} from '../ops/scalar';\nimport {SELU_SCALE, SELU_SCALEALPHA} from '../ops/selu_util';\nimport {where} from '../ops/where';\nimport {Tensor} from '../tensor';\n\nexport const seluGradConfig: GradConfig = {\n  kernelName: Selu,\n  inputsToSave: ['x'],\n  gradFunc: (dy: Tensor, saved: Tensor[]) => {\n    const [x] = saved;\n    return {\n      x: () => {\n        const mask = greater(x, scalar(0));\n\n        const scaleAlpha = scalar(SELU_SCALEALPHA);\n        const scale = scalar(SELU_SCALE);\n\n        const greaterThanZeroDer = mul(dy, scale);\n        const lessEqualZeroDer =\n            mul(mul(dy, scaleAlpha), exp(cast(x, 'float32')));\n\n        return where(mask, greaterThanZeroDer, lessEqualZeroDer);\n      }\n    };\n  }\n};\n"]}