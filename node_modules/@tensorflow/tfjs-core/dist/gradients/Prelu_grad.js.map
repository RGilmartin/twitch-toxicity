{"version":3,"file":"Prelu_grad.js","sourceRoot":"","sources":["../../src/gradients/Prelu_grad.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AACH,OAAO,EAAC,KAAK,EAAC,MAAM,iBAAiB,CAAC;AAEtC,OAAO,EAAC,gBAAgB,EAAC,MAAM,uBAAuB,CAAC;AACvD,OAAO,EAAC,OAAO,EAAC,MAAM,gBAAgB,CAAC;AACvC,OAAO,EAAC,GAAG,EAAC,MAAM,YAAY,CAAC;AAC/B,OAAO,EAAC,OAAO,EAAC,MAAM,gBAAgB,CAAC;AACvC,OAAO,EAAC,GAAG,EAAC,MAAM,YAAY,CAAC;AAC/B,OAAO,EAAC,KAAK,EAAC,MAAM,cAAc,CAAC;AACnC,OAAO,EAAC,SAAS,EAAC,MAAM,mBAAmB,CAAC;AAG5C,MAAM,CAAC,MAAM,eAAe,GAAe;IACzC,UAAU,EAAE,KAAK;IACjB,YAAY,EAAE,CAAC,GAAG,EAAE,OAAO,CAAC;IAC5B,QAAQ,EAAE,CAAC,EAAU,EAAE,KAAe,EAAE,EAAE;QACxC,MAAM,CAAC,CAAC,EAAE,KAAK,CAAC,GAAG,KAAK,CAAC;QACzB,MAAM,IAAI,GAAG,OAAO,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAE3B,OAAO;YACL,CAAC,EAAE,GAAG,EAAE,CAAC,KAAK,CAAC,IAAI,EAAE,EAAE,EAAE,GAAG,CAAC,EAAE,EAAE,KAAK,CAAC,CAAC;YACxC,KAAK,EAAE,GAAG,EAAE;gBACV,IAAI,GAAG,GAAG,KAAK,CAAC,IAAI,EAAE,SAAS,CAAC,EAAE,CAAC,EAAE,GAAG,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC;gBACjD,MAAM,UAAU,GAAG,gBAAgB,CAAC,KAAK,CAAC,KAAK,EAAE,EAAE,CAAC,KAAK,CAAC,CAAC;gBAC3D,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;oBACzB,GAAG,GAAG,GAAG,CAAC,GAAG,EAAE,UAAU,CAAC,CAAC;iBAC5B;gBACD,OAAO,OAAO,CAAC,GAAG,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC;YACnC,CAAC;SACF,CAAC;IACJ,CAAC;CACF,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Prelu} from '../kernel_names';\nimport {GradConfig} from '../kernel_registry';\nimport {getReductionAxes} from '../ops/broadcast_util';\nimport {greater} from '../ops/greater';\nimport {mul} from '../ops/mul';\nimport {reshape} from '../ops/reshape';\nimport {sum} from '../ops/sum';\nimport {where} from '../ops/where';\nimport {zerosLike} from '../ops/zeros_like';\nimport {Tensor} from '../tensor';\n\nexport const preluGradConfig: GradConfig = {\n  kernelName: Prelu,\n  inputsToSave: ['x', 'alpha'],\n  gradFunc: (dy: Tensor, saved: Tensor[]) => {\n    const [x, alpha] = saved;\n    const mask = greater(x, 0);\n\n    return {\n      x: () => where(mask, dy, mul(dy, alpha)),\n      alpha: () => {\n        let res = where(mask, zerosLike(dy), mul(dy, x));\n        const reduceAxes = getReductionAxes(alpha.shape, dy.shape);\n        if (reduceAxes.length > 0) {\n          res = sum(res, reduceAxes);\n        }\n        return reshape(res, alpha.shape);\n      }\n    };\n  }\n};\n"]}