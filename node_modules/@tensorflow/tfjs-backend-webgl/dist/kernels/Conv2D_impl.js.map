{"version":3,"file":"Conv2D_impl.js","sourceRoot":"","sources":["../../src/kernels/Conv2D_impl.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;GAeG;AAEH,OAAO,EAAe,GAAG,EAAc,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAG1E,OAAO,EAAC,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;AACzD,OAAO,EAAC,4BAA4B,EAAC,MAAM,oCAAoC,CAAC;AAChF,OAAO,EAAC,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;AACzD,OAAO,KAAK,UAAU,MAAM,eAAe,CAAC;AAE5C,OAAO,EAAC,eAAe,EAAE,2BAA2B,EAAC,MAAM,oBAAoB,CAAC;AAChF,OAAO,EAAC,QAAQ,EAAC,MAAM,YAAY,CAAC;AACpC,OAAO,EAAC,OAAO,EAAC,MAAM,WAAW,CAAC;AAalC,6EAA6E;AAC7E,qEAAqE;AACrE,cAAc;AACd,MAAM,UAAU,cAAc,CAAC,EAC7B,CAAC,EACD,MAAM,EACN,QAAQ,EACR,OAAO,EACP,IAAI,GAAG,IAAI,EACX,sBAAsB,GAAG,IAAI,EAC7B,cAAc,GAAG,CAAC,EAClB,UAAU,GAAG,IAAI,EACJ;IACb,wEAAwE;IACxE,wBAAwB;IACxB,MAAM,MAAM,GAAG,CAAC,CAAC,KAAK,CAAC;IACvB,MAAM,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;IAC/C,MAAM,eAAe,GAAG,QAAQ,CAAC,UAAU,CAAC;IAC5C,MAAM,WAAW,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;IACtD,MAAM,gBAAgB,GAAG,QAAQ,CAAC,WAAW,CAAC;IAC9C,MAAM,cAAc,GAAG,QAAQ,CAAC,UAAU,KAAK,cAAc,CAAC;IAC9D,MAAM,UAAU,GAAG,KAAK,CAAC;IACzB,MAAM,UAAU,GAAG,KAAK,CAAC;IAEzB,IAAI,GAAe,CAAC;IACpB,MAAM,aAAa,GAAiB,EAAE,CAAC;IAEvC,yEAAyE;IACzE,oCAAoC;IACpC,MAAM,yBAAyB,GAC3B,CAAC,WAAW,KAAK,CAAC,IAAI,gBAAgB,KAAK,CAAC,CAAC;QAC7C,eAAe,GAAG,2BAA2B,CAAC;IAClD,MAAM,sBAAsB,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,QAAQ,CAAC,QAAQ,CAAC;IAE1E,IAAI,yBAAyB,IAAI,CAAC,GAAG,EAAE,CAAC,OAAO,CAAC,qBAAqB,CAAC;QAClE,CAAC,GAAG,EAAE,CAAC,OAAO,CAAC,8BAA8B,CAAC;QAC9C,CAAC,sBAAsB,EAAE;QAC3B,MAAM,WAAW,GAAG,cAAc,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;YACnC,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;QACvE,MAAM,SAAS,GAAG,OAAO,CAAC;YACxB,MAAM,EAAE,EAAC,CAAC,EAAC;YACX,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,WAAW,EAAE,QAAQ,CAAC,UAAU,CAAC,EAAC;SACtD,CAAC,CAAC;QACH,MAAM,cAAc,GAAG,OAAO,CAAC;YAC7B,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC;YACnB,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,QAAQ,CAAC,UAAU,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC;SAC/D,CAAC,CAAC;QACH,MAAM,MAAM,GAAG,eAAe,CAAC;YAC7B,CAAC,EAAE,SAAS;YACZ,CAAC,EAAE,cAAc;YACjB,UAAU;YACV,UAAU;YACV,OAAO;YACP,IAAI;YACJ,UAAU;YACV,sBAAsB;YACtB,cAAc;SACf,CAAC,CAAC;QAEH,GAAG,GAAG,OAAO,CACT,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,CAAC,QAAQ,EAAC,EAAC,CAAC,CAAC;QAEvE,aAAa,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QAC9B,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QACnC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;KAC5B;SAAM;QACL,sEAAsE;QACtE,wEAAwE;QACxE,sEAAsE;QACtE,2EAA2E;QAC3E,0EAA0E;QAC1E,0EAA0E;QAC1E,oEAAoE;QACpE,uDAAuD;QACvD,MAAM,WAAW,GAAG,cAAc,CAAC,CAAC;YAChC,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;YACzC,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;QAC5C,MAAM,SAAS,GAAe;YAC5B,MAAM,EAAE,CAAC,CAAC,MAAM;YAChB,KAAK,EAAE,CAAC,CAAC,EAAE,WAAW,EAAE,QAAQ,CAAC,UAAU,CAAC;YAC5C,KAAK,EAAE,CAAC,CAAC,KAAK;SACf,CAAC;QACF,gEAAgE;QAChE,0EAA0E;QAC1E,sEAAsE;QACtE,yEAAyE;QACzE,qEAAqE;QACrE,uEAAuE;QACvE,wEAAwE;QACxE,8BAA8B;QAC9B,MAAM,qBAAqB,GAAG,QAAQ,CAAC,KAAK,CAAC;QAC7C,QAAQ,CAAC,KAAK,GAAG,QAAQ,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC;QACxC,QAAQ,CAAC,KAAK,CAAC,QAAQ,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,EAAE,CAAC;QAC5C,IAAI,CAAC,MAAM,CACP,UAAU,CAAC,aAAa,CAAC,QAAQ,CAAC,KAAK,EAAE,SAAS,CAAC,KAAK,CAAC,EACzD,GAAG,EAAE,CAAC,kBAAkB,QAAQ,CAAC,KAAK,OAClC,SAAS,CAAC,KAAK,aAAa,CAAC,CAAC;QACtC,MAAM,cAAc,GAAG,OAAO,CAAC;YAC7B,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC;YACnB,OAAO;YACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,QAAQ,CAAC,UAAU,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAC;SAC/D,CAAC,CAAC;QACH,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QACnC,MAAM,aAAa,GAAG,eAAe,CAAC;YACpC,CAAC,EAAE,SAAS;YACZ,CAAC,EAAE,cAAc;YACjB,OAAO;YACP,UAAU;YACV,UAAU;YACV,IAAI;YACJ,UAAU;YACV,sBAAsB;YACtB,cAAc;SACf,CAAC,CAAC;QAEH,MAAM,oBAAoB,GAAG,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,aAAa,CAAC,MAAM,CAAC,CAAC;QACvE,IAAI,CAAC,MAAM,CACP,oBAAoB,CAAC,QAAQ,EAC7B,GAAG,EAAE,CAAC,6CAA6C,CAAC,CAAC;QACzD,uCAAuC;QACvC,QAAQ,CAAC,KAAK,GAAG,qBAAqB,CAAC;QACvC,wEAAwE;QACxE,6BAA6B;QAC7B,oBAAoB,CAAC,KAAK,GAAG,QAAQ,CAAC,QAAQ,CAAC;QAE/C,GAAG,GAAG,QAAQ,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,aAAa,EAAC,EAAE,OAAO,EAAC,CAAC,CAAC;QACtD,GAAG,CAAC,KAAK,GAAG,QAAQ,CAAC,QAAQ,CAAC;QAE9B,aAAa,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC;KACnC;IAED,KAAK,MAAM,CAAC,IAAI,aAAa,EAAE;QAC7B,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;KAC1C;IAED,OAAO,GAAG,CAAC;AACb,CAAC;AAED,mEAAmE;AACnE,0EAA0E;AAC1E,MAAM,UAAU,gBAAgB,CAAC,EAC/B,CAAC,EACD,MAAM,EACN,QAAQ,EACR,OAAO,EACP,IAAI,GAAG,IAAI,EACX,sBAAsB,GAAG,IAAI,EAC7B,cAAc,GAAG,CAAC,EAClB,UAAU,GAAG,IAAI,EACJ;IACb,uEAAuE;IACvE,kEAAkE;IAClE,2EAA2E;IAC3E,sEAAsE;IACtE,oEAAoE;IACpE,mEAAmE;IACnE,MAAM,EACJ,WAAW,EACX,YAAY,EACZ,UAAU,EACV,QAAQ,EACR,SAAS,EACT,UAAU,EACX,GAAG,QAAQ,CAAC;IAEb,MAAM,cAAc,GAAG,UAAU,KAAK,cAAc,CAAC;IAErD,MAAM,SAAS,GAAG,WAAW,GAAG,YAAY,GAAG,UAAU,CAAC;IAC1D,MAAM,OAAO,GAAG,SAAS,GAAG,QAAQ,CAAC;IACrC,MAAM,UAAU,GAAG,CAAC,SAAS,EAAE,OAAO,CAAC,CAAC;IACxC,MAAM,UAAU,GAAG,IAAI,CAAC;IACxB,MAAM,UAAU,GAAG,KAAK,CAAC;IAEzB,MAAM,aAAa,GAAiB,EAAE,CAAC;IAEvC,MAAM,SAAS,GACX,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAC,EAAC,CAAC,CAAC;IACtE,MAAM,KAAK,GAAG,OAAO,CAAC;QACpB,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC;QACnB,OAAO;QACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,SAAS,EAAE,IAAI,CAAC,aAAa,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,SAAS,CAAC,EAAC;KAC7E,CAAC,CAAC;IAEH,aAAa,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;IAC9B,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;IAE1B,MAAM,aAAa,GACf,IAAI,mBAAmB,CAAC,UAAU,EAAE,SAAS,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAC;IACnE,MAAM,MAAM,GAAG,OAAO,CAAC,eAAe,CAAC,aAAa,EAAE,CAAC,SAAS,CAAC,EAAE,SAAS,CAAC,CAAC;IAC9E,MAAM,cAAc,GAAG,OAAO,CAAC;QAC7B,MAAM,EAAE,EAAC,CAAC,EAAE,MAAM,EAAC;QACnB,OAAO;QACP,KAAK,EAAE,EAAC,KAAK,EAAE,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,CAAC,EAAC;KAClD,CAAC,CAAC;IAEH,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IAC3B,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;IAEnC,MAAM,OAAO,GAAG,IAAI,IAAI,IAAI,CAAC;IAC7B,MAAM,yBAAyB,GAAG,sBAAsB,IAAI,IAAI,CAAC;IACjE,MAAM,iBAAiB,GAAG,UAAU,KAAK,WAAW,CAAC;IACrD,MAAM,eAAe,GACjB,UAAU,CAAC,CAAC,CAAC,4BAA4B,CAAC,UAAU,EAAE,IAAI,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;IACvE,MAAM,aAAa,GAAG,IAAI,mBAAmB,CACzC,cAAc,CAAC,KAAiC,EAChD,KAAK,CAAC,KAAiC,EACvC,CAAC,CAAC,EAAE,OAAO,EAAE,QAAQ,CAAC,WAAW,CAAC,EAAE,UAAU,EAAE,UAAU,EAAE,OAAO,EACnE,eAAe,EAAE,yBAAyB,EAAE,iBAAiB,CAAC,CAAC;IACnE,MAAM,MAAM,GAAiB,CAAC,cAAc,EAAE,KAAK,CAAC,CAAC;IACrD,IAAI,IAAI,EAAE;QACR,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;KACnB;IACD,IAAI,yBAAyB,EAAE;QAC7B,MAAM,CAAC,IAAI,CAAC,sBAAsB,CAAC,CAAC;KACrC;IACD,IAAI,iBAAiB,EAAE;QACrB,MAAM,eAAe,GAAG,OAAO,CAAC,cAAc,CAC1C,EAAE,EAAE,SAAS,EACb,IAAI,CAAC,iBAAiB,CAAC,cAAiC,EAAE,SAAS,CAAC,CAAC,CAAC;QAC1E,MAAM,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAC7B,aAAa,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;KACrC;IACD,MAAM,OAAO,GAAG,OAAO,CAAC,eAAe,CAAC,aAAa,EAAE,MAAM,EAAE,SAAS,CAAC,CAAC;IAE1E,MAAM,QAAQ,GAAG,cAAc,CAAC,CAAC;QAC7B,CAAC,CAAC,EAAE,SAAS,EAAE,QAAQ,EAAE,QAAQ,CAAC,WAAW,CAAC,CAAC,CAAC;QAChD,CAAC,CAAC,EAAE,QAAQ,CAAC,WAAW,EAAE,SAAS,EAAE,QAAQ,CAAC,CAAC;IACnD,MAAM,GAAG,GACL,OAAO,CAAC,EAAC,MAAM,EAAE,EAAC,CAAC,EAAE,OAAO,EAAC,EAAE,OAAO,EAAE,KAAK,EAAE,EAAC,KAAK,EAAE,QAAQ,EAAC,EAAC,CAAC,CAAC;IAEvE,aAAa,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;IAC5B,KAAK,MAAM,CAAC,IAAI,aAAa,EAAE;QAC7B,OAAO,CAAC,6BAA6B,CAAC,CAAC,CAAC,CAAC;KAC1C;IAED,OAAO,GAAG,CAAC;AACb,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, env, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendWebGL} from '../backend_webgl';\nimport {Im2ColPackedProgram} from '../im2col_packed_gpu';\nimport {mapActivationToShaderProgram} from '../kernel_utils/kernel_funcs_utils';\nimport {MatMulPackedProgram} from '../mulmat_packed_gpu';\nimport * as webgl_util from '../webgl_util';\n\nimport {batchMatMulImpl, MATMUL_SHARED_DIM_THRESHOLD} from './BatchMatMul_impl';\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\n\ntype Conv2DConfig = {\n  x: TensorInfo,\n  filter: TensorInfo,\n  convInfo: backend_util.Conv2DInfo,\n  backend: MathBackendWebGL,\n  bias?: TensorInfo,\n  preluActivationWeights?: TensorInfo,\n  leakyreluAlpha?: number,\n  activation?: backend_util.Activation\n};\n\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nexport function conv2dByMatMul({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n  // result from 2D to 4D.\n  const xShape = x.shape;\n  const xTexData = backend.texData.get(x.dataId);\n  const sharedMatMulDim = convInfo.inChannels;\n  const outerShapeX = xShape[0] * xShape[1] * xShape[2];\n  const outerShapeFilter = convInfo.outChannels;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const transposeA = false;\n  const transposeB = false;\n\n  let out: TensorInfo;\n  const intermediates: TensorInfo[] = [];\n\n  // TODO: Once reduction ops are packed, batchMatMul will always be packed\n  // and we can remove this condition.\n  const batchMatMulWillBeUnpacked =\n      (outerShapeX === 1 || outerShapeFilter === 1) &&\n      sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;\n  const reshapeWillBeExpensive = xShape[2] % 2 !== 0 && !!xTexData.isPacked;\n\n  if (batchMatMulWillBeUnpacked || !env().getBool('WEBGL_LAZILY_UNPACK') ||\n      !env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ||\n      !reshapeWillBeExpensive) {\n    const targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] :\n                                         xShape[0] * xShape[2] * xShape[3];\n    const xReshaped = reshape({\n      inputs: {x},\n      backend,\n      attrs: {shape: [1, targetShape, convInfo.inChannels]}\n    });\n    const filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n    const result = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      transposeA,\n      transposeB,\n      backend,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n\n    out = reshape(\n        {inputs: {x: result}, backend, attrs: {shape: convInfo.outShape}});\n\n    intermediates.push(xReshaped);\n    intermediates.push(filterReshaped);\n    intermediates.push(result);\n  } else {\n    // Following optimization is specific to packed |x| with odd row count\n    // (For example, in channelLast mode, 'row count' refers to x.shape[2]):\n    // we avoid expensive packed 2x2 reshape by padding row count to next,\n    // even number. When x.shape[2] is odd, the result of packed batchMatMul is\n    // the same (has the same texture layout and and values in the texture) as\n    // it is for even x.shape[2] + 1. We make the odd-rows tensor to look like\n    // even-rows tensor before the operation and, after the batchMatMul,\n    // fix the even-rows result to have odd number of rows.\n    const targetShape = isChannelsLast ?\n        xShape[0] * xShape[1] * (xShape[2] + 1) :\n        xShape[0] * xShape[2] * (xShape[3] + 1);\n    const xReshaped: TensorInfo = {\n      dataId: x.dataId,\n      shape: [1, targetShape, convInfo.inChannels],\n      dtype: x.dtype\n    };\n    // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n    // Decrementing row count, after batchMatMul->...->compileProgram leads to\n    // invalid row count within the reference in GPGPUBinary.inShapeInfos.\n    // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n    // in compileProgram method, but that would affect compilation of all\n    // programs - instead, provide a copy here, with even row count, before\n    // calling batchMatMul->...->compileProgram and after that, the original\n    // xTexData.shape is restored.\n    const originalXTexDataShape = xTexData.shape;\n    xTexData.shape = xTexData.shape.slice();\n    xTexData.shape[xTexData.shape.length - 2]++;\n    util.assert(\n        webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape),\n        () => `packed reshape ${xTexData.shape} to ${\n            xReshaped.shape} isn't free`);\n    const filterReshaped = reshape({\n      inputs: {x: filter},\n      backend,\n      attrs: {shape: [1, convInfo.inChannels, convInfo.outChannels]}\n    });\n    intermediates.push(filterReshaped);\n    const pointwiseConv = batchMatMulImpl({\n      a: xReshaped,\n      b: filterReshaped,\n      backend,\n      transposeA,\n      transposeB,\n      bias,\n      activation,\n      preluActivationWeights,\n      leakyreluAlpha\n    });\n\n    const pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);\n    util.assert(\n        pointwiseConvTexData.isPacked,\n        () => 'batchMatMul result is expected to be packed');\n    // Restore the input shape to original.\n    xTexData.shape = originalXTexDataShape;\n    // Set the output shape - there is no need for expensive reshape as data\n    // layout is already correct.\n    pointwiseConvTexData.shape = convInfo.outShape;\n\n    out = identity({inputs: {x: pointwiseConv}, backend});\n    out.shape = convInfo.outShape;\n\n    intermediates.push(pointwiseConv);\n  }\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n}\n\n// Implements the im2row algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\nexport function conv2dWithIm2Row({\n  x,\n  filter,\n  convInfo,\n  backend,\n  bias = null,\n  preluActivationWeights = null,\n  leakyreluAlpha = 0,\n  activation = null\n}: Conv2DConfig) {\n  // Rearranges conv2d input so each block to be convolved over forms the\n  // column of a new matrix with shape [filterWidth * filterHeight *\n  // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n  // output channel forms a row of a new matrix with shape [outChannels,\n  // filterWidth * filterHeight * inChannels]. The convolution is then\n  // computed by multiplying these matrices and reshaping the result.\n  const {\n    filterWidth,\n    filterHeight,\n    inChannels,\n    outWidth,\n    outHeight,\n    dataFormat\n  } = convInfo;\n\n  const isChannelsLast = dataFormat === 'channelsLast';\n\n  const sharedDim = filterWidth * filterHeight * inChannels;\n  const numCols = outHeight * outWidth;\n  const x2ColShape = [sharedDim, numCols];\n  const transposeA = true;\n  const transposeB = false;\n\n  const intermediates: TensorInfo[] = [];\n\n  const xSqueezed =\n      reshape({inputs: {x}, backend, attrs: {shape: x.shape.slice(1)}});\n  const w2Row = reshape({\n    inputs: {x: filter},\n    backend,\n    attrs: {shape: [1, sharedDim, util.sizeFromShape(filter.shape) / sharedDim]}\n  });\n\n  intermediates.push(xSqueezed);\n  intermediates.push(w2Row);\n\n  const im2ColProgram =\n      new Im2ColPackedProgram(x2ColShape, xSqueezed.shape, convInfo);\n  const im2Col = backend.runWebGLProgram(im2ColProgram, [xSqueezed], 'float32');\n  const im2ColReshaped = reshape({\n    inputs: {x: im2Col},\n    backend,\n    attrs: {shape: [1, x2ColShape[0], x2ColShape[1]]}\n  });\n\n  intermediates.push(im2Col);\n  intermediates.push(im2ColReshaped);\n\n  const hasBias = bias != null;\n  const hasPreluActivationWeights = preluActivationWeights != null;\n  const hasLeakyreluAlpha = activation === 'leakyrelu';\n  const fusedActivation =\n      activation ? mapActivationToShaderProgram(activation, true) : null;\n  const matmulProgram = new MatMulPackedProgram(\n      im2ColReshaped.shape as [number, number, number],\n      w2Row.shape as [number, number, number],\n      [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias,\n      fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n  const inputs: TensorInfo[] = [im2ColReshaped, w2Row];\n  if (bias) {\n    inputs.push(bias);\n  }\n  if (hasPreluActivationWeights) {\n    inputs.push(preluActivationWeights);\n  }\n  if (hasLeakyreluAlpha) {\n    const $leakyreluAlpha = backend.makeTensorInfo(\n        [], 'float32',\n        util.createScalarValue(leakyreluAlpha as {} as 'float32', 'float32'));\n    inputs.push($leakyreluAlpha);\n    intermediates.push($leakyreluAlpha);\n  }\n  const product = backend.runWebGLProgram(matmulProgram, inputs, 'float32');\n\n  const outShape = isChannelsLast ?\n      [1, outHeight, outWidth, convInfo.outChannels] :\n      [1, convInfo.outChannels, outHeight, outWidth];\n  const out =\n      reshape({inputs: {x: product}, backend, attrs: {shape: outShape}});\n\n  intermediates.push(product);\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return out;\n}\n"]}