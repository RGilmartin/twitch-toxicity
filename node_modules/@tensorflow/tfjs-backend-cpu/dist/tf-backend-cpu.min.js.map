{"version":3,"file":"tf-backend-cpu.min.js","sources":["../src/cpu_util.ts","../src/backend_cpu.ts","../src/kernels/Abs.ts","../src/utils/binary_impl.ts","../src/kernels/Complex.ts","../src/utils/zeros_impl.ts","../src/kernels/Identity.ts","../src/kernels/Real.ts","../src/kernels/Cast.ts","../src/utils/binary_utils.ts","../src/kernels/Add.ts","../src/kernels/Bincount_impl.ts","../src/utils/unary_impl.ts","../src/utils/unary_utils.ts","../src/kernels/Ceil.ts","../src/kernels/Concat_impl.ts","../src/kernels/Exp.ts","../src/kernels/Expm1.ts","../src/kernels/Floor.ts","../src/kernels/GatherV2_impl.ts","../src/kernels/Greater.ts","../src/kernels/Less.ts","../src/kernels/LinSpace_impl.ts","../src/kernels/Log.ts","../src/kernels/Max_impl.ts","../src/kernels/Maximum.ts","../src/kernels/Minimum.ts","../src/kernels/Multiply.ts","../src/kernels/Neg.ts","../src/kernels/NotEqual.ts","../src/kernels/Transpose_impl.ts","../src/kernels/Transpose.ts","../src/kernels/Prod.ts","../src/kernels/Range_impl.ts","../src/kernels/Rsqrt.ts","../src/kernels/Slice.ts","../src/kernels/SparseFillEmptyRows_impl.ts","../src/kernels/SparseReshape_impl.ts","../src/kernels/SquaredDifference.ts","../src/kernels/StridedSlice_impl.ts","../src/kernels/Sub.ts","../src/kernels/Tile_impl.ts","../src/kernels/TopK_impl.ts","../src/kernels/Unique_impl.ts","../src/base.ts","../src/kernels/Elu.ts","../src/kernels/LeakyRelu.ts","../src/kernels/Prelu.ts","../src/kernels/Relu.ts","../src/kernels/Relu6.ts","../src/kernels/Sigmoid.ts","../src/utils/fused_utils.ts","../src/kernels/Reshape.ts","../src/kernels/BatchMatMul.ts","../src/kernels/_FusedMatMul.ts","../src/kernels/Acos.ts","../src/kernels/Acosh.ts","../src/kernels/AddN.ts","../src/kernels/All.ts","../src/kernels/Any.ts","../src/kernels/ArgMax.ts","../src/kernels/ArgMin.ts","../src/kernels/Asin.ts","../src/kernels/Asinh.ts","../src/kernels/Atan.ts","../src/kernels/Atan2.ts","../src/kernels/Atanh.ts","../src/utils/pool_utils.ts","../src/kernels/AvgPool.ts","../src/kernels/AvgPool3D.ts","../src/kernels/AvgPool3DGrad.ts","../src/kernels/AvgPoolGrad.ts","../src/kernels/BatchNorm.ts","../src/kernels/BatchToSpaceND.ts","../src/kernels/Bincount.ts","../src/kernels/Clip.ts","../src/kernels/ComplexAbs.ts","../src/kernels/Imag.ts","../src/kernels/Concat.ts","../src/kernels/Conv2D.ts","../src/kernels/Conv2DBackpropFilter.ts","../src/kernels/Conv2DBackpropInput.ts","../src/kernels/Conv3D.ts","../src/kernels/Conv3DBackpropFilterV2.ts","../src/kernels/Conv3DBackpropInputV2.ts","../src/kernels/Cos.ts","../src/kernels/Cosh.ts","../src/kernels/CropAndResize.ts","../src/kernels/Cumsum.ts","../src/kernels/DenseBincount.ts","../src/kernels/DepthToSpace.ts","../src/kernels/DepthwiseConv2dNative.ts","../src/kernels/DepthwiseConv2dNativeBackpropFilter.ts","../src/kernels/DepthwiseConv2dNativeBackpropInput.ts","../src/kernels/Diag.ts","../src/kernels/Dilation2D.ts","../src/kernels/Dilation2DBackpropFilter.ts","../src/kernels/Dilation2DBackpropInput.ts","../src/kernels/Sum.ts","../src/kernels/Einsum.ts","../src/kernels/EluGrad.ts","../src/kernels/Equal.ts","../src/kernels/Erf.ts","../src/kernels/ExpandDims.ts","../src/kernels/RealDiv.ts","../src/utils/fft_utils.ts","../src/kernels/FFT.ts","../src/kernels/Fill.ts","../src/kernels/FlipLeftRight.ts","../src/kernels/FloorDiv.ts","../src/kernels/FusedConv2D.ts","../src/kernels/FusedDepthwiseConv2D.ts","../src/kernels/GatherNd.ts","../src/kernels/GatherV2.ts","../src/kernels/GreaterEqual.ts","../src/kernels/IFFT.ts","../src/kernels/IsFinite.ts","../src/kernels/IsInf.ts","../src/kernels/IsNaN.ts","../src/kernels/LessEqual.ts","../src/kernels/LinSpace.ts","../src/kernels/Log1p.ts","../src/kernels/LogicalAnd.ts","../src/kernels/LogicalNot.ts","../src/kernels/LogicalOr.ts","../src/kernels/LRN.ts","../src/kernels/LRNGrad.ts","../src/kernels/Max.ts","../src/kernels/MaxPool.ts","../src/kernels/MaxPool3D.ts","../src/kernels/MaxPool3DGrad.ts","../src/kernels/MaxPoolGrad.ts","../src/kernels/MaxPoolWithArgmax.ts","../src/kernels/MaxPoolWithArgmax_impl.ts","../src/kernels/Mean.ts","../src/kernels/Min.ts","../src/kernels/MirrorPad.ts","../src/kernels/Mod.ts","../src/kernels/Softmax.ts","../src/kernels/Multinomial.ts","../src/kernels/NonMaxSuppressionV3.ts","../src/kernels/NonMaxSuppressionV4.ts","../src/kernels/NonMaxSuppressionV5.ts","../src/kernels/OneHot.ts","../src/kernels/ZerosLike.ts","../src/kernels/OnesLike.ts","../src/kernels/Pack.ts","../src/kernels/PadV2.ts","../src/kernels/Pow.ts","../src/kernels/Range.ts","../src/kernels/Reciprocal.ts","../src/kernels/ResizeBilinear.ts","../src/kernels/ResizeBilinearGrad.ts","../src/kernels/ResizeNearestNeighbor.ts","../src/kernels/ResizeNearestNeighborGrad.ts","../src/kernels/Reverse.ts","../src/kernels/RotateWithOffset.ts","../src/kernels/Round.ts","../src/kernels/Scatter_impl.ts","../src/kernels/ScatterNd.ts","../src/kernels/Select.ts","../src/kernels/Selu.ts","../src/kernels/Sign.ts","../src/kernels/Sin.ts","../src/kernels/Sinh.ts","../src/kernels/Softplus.ts","../src/kernels/SpaceToBatchND.ts","../src/kernels/SparseFillEmptyRows.ts","../src/kernels/SparseReshape.ts","../src/kernels/SparseToDense.ts","../src/kernels/SplitV.ts","../src/kernels/Sqrt.ts","../src/kernels/Square.ts","../src/kernels/Step.ts","../src/kernels/StridedSlice.ts","../src/kernels/Tan.ts","../src/kernels/Tanh.ts","../src/kernels/Tile.ts","../src/kernels/TopK.ts","../src/kernels/Transform.ts","../src/kernels/Unique.ts","../src/kernels/Unpack.ts","../src/register_all_kernels.ts","../src/kernels/UnsortedSegmentSum.ts","../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${\n              opName} does not support complex64 tensors in the CPU backend.`);\n    }\n  });\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendTimingInfo, buffer, DataStorage, DataType, DataValues, engine, env, kernel_impls, KernelBackend, Rank, ShapeMap, Tensor, Tensor2D, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nconst whereImpl = kernel_impls.whereImpl;\nimport {assertNotComplex} from './cpu_util';\n\ninterface DataId {}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo};\n  // refCount keeps track of how many tensors reference it. Used for memory\n  // management.\n  refCount: number;\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n  private static nextDataId = 0;\n  private nextDataId(): number {\n    return MathBackendCPU.nextDataId++;\n  }\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, which binds to TensorFlow C++, by running ' +\n            'npm i @tensorflow/tfjs-node, ' +\n            'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n            'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n            'suffix for CUDA) at the start of your program. ' +\n            'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n            '\\n============================');\n      }\n    }\n    const dataId = {id: this.nextDataId()};\n\n    this.data.set(dataId, {values, dtype, refCount: 1});\n\n    return dataId;\n  }\n\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: backend_util.BackendValues|string[]): TensorInfo {\n    let outId;\n    if (dtype === 'string' && values != null && values.length > 0 &&\n        util.isString(values[0])) {\n      const encodedValues =\n          (values as {} as string[]).map(d => util.encodeString(d));\n\n      outId = this.write(encodedValues, shape, dtype);\n    } else {\n      outId = this.write(values as TypedArray, shape, dtype);\n    }\n\n    return {dataId: outId, shape, dtype};\n  }\n\n  /** Return refCount of a `TensorData`. */\n  refCount(dataId: DataId): number {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      return tensorData.refCount;\n    }\n    return 0;\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId: DataId): void {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType, refCount: number): void {\n    this.data.set(dataId, {values, dtype, refCount});\n  }\n\n  numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensorInfos} = this.data.get(dataId);\n\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n\n    return this.data.get(dataId).values;\n  }\n\n  bufferSync<R extends Rank>(t: TensorInfo): TensorBuffer<R> {\n    const data = this.readSync(t.dataId);\n    let decodedData = data as DataValues;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = (data as Uint8Array[]).map(d => util.decodeString(d));\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape as ShapeMap[R], t.dtype, decodedData) as\n        TensorBuffer<R>;\n  }\n\n  makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this) as T;\n  }\n\n  /**\n   * Dispose the memory if the dataId has 0 refCount. Return true if the memory\n   * is released or memory is not managed in this backend, false if memory is\n   * not cleared.\n   * @param dataId\n   * @oaram force Optional, remove the data regardless of refCount\n   */\n  disposeData(dataId: DataId, force = false): boolean {\n    if (this.data.has(dataId)) {\n      this.data.get(dataId).refCount--;\n      if (!force && this.data.get(dataId).refCount > 0) {\n        return false;\n      }\n\n      const {complexTensorInfos} = this.data.get(dataId);\n\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId, true);\n        this.disposeData(complexTensorInfos.imag.dataId, true);\n      }\n\n      this.data.delete(dataId);\n    }\n    return true;\n  }\n\n  disposeIntermediateTensorInfo(tensorInfo: TensorInfo): void {\n    this.disposeData(tensorInfo.dataId);\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  dispose() {}\n\n  floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return super.epsilon();\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, AbsInputs, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function simpleAbsImpl(vals: TypedArray): Float32Array {\n  const resultValues = new Float32Array(vals.length);\n  for (let i = 0; i < vals.length; ++i) {\n    resultValues[i] = Math.abs(vals[i]);\n  }\n  return resultValues;\n}\n\nexport const abs = (args: {inputs: AbsInputs, backend: MathBackendCPU}) => {\n  const {x} = args.inputs;\n  const cpuBackend = args.backend;\n\n  assertNotComplex(x, 'abs');\n\n  let resultValues = new Float32Array(util.sizeFromShape(x.shape));\n  const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n  resultValues = simpleAbsImpl(values);\n\n  return cpuBackend.makeOutput(resultValues, x.shape, 'float32');\n};\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'cpu',\n  kernelFunc: abs as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleBinaryKernelImpl, SimpleBinaryOperation} from './binary_types';\n\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nexport function createSimpleBinaryKernelImpl(op: SimpleBinaryOperation):\n    SimpleBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aVals: TypedArray,\n          bVals: TypedArray, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function complex(args: {inputs: ComplexInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const realVals = backend.data.get(real.dataId).values as TypedArray;\n  const imagVals = backend.data.get(imag.dataId).values as TypedArray;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n\n  const complex = backend.data.get(complexInfo.dataId);\n\n  // The complex tensor owns the underlying real and imag tensorInfos, only the\n  // complex tensor tracks refCount, when complexData is disposed the\n  // underlying tensorData will be disposed.\n  complex.complexTensorInfos = {\n    real: backend.makeTensorInfo(real.shape, 'float32', realVals),\n    imag: backend.makeTensorInfo(imag.shape, 'float32', imagVals)\n  };\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'cpu',\n  kernelFunc: complex as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TensorInfo, util} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {complex} from '../kernels/Complex';\n\n/**\n * Generates a tensorInfo with all zeros value.\n * @param backend cpu backend.\n * @param shape Shape for the zeros tensor.\n * @param dtype Optional. If set, the result has this dtype.\n */\nexport function zeros(\n    backend: MathBackendCPU, shape: number[],\n    dtype: DataType = 'float32'): TensorInfo {\n  if (dtype === 'complex64') {\n    const real = zeros(backend, shape, 'float32');\n    const imag = zeros(backend, shape, 'float32');\n\n    return complex({inputs: {real, imag}, backend});\n  }\n\n  const values = util.makeZerosTypedArray(util.sizeFromShape(shape), dtype);\n\n  return backend.makeTensorInfo(shape, dtype, values);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  backend.incRef(x.dataId);\n\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'cpu',\n  kernelFunc: identity as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function real(args: {inputs: RealInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const real = backend.data.get(input.dataId).complexTensorInfos.real;\n  const realVal = backend.data.get(real.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the real value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(real.shape, real.dtype, realVal);\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'cpu',\n  kernelFunc: real as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {zeros} from '../utils/zeros_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensorInfo}, backend});\n\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (dtype === 'int32') {\n    const values = backend.data.get(x.dataId).values as TypedArray;\n    const resultValues = Int32Array.from(values);\n    return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const zero = util.toTypedArray([0], x.dtype);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(x.shape, [], xVals, zero, 'bool');\n\n    return backend.makeTensorInfo(resultShape, 'bool', resultData);\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from '../kernels/Cast';\nimport {complex} from '../kernels/Complex';\n\nimport {ComplexBinaryKernelImpl, ComplexBinaryOperation, SimpleBinaryKernelImpl} from './binary_types';\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param name Kernel name.\n * @param binaryKernelImpl A `SimpleBinaryKernelImpl` for the kernel.\n * @param binaryKernelComplexImpl Optional. If exists, represents a\n *     `ComplexBinaryKernelImpl` for the kernel, will be used when input dtype\n *     is `complex64`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    name: string, simpleImpl: SimpleBinaryKernelImpl,\n    complexImpl?: ComplexBinaryKernelImpl, dtype?: DataType): KernelFunc {\n  if (complexImpl == null) {\n    return ({inputs, backend}) => {\n      const {a, b} = inputs as BinaryInputs;\n      const cpuBackend = backend as MathBackendCPU;\n\n      assertNotComplex([a, b], name);\n\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    };\n  }\n\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      const $aComplex = cast(\n          {inputs: {x: a}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);\n\n      const aReal = $aComplexVals.complexTensorInfos.real;\n      const aImag = $aComplexVals.complexTensorInfos.imag;\n\n      const aRealVals =\n          cpuBackend.data.get(aReal.dataId).values as Float32Array;\n      const aImagVals =\n          cpuBackend.data.get(aImag.dataId).values as Float32Array;\n\n      const $bComplex = cast(\n          {inputs: {x: b}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);\n\n      const bReal = $bComplexVals.complexTensorInfos.real;\n      const bImag = $bComplexVals.complexTensorInfos.imag;\n\n      const bRealVals =\n          cpuBackend.data.get(bReal.dataId).values as Float32Array;\n      const bImagVals =\n          cpuBackend.data.get(bImag.dataId).values as Float32Array;\n\n      const [resultRealData, resultImagData, resultShape] = complexImpl(\n          a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);\n\n      const resultReal =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultRealData);\n\n      const resultImag =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultImagData);\n\n      const result = complex(\n          {inputs: {real: resultReal, imag: resultImag}, backend: cpuBackend});\n\n      cpuBackend.disposeIntermediateTensorInfo($aComplex);\n      cpuBackend.disposeIntermediateTensorInfo($bComplex);\n      cpuBackend.disposeIntermediateTensorInfo(resultReal);\n      cpuBackend.disposeIntermediateTensorInfo(resultImag);\n\n      return result;\n    } else {\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    }\n  };\n}\n\n/**\n * Template that creates the complex type implementation for binary ops.\n * Supports broadcast.\n */\nexport function createComplexBinaryKernelImpl(op: ComplexBinaryOperation):\n    ComplexBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aRealVals: Float32Array,\n          aImagVals: Float32Array, bRealVals: Float32Array,\n          bImagVals: Float32Array): [TypedArray, TypedArray, number[]] => {\n    const resultShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    const resultSize = util.sizeFromShape(resultShape);\n    const resultRank = resultShape.length;\n    const resultStrides = util.computeStrides(resultShape);\n\n    const resultRealVals = util.getTypedArrayFromDType('float32', resultSize);\n    const resultImagVals = util.getTypedArrayFromDType('float32', resultSize);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, resultShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, resultShape);\n\n    const aVals = backend_util.mergeRealAndImagArrays(aRealVals, aImagVals);\n    const bVals = backend_util.mergeRealAndImagArrays(bRealVals, bImagVals);\n\n    const aRank = aShape.length;\n    const aStrides = util.computeStrides(aShape);\n\n    const bRank = bShape.length;\n    const bStrides = util.computeStrides(bShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const aIdx = i % aVals.length;\n        const bIdx = i % bVals.length;\n\n        const result =\n            op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2],\n               bVals[bIdx * 2 + 1]);\n\n        resultRealVals[i] = result.real;\n        resultImagVals[i] = result.imag;\n      }\n    } else {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        const opResult =\n            op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2],\n               bVals[bIndex * 2 + 1]);\n\n        resultRealVals[i] = opResult.real;\n        resultImagVals[i] = opResult.imag;\n      }\n    }\n    return [resultRealVals, resultImagVals, resultShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const addImpl = createSimpleBinaryKernelImpl(((a, b) => a + b));\nexport const addComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal + bReal, imag: aImag + bImag};\n    }));\n\nexport const add = binaryKernelFunc(Add, addImpl, addComplexImpl);\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'cpu',\n  kernelFunc: add\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function bincountImpl(\n    xVals: TypedArray, weightsVals: TypedArray, weightsDtype: DataType,\n    weightsShape: number[], size: number): TypedArray {\n  const weightsSize = util.sizeFromShape(weightsShape);\n  const outVals = util.makeZerosTypedArray(size, weightsDtype) as TypedArray;\n\n  for (let i = 0; i < xVals.length; i++) {\n    const value = xVals[i];\n    if (value < 0) {\n      throw new Error('Input x must be non-negative!');\n    }\n\n    if (value >= size) {\n      continue;\n    }\n\n    if (weightsSize > 0) {\n      outVals[value] += weightsVals[i];\n    } else {\n      outVals[value] += 1;\n    }\n  }\n\n  return outVals;\n}\n\nexport function bincountReduceImpl<R extends Rank>(\n    xBuf: TensorBuffer<R>, weightsBuf: TensorBuffer<R>, size: number,\n    binaryOutput = false): TensorBuffer<R> {\n  const numRows = xBuf.shape[0];\n  const numCols = xBuf.shape[1];\n\n  const outBuf = buffer([numRows, size], weightsBuf.dtype);\n\n  for (let i = 0; i < numRows; i++) {\n    for (let j = 0; j < numCols; j++) {\n      const value = xBuf.get(i, j);\n      if (value < 0) {\n        throw new Error('Input x must be non-negative!');\n      }\n\n      if (value >= size) {\n        continue;\n      }\n\n      if (binaryOutput) {\n        outBuf.set(1, i, value);\n      } else {\n        if (weightsBuf.size > 0) {\n          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);\n        } else {\n          outBuf.set(outBuf.get(i, value) + 1, i, value);\n        }\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumericDataType, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates implementation for unary op.\n */\nexport function createSimpleUnaryImpl(op: SimpleUnaryOperation):\n    SimpleUnaryImpl {\n  return (values, dtype, attrs) => {\n    const newValues =\n        util.getTypedArrayFromDType(dtype as NumericDataType, values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return newValues;\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelFunc, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param name Kernel name.\n * @param op A `SimpleUnaryOperation` for the kernel.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFunc(\n    name: string, op: SimpleUnaryOperation, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xSize = util.sizeFromShape(x.shape);\n    const $dtype = dtype || x.dtype;\n    const newValues = util.getArrayFromDType($dtype, xSize);\n    for (let i = 0; i < xSize; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n\n/**\n * Template that creates a `KernelFunc` for unary ops from the given\n * `SimpleUnaryImpl`..\n * @param name Kernel name.\n * @param unaryImpl A `SimpleUnaryImpl` that implements the op.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFuncFromImpl(\n    name: string, unaryImpl: SimpleUnaryImpl, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const $dtype = dtype || x.dtype;\n    const newValues = unaryImpl(values, $dtype, attrs);\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));\nexport const ceil = unaryKernelFuncFromImpl(Ceil, ceilImpl);\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'cpu',\n  kernelFunc: ceil,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function concatImpl(\n    inputs: Array<{vals: BackendValues, shape: number[]}>, outShape: number[],\n    dtype: DataType, simplyConcat: boolean): TypedArray|string[] {\n  const outVals = util.getArrayFromDType(dtype, util.sizeFromShape(outShape));\n\n  if (simplyConcat && dtype !== 'string') {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs.forEach(input => {\n      const size = util.sizeFromShape(input.shape);\n\n      (outVals as TypedArray).set(input.vals as TypedArray, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs.forEach(input => {\n      const decodedData = dtype === 'string' ?\n          backend_util.fromUint8ToStringArray(input.vals as Uint8Array[]) :\n          input.vals as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < input.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < input.shape[1]; ++col) {\n          outVals[resIdx + col] = decodedData[tIdx++];\n        }\n      }\n\n      colOffset += input.shape[1];\n    });\n  }\n\n  return outVals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));\nexport const exp = unaryKernelFuncFromImpl(Exp, expImpl);\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'cpu',\n  kernelFunc: exp,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));\nexport const expm1 = unaryKernelFuncFromImpl(Expm1, expm1Impl);\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'cpu',\n  kernelFunc: expm1,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));\nexport const floor = unaryKernelFuncFromImpl(Floor, floorImpl);\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'cpu',\n  kernelFunc: floor,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function gatherV2Impl<R extends Rank, D extends DataType>(\n    xBuf: TensorBuffer<R, D>, indicesBuf: TensorBuffer<R, D>,\n    flattenOutputShape: number[]): TensorBuffer<R, D> {\n  const outBuf = buffer(flattenOutputShape, xBuf.dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const newLoc = outBuf.indexToLoc(i);\n\n    const originalLoc: number[] = newLoc.slice();\n    const batchIdx = originalLoc[0];\n    const indicesIdx = originalLoc[2];\n    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);\n    originalLoc[2] = indicesBuf.values[indicesIndex] as number;\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n    outBuf.values[i] = xBuf.values[originalIndex];\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a > b) ? 1 : 0);\nexport const greater =\n    binaryKernelFunc(Greater, greaterImpl, null /* complexImpl */, 'bool');\n\nexport const greaterConfig: KernelConfig = {\n  kernelName: Greater,\n  backendName: 'cpu',\n  kernelFunc: greater\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a < b) ? 1 : 0);\nexport const less =\n    binaryKernelFunc(Less, lessImpl, null /* complexImpl */, 'bool');\n\nexport const lessConfig: KernelConfig = {\n  kernelName: Less,\n  backendName: 'cpu',\n  kernelFunc: less\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function linSpaceImpl(\n    start: number, stop: number, num: number): TypedArray {\n  const step = (stop - start) / (num - 1);\n\n  const values = util.makeZerosTypedArray(num, 'float32');\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));\nexport const log = unaryKernelFuncFromImpl(Log, logImpl);\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'cpu',\n  kernelFunc: log,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const maximumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.max(aValue, bValue)));\nexport const maximum = binaryKernelFunc(Maximum, maximumImpl);\n\nexport const maximumConfig: KernelConfig = {\n  kernelName: Maximum,\n  backendName: 'cpu',\n  kernelFunc: maximum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const minimumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.min(aValue, bValue)));\nexport const minimum = binaryKernelFunc(Minimum, minimumImpl);\n\nexport const minimumConfig: KernelConfig = {\n  kernelName: Minimum,\n  backendName: 'cpu',\n  kernelFunc: minimum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const multiplyImpl =\n    createSimpleBinaryKernelImpl(((aValue, bValue) => aValue * bValue));\nexport const multiplyComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n      };\n    }));\n\nexport const multiply =\n    binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'cpu',\n  kernelFunc: multiply\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, KernelFunc, Neg, TensorInfo, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {multiplyImpl} from './Multiply';\n\nexport function negImpl(xVals: TypedArray, xShape: number[], xDtype: DataType):\n    [TypedArray, number[]] {\n  const minusOne =\n      util.createScalarValue(-1 as {} as 'float32', xDtype) as TypedArray;\n  return multiplyImpl([], xShape, minusOne, xVals, xDtype);\n}\n\nexport function neg(args: {inputs: UnaryInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  assertNotComplex(x, 'neg');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const [res, newShape] = negImpl(xVals, x.shape, x.dtype);\n\n  return backend.makeTensorInfo(newShape, x.dtype, res);\n}\n\nexport const negConfig: KernelConfig = {\n  kernelName: Neg,\n  backendName: 'cpu',\n  kernelFunc: neg as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const notEqualImpl =\n    createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));\nexport const notEqual =\n    binaryKernelFunc(NotEqual, notEqualImpl, null /* complexOp */, 'bool');\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'cpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transpose, TransposeAttrs, TransposeInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n\n  assertNotComplex(x, 'transpose');\n\n  const xRank = x.shape.length;\n\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n\n  const dataId = backend.write(result, newShape, x.dtype);\n  return {dataId, shape: newShape, dtype: x.dtype};\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'cpu',\n  kernelFunc: transpose as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function prodImpl(\n    xShape: number[], xDtype: DataType, xVals: TypedArray,\n    reductionAxes: number[]):\n    {outVals: TypedArray, outShape: number[], outDtype: DataType} {\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, reductionAxes);\n  const outDtype = upcastType(xDtype, 'int32');\n  const outVals = util.makeZerosTypedArray(\n                      util.sizeFromShape(outShape), outDtype) as TypedArray;\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  for (let i = 0; i < outVals.length; ++i) {\n    const offset = i * reduceSize;\n    let prod = 1;\n    for (let j = 0; j < reduceSize; ++j) {\n      prod *= xVals[offset + j];\n    }\n    outVals[i] = prod;\n  }\n\n  return {outVals, outShape, outDtype};\n}\n\nexport function prod(\n    args: {inputs: ProdInputs, backend: MathBackendCPU, attrs: ProdAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'prod');\n\n  const xRank = x.shape.length;\n  const axes = util.parseAxisParam(axis, x.shape);\n\n  const permutation = backend_util.getAxesPermutation(axes, xRank);\n  let reductionAxes = axes;\n  let permutedX = x;\n  const intermediateTensorInfos = [];\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n    intermediateTensorInfos.push(permutedX);\n    reductionAxes = backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n  }\n\n  const xVals = backend.data.get(permutedX.dataId).values as TypedArray;\n  const {outVals, outShape, outDtype} =\n      prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);\n\n  let resultShape = outShape;\n  if (keepDims) {\n    resultShape = backend_util.expandShapeToKeepDim(outShape, axes);\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(resultShape, outDtype, outVals);\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'cpu',\n  kernelFunc: prod as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataTypeMap, util} from '@tensorflow/tfjs-core';\n\nexport function rangeImpl(\n    start: number, stop: number, step: number,\n    dtype: 'float32'|'int32'): DataTypeMap['float32' | 'int32'] {\n  const sameStartStop = start === stop;\n  const increasingRangeNegativeStep = start < stop && step < 0;\n  const decreasingRangePositiveStep = stop < start && step > 1;\n\n  if (sameStartStop || increasingRangeNegativeStep ||\n      decreasingRangePositiveStep) {\n    return util.makeZerosTypedArray(0, dtype);\n  }\n\n  const numElements = Math.abs(Math.ceil((stop - start) / step));\n  const values = util.makeZerosTypedArray(numElements, dtype);\n\n  if (stop < start && step === 1) {\n    // Auto adjust the step's sign if it hasn't been set\n    // (or was set to 1)\n    step = -1;\n  }\n\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));\nexport const rsqrt = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'cpu',\n  kernelFunc: rsqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, buffer, DataType, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: BackendValues, begin: number[], size: number[], shape: number[],\n    dtype: DataType): BackendValues {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n\n    if (dtype === 'string') {\n      return (vals as Uint8Array[]).slice(flatOffset, flatOffset + length);\n    }\n\n    return (vals as TypedArray).subarray(flatOffset, flatOffset + length);\n  }\n\n  const decodedData = dtype === 'string' ?\n      backend_util.fromUint8ToStringArray(vals as Uint8Array[]) :\n      vals as TypedArray;\n\n  const inBuf = buffer(shape, dtype, decodedData);\n  const outBuf = buffer(size, dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.map((idx: number, j) => idx + begin[j]);\n    outBuf.set(inBuf.get(...inLoc), ...outLoc);\n  }\n\n  if (dtype === 'string') {\n    return backend_util.fromStringArrayToUint8(outBuf.values as string[]);\n  }\n  return outBuf.values as TypedArray;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseFillEmptyRowsImpl(\n    indices: TypedArray, indicesShape: number[], indicesDType: DataType,\n    values: TypedArray, valuesDType: DataType, denseShape: TypedArray,\n    defaultValue: number):\n    [TypedArray, number[], TypedArray, boolean[], number[]] {\n  const indicesCount = indicesShape[0];\n  const denseRows = denseShape[0];\n\n  const emptyRowIndicator: boolean[] = new Array(denseRows);\n  const reverseIndexMap: number[] = new Array(indicesCount);\n\n  const rank = indicesShape[1];\n\n  if (denseRows === 0) {\n    if (indicesCount !== 0) {\n      throw new Error(`Received SparseTensor with denseShape[0] = 0 but\n         indices.shape[0] = ${indicesCount}`);\n    }\n    const outputIndices = util.getArrayFromDType(indicesDType, 0) as TypedArray;\n    const outputValues = util.getArrayFromDType(valuesDType, 0) as TypedArray;\n    return [\n      outputIndices, [0, rank], outputValues, emptyRowIndicator, reverseIndexMap\n    ];\n  }\n\n  let rowsAreOrdered = true;\n  let lastIndicesRow = 0;\n  const csrOffset: number[] = new Array(denseRows).fill(0);\n\n  for (let i = 0; i < indicesCount; ++i) {\n    // indices is a 2d tensor with shape of [N, rank]\n    const row = indices[i * rank];\n    if (row < 0) {\n      throw new Error(`indices(${i}, 0) is invalid: ${row} < 0`);\n    }\n    if (row >= denseRows) {\n      throw new Error(`indices(${i}, 0) is invalid: ${row} >= ${denseRows}`);\n    }\n    ++csrOffset[row];\n    rowsAreOrdered = rowsAreOrdered && (row >= lastIndicesRow);\n    lastIndicesRow = row;\n  }\n\n  let allRowsFull = true;\n  for (let row = 0; row < denseRows; ++row) {\n    // csrOffset here describes the number of elements in this dense row\n    const rowEmpty = (csrOffset[row] === 0);\n    emptyRowIndicator[row] = rowEmpty;\n    allRowsFull = allRowsFull && !rowEmpty;\n    // In filled version, each row has at least one element.\n    csrOffset[row] = Math.max(csrOffset[row], 1);\n    // Update csrOffset to represent the number of elements up to and\n    // including denseRows + 1:\n    //  csrOffset[0] == #{elements of row 0}\n    //  csrOffset[1] == #{elements of row 1} + #{elements of row 0}\n    //  ..\n    //  csrOffset[i] == starting index for elements in row i + 1.\n    if (row > 0) {\n      csrOffset[row] += csrOffset[row - 1];\n    }\n  }\n\n  if (allRowsFull && rowsAreOrdered) {\n    const outputIndices: TypedArray = indices;\n    const outputValues: TypedArray = values;\n    for (let i = 0; i < indicesCount; ++i) {\n      reverseIndexMap[i] = i;\n    }\n    return [\n      outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  } else {\n    const fullIndicesCount = csrOffset[denseRows - 1];\n    const outputIndices =\n        util.getArrayFromDType(indicesDType, fullIndicesCount * rank) as\n        TypedArray;\n    const outputValues =\n        util.getArrayFromDType(valuesDType, fullIndicesCount) as TypedArray;\n    const filledCount: number[] = new Array(denseRows).fill(0);\n\n    // Fill in values for rows that are not missing\n    for (let i = 0; i < indicesCount; ++i) {\n      // indices is a 2d tensor with shape of [N, rank]\n      const row = indices[i * rank];\n      const offset = filledCount[row];\n      const outputI = ((row === 0) ? 0 : csrOffset[row - 1]) + offset;\n      filledCount[row]++;  // Increment the filled count for this row.\n      for (let j = 0; j < rank; ++j) {\n        // indices and outputIndices are 2d tensors with shape of [N, rank]\n        outputIndices[outputI * rank + j] = indices[i * rank + j];\n      }\n      outputValues[outputI] = values[i];\n      // We'll need this reverse index map to backprop correctly.\n      reverseIndexMap[i] = outputI;\n    }\n\n    // Fill in values for rows that are missing\n    for (let row = 0; row < denseRows; ++row) {\n      const rowCount = filledCount[row];\n      if (rowCount === 0) {  // We haven't filled this row\n        const startingIndex = (row === 0) ? 0 : csrOffset[row - 1];\n        // Remaining index values were set to zero already.\n        // Just need to set the row index in the right location.\n        // outputIndices is a 2d tensor with shape of [N, rank]\n        outputIndices[startingIndex * rank + 0] = row;\n        for (let col = 1; col < rank; ++col) {\n          outputIndices[startingIndex * rank + col] = 0;\n        }\n        outputValues[startingIndex] = defaultValue;\n      }\n    }\n    return [\n      outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseReshapeImpl(\n    inputIndices: TypedArray, inputIndicesShape: number[], inputDType: DataType,\n    inputShape: number[],\n    targetShape: number[]): [TypedArray, number[], number[]] {\n  const denseSize = util.sizeFromShape(inputShape);\n  const nnz = inputIndicesShape[0];\n  const outputRank = targetShape.length;\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  const outputShape: number[] = [];\n  let product = 1;\n  let unknownIndex = -1;\n  for (let d = 0; d < outputRank; ++d) {\n    const size = targetShape[d];\n    if (size === -1) {\n      if (unknownIndex !== -1) {\n        throw new Error(`only one output dimension may be -1, not both ${\n            unknownIndex} and ${d}`);\n      }\n      unknownIndex = d;\n      outputShape.push(1);\n    } else {\n      if (size < 0) {\n        throw new Error(`size ${d} must be non-negative, not ${size}`);\n      }\n      product *= size;\n      outputShape.push(size);\n    }\n  }\n  if (unknownIndex !== -1) {\n    if (product <= 0) {\n      throw new Error(\n          'reshape cannot infer the missing ' +\n          'input size for an empty tensor unless all ' +\n          'specified input sizes are non-zero');\n    }\n    const missing = Math.trunc(denseSize / product);\n    if (product * missing !== denseSize) {\n      throw new Error(`Input to reshape is a SparseTensor with ${denseSize}\n          dense values, but the requested shape requires a multiple of ${\n          product}. inputShape=${inputShape} outputShape= ${outputShape}`);\n    }\n\n    outputShape[unknownIndex] = missing;\n  }\n  const outputSize = util.sizeFromShape(outputShape);\n  if (outputSize !== denseSize) {\n    throw new Error(`Input to reshape is a tensor with ${\n        denseSize} dense values, but the requested shape has ${\n        outputSize}. inputShape=${inputShape} outputShape=${outputShape}`);\n  }\n\n  const inputRank = inputShape.length;\n  const inputStrides: number[] = [];\n  if (inputRank > 0) {\n    inputStrides[inputRank - 1] = 1;\n    for (let d = inputRank - 2; d >= 0; --d) {\n      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];\n    }\n  }\n\n  const outputStrides: number[] = [];\n  if (outputRank > 0) {\n    outputStrides[outputRank - 1] = 1;\n    for (let d = outputRank - 2; d >= 0; --d) {\n      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];\n    }\n  }\n\n  const newIndices =\n      util.getArrayFromDType(inputDType, nnz * outputRank) as TypedArray;\n  for (let i = 0; i < nnz; ++i) {\n    let id = 0;\n    for (let j = 0; j < inputRank; ++j) {\n      // inputIndices is a 2d tensor with shape of [nnz, inputRank]\n      id += inputIndices[i * inputRank + j] * inputStrides[j];\n    }\n    for (let j = 0; j < outputRank; ++j) {\n      // newIndices is a 2d tensor with shape of [nnz, outputRank]\n      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);\n      id %= outputStrides[j];\n    }\n  }\n  return [newIndices, [nnz, outputRank], outputShape];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const squaredDifferenceImpl = createSimpleBinaryKernelImpl(((a, b) => {\n  const diff = a - b;\n  return diff * diff;\n}));\nexport const squaredDifference =\n    binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'cpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function stridedSliceImpl<R extends Rank>(\n    outShape: number[], xBuf: TensorBuffer<R>, strides: number[],\n    begin: number[]): TensorBuffer<R> {\n  const outBuf = buffer(outShape, xBuf.dtype);\n\n  for (let i = 0; i < outBuf.size; i++) {\n    const loc = outBuf.indexToLoc(i);\n\n    const newLoc: number[] = new Array(loc.length);\n    for (let j = 0; j < newLoc.length; j++) {\n      newLoc[j] = loc[j] * strides[j] + begin[j];\n    }\n    outBuf.set(xBuf.get(...newLoc), ...loc);\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const subImpl =\n    createSimpleBinaryKernelImpl(((aValue, bValue) => aValue - bValue));\nexport const subComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal - bReal, imag: aImag - bImag};\n    }));\nexport const sub = binaryKernelFunc(Sub, subImpl, subComplexImpl);\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'cpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\n/**\n * An implementation of the tile kernel shared between webgl and cpu for string\n * tensors only.\n */\n\nexport function tileImpl<R extends Rank>(\n    xBuf: TensorBuffer<R, DataType>,\n    reps: number[]): TensorBuffer<R, DataType> {\n  const newShape: number[] = new Array(xBuf.rank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = xBuf.shape[i] * reps[i];\n  }\n  const result = buffer(newShape, xBuf.dtype);\n  for (let i = 0; i < result.values.length; ++i) {\n    const newLoc = result.indexToLoc(i);\n\n    const originalLoc: number[] = new Array(xBuf.rank);\n    for (let j = 0; j < originalLoc.length; j++) {\n      originalLoc[j] = newLoc[j] % xBuf.shape[j];\n    }\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    result.values[i] = xBuf.values[originalIndex];\n  }\n  return result as TensorBuffer<R, DataType>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/** An implementation of the TopK kernel shared between webgl and cpu. */\n\nimport {buffer, NumericDataType, Rank, ShapeMap, Tensor, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function topKImpl<T extends Tensor, R extends Rank>(\n    x: TypedArray, xShape: number[], xDtype: NumericDataType, k: number,\n    sorted: boolean):\n    [TensorBuffer<R, NumericDataType>, TensorBuffer<R, 'int32'>] {\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const lastDim = xShape[xShape.length - 1];\n  const [batch, size] = [x.length / lastDim, lastDim];\n  const allTopKVals = util.getTypedArrayFromDType(xDtype, batch * k);\n  const allTopKIndices = util.getTypedArrayFromDType('int32', batch * k);\n\n  for (let b = 0; b < batch; b++) {\n    const offset = b * size;\n    const vals = x.subarray(offset, offset + size);\n    const valAndInd: Array<{value: number, index: number}> = [];\n    for (let i = 0; i < vals.length; i++) {\n      valAndInd.push({value: vals[i], index: i});\n    }\n    valAndInd.sort((a, b) => b.value - a.value);\n\n    const outOffset = b * k;\n    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);\n    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);\n    for (let i = 0; i < k; i++) {\n      topKVals[i] = valAndInd[i].value;\n      topKIndices[i] = valAndInd[i].index;\n    }\n  }\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const outputShape = xShape.slice();\n  outputShape[outputShape.length - 1] = k;\n\n  return [\n    buffer(outputShape as ShapeMap[R], xDtype, allTopKVals),\n    buffer(outputShape as ShapeMap[R], 'int32', allTopKIndices)\n  ];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements: {[key: string]: number} = {};\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    if (uniqueElements[element] !== undefined) {\n      indices[i] = uniqueElements[element];\n    } else {\n      const uniqueIndex = Object.keys(uniqueElements).length;\n      uniqueElements[element] = uniqueIndex;\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = Object.keys(uniqueElements).length;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/*\n * base.ts contains all the exports from tfjs-backend-cpu\n * without auto-kernel registration\n */\nimport {registerBackend} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from './backend_cpu';\nimport * as shared from './shared';\n\nexport {MathBackendCPU} from './backend_cpu';\nexport {version as version_cpu} from './version';\nexport {shared};\n\n// Side effects for default initialization of MathBackendCPU\nregisterBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const elu =\n    unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : (Math.exp(xi) - 1));\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'cpu',\n  kernelFunc: elu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LeakyRelu, LeakyReluAttrs, LeakyReluInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function leakyRelu(args: {\n  inputs: LeakyReluInputs,\n  backend: MathBackendCPU,\n  attrs: LeakyReluAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {alpha} = attrs;\n\n  assertNotComplex([x], 'leakyRelu');\n\n  const xSize = util.sizeFromShape(x.shape);\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const outVals = util.getTypedArrayFromDType('float32', xSize);\n\n  for (let i = 0; i < xVals.length; i++) {\n    outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];\n  }\n\n  return backend.makeTensorInfo(x.shape, 'float32', outVals);\n}\n\nexport const leakyReluConfig: KernelConfig = {\n  kernelName: LeakyRelu,\n  backendName: 'cpu',\n  kernelFunc: leakyRelu as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Prelu, PreluInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\n\nconst preluImpl = createSimpleBinaryKernelImpl(\n    (xValue: number, aValue: number) => xValue < 0 ? aValue * xValue : xValue);\n\nexport function prelu(args: {inputs: PreluInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x, alpha} = inputs;\n\n  assertNotComplex([x, alpha], 'prelu');\n\n  const aVals = backend.data.get(x.dataId).values as TypedArray;\n  const bVals = backend.data.get(alpha.dataId).values as TypedArray;\n\n  const [resultData, resultShape] =\n      preluImpl(x.shape, alpha.shape, aVals, bVals, x.dtype);\n\n  return backend.makeTensorInfo(resultShape, x.dtype, resultData);\n}\n\nexport const preluConfig: KernelConfig = {\n  kernelName: Prelu,\n  backendName: 'cpu',\n  kernelFunc: prelu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const relu = unaryKernelFunc(Relu, (xi) => Math.max(0, xi));\n\nexport const reluConfig: KernelConfig = {\n  kernelName: Relu,\n  backendName: 'cpu',\n  kernelFunc: relu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu6} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const relu6 =\n    unaryKernelFunc(Relu6, (xi) => Math.min(Math.max(0, xi), 6));\n\nexport const relu6Config: KernelConfig = {\n  kernelName: Relu6,\n  backendName: 'cpu',\n  kernelFunc: relu6,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sigmoid =\n    unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'cpu',\n  kernelFunc: sigmoid,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {elu} from '../kernels/Elu';\nimport {identity} from '../kernels/Identity';\nimport {leakyRelu} from '../kernels/LeakyRelu';\nimport {prelu} from '../kernels/Prelu';\nimport {relu} from '../kernels/Relu';\nimport {relu6} from '../kernels/Relu6';\nimport {sigmoid} from '../kernels/Sigmoid';\n\nexport function applyActivation(\n    backend: MathBackendCPU, x: TensorInfo, activation: backend_util.Activation,\n    preluActivationWeights?: TensorInfo, leakyreluAlpha?: number): TensorInfo {\n  if (activation === 'linear') {\n    return identity({inputs: {x}, backend});\n  } else if (activation === 'relu') {\n    return relu({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'elu') {\n    return elu({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'relu6') {\n    return relu6({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'prelu') {\n    return prelu({inputs: {x, alpha: preluActivationWeights}, backend});\n  } else if (activation === 'leakyrelu') {\n    return leakyRelu({inputs: {x}, backend, attrs: {alpha: leakyreluAlpha}});\n  } else if (activation === 'sigmoid') {\n    return sigmoid({inputs: {x}, backend}) as TensorInfo;\n  }\n  throw new Error(\n      `Activation ${activation} has not been implemented for the CPU backend.`);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function reshape(\n    args:\n        {inputs: ReshapeInputs, backend: MathBackendCPU, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  backend.incRef(x.dataId);\n\n  const xData = backend.data.get(x.dataId);\n\n  if (xData.complexTensorInfos != null) {\n    const real = xData.complexTensorInfos.real;\n    const imag = xData.complexTensorInfos.imag;\n\n    real.shape = $shape;\n    imag.shape = $shape;\n  }\n\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'cpu',\n  kernelFunc: reshape as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, buffer, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {reshape} from './Reshape';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  assertNotComplex([a, b], 'matMul');\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const batchDimsCompatible =\n      batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;\n\n  util.assert(\n      aRank >= 2 && bRank >= 2 && batchDimsCompatible,\n      () => `Error in matMul: the input batch dimensions must either be the ` +\n          `same or at least one input batch dimension must be 1. Got input ` +\n          `batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);\n\n  const outShapeOuterDims =\n      batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const a3dValues = backend.data.get(a3d.dataId).values as TypedArray;\n  const b3dValues = backend.data.get(b3d.dataId).values as TypedArray;\n\n  const a3dStrides = util.computeStrides(a3d.shape);\n  const b3dStrides = util.computeStrides(b3d.shape);\n\n  const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n      [a3dStrides[0], 1, a3dStrides[1]] :\n      [a3dStrides[0], a3dStrides[1], 1];\n  const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n      [1, b3dStrides[1], b3dStrides[0]] :\n      [b3dStrides[1], 1, b3dStrides[0]];\n\n  const size = leftDim * rightDim;\n  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n\n  const resVals = result.values as TypedArray;\n  const blockSize = backend.blockSize;\n\n  for (let bi = 0; bi < batchDim; bi++) {\n    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n        for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          // for when blockSize doesn't evenly divide the input\n          const iBlock = Math.min(i0 + blockSize, leftDim);\n          const jBlock = Math.min(j0 + blockSize, rightDim);\n          const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n          for (let i = i0; i < iBlock; i++) {\n            for (let j = j0; j < jBlock; j++) {\n              let sum = 0.0;\n\n              for (let k = k0; k < kBlock; k++) {\n                const batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;\n                const batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;\n                const aVal =\n                    a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];\n                const bVal =\n                    b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];\n                sum += aVal * bVal;\n              }\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d);\n\n  // set correct shape on output.\n  return backend.makeTensorInfo(\n      outShape, result.dtype, result.values as TypedArray);\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\n\nimport {add} from './Add';\nimport {batchMatMul} from './BatchMatMul';\n\nexport function _fusedMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  attrs: _FusedMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n  const {transposeA, transposeB, activation, leakyreluAlpha} = attrs;\n\n  let current;\n  let addRes;\n  let activationRes;\n\n  const intermediates: TensorInfo[] = [];\n\n  const matMulRes =\n      batchMatMul({inputs: {a, b}, attrs: {transposeA, transposeB}, backend});\n  current = matMulRes;\n\n  if (bias) {\n    addRes = add({inputs: {a: current, b: bias}, backend}) as TensorInfo;\n    intermediates.push(current);\n    current = addRes;\n  }\n  if (activation) {\n    activationRes = applyActivation(\n        backend, current, activation, preluActivationWeights, leakyreluAlpha);\n    intermediates.push(current);\n    current = activationRes;\n  }\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return current;\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'cpu',\n  kernelFunc: _fusedMatMul as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acos = unaryKernelFunc(Acos, (xi) => Math.acos(xi));\n\nexport const acosConfig: KernelConfig = {\n  kernelName: Acos,\n  backendName: 'cpu',\n  kernelFunc: acos,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acosh = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));\n\nexport const acoshConfig: KernelConfig = {\n  kernelName: Acosh,\n  backendName: 'cpu',\n  kernelFunc: acosh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AddN, AddNInputs, buffer, KernelConfig, KernelFunc, Tensor, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function addN(args: {inputs: AddNInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const tensors = inputs as Tensor[];\n\n  assertNotComplex(inputs, 'addN');\n\n  const vals =\n      tensors.map(t => backend.data.get(t.dataId).values as TypedArray);\n  const outBuf = buffer(tensors[0].shape, tensors[0].dtype as 'float32');\n  const outVals = outBuf.values;\n  for (let i = 0; i < tensors.length; i++) {\n    const currVals = vals[i];\n    for (let j = 0; j < outVals.length; j++) {\n      outVals[j] += currVals[j];\n    }\n  }\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const addNConfig: KernelConfig = {\n  kernelName: AddN,\n  backendName: 'cpu',\n  kernelFunc: addN as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {All, AllAttrs, AllInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function all(\n    args: {inputs: AllInputs, backend: MathBackendCPU, attrs: AllAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'all');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('all', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let all = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      all = all && value;\n    }\n    vals[i] = all;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const allConfig: KernelConfig = {\n  kernelName: All,\n  backendName: 'cpu',\n  kernelFunc: all as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Any, AnyAttrs, AnyInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function any(\n    args: {inputs: AnyInputs, backend: MathBackendCPU, attrs: AnyAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'any');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('any', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let anyVal = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      anyVal = anyVal || value;\n    }\n    vals[i] = anyVal;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const anyConfig: KernelConfig = {\n  kernelName: Any,\n  backendName: 'cpu',\n  kernelFunc: any as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMax, ArgMaxAttrs, ArgMaxInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function argMax(\n    args: {inputs: ArgMaxInputs, backend: MathBackendCPU, attrs: ArgMaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  assertNotComplex(x, 'argMax');\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  axes = [axes[0]];\n  backend_util.assertAxesAreInnerMostDims('argMax', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n\n  const outSize = util.sizeFromShape(outShape);\n  const vals = util.makeZerosTypedArray(outSize, 'int32');\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    let maxIndex = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n        maxIndex = j;\n      }\n    }\n    vals[i] = maxIndex;\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(outShape, 'int32', vals);\n}\n\nexport const argMaxConfig: KernelConfig = {\n  kernelName: ArgMax,\n  backendName: 'cpu',\n  kernelFunc: argMax as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMin, ArgMinAttrs, ArgMinInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function argMin(\n    args: {inputs: ArgMinInputs, backend: MathBackendCPU, attrs: ArgMinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  assertNotComplex(x, 'argMin');\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  axes = [axes[0]];\n  backend_util.assertAxesAreInnerMostDims('argMin', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n\n  const outSize = util.sizeFromShape(outShape);\n  const vals = util.makeZerosTypedArray(outSize, 'int32');\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let min = aVals[offset];\n    let minIndex = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value < min) {\n        min = value;\n        minIndex = j;\n      }\n    }\n    vals[i] = minIndex;\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(outShape, 'int32', vals);\n}\n\nexport const argMinConfig: KernelConfig = {\n  kernelName: ArgMin,\n  backendName: 'cpu',\n  kernelFunc: argMin as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asin = unaryKernelFunc(Asin, (xi) => Math.asin(xi));\n\nexport const asinConfig: KernelConfig = {\n  kernelName: Asin,\n  backendName: 'cpu',\n  kernelFunc: asin,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asinh = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));\n\nexport const asinhConfig: KernelConfig = {\n  kernelName: Asinh,\n  backendName: 'cpu',\n  kernelFunc: asinh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atan = unaryKernelFunc(Atan, (xi) => Math.atan(xi));\n\nexport const atanConfig: KernelConfig = {\n  kernelName: Atan,\n  backendName: 'cpu',\n  kernelFunc: atan,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan2, KernelConfig} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const atan2Impl = createSimpleBinaryKernelImpl(\n    (aValue, bValue) => Math.atan2(aValue, bValue));\n\nexport const atan2 = binaryKernelFunc(Atan2, atan2Impl);\n\nexport const atan2Config: KernelConfig = {\n  kernelName: Atan2,\n  backendName: 'cpu',\n  kernelFunc: atan2,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atanh = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));\n\nexport const atanhConfig: KernelConfig = {\n  kernelName: Atanh,\n  backendName: 'cpu',\n  kernelFunc: atanh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function pool(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv2DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides =\n      convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n  const outputColStrides = convInfo.outShape[3];\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const outputBatchOffset = b * outputBatchStrides;\n    const inputBatchOffset = b * strides[0];\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          const xCMin = Math.max(0, xCCorner);\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let minMaxValue = initialValue;\n          let avgValue = 0;\n          let count = 0;\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const xROffset = inputBatchOffset + xR * strides[1];\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const xCOffset = xROffset + xC * strides[2];\n              const pixel = xValues[xCOffset + d];\n              if ((poolType === 'max' && pixel > minMaxValue)) {\n                minMaxValue = pixel;\n              } else if (poolType === 'avg') {\n                avgValue += pixel;\n                count++;\n              }\n            }\n            if (isNaN(minMaxValue)) {\n              break;\n            }\n          }\n          const outputOffset = outputRowOffset + yC * outputColStrides + d;\n          outputVals[outputOffset] =\n              poolType === 'avg' ? avgValue / count : minMaxValue;\n        }\n      }\n    }\n  }\n  return output;\n}\n\nexport function maxPoolPositions(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    convInfo: backend_util.Conv2DInfo, flattenPositions = false,\n    includeBatchInIndex = false): TensorBuffer<Rank, 'int32'> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const xBuf = buffer(xShape, dtype, xValues);\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        let xRMin = xRCorner;\n        while (xRMin < 0) {\n          xRMin += dilationHeight;\n        }\n        // const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          let xCMin = xCCorner;\n          while (xCMin < 0) {\n            xCMin += dilationWidth;\n          }\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let maxValue = Number.NEGATIVE_INFINITY;\n          let maxPosition = -1;\n\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const wR = xR - xRCorner;\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const wC = xC - xCCorner;\n              const pixel = xBuf.get(b, xR, xC, d);\n              if (pixel > maxValue) {\n                maxValue = pixel as number;\n                if (flattenPositions) {\n                  maxPosition = includeBatchInIndex ?\n                      ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                              convInfo.inChannels +\n                          d :\n                      (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                } else {\n                  maxPosition = wR * effectiveFilterWidth + wC;\n                }\n              }\n            }\n          }\n          maxPositions.set(maxPosition, b, yR, yC, d);\n        }\n      }\n    }\n  }\n  return maxPositions;\n}\n\nexport function pool3d(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv3DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = convInfo.padInfo.front;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n      convInfo.outShape[3] * convInfo.outShape[4];\n  const outputDepthStrides =\n      convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n  const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n  const outputColStrides = convInfo.outShape[4];\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    const outputBatchOffset = batch * outputBatchStrides;\n    const inputBatchOffset = batch * strides[0];\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n        const xDepthCorner = yDepth * strideDepth - padFront;\n        let xDepthMin = xDepthCorner;\n        while (xDepthMin < 0) {\n          xDepthMin += dilationDepth;\n        }\n        const xDepthMax =\n            Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n        const outputDepthOffset =\n            outputBatchOffset + yDepth * outputDepthStrides;\n        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n          const xRowCorner = yRow * strideHeight - padTop;\n          let xRowMin = xRowCorner;\n          while (xRowMin < 0) {\n            xRowMin += dilationHeight;\n          }\n          const xRowMax =\n              Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n          const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n            const xColCorner = yCol * strideWidth - padLeft;\n            let xColMin = xColCorner;\n            while (xColMin < 0) {\n              xColMin += dilationWidth;\n            }\n            const xColMax =\n                Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n            // Shader code begins\n            const outputColOffset = outputRowOffset + yCol * outputColStrides;\n            let minMaxValue = initialValue;\n            let avgValue = 0;\n            let count = 0;\n            for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                 xDepth += dilationDepth) {\n              const xDepthOffset = inputBatchOffset + xDepth * strides[1];\n              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                const xRowOffset = xDepthOffset + xRow * strides[2];\n                for (let xCol = xColMin; xCol < xColMax;\n                     xCol += dilationWidth) {\n                  const xColOffset = xRowOffset + xCol * strides[3];\n                  const pixel = xValues[xColOffset + channel];\n                  if ((poolType === 'max' && pixel > minMaxValue)) {\n                    minMaxValue = pixel;\n                  } else if (poolType === 'avg') {\n                    avgValue += pixel;\n                    count++;\n                  }\n                  if (isNaN(minMaxValue)) {\n                    break;\n                  }\n                }\n                if (isNaN(minMaxValue)) {\n                  break;\n                }\n              }\n              if (isNaN(minMaxValue)) {\n                break;\n              }\n            }\n            const outputOffset = outputColOffset + channel;\n            outputVals[outputOffset] =\n                poolType === 'avg' ? avgValue / count : minMaxValue;\n          }\n        }\n      }\n    }\n  }\n\n  return output;\n}\n\nexport function maxPool3dPositions(\n    xBuf: TensorBuffer<Rank, DataType>,\n    convInfo: backend_util.Conv3DInfo): TensorBuffer<Rank, DataType> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = convInfo.padInfo.front;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n        const xDepthCorner = yDepth * strideDepth - padFront;\n        let xDepthMin = xDepthCorner;\n        while (xDepthMin < 0) {\n          xDepthMin += dilationDepth;\n        }\n        const xDepthMax =\n            Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n          const xRowCorner = yRow * strideHeight - padTop;\n          let xRowMin = xRowCorner;\n          while (xRowMin < 0) {\n            xRowMin += dilationHeight;\n          }\n          const xRowMax =\n              Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n            const xColCorner = yCol * strideWidth - padLeft;\n            let xColMin = xColCorner;\n            while (xColMin < 0) {\n              xColMin += dilationWidth;\n            }\n            const xColMax =\n                Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n\n            // Shader code begins\n            let maxValue = Number.NEGATIVE_INFINITY;\n            let maxPosition = -1;\n\n            for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                 xDepth += dilationDepth) {\n              const wDepth = xDepth - xDepthCorner;\n              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                const wRow = xRow - xRowCorner;\n                for (let xCol = xColMin; xCol < xColMax;\n                     xCol += dilationWidth) {\n                  const wCol = xCol - xColCorner;\n                  const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                  if (pixel >= maxValue) {\n                    maxValue = pixel as number;\n                    maxPosition =\n                        wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                        wRow * effectiveFilterHeight + wCol;\n                  }\n                }\n              }\n            }\n\n            maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return maxPositions;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function avgPool(\n    args:\n        {inputs: AvgPoolInputs, backend: MathBackendCPU, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'avgPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'avg');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'cpu',\n  kernelFunc: avgPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3D, AvgPool3DAttrs, AvgPool3DInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool3d} from '../utils/pool_utils';\n\nexport function avgPool3D(args: {\n  inputs: AvgPool3DInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode, dataFormat} = attrs;\n\n  assertNotComplex(x, 'avgPool3d');\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode, dataFormat);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = pool3d(\n      xValues, x.shape, x.dtype, util.computeStrides(x.shape), convInfo, 'avg');\n\n  return backend.makeTensorInfo(outBuf.shape, 'float32', outBuf.values);\n}\n\nexport const avgPool3DConfig: KernelConfig = {\n  kernelName: AvgPool3D,\n  backendName: 'cpu',\n  kernelFunc: avgPool3D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3DGrad, AvgPool3DGradAttrs, AvgPool3DGradInputs, backend_util, buffer, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPool3DGrad(args: {\n  inputs: AvgPool3DGradInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, input], 'avgPool3DGrad');\n\n  const convInfo = backend_util.computePool3DInfo(\n      input.shape as [number, number, number, number, number], filterSize,\n      strides, 1 /* dilations */, pad, dimRoundingMode);\n\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterDepth = convInfo.filterDepth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx = buffer(input.shape, 'float32');\n\n  const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n\n  const dyBuf = backend.bufferSync(dy);\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n            // Shader code begins.\n            const dyDepthCorner = dxDepth - padFront;\n            const dyRowCorner = dxRow - padTop;\n            const dyColCorner = dxCol - padLeft;\n            let dotProd = 0;\n            for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                 wDepth += dilationDepth) {\n              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n              if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                  Math.floor(dyDepth) !== dyDepth) {\n                continue;\n              }\n              for (let wRow = 0; wRow < effectiveFilterHeight;\n                   wRow += dilationHeight) {\n                const dyRow = (dyRowCorner + wRow) / strideHeight;\n                if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                    Math.floor(dyRow) !== dyRow) {\n                  continue;\n                }\n                for (let wCol = 0; wCol < effectiveFilterWidth;\n                     wCol += dilationWidth) {\n                  const dyCol = (dyColCorner + wCol) / strideWidth;\n                  if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                      Math.floor(dyCol) !== dyCol) {\n                    continue;\n                  }\n\n                  const pixel =\n                      dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                  dotProd += pixel;\n                }\n              }\n            }\n            dx.set(\n                dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPool3DGradConfig: KernelConfig = {\n  kernelName: AvgPool3DGrad,\n  backendName: 'cpu',\n  kernelFunc: avgPool3DGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPoolGrad, AvgPoolGradAttrs, AvgPoolGradInputs, backend_util, buffer, KernelConfig, KernelFunc, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPoolGrad(args: {\n  inputs: AvgPoolGradInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  assertNotComplex([dy, input], 'avgPoolGrad');\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel;\n            }\n          }\n          dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPoolGradConfig: KernelConfig = {\n  kernelName: AvgPoolGrad,\n  backendName: 'cpu',\n  kernelFunc: avgPoolGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function batchNorm(args: {\n  inputs: FusedBatchNormInputs,\n  backend: MathBackendCPU,\n  attrs: FusedBatchNormAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, scale, offset, mean, variance} = inputs;\n\n  util.assert(\n      mean.shape.length === variance.shape.length,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      offset == null || mean.shape.length === offset.shape.length,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      scale == null || mean.shape.length === scale.shape.length,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n  let {varianceEpsilon} = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const mVals = backend.data.get(mean.dataId).values as TypedArray;\n  const varVals = backend.data.get(variance.dataId).values as TypedArray;\n  const sVals = scale ? backend.data.get(scale.dataId).values as TypedArray :\n                        new Float32Array([1]);\n  const offVals = offset ?\n      backend.data.get(offset.dataId).values as TypedArray :\n      new Float32Array([0]);\n  const outVals = new Float32Array(xVals.length);\n\n  const offValsLength = offVals.length;\n  const sValsLength = sVals.length;\n  const varValsLength = varVals.length;\n  const mValsLength = mVals.length;\n\n  let offi = 0;\n  let mi = 0;\n  let si = 0;\n  let vi = 0;\n  for (let i = 0; i < xVals.length; ++i) {\n    outVals[i] = offVals[offi++] +\n        (xVals[i] - mVals[mi++]) * sVals[si++] /\n            Math.sqrt(varVals[vi++] + varianceEpsilon);\n    if (offi >= offValsLength) {\n      offi = 0;\n    }\n    if (mi >= mValsLength) {\n      mi = 0;\n    }\n    if (si >= sValsLength) {\n      si = 0;\n    }\n    if (vi >= varValsLength) {\n      vi = 0;\n    }\n  }\n  return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\n\nexport const batchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'cpu',\n  kernelFunc: batchNorm as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BatchToSpaceND, BatchToSpaceNDAttrs, BatchToSpaceNDInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {transpose} from './Transpose';\n\nexport function batchToSpaceND(args: {\n  inputs: BatchToSpaceNDInputs,\n  backend: MathBackendCPU,\n  attrs: BatchToSpaceNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, crops} = attrs;\n\n  assertNotComplex([x], 'batchToSpaceND');\n\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n  const permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n  const reshapedPermuted =\n      backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n  const sliceBeginCoords =\n      backend_util.getSliceBeginCoords(crops, blockShape.length);\n  const sliceSize =\n      backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n  const xReshaped = reshape({inputs: {x}, backend, attrs: {shape: reshaped}});\n  const xTransposed =\n      transpose({inputs: {x: xReshaped}, backend, attrs: {perm: permuted}});\n  const xTransposedReshaped = reshape(\n      {inputs: {x: xTransposed}, backend, attrs: {shape: reshapedPermuted}});\n  const result = slice({\n    inputs: {x: xTransposedReshaped},\n    backend,\n    attrs: {begin: sliceBeginCoords, size: sliceSize}\n  });\n\n  backend.disposeIntermediateTensorInfo(xReshaped);\n  backend.disposeIntermediateTensorInfo(xTransposed);\n  backend.disposeIntermediateTensorInfo(xTransposedReshaped);\n\n  return result;\n}\n\nexport const batchToSpaceNDConfig: KernelConfig = {\n  kernelName: BatchToSpaceND,\n  backendName: 'cpu',\n  kernelFunc: batchToSpaceND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Bincount, BincountAttrs, BincountInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {bincountImpl} from './Bincount_impl';\n\nexport function bincount(args: {\n  inputs: BincountInputs,\n  backend: MathBackendCPU,\n  attrs: BincountAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size} = attrs;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const weightsVals = backend.data.get(weights.dataId).values as TypedArray;\n\n  const outVals =\n      bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);\n\n  return backend.makeTensorInfo([size], weights.dtype, outVals);\n}\n\nexport const bincountConfig: KernelConfig = {\n  kernelName: Bincount,\n  backendName: 'cpu',\n  kernelFunc: bincount as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const clip = unaryKernelFunc(ClipByValue, (xi, attrs) => {\n  const clipAttrs = attrs as {} as ClipByValueAttrs;\n  if (xi > clipAttrs.clipValueMax) {\n    return clipAttrs.clipValueMax;\n  }\n  return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;\n});\n\nexport const clipConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'cpu',\n  kernelFunc: clip,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ComplexAbs, ComplexAbsInputs, KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const complexAbs =\n    (args: {inputs: ComplexAbsInputs, backend: MathBackendCPU}) => {\n      const {x} = args.inputs;\n      const cpuBackend = args.backend;\n      const resultValues = new Float32Array(util.sizeFromShape(x.shape));\n      const complexVals = cpuBackend.data.get(x.dataId);\n      const real = complexVals.complexTensorInfos.real;\n      const imag = complexVals.complexTensorInfos.imag;\n      const realVals = cpuBackend.data.get(real.dataId).values as Float32Array;\n      const imagVals = cpuBackend.data.get(imag.dataId).values as Float32Array;\n      for (let i = 0; i < realVals.length; i++) {\n        const real = realVals[i];\n        const imag = imagVals[i];\n        resultValues[i] = Math.hypot(real, imag);\n      }\n\n      return cpuBackend.makeOutput(resultValues, x.shape, 'float32');\n    };\n\nexport const complexAbsConfig: KernelConfig = {\n  kernelName: ComplexAbs,\n  backendName: 'cpu',\n  kernelFunc: complexAbs as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function imag(args: {inputs: ImagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const imag = backend.data.get(input.dataId).complexTensorInfos.imag;\n  const imagVal = backend.data.get(imag.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the imag value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(imag.shape, imag.dtype, imagVal);\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'cpu',\n  kernelFunc: imag as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {concatImpl} from './Concat_impl';\nimport {identity} from './Identity';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concat(\n    args: {inputs: ConcatInputs, backend: MathBackendCPU, attrs: ConcatAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({inputs: {x: $inputs[0]}, backend});\n  }\n\n  const shapes = $inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = $inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concat({inputs: reals, backend, attrs: {axis: $axis}});\n    const imagConcated = concat({inputs: imags, backend, attrs: {axis: $axis}});\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n\n    return result;\n  }\n\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({inputs: {x: t}, backend, attrs: {shape}});\n  });\n\n  const inputsValShapes = inputs2D.map(t => {\n    return {vals: backend.data.get(t.dataId).values, shape: t.shape};\n  });\n\n  // Concats 2d tensors along axis=1.\n  outShape =\n      backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n  const simplyConcat = inputs2D[0].shape[0] === 1;\n  const outVals =\n      concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n\n  const finalOutShape =\n      backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n\n  const outInfo =\n      backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outInfo;\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2D, Conv2DAttrs, Conv2DInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2D(\n    args: {inputs: Conv2DInputs, backend: MathBackendCPU, attrs: Conv2DAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n\n  assertNotComplex([x, filter], 'conv2d');\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const padLeft = convInfo.padInfo.left;\n  const padTop = convInfo.padInfo.top;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const xBatchStride = xStrides[0];\n  const xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];\n  const xColStride = isChannelsLast ? xStrides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : xStrides[1];\n  const yBatchStride = y.strides[0];\n  const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n  const yColStride = isChannelsLast ? y.strides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : y.strides[1];\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xBatchStride;\n    const yOffset1 = b * yBatchStride;\n    for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n      const yOffset2 = yOffset1 + yR * yRowStride;\n      const xRCorner = yR * convInfo.strideHeight - padTop;\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const xR = xRCorner + wR * dilationHeight;\n        if (xR < 0 || xR >= convInfo.inHeight) {\n          continue;\n        }\n        const wOffset1 = wR * filterStrides[0];\n        const xOffset2 = xOffset1 + xR * xRowStride;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const yOffset3 = yOffset2 + yC * yColStride;\n          const xCCorner = yC * convInfo.strideWidth - padLeft;\n          for (let wC = 0; wC < filterWidth; ++wC) {\n            const xC = xCCorner + wC * dilationWidth;\n            if (xC < 0 || xC >= convInfo.inWidth) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wC * filterStrides[1];\n            const xOffset3 = xOffset2 + xC * xColStride;\n            let wOffset3 = wOffset2;\n            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n              const xVal = xVals[xOffset3 + d1 * xChannelStride];\n              for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                yVals[yOffset3 + d2 * yChannelStride] +=\n                    xVal * wVals[wOffset3 + d2];\n              }\n              wOffset3 += convInfo.outChannels;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, yVals);\n}\n\nexport const conv2DConfig: KernelConfig = {\n  kernelName: Conv2D,\n  backendName: 'cpu',\n  kernelFunc: conv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropFilter, Conv2DBackpropFilterAttrs, Conv2DBackpropFilterInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2DBackpropFilter(args: {\n  inputs: Conv2DBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: Conv2DBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, dataFormat, dimRoundingMode, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'conv2dBackpropFilter');\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad, dimRoundingMode, false /* depthwise */,\n      $dataFormat);\n\n  const {strideHeight, strideWidth, filterHeight, filterWidth} = convInfo;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const dW = new TensorBuffer(convInfo.filterShape, 'float32');\n\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const dyVals = backend.data.get(dy.dataId).values as TypedArray;\n\n  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);\n  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);\n\n  for (let wR = 0; wR < filterHeight; ++wR) {\n    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n    const yRMax = Math.min(\n        convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n    for (let wC = 0; wC < filterWidth; ++wC) {\n      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n      const yCMax = Math.min(\n          convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n      for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n          let dotProd = 0;\n          for (let b = 0; b < convInfo.batchSize; ++b) {\n            for (let yR = yRMin; yR < yRMax; ++yR) {\n              const xR = wR + yR * strideHeight - topPad;\n              for (let yC = yCMin; yC < yCMax; ++yC) {\n                const xC = wC + yC * strideWidth - leftPad;\n                if (isChannelsLast) {\n                  dotProd += (xBuf.get(b, xR, xC, d1) as number) *\n                      (dyBuf.get(b, yR, yC, d2) as number);\n                } else {\n                  dotProd += (xBuf.get(b, d1, xR, xC) as number) *\n                      (dyBuf.get(b, d2, yR, yC) as number);\n                }\n              }\n            }\n          }\n          dW.set(dotProd, wR, wC, d1, d2);\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\n\nexport const conv2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Conv2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: conv2DBackpropFilter as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2DBackpropInput(args: {\n  inputs: Conv2DBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: Conv2DBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {inputShape, strides, pad, dataFormat, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, filter], 'conv2dBackpropInput');\n\n  const filterStrides = util.computeStrides(filter.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n\n  let $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2] = filterStrides;\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  $dataFormat = convInfo.dataFormat;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  const isChannelsLast = $dataFormat === 'channelsLast';\n  const xBatchStride = dx.strides[0];\n  const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n  const xColStride = isChannelsLast ? dx.strides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n  const yBatchStride = dyStrides[0];\n  const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];\n  const yColStride = isChannelsLast ? dyStrides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : dyStrides[1];\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      for (let xR = 0; xR < inHeight; ++xR) {\n        const xRCorner = xR - topPad;\n        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n        const yRMax =\n            Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n        for (let xC = 0; xC < inWidth; ++xC) {\n          const xCCorner = xC - leftPad;\n          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n          const yCMax =\n              Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n          let dotProd = 0;\n          for (let yR = xRMin; yR < yRMax; ++yR) {\n            const wR = yR * strideHeight - xRCorner;\n\n            for (let yC = xCMin; yC < yCMax; ++yC) {\n              const wC = yC * strideWidth - xCCorner;\n              const dyOffset =\n                  yBatchStride * b + yRowStride * yR + yColStride * yC;\n              const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                  fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n              for (let d2 = 0; d2 < outChannels; ++d2) {\n                const pixel = dyValues[dyOffset + yChannelStride * d2];\n                const weight = fltValues[fltOffset + d2];\n                dotProd += pixel * weight;\n              }\n            }\n          }\n          const dxOffset = xBatchStride * b + xRowStride * xR +\n              xColStride * xC + xChannelStride * d1;\n          dxValues[dxOffset] = dotProd;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const conv2DBackpropInputConfig: KernelConfig = {\n  kernelName: Conv2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: conv2DBackpropInput as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3D, Conv3DAttrs, Conv3DInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3D(\n    args: {inputs: Conv3DInputs, backend: MathBackendCPU, attrs: Conv3DAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  assertNotComplex([x, filter], 'conv3d');\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number],\n      filter.shape as [number, number, number, number, number], strides,\n      dilations, pad);\n\n  const {\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    dilationDepth,\n    dilationHeight,\n    dilationWidth,\n    padInfo\n  } = convInfo;\n  const padFront = padInfo.front;\n  const padLeft = padInfo.left;\n  const padTop = padInfo.top;\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xStrides[0];\n    const yOffset1 = b * y.strides[0];\n    for (let yF = 0; yF < convInfo.outDepth; ++yF) {\n      const yOffset2 = yOffset1 + yF * y.strides[1];\n      const xFCorner = yF * convInfo.strideDepth - padFront;\n      for (let wF = 0; wF < filterDepth; ++wF) {\n        const xF = xFCorner + wF * dilationDepth;\n        if (xF < 0 || xF >= convInfo.inDepth) {\n          continue;\n        }\n        const wOffset1 = wF * filterStrides[0];\n        const xOffset2 = xOffset1 + xF * xStrides[1];\n\n        for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n          const yOffset3 = yOffset2 + yR * y.strides[2];\n          const xRCorner = yR * convInfo.strideHeight - padTop;\n          for (let wR = 0; wR < filterHeight; ++wR) {\n            const xR = xRCorner + wR * dilationHeight;\n            if (xR < 0 || xR >= convInfo.inHeight) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wR * filterStrides[1];\n            const xOffset3 = xOffset2 + xR * xStrides[2];\n            for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n              const yOffset4 = yOffset3 + yC * convInfo.outChannels;\n              const xCCorner = yC * convInfo.strideWidth - padLeft;\n              for (let wC = 0; wC < filterWidth; ++wC) {\n                const xC = xCCorner + wC * dilationWidth;\n                if (xC < 0 || xC >= convInfo.inWidth) {\n                  continue;\n                }\n                const wOffset3 = wOffset2 + wC * filterStrides[2];\n                const xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                let wOffset4 = wOffset3;\n                for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                  const xVal = xVals[xOffset4 + d1];\n                  for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                    yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                  }\n                  wOffset4 += convInfo.outChannels;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\n\nexport const conv3DConfig: KernelConfig = {\n  kernelName: Conv3D,\n  backendName: 'cpu',\n  kernelFunc: conv3D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropFilterV2, Conv3DBackpropFilterV2Attrs, Conv3DBackpropFilterV2Inputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3DBackpropFilterV2(args: {\n  inputs: Conv3DBackpropFilterV2Inputs,\n  backend: MathBackendCPU,\n  attrs: Conv3DBackpropFilterV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'conv3dBackpropFilterV2');\n\n  const xStrides = util.computeStrides(x.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad);\n\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterDepth = convInfo.filterDepth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n\n  const dw = new TensorBuffer(convInfo.filterShape, 'float32');\n  const dwValues = dw.values;\n  const [dwS0, dwS1, dwS2, dwS3] = dw.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const [xS0, xS1, xS2, xS3] = xStrides;\n\n  const frontPad = convInfo.padInfo.front;\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n\n  for (let wF = 0; wF < filterDepth; ++wF) {\n    const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n    const yFMax = Math.min(\n        convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n    const wOffset1 = wF * dwS0;\n\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n      const wOffset2 = wR * dwS1 + wOffset1;\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n        const wOffset3 = wC * dwS2 + wOffset2;\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          const wOffset4 = d1 * dwS3 + wOffset3;\n\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              const xOffset1 = b * xS0;\n              const yOffset1 = b * dyS0;\n\n              for (let yF = yFMin; yF < yFMax; ++yF) {\n                const xF = wF + yF * strideDepth - frontPad;\n                const xOffset2 = xF * xS1 + xOffset1;\n                const yOffset2 = yF * dyS1 + yOffset1;\n\n                for (let yR = yRMin; yR < yRMax; ++yR) {\n                  const xR = wR + yR * strideHeight - topPad;\n                  const xOffset3 = xR * xS2 + xOffset2;\n                  const yOffset3 = yR * dyS2 + yOffset2;\n\n                  for (let yC = yCMin; yC < yCMax; ++yC) {\n                    const xC = wC + yC * strideWidth - leftPad;\n                    const xOffset4 = xC * xS3 + xOffset3;\n                    const yOffset4 = yC * dyS3 + yOffset3;\n\n                    dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                  }\n                }\n              }\n            }\n            dwValues[wOffset4 + d2] = dotProd;\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dw.shape, dw.dtype, dw.values);\n}\n\nexport const conv3DBackpropFilterV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropFilterV2,\n  backendName: 'cpu',\n  kernelFunc: conv3DBackpropFilterV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropInputV2, Conv3DBackpropInputV2Attrs, Conv3DBackpropInputV2Inputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3DBackpropInputV2(args: {\n  inputs: Conv3DBackpropInputV2Inputs,\n  backend: MathBackendCPU,\n  attrs: Conv3DBackpropInputV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {pad, strides, inputShape} = attrs;\n\n  assertNotComplex([dy], 'conv3dBackpropInputV2');\n\n  const dyStrides = util.computeStrides(dy.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const convInfo = backend_util.computeConv3DInfo(\n      inputShape, filter.shape as [number, number, number, number, number],\n      strides, 1 /* dilations */, pad);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const [dxS0, dxS1, dxS2, dxS3] = dx.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2, fltS3] = filterStrides;\n  const {\n    batchSize,\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inDepth,\n    inHeight,\n    inWidth,\n    outChannels,\n    outDepth,\n    outHeight,\n    outWidth,\n    strideDepth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  const frontPad = filterDepth - 1 - convInfo.padInfo.front;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      // Frames of depth\n      for (let xF = 0; xF < inDepth; ++xF) {\n        const xFCorner = xF - frontPad;\n        const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n        const yFMax =\n            Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n\n        // Rows as per standard 2d matrix notation\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n          // Columns as per standard 2d matrix notation\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yF = xFMin; yF < yFMax; ++yF) {\n              const wF = yF * strideDepth - xFCorner;\n\n              for (let yR = xRMin; yR < yRMax; ++yR) {\n                const wR = yR * strideHeight - xRCorner;\n\n                for (let yC = xCMin; yC < yCMax; ++yC) {\n                  const wC = yC * strideWidth - xCCorner;\n                  const dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                  const fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                      fltS1 * (filterHeight - 1 - wR) +\n                      fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n\n                  for (let d2 = 0; d2 < outChannels; ++d2) {\n                    const pixel = dyValues[dyOffset + d2];\n                    const weight = fltValues[fltOffset + d2];\n                    dotProd += pixel * weight;\n                  }\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                dotProd;\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const conv3DBackpropInputV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropInputV2,\n  backendName: 'cpu',\n  kernelFunc: conv3DBackpropInputV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cos = unaryKernelFunc(Cos, (xi) => Math.cos(xi));\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'cpu',\n  kernelFunc: cos,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cosh = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'cpu',\n  kernelFunc: cosh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, CropAndResize, CropAndResizeAttrs, CropAndResizeInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function cropAndResize(args: {\n  inputs: CropAndResizeInputs,\n  backend: MathBackendCPU,\n  attrs: CropAndResizeAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image, boxes, boxInd} = inputs;\n  const {cropSize, method, extrapolationValue} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const numBoxes = boxes.shape[0];\n\n  const [cropHeight, cropWidth] = cropSize;\n  const output =\n      buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n\n  const boxVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const boxIndVals = backend.data.get(boxInd.dataId).values as TypedArray;\n  const imageVals = backend.data.get(image.dataId).values as TypedArray;\n\n  const inStride =\n      util.computeStrides(image.shape);  // to calculate flat indexes into image\n  const outStride = util.computeStrides(\n      output.shape);  // to calculate flat indexes into output\n\n  // Reference implementation\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n  for (let b = 0; b < numBoxes; b++) {\n    const startInd = b * 4;\n    const y1 = boxVals[startInd];\n    const x1 = boxVals[startInd + 1];\n    const y2 = boxVals[startInd + 2];\n    const x2 = boxVals[startInd + 3];\n\n    const bInd: number = boxIndVals[b];\n    if (bInd >= batch) {\n      continue;\n    }\n\n    const heightScale =\n        (cropHeight > 1) ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;\n    const widthScale =\n        (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n\n    for (let y = 0; y < cropHeight; y++) {\n      const yInd: number = (cropHeight > 1) ?\n          y1 * (imageHeight - 1) + y * (heightScale) :\n          0.5 * (y1 + y2) * (imageHeight - 1);\n\n      if (yInd < 0 || yInd > imageHeight - 1) {\n        for (let x = 0; x < cropWidth; x++) {\n          for (let c = 0; c < numChannels; c++) {\n            const ind =\n                c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[ind] = extrapolationValue;\n          }\n        }\n        continue;\n      }\n\n      if (method === 'bilinear') {\n        const topInd = Math.floor(yInd);\n        const bottomInd = Math.ceil(yInd);\n        const yLerp = yInd - topInd;\n\n        for (let x = 0; x < cropWidth; x++) {\n          const xInd = (cropWidth > 1) ?\n              x1 * (imageWidth - 1) + x * widthScale :\n              0.5 * (x1 + x2) * (imageWidth - 1);\n\n          if (xInd < 0 || xInd > imageWidth - 1) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n            continue;\n          }\n\n          const leftInd = Math.floor(xInd);\n          const rightInd = Math.ceil(xInd);\n          const xLerp = xInd - leftInd;\n\n          for (let c = 0; c < numChannels; c++) {\n            let ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                bInd * inStride[0];\n            const topLeft = imageVals[ind];\n\n            ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                bInd * inStride[0];\n            const topRight = imageVals[ind];\n\n            ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                bInd * inStride[0];\n            const bottomLeft = imageVals[ind];\n\n            ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                bInd * inStride[0];\n            const bottomRight = imageVals[ind];\n\n            const top = topLeft + (topRight - topLeft) * xLerp;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n\n            ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[ind] = top + ((bottom - top) * yLerp);\n          }\n        }\n      } else {  // method == \"nearest\"\n        for (let x = 0; x < cropWidth; ++x) {\n          const xInd = (cropWidth > 1) ?\n              x1 * (imageWidth - 1) + x * widthScale :\n              0.5 * (x1 + x2) * (imageWidth - 1);\n\n          if (xInd < 0 || xInd > imageWidth - 1) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n            continue;\n          }\n\n          const closestX = Math.round(xInd);\n          const closestY = Math.round(yInd);\n          for (let c = 0; c < numChannels; c++) {\n            const inInd = c + closestX * inStride[2] + closestY * inStride[1] +\n                bInd * inStride[0];\n            const outInd =\n                c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[outInd] = imageVals[inInd];\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(output.shape, output.dtype, output.values);\n}\n\nexport const cropAndResizeConfig: KernelConfig = {\n  kernelName: CropAndResize,\n  backendName: 'cpu',\n  kernelFunc: cropAndResize as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function cumsum(\n    args: {inputs: CumsumInputs, backend: MathBackendCPU, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n\n  assertNotComplex(x, 'cumsum');\n\n  const permutation = backend_util.getAxesPermutation([axis], x.shape.length);\n  let $x = x;\n  if (permutation != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, x.shape.length)[0];\n\n  if (permutedAxis !== $x.shape.length - 1) {\n    throw new Error(\n        `backend.cumsum in CPU expects an inner-most ` +\n        `axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);\n  }\n\n  const resultDtype = upcastType($x.dtype, 'int32');\n  const vals = util.makeZerosTypedArray(\n                   util.sizeFromShape($x.shape), resultDtype) as TypedArray;\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  const finalDim = $x.shape[$x.shape.length - 1];\n  const indexAdjuster = reverse ?\n      (i: number, j: number) => i + finalDim - j - 1 :\n      (i: number, j: number) => i + j;\n  for (let i = 0; i < aVals.length; i += finalDim) {\n    for (let j = 0; j < finalDim; j++) {\n      const idx = indexAdjuster(i, j);\n      if (j === 0) {\n        vals[idx] = exclusive ? 0 : aVals[idx];\n      } else {\n        const prevIdx = indexAdjuster(i, j - 1);\n        vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                aVals[idx] + vals[prevIdx];\n      }\n    }\n  }\n\n  const result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo($x);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'cpu',\n  kernelFunc: cumsum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DenseBincount, DenseBincountAttrs, DenseBincountInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {bincountImpl, bincountReduceImpl} from './Bincount_impl';\n\nexport function denseBincount(args: {\n  inputs: DenseBincountInputs,\n  backend: MathBackendCPU,\n  attrs: DenseBincountAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size, binaryOutput} = attrs;\n\n  if (x.shape.length === 1) {\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const weightsVals = backend.data.get(weights.dataId).values as TypedArray;\n\n    const outVals =\n        bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);\n\n    return backend.makeTensorInfo([size], weights.dtype, outVals);\n  } else if (x.shape.length === 2) {\n    const xBuf = backend.bufferSync(x);\n    const weightsBuf = backend.bufferSync(weights);\n\n    const outBuf = bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput);\n\n    return backend.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);\n  }\n\n  throw new Error(\n      `Error in denseBincount: input must be at most rank 2, but got rank` +\n      `${x.shape.length}.`);\n}\n\nexport const denseBincountConfig: KernelConfig = {\n  kernelName: DenseBincount,\n  backendName: 'cpu',\n  kernelFunc: denseBincount as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DepthToSpace, DepthToSpaceAttrs, DepthToSpaceInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function depthToSpace(args: {\n  inputs: DepthToSpaceInputs,\n  backend: MathBackendCPU,\n  attrs: DepthToSpaceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockSize, dataFormat} = attrs;\n\n  util.assert(\n      dataFormat === 'NHWC',\n      () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${\n          dataFormat}`);\n  util.assert(\n      blockSize > 1,\n      () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);\n\n  const batchSize = x.shape[0];\n  const inputHeight = x.shape[1];\n  const inputWidth = x.shape[2];\n  const inputDepth = x.shape[3];\n\n  const outputHeight = inputHeight * blockSize;\n  const outputWidth = inputWidth * blockSize;\n  const outputDepth = inputDepth / (blockSize * blockSize);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const result =\n      new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n\n  let outputIdx = 0;\n  for (let b = 0; b < batchSize; ++b) {\n    for (let h = 0; h < outputHeight; ++h) {\n      const inH = Math.floor(h / blockSize);\n      const offsetH = (h % blockSize);\n      for (let w = 0; w < outputWidth; ++w) {\n        const inW = Math.floor(w / blockSize);\n        const offsetW = (w % blockSize);\n        const offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n        for (let d = 0; d < outputDepth; ++d) {\n          const inD = d + offsetD;\n          const inputIdx =\n              inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n          result[outputIdx++] = xValues[inputIdx];\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);\n}\n\nexport const depthToSpaceConfig: KernelConfig = {\n  kernelName: DepthToSpace,\n  backendName: 'cpu',\n  kernelFunc: depthToSpace as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNative(args: {\n  inputs: DepthwiseConv2dNativeInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations, dimRoundingMode} = attrs;\n\n  assertNotComplex([x, filter], 'depthwiseConv2DNative');\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, $dilations),\n      () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n          `1. Got strides ${strides} and dilations '${$dilations}'`);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */);\n\n  const {filterHeight, filterWidth, dilationHeight, dilationWidth, padInfo} =\n      convInfo;\n  const padLeft = padInfo.left;\n  const padTop = padInfo.top;\n  const chMul = convInfo.outChannels / convInfo.inChannels;\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xStrides[0];\n    const yOffset1 = b * y.strides[0];\n    for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n      const yOffset2 = yOffset1 + yR * y.strides[1];\n      const xRCorner = yR * convInfo.strideHeight - padTop;\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const xR = xRCorner + wR * dilationHeight;\n        if (xR < 0 || xR >= convInfo.inHeight) {\n          continue;\n        }\n        const wOffset1 = wR * filterStrides[0];\n        const xOffset2 = xOffset1 + xR * xStrides[1];\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const yOffset3 = yOffset2 + yC * y.strides[2];\n          const xCCorner = yC * convInfo.strideWidth - padLeft;\n          for (let wC = 0; wC < filterWidth; ++wC) {\n            const xC = xCCorner + wC * dilationWidth;\n            if (xC < 0 || xC >= convInfo.inWidth) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wC * filterStrides[1];\n            const xOffset3 = xOffset2 + xC * convInfo.inChannels;\n            let yOffset4 = yOffset3;\n            let wOffset3 = wOffset2;\n            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n              const xVal = xVals[xOffset3 + d1];\n              for (let q = 0; q < chMul; ++q) {\n                yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n              }\n              yOffset4 += chMul;\n              wOffset3 += chMul;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\n\nexport const depthwiseConv2dNativeConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNative,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNative as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropFilterAttrs, DepthwiseConv2dNativeBackpropFilterInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNativeBackpropFilter(args: {\n  inputs: DepthwiseConv2dNativeBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'depthwiseConv2dNativeBackpropFilter');\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const {strideHeight, strideWidth, filterHeight, filterWidth} = convInfo;\n\n  const dW = new TensorBuffer(convInfo.filterShape, 'float32');\n\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n  const chMul = convInfo.outChannels / convInfo.inChannels;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);\n  const dyVals = backend.data.get(dy.dataId).values as TypedArray;\n  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);\n  for (let wR = 0; wR < filterHeight; ++wR) {\n    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n    const yRMax = Math.min(\n        convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n    for (let wC = 0; wC < filterWidth; ++wC) {\n      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n      const yCMax = Math.min(\n          convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n      for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n        const d1 = Math.trunc(d2 / chMul);\n        const dm = d2 % chMul;\n\n        let dotProd = 0;\n        for (let b = 0; b < convInfo.batchSize; ++b) {\n          for (let yR = yRMin; yR < yRMax; ++yR) {\n            const xR = wR + yR * strideHeight - topPad;\n            for (let yC = yCMin; yC < yCMax; ++yC) {\n              const xC = wC + yC * strideWidth - leftPad;\n              dotProd += (xBuf.get(b, xR, xC, d1) as number) *\n                  (dyBuf.get(b, yR, yC, d2) as number);\n            }\n          }\n        }\n        dW.set(dotProd, wR, wC, d1, dm);\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\n\nexport const depthwiseConv2dNativeBackpropFilterConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNativeBackpropFilter as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropInput, DepthwiseConv2dNativeBackpropInputAttrs, DepthwiseConv2dNativeBackpropInputInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNativeBackpropInput(args: {\n  inputs: DepthwiseConv2dNativeBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, inputShape} = attrs;\n\n  assertNotComplex([dy, filter], 'depthwiseConv2DNativeBackpropInput');\n\n  const dyStrides = util.computeStrides(dy.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const [dxS0, dxS1, dxS2] = dx.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2] = dyStrides;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2] = filterStrides;\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n  const chMul = outChannels / inChannels;\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      for (let xR = 0; xR < inHeight; ++xR) {\n        const xRCorner = xR - topPad;\n        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n        const yRMax =\n            Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n        for (let xC = 0; xC < inWidth; ++xC) {\n          const xCCorner = xC - leftPad;\n          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n          const yCMax =\n              Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n          let dotProd = 0;\n          for (let yR = xRMin; yR < yRMax; ++yR) {\n            const wR = yR * strideHeight - xRCorner;\n\n            for (let yC = xCMin; yC < yCMax; ++yC) {\n              const wC = yC * strideWidth - xCCorner;\n              const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n              const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                  fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n              for (let dm = 0; dm < chMul; ++dm) {\n                const d2 = d1 * chMul + dm;\n                const pixel = dyValues[dyOffset + d2];\n                const weight = fltValues[fltOffset + dm];\n                dotProd += pixel * weight;\n              }\n            }\n          }\n          dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const depthwiseConv2dNativeBackpropInputConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNativeBackpropInput as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, Diag, DiagInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function diag(args: {inputs: DiagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  const xSize = util.sizeFromShape(x.shape);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = buffer([xSize, xSize], x.dtype);\n  const vals = outBuf.values;\n  for (let i = 0; i < xVals.length; i++) {\n    vals[i * xSize + i] = xVals[i];\n  }\n\n  const outShape = [...x.shape, ...x.shape];\n\n  return backend.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);\n}\n\nexport const diagConfig: KernelConfig = {\n  kernelName: Diag,\n  backendName: 'cpu',\n  kernelFunc: diag as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter} = inputs as Dilation2DInputs;\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xRank = x.shape.length;\n\n    const filterVals = cpuBackend.data.get(filter.dataId).values as TypedArray;\n    const filterRank = filter.shape.length;\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    const outSize = util.sizeFromShape(outShape);\n    const outRank = outShape.length;\n    const outputVals = util.getArrayFromDType(x.dtype, outSize);\n\n    // Upsampling the input by fill in `dilation size - 1` values between each\n    // input value.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const xIndex = util.locToIndex(\n                        [b, hIn, wIn, d], xRank, util.computeStrides(x.shape));\n                    const filterIndex = util.locToIndex(\n                        [h, w, d], filterRank,\n                        util.computeStrides(filter.shape));\n                    const val = xVals[xIndex] + filterVals[filterIndex];\n                    if (val > curVal) {\n                      curVal = val;\n                    }\n                  }\n                }\n              }\n            }\n            const outputIndex = util.locToIndex(\n                [b, hOut, wOut, d], outRank, util.computeStrides(outShape));\n            outputVals[outputIndex] = curVal;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropFilter}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed filter gradients has the same dimensions as the filter:\n    // [filterHeight, filterWidth, depth]\n    const gradients = util.makeZerosNestedTypedArray(\n                          filter.shape, filter.dtype) as number[][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hMax = 0;\n            let wMax = 0;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hMax = h;\n                      wMax = w;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);\n\n    return {dataId, shape: filter.shape, dtype: filter.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n    const gradients =\n        util.makeZerosNestedTypedArray(x.shape, x.dtype) as number[][][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hInMax = (hBeg < 0) ? 0 : hBeg;\n            let wInMax = (wBeg < 0) ? 0 : wBeg;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Sum, SumAttrs, SumInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {zeros} from '../utils/zeros_impl';\nimport {cast} from './Cast';\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function sum(\n    args: {inputs: SumInputs, backend: MathBackendCPU, attrs: SumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'sum');\n\n  let $x;\n  if (x.dtype === 'bool') {\n    $x = cast({inputs: {x}, backend, attrs: {dtype: 'int32'}});\n  } else {\n    $x = identity({inputs: {x}, backend});\n  }\n\n  const xRank = $x.shape.length;\n  const axes = util.parseAxisParam(axis, $x.shape);\n  const permutation = backend_util.getAxesPermutation(axes, xRank);\n\n  let reductionAxes = axes;\n  let permutedX = $x;\n  if (permutation != null) {\n    permutedX =\n        transpose({inputs: {x: $x}, backend, attrs: {perm: permutation}});\n    reductionAxes = backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims(\n      'sum', reductionAxes, permutedX.shape.length);\n\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(permutedX.shape, reductionAxes);\n  const resultDtype = backend_util.upcastType(permutedX.dtype, 'int32');\n  let result = zeros(backend, outShape, resultDtype);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = backend.data.get(result.dataId).values as TypedArray;\n\n  const aVals = backend.data.get(permutedX.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let sum = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      sum += aVals[offset + j];\n    }\n    vals[i] = sum;\n  }\n\n  if (keepDims) {\n    const newShape = backend_util.expandShapeToKeepDim(result.shape, axes);\n    const oldResult = result;\n    result = reshape({inputs: {x: result}, backend, attrs: {shape: newShape}});\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n\n  backend.disposeIntermediateTensorInfo($x);\n\n  if (permutation != null) {\n    backend.disposeIntermediateTensorInfo(permutedX);\n  }\n\n  return result;\n}\n\nexport const sumConfig: KernelConfig = {\n  kernelName: Sum,\n  backendName: 'cpu',\n  kernelFunc: sum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Einsum, EinsumAttrs, EinsumInputs, KernelConfig, KernelFunc, Tensor, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {multiply} from './Multiply';\nimport {reshape} from './Reshape';\nimport {sum} from './Sum';\nimport {transpose} from './Transpose';\n\nexport function einsum(\n    args: {inputs: EinsumInputs, backend: MathBackendCPU, attrs: EinsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {equation} = attrs;\n  const tensors = inputs as Tensor[];\n\n  const {allDims, summedDims, idDims} =\n      backend_util.decodeEinsumEquation(equation, tensors.length);\n  backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);\n  const {path, steps} = backend_util.getEinsumComputePath(summedDims, idDims);\n\n  const nSteps = steps.length;\n  let out: TensorInfo|null = null;\n  let numDimsRemaining = allDims.length;\n  const tensorsToDispose: TensorInfo[] = [];\n  for (let i = 0; i < nSteps; ++i) {\n    for (const idTerm of steps[i]) {\n      const {permutationIndices: perm, expandDims: dimsToExpand} =\n          backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);\n      let x: TensorInfo;\n      if (backend_util.isIdentityPermutation(perm)) {\n        x = tensors[idTerm];\n      } else {\n        x = transpose({inputs: {x: tensors[idTerm]}, backend, attrs: {perm}});\n        tensorsToDispose.push(x);\n      }\n      const targetShape: number[] = x.shape.slice();\n      for (let k = 0; k < dimsToExpand.length; ++k) {\n        targetShape.splice(dimsToExpand[k], 0, 1);\n      }\n\n      if (!util.arraysEqual(x.shape, targetShape)) {\n        x = reshape({inputs: {x}, backend, attrs: {shape: targetShape}});\n        tensorsToDispose.push(x);\n      }\n      if (out === null) {\n        out = x;\n      } else {\n        // tslint:disable-next-line: no-unnecessary-type-assertion\n        out = multiply({inputs: {a: x, b: out}, backend}) as TensorInfo;\n        tensorsToDispose.push(out);\n      }\n    }\n    if (i < nSteps - 1) {\n      if (path[i] >= 0) {\n        out = sum({\n          inputs: {x: out},\n          backend,\n          attrs: {\n            axis: path[i] - (allDims.length - numDimsRemaining),\n            keepDims: false\n          }\n        });\n        tensorsToDispose.push(out);\n      }\n      numDimsRemaining--;\n    }\n  }\n\n  // Clean up intermediate tensors.\n  for (const tensorInfo of tensorsToDispose) {\n    if (tensorInfo === out) {\n      continue;\n    }\n    backend.disposeIntermediateTensorInfo(tensorInfo);\n  }\n\n  return out;\n}\n\nexport const einsumConfig: KernelConfig = {\n  kernelName: Einsum,\n  backendName: 'cpu',\n  kernelFunc: einsum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {EluGrad, EluGradInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function eluGrad(args: {inputs: EluGradInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {dy, y} = inputs;\n\n  assertNotComplex([dy, y], 'eluGrad');\n\n  const resultValues = new Float32Array(util.sizeFromShape(y.shape));\n  const values = backend.data.get(y.dataId).values as TypedArray;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  for (let i = 0; i < values.length; ++i) {\n    const v = values[i];\n    if (v >= 1) {\n      resultValues[i] = dyValues[i];\n    } else {\n      resultValues[i] = dyValues[i] * (v + 1);\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, 'float32', resultValues);\n}\n\nexport const eluGradConfig: KernelConfig = {\n  kernelName: EluGrad,\n  backendName: 'cpu',\n  kernelFunc: eluGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const equalImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a === b) ? 1 : 0);\nexport const equal =\n    binaryKernelFunc(Equal, equalImpl, null /* complexImpl */, 'bool');\n\nexport const equalConfig: KernelConfig = {\n  kernelName: Equal,\n  backendName: 'cpu',\n  kernelFunc: equal\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst p = backend_util.ERF_P;\nconst a1 = backend_util.ERF_A1;\nconst a2 = backend_util.ERF_A2;\nconst a3 = backend_util.ERF_A3;\nconst a4 = backend_util.ERF_A4;\nconst a5 = backend_util.ERF_A5;\n\nexport const erf = unaryKernelFunc(\n    Erf,\n    (xi) => {\n      const sign = Math.sign(xi);\n      const v = Math.abs(xi);\n      const t = 1.0 / (1.0 + p * v);\n      return sign *\n          (1.0 -\n           (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n               Math.exp(-v * v));\n    },\n);\n\nexport const erfConfig: KernelConfig = {\n  kernelName: Erf,\n  backendName: 'cpu',\n  kernelFunc: erf,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ExpandDims, ExpandDimsAttrs, ExpandDimsInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {reshape} from './Reshape';\n\nexport function expandDims(args: {\n  inputs: ExpandDimsInputs,\n  backend: MathBackendCPU,\n  attrs: ExpandDimsAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {input} = inputs;\n  const {dim} = attrs;\n\n  const inputRank = input.shape.length;\n  const newShape = input.shape.slice();\n  let $dim = dim;\n  if (dim < 0) {\n    // Negative value is counted from the tail of rank.\n    util.assert(\n        -(inputRank + 1) <= dim,\n        () => `Axis must be in the interval [${- (inputRank + 1)}, ${\n            inputRank}]`);\n    $dim = inputRank + dim + 1;\n  }\n  newShape.splice($dim, 0, 1);\n\n  return reshape({inputs: {x: input}, backend, attrs: {shape: newShape}});\n}\n\nexport const expandDimsConfig: KernelConfig = {\n  kernelName: ExpandDims,\n  backendName: 'cpu',\n  kernelFunc: expandDims as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, RealDiv} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const realDivImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a / b);\nexport const div = binaryKernelFunc(RealDiv, realDivImpl);\n\nexport const realDivConfig: KernelConfig = {\n  kernelName: RealDiv,\n  backendName: 'cpu',\n  kernelFunc: div\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Tensor, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {add} from '../kernels/Add';\nimport {complex} from '../kernels/Complex';\nimport {concat} from '../kernels/Concat';\nimport {identity} from '../kernels/Identity';\nimport {imag} from '../kernels/Imag';\nimport {multiply} from '../kernels/Multiply';\nimport {real} from '../kernels/Real';\nimport {realDivConfig} from '../kernels/RealDiv';\nimport {slice} from '../kernels/Slice';\nimport {sub} from '../kernels/Sub';\n\n/**\n * Calculate FFT of inner most elements of batch tensor.\n */\nexport function fftBatch(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): TensorInfo {\n  const inputShape = input.shape;\n  const batch = inputShape[0];\n  const innerDim = inputShape[1];\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const real2D = inputVals.complexTensorInfos.real;\n  const imag2D = inputVals.complexTensorInfos.imag;\n\n  // Collects real and imaginary values separately.\n  const resultShape = [batch, innerDim];\n  const resultSize = util.sizeFromShape(resultShape);\n  const resultReal = util.getTypedArrayFromDType('float32', resultSize);\n  const resultImag = util.getTypedArrayFromDType('float32', resultSize);\n\n  for (let b = 0; b < batch; b++) {\n    // TODO: Support slice ops for complex type.\n    const r = slice({\n      inputs: {x: real2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n    const i = slice({\n      inputs: {x: imag2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n\n    const input = complex({inputs: {real: r, imag: i}, backend: cpuBackend});\n\n    // Run FFT by batch element.\n    const {real, imag} = fftImpl(input, inverse, cpuBackend);\n    const res = backend_util.mergeRealAndImagArrays(real, imag);\n\n    for (let d = 0; d < innerDim; d++) {\n      const c = backend_util.getComplexWithIndex(res, d);\n      resultReal[b * innerDim + d] = c.real;\n      resultImag[b * innerDim + d] = c.imag;\n    }\n\n    cpuBackend.disposeIntermediateTensorInfo(r);\n    cpuBackend.disposeIntermediateTensorInfo(i);\n    cpuBackend.disposeIntermediateTensorInfo(input);\n  }\n\n  const $realInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultReal);\n  const $imagInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultImag);\n\n  const result = complex(\n      {inputs: {real: $realInfo, imag: $imagInfo}, backend: cpuBackend});\n\n  cpuBackend.disposeIntermediateTensorInfo($realInfo);\n  cpuBackend.disposeIntermediateTensorInfo($imagInfo);\n\n  return result;\n}\n\nexport function fftImpl(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  const inputSize = util.sizeFromShape(input.shape);\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const realVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values as\n      Float32Array;\n\n  const imagVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values as\n      Float32Array;\n\n  if (isExponentOf2(inputSize)) {\n    const result =\n        fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);\n\n    const resultShape = [input.shape[0], input.shape[1]];\n\n    if (inverse) {\n      const realInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.real);\n      const imagInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.imag);\n\n      const sizeInfo: TensorInfo = cpuBackend.makeTensorInfo(\n          [], 'float32',\n          util.createScalarValue(inputSize as {} as 'float32', 'float32'));\n      const sizeInfoCopy =\n          identity({inputs: {x: sizeInfo}, backend: cpuBackend});\n\n      const divRealInfo =\n          realDivConfig.kernelFunc(\n              {inputs: {a: realInfo, b: sizeInfo}, backend: cpuBackend}) as\n          TensorInfo;\n      const divImagInfo =\n          realDivConfig.kernelFunc(\n              {inputs: {a: imagInfo, b: sizeInfoCopy}, backend: cpuBackend}) as\n          TensorInfo;\n\n      const divRealVals =\n          cpuBackend.data.get(divRealInfo.dataId).values as Float32Array;\n      const divImagVals =\n          cpuBackend.data.get(divImagInfo.dataId).values as Float32Array;\n\n      cpuBackend.disposeIntermediateTensorInfo(realInfo);\n      cpuBackend.disposeIntermediateTensorInfo(imagInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);\n      cpuBackend.disposeIntermediateTensorInfo(divRealInfo);\n      cpuBackend.disposeIntermediateTensorInfo(divImagInfo);\n\n      return {real: divRealVals, imag: divImagVals};\n    }\n\n    return result;\n  } else {\n    const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n    const rawOutput =\n        fourierTransformByMatmul(data, inputSize, inverse) as Float32Array;\n\n    return backend_util.splitRealAndImagArrays(rawOutput);\n  }\n}\n\nfunction isExponentOf2(size: number): boolean {\n  return (size & size - 1) === 0;\n}\n\n// FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\nfunction fftRadix2(\n    realVals: Float32Array, imagVals: Float32Array, size: number,\n    inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  if (size === 1) {\n    return {real: realVals, imag: imagVals};\n  }\n\n  const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n  const half = size / 2;\n\n  const evenComplex = backend_util.complexWithEvenIndex(data);\n\n  const evenRealVals = evenComplex.real;\n  const evenImagVals = evenComplex.imag;\n\n  const evenShape = [evenRealVals.length];\n\n  const evenRealInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenRealVals);\n  const evenImagInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenImagVals);\n\n  const evenTensorInfo = complex(\n      {inputs: {real: evenRealInfo, imag: evenImagInfo}, backend: cpuBackend});\n\n  const oddComplex = backend_util.complexWithOddIndex(data);\n\n  const oddRealVals = oddComplex.real;\n  const oddImagVals = oddComplex.imag;\n\n  const oddShape = [oddRealVals.length];\n\n  const oddRealInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddRealVals);\n  const oddImagInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddImagVals);\n\n  const oddTensorInfo = complex(\n      {inputs: {real: oddRealInfo, imag: oddImagInfo}, backend: cpuBackend});\n\n  // Recursive call for half part of original input.\n  const $evenComplex =\n      fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);\n\n  const $evenRealVals = $evenComplex.real;\n  const $evenImagVals = $evenComplex.imag;\n\n  const $evenShape = [$evenRealVals.length];\n\n  const $evenRealInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenRealVals);\n  const $evenImagInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenImagVals);\n\n  const $evenTensorInfo = complex({\n    inputs: {real: $evenRealInfo, imag: $evenImagInfo},\n    backend: cpuBackend\n  });\n\n  const $oddComplex =\n      fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);\n\n  const $oddRealVals = $oddComplex.real;\n  const $oddImagVals = $oddComplex.imag;\n\n  const $oddShape = [$oddRealVals.length];\n\n  const $oddRealInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddRealVals);\n  const $oddImagInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddImagVals);\n\n  const $oddTensorInfo = complex(\n      {inputs: {real: $oddRealInfo, imag: $oddImagInfo}, backend: cpuBackend});\n\n  const e = backend_util.exponents(size, inverse);\n  const eShape = [e.real.length];\n\n  const eRealInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.real);\n  const eImagInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.imag);\n\n  const complexInfo = complex(\n      {inputs: {real: eRealInfo, imag: eImagInfo}, backend: cpuBackend});\n\n  const exponentInfo =\n      multiply(\n          {inputs: {a: complexInfo, b: $oddTensorInfo}, backend: cpuBackend}) as\n      TensorInfo;\n\n  const addPart = add({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n  const subPart = sub({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n\n  const addPartReal = real({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartReal = real({inputs: {input: subPart}, backend: cpuBackend});\n\n  const addPartImag = imag({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartImag = imag({inputs: {input: subPart}, backend: cpuBackend});\n\n  const $real = concat({\n    inputs: [addPartReal as Tensor, subPartReal as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n  const $imag = concat({\n    inputs: [addPartImag as Tensor, subPartImag as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n\n  const $realVals = cpuBackend.data.get($real.dataId).values as Float32Array;\n  const $imagVals = cpuBackend.data.get($imag.dataId).values as Float32Array;\n\n  cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(complexInfo);\n  cpuBackend.disposeIntermediateTensorInfo(exponentInfo);\n  cpuBackend.disposeIntermediateTensorInfo(addPart);\n  cpuBackend.disposeIntermediateTensorInfo(subPart);\n  cpuBackend.disposeIntermediateTensorInfo(addPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(addPartImag);\n  cpuBackend.disposeIntermediateTensorInfo(subPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(subPartImag);\n  cpuBackend.disposeIntermediateTensorInfo($real);\n  cpuBackend.disposeIntermediateTensorInfo($imag);\n\n  return {real: $realVals, imag: $imagVals};\n}\n\n// Calculate fourier transform by multplying sinusoid matrix.\nfunction fourierTransformByMatmul(\n    data: TypedArray, size: number, inverse: boolean): TypedArray {\n  const ret = new Float32Array(size * 2);\n  // TODO: Use matmul instead once it supports complex64 type.\n  for (let r = 0; r < size; r++) {\n    let real = 0.0;\n    let imag = 0.0;\n    for (let c = 0; c < size; c++) {\n      const e = backend_util.exponent(r * c, size, inverse);\n      const term = backend_util.getComplexWithIndex(data as Float32Array, c);\n      real += term.real * e.real - term.imag * e.imag;\n      imag += term.real * e.imag + term.imag * e.real;\n    }\n    if (inverse) {\n      real /= size;\n      imag /= size;\n    }\n    backend_util.assignToTypedArray(ret, real, imag, r);\n  }\n  return ret;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FFT, FFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function fft(args: {inputs: FFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, false, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const fftConfig: KernelConfig = {\n  kernelName: FFT,\n  backendName: 'cpu',\n  kernelFunc: fft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, DataValues, Fill, FillAttrs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function fill(args: {backend: MathBackendCPU, attrs: FillAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {shape, value, dtype} = attrs;\n\n  const $dtype = dtype || util.inferDtype(value);\n  const values = util.getArrayFromDType($dtype, util.sizeFromShape(shape));\n  fillValues(values, value, $dtype);\n\n  return backend.makeTensorInfo(shape, $dtype, values);\n}\n\nexport const fillConfig: KernelConfig = {\n  kernelName: Fill,\n  backendName: 'cpu',\n  kernelFunc: fill as {} as KernelFunc\n};\n\nfunction fillValues(\n    values: DataValues, value: string|number, dtype: DataType): void {\n  if (dtype === 'string') {\n    (values as string[]).fill(value as string);\n  } else {\n    (values as TypedArray).fill(value as number);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n  kernelName: FlipLeftRight,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as FlipLeftRightInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n\n            const coordX = Math.round(imageWidth - x);\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n\n            let outputValue = imageVals[outIdx];\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth) {\n              // set the output to the image value at the coordinate position.\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n            output[outIdx] = outputValue;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FloorDiv, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const floorDivImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => Math.floor(a / b));\nexport const floorDiv =\n    binaryKernelFunc(FloorDiv, floorDivImpl, null /* complexImpl */, 'int32');\n\nexport const floorDivConfig: KernelConfig = {\n  kernelName: FloorDiv,\n  backendName: 'cpu',\n  kernelFunc: floorDiv\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {conv2D} from './Conv2D';\n\nexport function fusedConv2D(args: {\n  inputs: FusedConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  let result = conv2D({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const resultOld = result;\n    result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  if (activation) {\n    const resultOld = result;\n    result = applyActivation(\n        backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  return result;\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedConv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {depthwiseConv2dNative} from './DepthwiseConv2dNative';\n\nexport function fusedDepthwiseConv2D(args: {\n  inputs: FusedDepthwiseConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedDepthwiseConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  let result = depthwiseConv2dNative({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const oldResult = result;\n    result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n  if (activation) {\n    const oldResult = result;\n    result = applyActivation(\n        backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n\n  return result;\n}\n\nexport const fusedDepthwiseConv2DConfig: KernelConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedDepthwiseConv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, GatherNd, GatherNdInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function gatherNd(\n    args: {inputs: GatherNdInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {params, indices} = inputs;\n\n  const paramsSize = util.sizeFromShape(params.shape);\n\n  const indicesShape = indices.shape;\n  const sliceRank = indicesShape[indicesShape.length - 1];\n\n  const [resultShape, numSlices, sliceSize, strides] =\n      backend_util.prepareAndValidate(params, indices);\n  if (numSlices === 0) {\n    return backend.makeTensorInfo(resultShape, params.dtype, []);\n  }\n\n  const outBuf = buffer([numSlices, sliceSize], params.dtype);\n  const indicesData = backend.data.get(indices.dataId).values as TypedArray;\n  const paramsData = backend.data.get(params.dataId).values as TypedArray;\n\n  for (let i = 0; i < numSlices; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      flattenIndex += dim * strides[j];\n      index.push(dim);\n    }\n    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {\n      throw new Error(\n          `Invalid indices: ${index} does not index into ${params.shape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      outBuf.values[i * sliceSize + k] =\n          paramsData[flattenIndex * sliceSize + k];\n    }\n  }\n\n  return backend.makeTensorInfo(resultShape, outBuf.dtype, outBuf.values);\n}\n\nexport const gatherNdConfig: KernelConfig = {\n  kernelName: GatherNd,\n  backendName: 'cpu',\n  kernelFunc: gatherNd as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherV2, GatherV2Attrs, GatherV2Inputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {gatherV2Impl} from './GatherV2_impl';\nimport {reshape} from './Reshape';\n\nexport function gatherV2(args: {\n  inputs: GatherV2Inputs,\n  backend: MathBackendCPU,\n  attrs: GatherV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, indices} = inputs;\n  const {axis, batchDims} = attrs;\n\n  assertNotComplex([x, indices], 'gatherV2');\n\n  let $batchDims = batchDims;\n\n  if (batchDims == null) {\n    $batchDims = 0;\n  }\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const parsedAxis = util.parseAxisParam(axis, x.shape)[0];\n  const shapeInfo = backend_util.segment_util.collectGatherOpShapeInfo(\n      x, indices, parsedAxis, $batchDims);\n\n  const flattenX = reshape({\n    inputs: {x},\n    backend,\n    attrs: {\n      shape: [\n        shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n        shapeInfo.sliceSize\n      ]\n    }\n  });\n\n  const flattenIndex = reshape({\n    inputs: {x: indices},\n    backend,\n    attrs: {shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize]}\n  });\n\n  const flattenOutputShape = [\n    shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n    shapeInfo.sliceSize\n  ];\n\n  const indicesBuf = backend.bufferSync(flattenIndex);\n  const xBuf = backend.bufferSync(flattenX);\n  const outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);\n\n  backend.disposeIntermediateTensorInfo(flattenX);\n  backend.disposeIntermediateTensorInfo(flattenIndex);\n\n  return backend.makeTensorInfo(\n      shapeInfo.outputShape, outBuf.dtype, outBuf.values);\n}\n\nexport const gatherV2Config: KernelConfig = {\n  kernelName: GatherV2,\n  backendName: 'cpu',\n  kernelFunc: gatherV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a >= b) ? 1 : 0);\nexport const greaterEqual = binaryKernelFunc(\n    GreaterEqual, greaterEqualImpl, null /* complexImpl */, 'bool');\n\nexport const greaterEqualConfig: KernelConfig = {\n  kernelName: GreaterEqual,\n  backendName: 'cpu',\n  kernelFunc: greaterEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IFFT, IFFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function ifft(args: {inputs: IFFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, true, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const ifftConfig: KernelConfig = {\n  kernelName: IFFT,\n  backendName: 'cpu',\n  kernelFunc: ifft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isFinite =\n    unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, 'bool');\n\nexport const isFiniteConfig: KernelConfig = {\n  kernelName: IsFinite,\n  backendName: 'cpu',\n  kernelFunc: isFinite,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isInf =\n    unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, 'bool');\n\nexport const isInfConfig: KernelConfig = {\n  kernelName: IsInf,\n  backendName: 'cpu',\n  kernelFunc: isInf,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isNaN =\n    unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, 'bool');\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'cpu',\n  kernelFunc: isNaN,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a <= b) ? 1 : 0);\nexport const lessEqual =\n    binaryKernelFunc(LessEqual, lessEqualImpl, null /* complexImpl */, 'bool');\n\nexport const lessEqualConfig: KernelConfig = {\n  kernelName: LessEqual,\n  backendName: 'cpu',\n  kernelFunc: lessEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LinSpace, LinSpaceAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {linSpaceImpl} from './LinSpace_impl';\n\nexport function linSpace(args: {backend: MathBackendCPU, attrs: LinSpaceAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {start, stop, num} = attrs;\n\n  const outVals = linSpaceImpl(start, stop, num);\n\n  return backend.makeTensorInfo([outVals.length], 'float32', outVals);\n}\n\nexport const linSpaceConfig: KernelConfig = {\n  kernelName: LinSpace,\n  backendName: 'cpu',\n  kernelFunc: linSpace as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const log1p = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));\n\nexport const log1pConfig: KernelConfig = {\n  kernelName: Log1p,\n  backendName: 'cpu',\n  kernelFunc: log1p,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalAnd} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const logicalAndImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a && b);\nexport const logicalAnd = binaryKernelFunc(\n    LogicalAnd, logicalAndImpl, null /* complexImpl */, 'bool');\n\nexport const logicalAndConfig: KernelConfig = {\n  kernelName: LogicalAnd,\n  backendName: 'cpu',\n  kernelFunc: logicalAnd\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const logicalNot =\n    unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, 'bool');\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'cpu',\n  kernelFunc: logicalNot,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalOr} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const logicalOrImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a || b);\nexport const logicalOr =\n    binaryKernelFunc(LogicalOr, logicalOrImpl, null /* complexImpl */, 'bool');\n\nexport const logicalOrConfig: KernelConfig = {\n  kernelName: LogicalOr,\n  backendName: 'cpu',\n  kernelFunc: logicalOr\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRN, LRNAttrs, LRNInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function lRN(\n    args: {inputs: LRNInputs, backend: MathBackendCPU, attrs: LRNAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  assertNotComplex(x, 'LRN');\n\n  const channels = x.shape[3];\n  const maxD = channels - 1;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const size = util.sizeFromShape(x.shape);\n  const result = new Float32Array(size);\n\n  function sumAcrossChannels(offset: number) {\n    const currentChannel = offset % channels;\n    let beginSumOffset =\n        offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n    const endSumOffset =\n        offset - currentChannel + Math.min(currentChannel + depthRadius, maxD);\n\n    let sum = 0.0;\n    for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n      const z = xValues[beginSumOffset];\n      sum += z * z;\n    }\n    return sum;\n  }\n\n  for (let offset = 0; offset < size; offset++) {\n    const sum = sumAcrossChannels(offset);\n    const val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n    result[offset] = val;\n  }\n\n  return backend.makeTensorInfo(x.shape, x.dtype, result);\n}\n\nexport const lRNConfig: KernelConfig = {\n  kernelName: LRN,\n  backendName: 'cpu',\n  kernelFunc: lRN as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRNGrad, LRNGradAttrs, LRNGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function lRNGrad(\n    args:\n        {inputs: LRNGradInputs, backend: MathBackendCPU, attrs: LRNGradAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, y, dy} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  assertNotComplex(dy, 'LRNGrad');\n\n  const dySize = util.sizeFromShape(dy.shape);\n\n  const channels = dy.shape[3];\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const yValues = backend.data.get(y.dataId).values as TypedArray;\n  const result = new Float32Array(dySize);\n  const size = dySize;\n\n  for (let offset = 0; offset < size; offset++) {\n    const currentChannel = offset % channels;\n    const depthBegin =\n        (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n    const depthEnd = (offset - currentChannel) +\n        Math.min(channels, currentChannel + depthRadius + 1);\n\n    let norm = 0;\n    for (let k = depthBegin; k < depthEnd; k++) {\n      norm += Math.pow(xValues[k], 2);\n    }\n    norm = alpha * norm + bias;\n\n    for (let k = depthBegin; k < depthEnd; k++) {\n      let dyi = -2 * alpha * beta * xValues[k] * yValues[offset] / norm;\n      if (offset === k) {\n        dyi += Math.pow(norm, -beta);\n      }\n      dyi *= dyValues[offset];\n      result[k] += dyi;\n    }\n  }\n\n  return backend.makeTensorInfo(dy.shape, x.dtype, result);\n}\n\nexport const lRNGradConfig: KernelConfig = {\n  kernelName: LRNGrad,\n  backendName: 'cpu',\n  kernelFunc: lRNGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: MathBackendCPU, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n  const cpuBackend = backend;\n  let xShape = x.shape;\n  const xRank = xShape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, xShape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n  if (permutedAxes != null) {\n    const newShape: number[] = new Array(xRank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = xShape[permutedAxes[i]];\n    }\n\n    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n    xShape = newShape;\n  }\n\n  assertNotComplex(x, 'max');\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, axes);\n\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    outShape = newShape;\n  }\n\n  return {dataId, shape: outShape, dtype: x.dtype};\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: max as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function maxPool(\n    args:\n        {inputs: MaxPoolInputs, backend: MathBackendCPU, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'maxPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'max');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'cpu',\n  kernelFunc: maxPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3D, MaxPool3DAttrs, MaxPool3DInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool3d} from '../utils/pool_utils';\n\nexport function maxPool3D(args: {\n  inputs: MaxPool3DInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode, dataFormat} = attrs;\n\n  assertNotComplex(x, 'maxPool3d');\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode, dataFormat);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = pool3d(\n      xValues, x.shape, x.dtype, util.computeStrides(x.shape), convInfo, 'max');\n\n  return backend.makeTensorInfo(outBuf.shape, 'float32', outBuf.values);\n}\n\nexport const maxPool3DConfig: KernelConfig = {\n  kernelName: MaxPool3D,\n  backendName: 'cpu',\n  kernelFunc: maxPool3D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPool3DGrad, MaxPool3DGradAttrs, MaxPool3DGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPool3dPositions} from '../utils/pool_utils';\n\nexport function maxPool3DGrad(args: {\n  inputs: MaxPool3DGradInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, input], 'maxPool3DGrad');\n\n  const convInfo = backend_util.computePool3DInfo(\n      input.shape as [number, number, number, number, number], filterSize,\n      strides, 1 /* dilations */, pad, dimRoundingMode);\n\n  const inputBuf = backend.bufferSync(input);\n  const maxPosBuf = maxPool3dPositions(inputBuf, convInfo);\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx = buffer(input.shape, 'float32');\n\n  const dyBuf = backend.bufferSync(dy);\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n            // Shader code begins\n            const dyDepthCorner = dxDepth - padFront;\n            const dyRowCorner = dxRow - padTop;\n            const dyColCorner = dxCol - padLeft;\n            let dotProd = 0;\n            for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                 wDepth += dilationDepth) {\n              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n              if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                  Math.floor(dyDepth) !== dyDepth) {\n                continue;\n              }\n              for (let wRow = 0; wRow < effectiveFilterHeight;\n                   wRow += dilationHeight) {\n                const dyRow = (dyRowCorner + wRow) / strideHeight;\n                if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                    Math.floor(dyRow) !== dyRow) {\n                  continue;\n                }\n                for (let wCol = 0; wCol < effectiveFilterWidth;\n                     wCol += dilationWidth) {\n                  const dyCol = (dyColCorner + wCol) / strideWidth;\n                  if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                      Math.floor(dyCol) !== dyCol) {\n                    continue;\n                  }\n\n                  const maxPos = effectiveFilterDepth * effectiveFilterHeight *\n                          effectiveFilterWidth -\n                      1 -\n                      (maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel) as\n                       number);\n                  const curPos =\n                      wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                      wRow * effectiveFilterWidth + wCol;\n\n                  const mask = maxPos === curPos ? 1 : 0;\n                  if (mask === 0) {\n                    continue;\n                  }\n\n                  const pixel =\n                      dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                  dotProd += pixel * mask;\n                }\n              }\n            }\n            dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPool3DGradConfig: KernelConfig = {\n  kernelName: MaxPool3DGrad,\n  backendName: 'cpu',\n  kernelFunc: maxPool3DGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPoolGrad, MaxPoolGradAttrs, MaxPoolGradInputs, Rank, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPoolPositions} from '../utils/pool_utils';\n\nexport function maxPoolGrad(args: {\n  inputs: MaxPoolGradInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input, output} = inputs;\n  const x = input;\n  assertNotComplex([input, output], 'maxPoolGrad');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const maxPosBuf = buffer(\n      convInfo.outShape, x.dtype,\n      maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n              const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 -\n                  (maxPosBuf.get(b, dyR, dyC, d) as number);\n              const curPos = wR * effectiveFilterWidth + wC;\n\n              const mask = maxPos === curPos ? 1 : 0;\n              if (mask === 0) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel * mask;\n            }\n          }\n          dx.set(dotProd, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPoolGradConfig: KernelConfig = {\n  kernelName: MaxPoolGrad,\n  backendName: 'cpu',\n  kernelFunc: maxPoolGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxPoolWithArgmaxImpl} from './MaxPoolWithArgmax_impl';\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxPoolWithArgmaxInputs;\n    const {filterSize, strides, pad, includeBatchInIndex} =\n        attrs as {} as MaxPoolWithArgmaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'MaxPoolWithArgmax');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const convInfo = backend_util.computePool2DInfo(\n        x.shape as [number, number, number, number], filterSize, strides,\n        [1, 1], pad);\n    const [pooled, indexes] = maxPoolWithArgmaxImpl(\n        values, x.shape, x.dtype, includeBatchInIndex, convInfo);\n\n    const pooledDataId =\n        cpuBackend.write(pooled as Float32Array, convInfo.outShape, x.dtype);\n    const indexesDataId =\n        cpuBackend.write(indexes as Int32Array, convInfo.outShape, x.dtype);\n    return [\n      {dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype},\n      {dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32'}\n    ];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {maxPoolPositions, pool} from '../utils/pool_utils';\nexport function maxPoolWithArgmaxImpl(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    includeBatchInIndex: boolean, convInfo: backend_util.Conv2DInfo) {\n  const strides = util.computeStrides(xShape);\n  const maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n  const maxPositions = maxPoolPositions(\n      xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n\n  return [maxPools.values, maxPositions.values];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Mean, MeanAttrs, MeanInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {cast} from './Cast';\nimport {div} from './RealDiv';\nimport {sum} from './Sum';\n\nexport function mean(\n    args: {inputs: MeanInputs, backend: MathBackendCPU, attrs: MeanAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  const axes = util.parseAxisParam(axis, x.shape);\n  const shapes = backend_util.computeOutAndReduceShapes(x.shape, axes);\n  const reduceShape = shapes[1];\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const toDispose = [];\n  const reduceSizeScalar =\n      backend.makeTensorInfo([], 'float32', new Float32Array([reduceSize]));\n  toDispose.push(reduceSizeScalar);\n\n  const $x = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n  toDispose.push($x);\n\n  const res =\n      div({inputs: {a: $x, b: reduceSizeScalar}, backend}) as TensorInfo;\n  toDispose.push(res);\n\n  const result = sum({inputs: {x: res}, backend, attrs: {axis, keepDims}});\n\n  toDispose.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const meanConfig: KernelConfig = {\n  kernelName: Mean,\n  backendName: 'cpu',\n  kernelFunc: mean as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Min, MinAttrs, MinInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function min(\n    args: {inputs: MinInputs, backend: MathBackendCPU, attrs: MinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'min');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('min', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let min = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value < min) {\n        min = value;\n      }\n    }\n    vals[i] = min;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const minConfig: KernelConfig = {\n  kernelName: Min,\n  backendName: 'cpu',\n  kernelFunc: min as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, MirrorPad, MirrorPadAttrs, MirrorPadInputs, NumericDataType, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function mirrorPad(args: {\n  inputs: MirrorPadInputs,\n  backend: MathBackendCPU,\n  attrs: MirrorPadAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, mode} = attrs;\n\n  assertNotComplex(x, 'mirrorPad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n  const end = paddings.map((p, i) => p[0] + x.shape[i]);\n  const offset = mode === 'reflect' ? 0 : 1;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  for (let i = 0; i < resultSize; i++) {\n    let coords = util.indexToLoc(i, resultRank, resultStrides);\n    for (let i = 0; i < resultRank; i++) {\n      if (coords[i] < start[i]) {\n        coords[i] = start[i] * 2 - coords[i] - offset;\n      } else if (coords[i] >= end[i]) {\n        coords[i] = (end[i] - 1) * 2 - coords[i] + offset;\n      }\n    }\n    coords = coords.map((c, i) => c - start[i]);\n\n    const inIndex = util.locToIndex(coords, xRank, xStrides);\n\n    resVals[i] = xVals[inIndex];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const mirrorPadConfig: KernelConfig = {\n  kernelName: MirrorPad,\n  backendName: 'cpu',\n  kernelFunc: mirrorPad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Mod} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const modImpl = createSimpleBinaryKernelImpl(((aValue, bValue) => {\n  const rem = aValue % bValue;\n  if ((aValue < 0 && bValue < 0) || (aValue >= 0 && bValue >= 0)) {\n    return rem;\n  } else {\n    return (rem + bValue) % bValue;\n  }\n}));\n\nexport const mod = binaryKernelFunc(Mod, modImpl);\n\nexport const modConfig: KernelConfig = {\n  kernelName: Mod,\n  backendName: 'cpu',\n  kernelFunc: mod\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {exp} from './Exp';\nimport {max} from './Max';\nimport {div} from './RealDiv';\nimport {reshape} from './Reshape';\nimport {sub} from './Sub';\nimport {sum} from './Sum';\n\nexport function softmax(\n    args:\n        {inputs: SoftmaxInputs, backend: MathBackendCPU, attrs: SoftmaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {dim} = attrs;\n\n  const logitsRank = logits.shape.length;\n\n  let $dim = dim;\n  if ($dim === -1) {\n    $dim = logitsRank - 1;\n  }\n  if ($dim !== logitsRank - 1) {\n    throw Error(\n        'Softmax along a non-last dimension is not yet supported. ' +\n        `Logits was rank ${logitsRank} and dim was ${$dim}`);\n  }\n\n  const axes = util.parseAxisParam([$dim], logits.shape);\n  const maxLogit = max({\n    inputs: {x: logits},\n    backend,\n    attrs: {reductionIndices: axes, keepDims: false}\n  });\n  const expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n\n  const maxLogitReshaped =\n      reshape({inputs: {x: maxLogit}, backend, attrs: {shape: expandedShape}});\n  const a =\n      sub({inputs: {a: logits, b: maxLogitReshaped}, backend}) as TensorInfo;\n  const b = exp({inputs: {x: a}, backend}) as TensorInfo;\n  const sumExp =\n      sum({inputs: {x: b}, backend, attrs: {axis: axes, keepDims: false}});\n  const sumReshaped =\n      reshape({inputs: {x: sumExp}, backend, attrs: {shape: expandedShape}});\n\n  const result = div({inputs: {a: b, b: sumReshaped}, backend}) as TensorInfo;\n\n  backend.disposeIntermediateTensorInfo(maxLogit);\n  backend.disposeIntermediateTensorInfo(maxLogitReshaped);\n  backend.disposeIntermediateTensorInfo(a);\n  backend.disposeIntermediateTensorInfo(b);\n  backend.disposeIntermediateTensorInfo(sumExp);\n  backend.disposeIntermediateTensorInfo(sumReshaped);\n\n  return result;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'cpu',\n  kernelFunc: softmax as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Multinomial, MultinomialAttrs, MultinomialInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {softmax} from './Softmax';\n\nexport function multinomial(args: {\n  inputs: MultinomialInputs,\n  backend: MathBackendCPU,\n  attrs: MultinomialAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {numSamples, seed, normalized} = attrs;\n\n  assertNotComplex(logits, 'multinomial');\n\n  const probabilities = normalized ?\n      logits :\n      softmax({inputs: {logits}, backend, attrs: {dim: -1}});\n\n  const batchSize = probabilities.shape[0];\n  const numEvents = probabilities.shape[1];\n  const probVals = backend.data.get(probabilities.dataId).values as TypedArray;\n  const resShape = [batchSize, numSamples];\n  const resVals =\n      util.makeZerosTypedArray(util.sizeFromShape(resShape), 'int32');\n\n  for (let b = 0; b < batchSize; ++b) {\n    const offset = b * numEvents;\n    // The cdf won't include the last event. It will be implicit if no other\n    // event happened.\n    const cdf = new Float32Array(numEvents - 1);\n    cdf[0] = probVals[offset];\n    for (let event = 1; event < cdf.length; ++event) {\n      cdf[event] = cdf[event - 1] + probVals[offset + event];\n    }\n\n    const random = seedrandom.alea(seed.toString());\n    const outOffset = b * numSamples;\n    for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n      const r = random();\n\n      // Assume last event happened by default.\n      resVals[outOffset + sampleId] = cdf.length;\n\n      for (let event = 0; event < cdf.length; event++) {\n        if (r < cdf[event]) {\n          resVals[outOffset + sampleId] = event;\n          break;\n        }\n      }\n    }\n  }\n\n  if (!normalized) {\n    backend.disposeIntermediateTensorInfo(probabilities);\n  }\n\n  return backend.makeTensorInfo(resShape, 'int32', resVals);\n}\n\nexport const multinomialConfig: KernelConfig = {\n  kernelName: Multinomial,\n  backendName: 'cpu',\n  kernelFunc: multinomial as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV3, NonMaxSuppressionV3Attrs, NonMaxSuppressionV3Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV3Impl = kernel_impls.nonMaxSuppressionV3Impl;\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV3(args: {\n  inputs: NonMaxSuppressionV3Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV3Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold} = attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppression');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const {selectedIndices} = nonMaxSuppressionV3Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n\n  return backend.makeTensorInfo(\n      [selectedIndices.length], 'int32', new Int32Array(selectedIndices));\n}\n\nexport const nonMaxSuppressionV3Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV3,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV3 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV4Impl = kernel_impls.nonMaxSuppressionV4Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV4(args: {\n  inputs: NonMaxSuppressionV4Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV4Attrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize} =\n      attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppressionPadded');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const {selectedIndices, validOutputs} = nonMaxSuppressionV4Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold,\n      padToMaxOutputSize);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo([], 'int32', new Int32Array([validOutputs]))\n  ];\n}\nexport const nonMaxSuppressionV4Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV4,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV4 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV5Impl = kernel_impls.nonMaxSuppressionV5Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV5(args: {\n  inputs: NonMaxSuppressionV5Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV5Attrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} = attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const maxOutputSizeVal = maxOutputSize;\n  const iouThresholdVal = iouThreshold;\n  const scoreThresholdVal = scoreThreshold;\n  const softNmsSigmaVal = softNmsSigma;\n\n  const {selectedIndices, selectedScores} = nonMaxSuppressionV5Impl(\n      boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n      scoreThresholdVal, softNmsSigmaVal);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo(\n        [selectedScores.length], 'float32', new Float32Array(selectedScores))\n  ];\n}\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV5 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OneHot, OneHotAttrs, OneHotInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function oneHot(\n    args: {inputs: OneHotInputs, backend: MathBackendCPU, attrs: OneHotAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices} = inputs;\n  const {depth, onValue, offValue} = attrs;\n\n  assertNotComplex(indices, 'oneHot');\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const res = new Float32Array(indicesSize * depth);\n  res.fill(offValue);\n  const indicesVal = backend.data.get(indices.dataId).values as TypedArray;\n\n  for (let event = 0; event < indicesSize; ++event) {\n    if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n      res[event * depth + indicesVal[event]] = onValue;\n    }\n  }\n\n  return backend.makeTensorInfo([...indices.shape, depth], 'int32', res);\n}\n\nexport const oneHotConfig: KernelConfig = {\n  kernelName: OneHot,\n  backendName: 'cpu',\n  kernelFunc: oneHot as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, ZerosLike, ZerosLikeInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\n\nexport function zerosLike(\n    args: {inputs: ZerosLikeInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('zerosLike is not supported for string tensors');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = zerosLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n    backend.disposeIntermediateTensorInfo(r);\n    backend.disposeIntermediateTensorInfo(imagPart);\n    backend.disposeIntermediateTensorInfo(i);\n\n    return result;\n  } else {\n    return fill({backend, attrs: {shape: x.shape, value: 0, dtype: x.dtype}});\n  }\n}\n\nexport const zerosLikeConfig: KernelConfig = {\n  kernelName: ZerosLike,\n  backendName: 'cpu',\n  kernelFunc: zerosLike as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OnesLike, OnesLikeInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {zerosLike} from './ZerosLike';\n\nexport function onesLike(\n    args: {inputs: OnesLikeInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('onesLike is not supported for string tensors');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = onesLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n    backend.disposeIntermediateTensorInfo(r);\n    backend.disposeIntermediateTensorInfo(imagPart);\n    backend.disposeIntermediateTensorInfo(i);\n\n    return result;\n  } else {\n    return fill({backend, attrs: {shape: x.shape, value: 1, dtype: x.dtype}});\n  }\n}\n\nexport const onesLikeConfig: KernelConfig = {\n  kernelName: OnesLike,\n  backendName: 'cpu',\n  kernelFunc: onesLike as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Pack, PackAttrs, PackInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {concat} from './Concat';\nimport {expandDims} from './ExpandDims';\n\nexport function pack(\n    args: {inputs: PackInputs, backend: MathBackendCPU, attrs: PackAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  if (inputs.length === 1) {\n    return expandDims(\n        {inputs: {input: inputs[0]}, backend, attrs: {dim: axis}});\n  }\n\n  const shape = inputs[0].shape;\n  const dtype = inputs[0].dtype;\n\n  inputs.forEach(t => {\n    util.assertShapesMatch(\n        shape, t.shape,\n        'All tensors passed to stack must have matching shapes');\n    util.assert(\n        dtype === t.dtype,\n        () => 'All tensors passed to stack must have matching dtypes');\n  });\n\n  const intermediateTensorInfos: TensorInfo[] = [];\n  const expandedTensors = inputs.map(t => {\n    const expandedT =\n        expandDims({inputs: {input: t}, backend, attrs: {dim: axis}});\n    intermediateTensorInfos.push(expandedT);\n    return expandedT;\n  });\n\n  const result = concat({inputs: expandedTensors, backend, attrs: {axis}});\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const packConfig: KernelConfig = {\n  kernelName: Pack,\n  backendName: 'cpu',\n  kernelFunc: pack as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function padV2(\n    args: {inputs: PadV2Inputs, backend: MathBackendCPU, attrs: PadV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, constantValue} = attrs;\n\n  assertNotComplex(x, 'pad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xSize = util.sizeFromShape(x.shape);\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  if (constantValue !== 0) {\n    resVals.fill(constantValue);\n  }\n\n  for (let i = 0; i < xSize; i++) {\n    const coords = util.indexToLoc(i, xRank, xStrides);\n    const outCoords = coords.map((c, i) => c + start[i]);\n    const outIndex = util.locToIndex(outCoords, resultRank, resultStrides);\n\n    resVals[outIndex] = xVals[i];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'cpu',\n  kernelFunc: padV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Pow} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const powImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => Math.pow(a, b));\nexport const pow = binaryKernelFunc(Pow, powImpl);\n\nexport const powConfig: KernelConfig = {\n  kernelName: Pow,\n  backendName: 'cpu',\n  kernelFunc: pow\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Range, RangeAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {rangeImpl} from './Range_impl';\n\nexport function range(args: {backend: MathBackendCPU, attrs: RangeAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {start, stop, dtype, step} = attrs;\n\n  const values = rangeImpl(start, stop, step, dtype);\n  return backend.makeTensorInfo([values.length], dtype, values);\n}\n\nexport const rangeConfig: KernelConfig = {\n  kernelName: Range,\n  backendName: 'cpu',\n  kernelFunc: range as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const reciprocal = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'cpu',\n  kernelFunc: reciprocal,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinear, ResizeBilinearAttrs, ResizeBilinearInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeBilinear(args: {\n  inputs: ResizeBilinearInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeBilinearAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  assertNotComplex(images, 'resizeBilinear');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const [newHeight, newWidth] = size;\n\n  const [batch, oldHeight, oldWidth, numChannels] = images.shape;\n  const xValues = backend.data.get(images.dataId).values as TypedArray;\n  const result = new Float32Array(\n      util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n\n  const effectiveInputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n    (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n  ];\n\n  const effectiveOutputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n    (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n  ];\n  let outputIdx = 0;\n  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n  for (let b = 0; b < batch; b++) {\n    for (let r = 0; r < newHeight; r++) {\n      let sourceFracRow: number;\n      if (halfPixelCenters) {\n        sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;\n      } else {\n        sourceFracRow = effectiveRowSizeRatio * r;\n      }\n\n      const sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));\n      const rowFrac = sourceFracRow - sourceRowFloor;\n      const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n      const topRowOffset =\n          b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];\n      const botRowOffset =\n          b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];\n      for (let c = 0; c < newWidth; c++) {\n        let sourceFracCol: number;\n        if (halfPixelCenters) {\n          sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;\n        } else {\n          sourceFracCol = effectiveColSizeRatio * c;\n        }\n        const sourceColFloor = Math.max(0, Math.floor(sourceFracCol));\n        const colFrac = sourceFracCol - sourceColFloor;\n        const sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n        const topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];\n        const botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];\n        const topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];\n        const botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];\n        for (let d = 0; d < numChannels; d++) {\n          // Begin shader.\n\n          // Compute the fractional index of the source.\n          const topLeft = xValues[topLeftOffest + d];\n          const bottomLeft = xValues[botLeftOffset + d];\n          const topRight = xValues[topRightOffset + d];\n          const bottomRight = xValues[botRightOffest + d];\n\n          const top = topLeft + (topRight - topLeft) * colFrac;\n          const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n          const newValue = top + (bottom - top) * rowFrac;\n\n          result[outputIdx++] = newValue;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, newHeight, newWidth, numChannels], 'float32', result);\n}\n\nexport const resizeBilinearConfig: KernelConfig = {\n  kernelName: ResizeBilinear,\n  backendName: 'cpu',\n  kernelFunc: resizeBilinear as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinearGrad, ResizeBilinearGradAttrs, ResizeBilinearGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeBilinearGrad(args: {\n  inputs: ResizeBilinearGradInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeBilinearGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  assertNotComplex([dy, images], 'resizeBilinearGrad');\n\n  const imagesStrides = util.computeStrides(images.shape);\n\n  const [batch, xHeight, xWidth, depth] = images.shape;\n  const [, yHeight, yWidth] = dy.shape;\n\n  const output = new Float32Array(batch * xHeight * xWidth * depth);\n\n  // In the backwards pass, we want to find the pixels that were generated\n  // for each pixel in the input image the forward pass and add the\n  // corresponding coefficient from dy to the gradient (with some\n  // interpolation).\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  // Reference implementation\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  let offset = 0;\n  for (let b = 0; b < batch; b++) {\n    const bOffset = b * imagesStrides[0];\n    for (let r = 0; r < yHeight; r++) {\n      const dxR = r * heightScale;\n      const topDxRIndex = Math.floor(dxR);\n      const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n\n      const topDxROffset = bOffset + topDxRIndex * imagesStrides[1];\n      const bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];\n\n      const dxRLerp = dxR - topDxRIndex;\n      const inverseDxRLerp = 1.0 - dxRLerp;\n      for (let c = 0; c < yWidth; c++) {\n        const dxC = c * widthScale;\n        const leftDxCIndex = Math.floor(dxC);\n        const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n        const dxCLerp = dxC - leftDxCIndex;\n        const inverseDxCLerp = 1.0 - dxCLerp;\n\n        const topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];\n        const topRightRCOffset =\n            topDxROffset + rightDxCIndex * imagesStrides[2];\n        const bottomLeftRCOffset =\n            bottomDxROffset + leftDxCIndex * imagesStrides[2];\n        const bottomRightRCOffset =\n            bottomDxROffset + rightDxCIndex * imagesStrides[2];\n\n        const inverseDxRLerpTimesInverseDxCLerp =\n            inverseDxRLerp * inverseDxCLerp;\n        const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n        const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n        const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n        for (let d = 0; d < depth; d++) {\n          const dyVal = dyValues[offset++];\n          output[topLeftRCOffset + d] +=\n              dyVal * inverseDxRLerpTimesInverseDxCLerp;\n          output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n          output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;\n          output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, xWidth, xHeight, depth], 'float32', output);\n}\n\nexport const resizeBilinearGradConfig: KernelConfig = {\n  kernelName: ResizeBilinearGrad,\n  backendName: 'cpu',\n  kernelFunc: resizeBilinearGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighbor, ResizeNearestNeighborAttrs, ResizeNearestNeighborInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeNearestNeighbor(args: {\n  inputs: ResizeNearestNeighborInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeNearestNeighborAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  assertNotComplex(images, 'resizeNearestNeighbor');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const [newHeight, newWidth] = size;\n\n  const [batch, oldHeight, oldWidth, numChannels] = images.shape;\n  const xValues = backend.data.get(images.dataId).values as TypedArray;\n  const output = new Float32Array(batch * newHeight * newWidth * numChannels);\n\n  const effectiveInputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n    (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n  ];\n\n  const effectiveOutputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n    (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n  ];\n\n  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n\n  let outputOffset = 0;\n  for (let b = 0; b < batch; b++) {\n    const batchOffset = b * imagesStrides[0];\n    for (let r = 0; r < newHeight; r++) {\n      const sourceFracRow = halfPixelCenters ?\n          effectiveRowSizeRatio * (r + 0.5) :\n          effectiveRowSizeRatio * r;\n      let sourceNearestRow = Math.min(\n          oldHeight - 1,\n          alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));\n      if (halfPixelCenters) {\n        sourceNearestRow = Math.max(0, sourceNearestRow);\n      }\n      const rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];\n      for (let c = 0; c < newWidth; c++) {\n        const sourceFracCol = halfPixelCenters ?\n            effectiveColSizeRatio * (c + 0.5) :\n            effectiveColSizeRatio * c;\n        let sourceNearestCol = Math.min(\n            oldWidth - 1,\n            alignCorners ? Math.round(sourceFracCol) :\n                           Math.floor(sourceFracCol));\n        if (halfPixelCenters) {\n          sourceNearestCol = Math.max(0, sourceNearestCol);\n        }\n        const colOffset = rowOffset + sourceNearestCol * imagesStrides[2];\n        for (let d = 0; d < numChannels; d++) {\n          // Begin shader.\n          // Compute the fractional index of the source.\n          const newVal = xValues[colOffset + d];\n          output[outputOffset++] = newVal;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, newHeight, newWidth, numChannels], images.dtype, output);\n}\n\nexport const resizeNearestNeighborConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighbor,\n  backendName: 'cpu',\n  kernelFunc: resizeNearestNeighbor as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighborGrad, ResizeNearestNeighborGradAttrs, ResizeNearestNeighborGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeNearestNeighborGrad(args: {\n  inputs: ResizeNearestNeighborGradInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeNearestNeighborGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  assertNotComplex([dy, images], 'resizeNearestNeighborGrad');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n  const [batch, xHeight, xWidth, depth] = images.shape;\n  const [, yHeight, yWidth] = dy.shape;\n\n  const output = new Float32Array(batch * xHeight * xWidth * depth);\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n\n  // In the backwards pass, we want to find the pixels that were generated\n  // for each pixel in the input image the forward pass\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  const invHeightScale = 1 / heightScale;\n  const invWidthScale = 1 / widthScale;\n\n  // This defines the size of the window of values around a particular\n  // index in dy that we want to search for contributions to dx.\n  const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n  const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n  // Loop over the output space.\n  for (let b = 0; b < batch; b++) {\n    const batchOffset = b * imagesStrides[0];\n    for (let r = 0; r < xHeight; r++) {\n      const rowOffset = batchOffset + r * imagesStrides[1];\n\n      // Compute bounds for where in dy we will look\n      const startRLerp = Math.floor(r * invHeightScale);\n      const startDyR = Math.floor(startRLerp - (winHeight / 2));\n      for (let c = 0; c < xWidth; c++) {\n        const colOffset = rowOffset + c * imagesStrides[2];\n\n        // Compute bounds for where in dy we will look\n        const startCLerp = Math.floor(c * invWidthScale);\n        const startDyC = Math.floor(startCLerp - (winWidth / 2));\n\n        for (let d = 0; d < depth; d++) {\n          let accum = 0;\n          // loop over dy\n\n          for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n            const dyR = dyRIndex + startDyR;\n            // Guard against the window exceeding the bounds of dy\n            if (dyR < 0 || dyR >= yHeight) {\n              continue;\n            }\n\n            const dyROffset = batchOffset + dyR * dyStrides[1];\n            const sourceFracRow = dyR * heightScale;\n            const sourceNearestRow = Math.min(\n                xHeight - 1,\n                alignCorners ? Math.round(sourceFracRow) :\n                               Math.floor(sourceFracRow));\n            if (r !== sourceNearestRow) {\n              continue;\n            }\n            for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n              const dyC = dyCIndex + startDyC;\n              // Guard against the window exceeding the bounds of dy\n              if (dyC < 0 || dyC >= yWidth) {\n                continue;\n              }\n\n              const dyCOffset = dyROffset + dyC * dyStrides[2];\n              const sourceFracCol = dyC * widthScale;\n              const sourceNearestCol = Math.min(\n                  xWidth - 1,\n                  alignCorners ? Math.round(sourceFracCol) :\n                                 Math.floor(sourceFracCol));\n\n              if (c === sourceNearestCol) {\n                accum += dyValues[dyCOffset + d];\n              }\n            }\n          }\n          output[colOffset + d] = accum;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(images.shape, images.dtype, output);\n}\n\nexport const resizeNearestNeighborGradConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighborGrad,\n  backendName: 'cpu',\n  kernelFunc: resizeNearestNeighborGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reverse, ReverseAttrs, ReverseInputs, TensorBuffer, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {identity} from './Identity';\n\nexport function reverse(\n    args:\n        {inputs: ReverseInputs, backend: MathBackendCPU, attrs: ReverseAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dims} = attrs;\n\n  assertNotComplex(x, 'reverse');\n\n  const xRank = x.shape.length;\n\n  const $dims = util.parseAxisParam(dims, x.shape);\n  if (xRank === 0) {\n    return identity({inputs: {x}, backend});\n  }\n\n  const outBuf = new TensorBuffer(x.shape, x.dtype);\n  const xBuf = backend.bufferSync(x);\n\n  for (let i = 0; i < outBuf.size; i++) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.slice();\n    $dims.forEach(d => inLoc[d] = x.shape[d] - 1 - inLoc[d]);\n    outBuf.set(xBuf.get(...inLoc), ...outLoc);\n  }\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const reverseConfig: KernelConfig = {\n  kernelName: Reverse,\n  backendName: 'cpu',\n  kernelFunc: reverse as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util, RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n  kernelName: RotateWithOffset,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as RotateWithOffsetInputs;\n    const {radians, fillValue, center} = attrs as {} as RotateWithOffsetAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const [centerX, centerY] =\n        backend_util.getImageCenter(center, imageHeight, imageWidth);\n    const fullOpacityValue = 255;\n\n    const sinFactor = Math.sin(radians);\n    const cosFactor = Math.cos(radians);\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n            const y = coords[1];\n\n            // coordX/coordY are the result of rotating and translating x/y.\n            let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;\n            let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;\n            coordX = Math.round(coordX + centerX);\n            coordY = Math.round(coordY + centerY);\n\n            let outputValue = fillValue;\n            if (typeof fillValue !== 'number') {\n              if (channel === 3) {\n                outputValue = fullOpacityValue;\n              } else {\n                outputValue = fillValue[channel];\n              }\n            }\n\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth && coordY >= 0 &&\n                coordY < imageHeight) {\n              // set the output to the image value at the coordinate position.\n              const rotatedRowOffset = coordY * (imageWidth * numChannels);\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rotatedRowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n            output[outIdx] = outputValue as number;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const round = unaryKernelFunc(Round, (xi) => {\n  // The algorithm is based on banker's rounding.\n  const base = Math.floor(xi);\n  if (xi - base < 0.5) {\n    return Math.floor(xi);\n  } else if (xi - base > 0.5) {\n    return Math.ceil(xi);\n  } else {\n    if (base % 2.0 === 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n});\n\nexport const roundConfig: KernelConfig = {\n  kernelName: Round,\n  backendName: 'cpu',\n  kernelFunc: round,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {buffer, Rank, ShapeMap, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function scatterImpl<R extends Rank>(\n    indices: TensorBuffer<R>, updates: TensorBuffer<R>, shape: number[],\n    outputSize: number, sliceSize: number, numUpdates: number,\n    sliceRank: number, strides: number[], defaultValue: number,\n    sumDupeIndices: boolean): TensorBuffer<R> {\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  const indicesData = indices.values as TypedArray;\n  const updatesData = updates.values as TypedArray;\n\n  if (outputSize === 0) {\n    return buffer(shape as ShapeMap[R], updates.dtype);\n  }\n\n  const outBuf = buffer(flattenShape, updates.dtype);\n  (outBuf.values as TypedArray).fill(defaultValue);\n\n  for (let i = 0; i < numUpdates; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      index.push(dim);\n      flattenIndex += dim * strides[j];\n    }\n\n    if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n      throw new Error(`Invalid indices: ${index} does not index into ${shape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      if (sumDupeIndices) {\n        outBuf.values[flattenIndex * sliceSize + k] +=\n            updatesData[i * sliceSize + k];\n      } else {\n        outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n            updatesData[0] :\n            updatesData[i * sliceSize + k];\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ScatterNd, ScatterNdAttrs, ScatterNdInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {scatterImpl} from './Scatter_impl';\n\nexport function scatterNd(args: {\n  inputs: ScatterNdInputs,\n  backend: MathBackendCPU,\n  attrs: ScatterNdAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices, updates} = inputs;\n  const {shape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, shape);\n  const sumDupeIndices = true;\n\n  const indicesBuf = backend.bufferSync(indices);\n  const updatesBuf = backend.bufferSync(updates);\n\n  const outBuf = scatterImpl(\n      indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates,\n      sliceRank, strides, 0 /* defaultValue */, sumDupeIndices);\n\n  return backend.makeTensorInfo(shape, outBuf.dtype, outBuf.values);\n}\n\nexport const scatterNdConfig: KernelConfig = {\n  kernelName: ScatterNd,\n  backendName: 'cpu',\n  kernelFunc: scatterNd as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Select, SelectInputs, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function select(args: {inputs: SelectInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {condition, t, e} = inputs;\n\n  assertNotComplex([condition, t, e], 'select');\n  const conditionRank = condition.shape.length;\n\n  const values = backend.data.get(condition.dataId).values as TypedArray;\n  const tValues = backend.data.get(t.dataId).values as TypedArray;\n  const eValues = backend.data.get(e.dataId).values as TypedArray;\n  const resultDtype = upcastType(t.dtype, e.dtype);\n  const newValues =\n      util.makeZerosTypedArray(util.sizeFromShape(t.shape), resultDtype);\n\n  let index = 0;\n  const offset =\n      conditionRank === 0 || conditionRank > 1 || t.shape.length === 1 ?\n      1 :\n      util.sizeFromShape(t.shape.slice(1));\n\n  for (let i = 0; i < values.length; i++) {\n    for (let j = 0; j < offset; j++) {\n      if (values[i] === 1) {\n        newValues[index++] = tValues[i];\n      } else {\n        newValues[index++] = eValues[i];\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(t.shape, resultDtype, newValues);\n}\n\nexport const selectConfig: KernelConfig = {\n  kernelName: Select,\n  backendName: 'cpu',\n  kernelFunc: select as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst scaleAlpha = backend_util.SELU_SCALEALPHA;\nconst scale = backend_util.SELU_SCALE;\n\nexport const selu = unaryKernelFunc(Selu, (xi) => {\n  if (xi >= 0) {\n    return scale * xi;\n  } else {\n    return scaleAlpha * (Math.exp(xi) - 1);\n  }\n});\n\nexport const seluConfig: KernelConfig = {\n  kernelName: Selu,\n  backendName: 'cpu',\n  kernelFunc: selu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sign = unaryKernelFunc(Sign, (xi) => {\n  if (xi < 0) {\n    return -1;\n  } else if (xi > 0) {\n    return 1;\n  } else {\n    return 0;\n  }\n});\n\nexport const signConfig: KernelConfig = {\n  kernelName: Sign,\n  backendName: 'cpu',\n  kernelFunc: sign,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sin = unaryKernelFunc(Sin, (xi) => Math.sin(xi));\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'cpu',\n  kernelFunc: sin,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sinh = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'cpu',\n  kernelFunc: sinh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\n// mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\nconst epsilon = 1.1920928955078125e-7;\nconst threshold = Math.log(epsilon) + 2.0;\n\nexport const softplus = unaryKernelFunc(Softplus, (xi) => {\n  // Value above which exp(x) may overflow, but softplus(x) == x\n  // is within machine epsilon.\n  const tooLarge = xi > -threshold;\n\n  // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n  // is within machine epsilon.\n  const tooSmall = xi < threshold;\n\n  const expX = Math.exp(xi);\n  let result;\n\n  if (tooSmall) {\n    result = expX;\n  } else if (tooLarge) {\n    result = xi;\n  } else {\n    result = Math.log(1.0 + expX);\n  }\n  return result;\n});\n\nexport const softplusConfig: KernelConfig = {\n  kernelName: Softplus,\n  backendName: 'cpu',\n  kernelFunc: softplus,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ReshapeAttrs, ReshapeInputs, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, TransposeAttrs, TransposeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {padV2Config} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function spaceToBatchND(args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: MathBackendCPU,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  assertNotComplex([x], 'spaceToBatchND');\n\n  const prod = util.sizeFromShape(blockShape);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...(paddings as Array<[number, number]>));\n\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedX = padV2Config.kernelFunc({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  }) as TensorInfo;\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapeInputs: ReshapeInputs = {x: paddedX};\n  const reshapeAttrs: ReshapeAttrs = {shape: reshapedPaddedShape};\n  const paddedXReshaped =\n      reshape({inputs: reshapeInputs, backend, attrs: reshapeAttrs});\n\n  const transposeInputs: TransposeInputs = {x: paddedXReshaped};\n  const transposeAttrs:\n      TransposeAttrs = {perm: permutedReshapedPaddedPermutation};\n  const paddedXT =\n      transpose({inputs: transposeInputs, backend, attrs: transposeAttrs});\n\n  const resultReshapeInputs: ReshapeInputs = {x: paddedXT};\n  const resultReshapeAttrs: ReshapeAttrs = {shape: flattenShape};\n  const result = reshape(\n      {inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs});\n\n  backend.disposeIntermediateTensorInfo(paddedX);\n  backend.disposeIntermediateTensorInfo(paddedXReshaped);\n  backend.disposeIntermediateTensorInfo(paddedXT);\n\n  return result;\n}\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'cpu',\n  kernelFunc: spaceToBatchND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseFillEmptyRows, SparseFillEmptyRowsInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseFillEmptyRowsImpl} from './SparseFillEmptyRows_impl';\n\nexport function sparseFillEmptyRows(args: {\n  inputs: SparseFillEmptyRowsInputs,\n  backend: MathBackendCPU\n}): [TensorInfo, TensorInfo, TensorInfo, TensorInfo] {\n  const {inputs, backend} = args;\n  const {indices, values, denseShape, defaultValue} = inputs;\n  if (denseShape.shape.length !== 1) {\n    throw new Error(`Dense shape must be a vector, saw:\n        ${denseShape.shape}`);\n  }\n  if (indices.shape.length !== 2) {\n    throw new Error(`Indices must be a matrix, saw:\n        ${indices.shape}`);\n  }\n  if (values.shape.length !== 1) {\n    throw new Error(`Values must be a vector, saw:\n        ${values.shape}`);\n  }\n  if (defaultValue.shape.length !== 0) {\n    throw new Error(`Default value must be a scalar, saw:\n        ${defaultValue.shape}`);\n  }\n\n  const $indices = backend.data.get(indices.dataId).values as TypedArray;\n  const $values = backend.data.get(values.dataId).values as TypedArray;\n  const $denseShape = backend.data.get(denseShape.dataId).values as TypedArray;\n  const $defaultValue =\n      backend.data.get(defaultValue.dataId).values[0] as number;\n\n  const [outputIndices, outputIndicesShape, outputValues,\n         emptyRowIndicator, reverseIndexMap] =\n      sparseFillEmptyRowsImpl(\n          $indices, indices.shape, indices.dtype, $values, values.dtype,\n          $denseShape, $defaultValue);\n  return [\n    backend.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),\n    backend.makeTensorInfo(\n        [outputIndicesShape[0]], values.dtype, outputValues),\n    backend.makeTensorInfo(\n        [emptyRowIndicator.length], 'bool',\n        new Uint8Array(\n            emptyRowIndicator.map((value: boolean) => Number(value)))),\n    backend.makeTensorInfo(\n        [reverseIndexMap.length], indices.dtype,\n        new Int32Array(reverseIndexMap)),\n  ];\n}\n\nexport const sparseFillEmptyRowsConfig: KernelConfig = {\n  kernelName: SparseFillEmptyRows,\n  backendName: 'cpu',\n  kernelFunc: sparseFillEmptyRows as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SparseReshape, SparseReshapeInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseReshapeImpl} from './SparseReshape_impl';\n\nexport function sparseReshape(\n    args: {inputs: SparseReshapeInputs, backend: MathBackendCPU}):\n    [TensorInfo, TensorInfo] {\n  const {inputs, backend} = args;\n  const {inputIndices, inputShape, newShape} = inputs;\n  if (inputIndices.shape.length !== 2) {\n    throw new Error(`Input indices should be a matrix but received shape\n        ${inputIndices.shape}`);\n  }\n  if (inputShape.shape.length !== 1) {\n    throw new Error(`Input shape should be a vector but received shape\n        ${inputShape.shape}`);\n  }\n\n  if (newShape.shape.length !== 1) {\n    throw new Error(\n        `Target shape should be a vector but received shape ${newShape.shape}`);\n  }\n\n  const $inputShape =\n      Array.from(backend.data.get(inputShape.dataId).values as TypedArray);\n  const $inputIndices =\n      backend.data.get(inputIndices.dataId).values as TypedArray;\n  const targetShape =\n      Array.from(backend.data.get(newShape.dataId).values as TypedArray);\n\n  const [newIndices, indicesShape, outputShape] = sparseReshapeImpl(\n      $inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape,\n      targetShape);\n  return [\n    backend.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),\n    backend.makeTensorInfo(\n        [outputShape.length], newShape.dtype, new Int32Array(outputShape)),\n  ];\n}\n\nexport const sparseReshapeConfig: KernelConfig = {\n  kernelName: SparseReshape,\n  backendName: 'cpu',\n  kernelFunc: sparseReshape,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, SparseToDense, SparseToDenseAttrs, SparseToDenseInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {scatterImpl} from './Scatter_impl';\n\nexport function sparseToDense(args: {\n  inputs: SparseToDenseInputs,\n  backend: MathBackendCPU,\n  attrs: SparseToDenseAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sparseIndices, sparseValues, defaultValue} = inputs;\n  const {outputShape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n  const sumDupeIndices = false;\n\n  const indicesBuf = backend.bufferSync(sparseIndices);\n  const updatesBuf = backend.bufferSync(sparseValues);\n  const $defaultValue =\n      backend.data.get(defaultValue.dataId).values[0] as number;\n\n  const outBuf = scatterImpl(\n      indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates,\n      sliceRank, strides, $defaultValue, sumDupeIndices);\n\n  return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);\n}\n\nexport const sparseToDenseConfig: KernelConfig = {\n  kernelName: SparseToDense,\n  backendName: 'cpu',\n  kernelFunc: sparseToDense as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, SplitVAttrs, SplitVInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, KernelFunc, SplitV, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {slice} from './Slice';\n\nexport function splitV(\n    args: {inputs: SplitVInputs, backend: MathBackendCPU, attrs: SplitVAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {numOrSizeSplits, axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, x.shape)[0];\n  const splitSizes = backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);\n\n  const begin = new Array(x.shape.length).fill(0);\n  const size = x.shape.slice();\n  return splitSizes.map(s => {\n    const sliceSize = [...size];\n    sliceSize[$axis] = s;\n    const sliceT =\n        slice({inputs: {x}, backend, attrs: {begin, size: sliceSize}});\n    begin[$axis] += s;\n    return sliceT;\n  });\n}\n\nexport const splitVConfig: KernelConfig = {\n  kernelName: SplitV,\n  backendName: 'cpu',\n  kernelFunc: splitV as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sqrt = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'cpu',\n  kernelFunc: sqrt,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'square');\n\n    const values = cpuBackend.data.get(x.dataId).values as Float32Array;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Step, StepAttrs} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const step = unaryKernelFunc(Step, (xi, attrs) => {\n  const stepAttrs = attrs as {} as StepAttrs;\n  if (isNaN(xi)) {\n    return NaN;\n  } else {\n    return xi > 0 ? 1 : stepAttrs.alpha;\n  }\n});\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'cpu',\n  kernelFunc: step,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, slice_util, StridedSlice, StridedSliceAttrs, StridedSliceInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {stridedSliceImpl} from './StridedSlice_impl';\n\nexport function stridedSlice(args: {\n  inputs: StridedSliceInputs,\n  backend: MathBackendCPU,\n  attrs: StridedSliceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {\n    begin,\n    end,\n    strides,\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  } = attrs;\n\n  assertNotComplex(x, 'stridedSlice');\n\n  const {nonStrided, $begin, $strides, size, newShape, outShape} =\n      slice_util.sliceInfo(\n          x.shape, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask);\n\n  const $x = reshape({inputs: {x}, backend, attrs: {shape: newShape}});\n\n  let result;\n  if (nonStrided) {\n    const sliced =\n        slice({inputs: {x: $x}, backend, attrs: {begin: $begin, size}});\n    result = reshape({inputs: {x: sliced}, backend, attrs: {shape: outShape}});\n\n    backend.disposeIntermediateTensorInfo(sliced);\n  } else if (outShape.some(axis => axis === 0)) {\n    result = backend.makeTensorInfo(outShape, x.dtype, []);\n  } else {\n    const xBuf = backend.bufferSync($x);\n    const outBuf = stridedSliceImpl(outShape, xBuf, $strides, $begin);\n\n    result = backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n  }\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: outShape}});\n\n  backend.disposeIntermediateTensorInfo($x);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const stridedSliceConfig: KernelConfig = {\n  kernelName: StridedSlice,\n  backendName: 'cpu',\n  kernelFunc: stridedSlice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tan = unaryKernelFunc(Tan, (xi) => Math.tan(xi));\n\nexport const tanConfig: KernelConfig = {\n  kernelName: Tan,\n  backendName: 'cpu',\n  kernelFunc: tan,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tanh = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'cpu',\n  kernelFunc: tanh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Tile, TileAttrs, TileInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {tileImpl} from './Tile_impl';\n\nexport function tile(\n    args: {inputs: TileInputs, backend: MathBackendCPU, attrs: TileAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reps} = attrs;\n\n  assertNotComplex(x, 'tile');\n  const outBuf = tileImpl(backend.bufferSync(x), reps);\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const tileConfig: KernelConfig = {\n  kernelName: Tile,\n  backendName: 'cpu',\n  kernelFunc: tile as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, TopK, TopKAttrs, TopKInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {topKImpl} from './TopK_impl';\n\nexport function topK(\n    args: {inputs: TopKInputs, backend: MathBackendCPU, attrs: TopKAttrs}):\n    [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {k, sorted} = attrs;\n\n  assertNotComplex(x, 'topk');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const [allTopKVals, allTopKIndices] =\n      topKImpl(xVals, x.shape, x.dtype as NumericDataType, k, sorted);\n\n  return [\n    backend.makeTensorInfo(\n        allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),\n    backend.makeTensorInfo(\n        allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)\n  ];\n}\n\nexport const topKConfig: KernelConfig = {\n  kernelName: TopK,\n  backendName: 'cpu',\n  kernelFunc: topK as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, Transform, TransformAttrs, TransformInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function transform(args: {\n  inputs: TransformInputs,\n  attrs: TransformAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {image, transforms} = inputs;\n  const {interpolation, fillMode, fillValue, outputShape} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const [outHeight, outWidth] =\n      outputShape != null ? outputShape : [imageHeight, imageWidth];\n  const outShape = [batch, outHeight, outWidth, numChannels];\n\n  const strides = util.computeStrides(image.shape);\n  const batchStride = strides[0];\n  const rowStride = strides[1];\n  const colStride = strides[2];\n\n  const outVals = util.getTypedArrayFromDType(\n      image.dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  outVals.fill(fillValue);\n\n  const imageVals = backend.data.get(image.dataId).values as TypedArray;\n  const transformVals =\n      backend.data.get(transforms.dataId).values as TypedArray;\n\n  // Ref TF implementation:\n  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/image/image_ops.h\n  for (let b = 0; b < batch; ++b) {\n    const transform = transforms.shape[0] === 1 ?\n        transformVals :\n        transformVals.subarray(b * 8, b * 8 + 8);\n\n    for (let outY = 0; outY < outHeight; ++outY) {\n      for (let outX = 0; outX < outWidth; ++outX) {\n        for (let channel = 0; channel < numChannels; ++channel) {\n          let val;\n\n          const projection = transform[6] * outX + transform[7] * outY + 1;\n\n          if (projection === 0) {\n            // Return the fill value for infinite coordinates,\n            // which are outside the input image\n            continue;\n          }\n\n          const inX =\n              (transform[0] * outX + transform[1] * outY + transform[2]) /\n              projection;\n          const inY =\n              (transform[3] * outX + transform[4] * outY + transform[5]) /\n              projection;\n\n          const x = mapCoord(inX, imageWidth, fillMode);\n          const y = mapCoord(inY, imageHeight, fillMode);\n\n          switch (interpolation) {\n            case 'nearest':\n              val = nearestInterpolation(\n                  imageVals, imageHeight, imageWidth, batchStride, rowStride,\n                  colStride, b, y, x, channel, fillValue);\n              break;\n            case 'bilinear':\n              val = bilinearInterpolation(\n                  imageVals, imageHeight, imageWidth, batchStride, rowStride,\n                  colStride, b, y, x, channel, fillValue);\n              break;\n            default:\n              throw new Error(\n                  `Error in Transform: Expect 'nearest' or ` +\n                  `'bilinear', but got ${interpolation}`);\n          }\n\n          const ind =\n              b * batchStride + outY * rowStride + outX * colStride + channel;\n\n          outVals[ind] = val;\n        }\n      }\n    }\n\n    return backend.makeTensorInfo(outShape, image.dtype, outVals);\n  }\n\n  const dataId = backend.write(outVals, outShape, image.dtype);\n  return {dataId, shape: image.shape, dtype: image.dtype};\n}\n\nexport const transformConfig: KernelConfig = {\n  kernelName: Transform,\n  backendName: 'cpu',\n  kernelFunc: transform as {} as KernelFunc\n};\n\nfunction mapCoord(\n    outCoord: number, len: number,\n    mode: 'constant'|'reflect'|'wrap'|'nearest') {\n  switch (mode) {\n    case 'reflect':\n      return mapCoordReflect(outCoord, len);\n    case 'wrap':\n      return mapCoordWrap(outCoord, len);\n    case 'nearest':\n      return mapCoordNearest(outCoord, len);\n    case 'constant':\n    default:\n      return mapCoordConstant(outCoord, len);\n  }\n}\n\nfunction mapCoordReflect(outCoord: number, len: number): number {\n  // Reflect [abcd] to [dcba|abcd|dcba].\n  let inCoord = outCoord;\n  if (inCoord < 0) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz2 = 2 * len;\n      if (inCoord < sz2) {\n        inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;\n      }\n      inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1;\n    }\n  } else if (inCoord > len - 1) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz2 = 2 * len;\n      inCoord -= sz2 * Math.trunc(inCoord / sz2);\n      if (inCoord >= len) {\n        inCoord = sz2 - inCoord - 1;\n      }\n    }\n  }\n  // clamp is necessary because when outCoord = 3.5 and len = 4,\n  // inCoord = 3.5 and will be rounded to 4 in nearest interpolation.\n  return util.clamp(0, inCoord, len - 1);\n}\n\nfunction mapCoordWrap(outCoord: number, len: number): number {\n  // Wrap [abcd] to [abcd|abcd|abcd].\n  let inCoord = outCoord;\n  if (inCoord < 0) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz = len - 1;\n      inCoord += len * (Math.trunc(-inCoord / sz) + 1);\n    }\n  } else if (inCoord > len - 1) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz = len - 1;\n      inCoord -= len * Math.trunc(inCoord / sz);\n    }\n  }\n  // clamp is necessary because when outCoord = -0.5 and len = 4,\n  // inCoord = 3.5 and will be rounded to 4 in nearest interpolation.\n  return util.clamp(0, inCoord, len - 1);\n}\n\nfunction mapCoordConstant(outCoord: number, len: number): number {\n  return outCoord;\n}\n\nfunction mapCoordNearest(outCoord: number, len: number): number {\n  return util.clamp(0, outCoord, len - 1);\n}\n\nfunction readWithFillValue(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number): number {\n  const ind = batch * batchStride + y * rowStride + x * colStride + channel;\n  if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {\n    return imageVals[ind];\n  } else {\n    return fillValue;\n  }\n}\n\nfunction nearestInterpolation(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number): number {\n  const $y = Math.round(y);\n  const $x = Math.round(x);\n\n  return readWithFillValue(\n      imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride,\n      batch, $y, $x, channel, fillValue);\n}\n\nfunction bilinearInterpolation(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number) {\n  const yFloor = Math.floor(y);\n  const xFloor = Math.floor(x);\n  const yCeil = yFloor + 1;\n  const xCeil = xFloor + 1;\n  // f(x, yFloor) = (xCeil - x) / (xCeil - xFloor) * f(xFloor, yFloor)\n  //               + (x - xFloor) / (xCeil - xFloor) * f(xCeil, yFloor)\n  const valueYFloor =\n      (xCeil - x) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yFloor, xFloor, channel, fillValue) +\n      (x - xFloor) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yFloor, xCeil, channel, fillValue);\n  // f(x, yCeil) = (xCeil - x) / (xCeil - xFloor) * f(xFloor, yCeil)\n  //             + (x - xFloor) / (xCeil - xFloor) * f(xCeil, yCeil)\n  const valueYCeil =\n      (xCeil - x) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yCeil, xFloor, channel, fillValue) +\n      (x - xFloor) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yCeil, xCeil, channel, fillValue);\n  // f(x, y) = (yCeil - y) / (yCeil - yFloor) * f(x, yFloor)\n  //         + (y - yFloor) / (yCeil - yFloor) * f(x, yCeil)\n  return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unique, UniqueAttrs, UniqueInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {uniqueImpl} from './Unique_impl';\n\nexport function unique(\n    args: {inputs: UniqueInputs, attrs: UniqueAttrs, backend: MathBackendCPU}):\n    TensorInfo[] {\n  const {inputs, attrs, backend} = args;\n  const {axis} = attrs;\n  const {x} = inputs;\n  assertNotComplex(x, 'unique');\n\n  const values = backend.data.get(x.dataId).values;\n  const {outputValues, outputShape, indices} =\n      uniqueImpl(values, axis, x.shape, x.dtype);\n  return [\n    backend.makeTensorInfo(outputShape, x.dtype, outputValues),\n    backend.makeTensorInfo([indices.length], 'int32', indices),\n  ];\n}\n\nexport const uniqueConfig: KernelConfig = {\n  kernelName: Unique,\n  backendName: 'cpu',\n  kernelFunc: unique as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unpack, UnpackAttrs, UnpackInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nexport function unpack(\n    args: {inputs: UnpackInputs, backend: MathBackendCPU, attrs: UnpackAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {value} = inputs;\n  let {axis} = attrs;\n\n  if (axis < 0) {\n    axis += value.shape.length;\n  }\n\n  const valueRank = value.shape.length;\n\n  const num = value.shape[axis];\n  const outShape: number[] = new Array(valueRank - 1);\n  let outIndex = 0;\n  for (let i = 0; i < valueRank; i++) {\n    if (i !== axis) {\n      outShape[outIndex++] = value.shape[i];\n    }\n  }\n\n  const begin = new Array(valueRank).fill(0);\n  const size = value.shape.slice();\n  size[axis] = 1;\n  const res = new Array(num);\n  for (let i = 0; i < res.length; i++) {\n    begin[axis] = i;\n    const tempRes = slice({inputs: {x: value}, backend, attrs: {begin, size}});\n    res[i] = reshape({inputs: {x: tempRes}, backend, attrs: {shape: outShape}});\n    backend.disposeIntermediateTensorInfo(tempRes);\n  }\n\n  return res;\n}\n\nexport const unpackConfig: KernelConfig = {\n  kernelName: Unpack,\n  backendName: 'cpu',\n  kernelFunc: unpack as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {_fusedMatMulConfig} from './kernels/_FusedMatMul';\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {addNConfig} from './kernels/AddN';\nimport {allConfig} from './kernels/All';\nimport {anyConfig} from './kernels/Any';\nimport {argMaxConfig} from './kernels/ArgMax';\nimport {argMinConfig} from './kernels/ArgMin';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atan2Config} from './kernels/Atan2';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPool3DConfig} from './kernels/AvgPool3D';\nimport {avgPool3DGradConfig} from './kernels/AvgPool3DGrad';\nimport {avgPoolGradConfig} from './kernels/AvgPoolGrad';\nimport {batchMatMulConfig} from './kernels/BatchMatMul';\nimport {batchNormConfig} from './kernels/BatchNorm';\nimport {batchToSpaceNDConfig} from './kernels/BatchToSpaceND';\nimport {bincountConfig} from './kernels/Bincount';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipConfig} from './kernels/Clip';\nimport {complexConfig} from './kernels/Complex';\nimport {complexAbsConfig} from './kernels/ComplexAbs';\nimport {concatConfig} from './kernels/Concat';\nimport {conv2DConfig} from './kernels/Conv2D';\nimport {conv2DBackpropFilterConfig} from './kernels/Conv2DBackpropFilter';\nimport {conv2DBackpropInputConfig} from './kernels/Conv2DBackpropInput';\nimport {conv3DConfig} from './kernels/Conv3D';\nimport {conv3DBackpropFilterV2Config} from './kernels/Conv3DBackpropFilterV2';\nimport {conv3DBackpropInputV2Config} from './kernels/Conv3DBackpropInputV2';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {cropAndResizeConfig} from './kernels/CropAndResize';\nimport {cumsumConfig} from './kernels/Cumsum';\nimport {denseBincountConfig} from './kernels/DenseBincount';\nimport {depthToSpaceConfig} from './kernels/DepthToSpace';\nimport {depthwiseConv2dNativeConfig} from './kernels/DepthwiseConv2dNative';\nimport {depthwiseConv2dNativeBackpropFilterConfig} from './kernels/DepthwiseConv2dNativeBackpropFilter';\nimport {depthwiseConv2dNativeBackpropInputConfig} from './kernels/DepthwiseConv2dNativeBackpropInput';\nimport {diagConfig} from './kernels/Diag';\nimport {dilation2dConfig} from './kernels/Dilation2D';\nimport {dilation2dBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2dBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {einsumConfig} from './kernels/Einsum';\nimport {eluConfig} from './kernels/Elu';\nimport {eluGradConfig} from './kernels/EluGrad';\nimport {equalConfig} from './kernels/Equal';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expandDimsConfig} from './kernels/ExpandDims';\nimport {expm1Config} from './kernels/Expm1';\nimport {fftConfig} from './kernels/FFT';\nimport {fillConfig} from './kernels/Fill';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {floorDivConfig} from './kernels/FloorDiv';\nimport {fusedConv2DConfig} from './kernels/FusedConv2D';\nimport {fusedDepthwiseConv2DConfig} from './kernels/FusedDepthwiseConv2D';\nimport {gatherNdConfig} from './kernels/GatherNd';\nimport {gatherV2Config} from './kernels/GatherV2';\nimport {greaterConfig} from './kernels/Greater';\nimport {greaterEqualConfig} from './kernels/GreaterEqual';\nimport {identityConfig} from './kernels/Identity';\nimport {ifftConfig} from './kernels/IFFT';\nimport {imagConfig} from './kernels/Imag';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {leakyReluConfig} from './kernels/LeakyRelu';\nimport {lessConfig} from './kernels/Less';\nimport {lessEqualConfig} from './kernels/LessEqual';\nimport {linSpaceConfig} from './kernels/LinSpace';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalAndConfig} from './kernels/LogicalAnd';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {logicalOrConfig} from './kernels/LogicalOr';\nimport {lRNConfig} from './kernels/LRN';\nimport {lRNGradConfig} from './kernels/LRNGrad';\nimport {maxConfig} from './kernels/Max';\nimport {maximumConfig} from './kernels/Maximum';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPool3DConfig} from './kernels/MaxPool3D';\nimport {maxPool3DGradConfig} from './kernels/MaxPool3DGrad';\nimport {maxPoolGradConfig} from './kernels/MaxPoolGrad';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {meanConfig} from './kernels/Mean';\nimport {minConfig} from './kernels/Min';\nimport {minimumConfig} from './kernels/Minimum';\nimport {mirrorPadConfig} from './kernels/MirrorPad';\nimport {modConfig} from './kernels/Mod';\nimport {multinomialConfig} from './kernels/Multinomial';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {negConfig} from './kernels/Neg';\nimport {nonMaxSuppressionV3Config} from './kernels/NonMaxSuppressionV3';\nimport {nonMaxSuppressionV4Config} from './kernels/NonMaxSuppressionV4';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {oneHotConfig} from './kernels/OneHot';\nimport {onesLikeConfig} from './kernels/OnesLike';\nimport {packConfig} from './kernels/Pack';\nimport {padV2Config} from './kernels/PadV2';\nimport {powConfig} from './kernels/Pow';\nimport {preluConfig} from './kernels/Prelu';\nimport {prodConfig} from './kernels/Prod';\nimport {rangeConfig} from './kernels/Range';\nimport {realConfig} from './kernels/Real';\nimport {realDivConfig} from './kernels/RealDiv';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reluConfig} from './kernels/Relu';\nimport {relu6Config} from './kernels/Relu6';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {resizeBilinearConfig} from './kernels/ResizeBilinear';\nimport {resizeBilinearGradConfig} from './kernels/ResizeBilinearGrad';\nimport {resizeNearestNeighborConfig} from './kernels/ResizeNearestNeighbor';\nimport {resizeNearestNeighborGradConfig} from './kernels/ResizeNearestNeighborGrad';\nimport {reverseConfig} from './kernels/Reverse';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {scatterNdConfig} from './kernels/ScatterNd';\nimport {selectConfig} from './kernels/Select';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softmaxConfig} from './kernels/Softmax';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sparseFillEmptyRowsConfig} from './kernels/SparseFillEmptyRows';\nimport {sparseReshapeConfig} from './kernels/SparseReshape';\nimport {sparseToDenseConfig} from './kernels/SparseToDense';\nimport {splitVConfig} from './kernels/SplitV';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stepConfig} from './kernels/Step';\nimport {stridedSliceConfig} from './kernels/StridedSlice';\nimport {subConfig} from './kernels/Sub';\nimport {sumConfig} from './kernels/Sum';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {tileConfig} from './kernels/Tile';\nimport {topKConfig} from './kernels/TopK';\nimport {transformConfig} from './kernels/Transform';\nimport {transposeConfig} from './kernels/Transpose';\nimport {uniqueConfig} from './kernels/Unique';\nimport {unpackConfig} from './kernels/Unpack';\nimport {unsortedSegmentSumConfig} from './kernels/UnsortedSegmentSum';\nimport {zerosLikeConfig} from './kernels/ZerosLike';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  _fusedMatMulConfig,\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  addNConfig,\n  allConfig,\n  anyConfig,\n  argMaxConfig,\n  argMinConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atan2Config,\n  atanhConfig,\n  avgPoolConfig,\n  avgPool3DConfig,\n  avgPool3DGradConfig,\n  avgPoolGradConfig,\n  batchMatMulConfig,\n  batchNormConfig,\n  batchToSpaceNDConfig,\n  bincountConfig,\n  castConfig,\n  ceilConfig,\n  clipConfig,\n  complexConfig,\n  complexAbsConfig,\n  concatConfig,\n  conv2DBackpropFilterConfig,\n  conv2DBackpropInputConfig,\n  conv2DConfig,\n  conv3DBackpropFilterV2Config,\n  conv3DBackpropInputV2Config,\n  conv3DConfig,\n  cosConfig,\n  coshConfig,\n  cropAndResizeConfig,\n  cumsumConfig,\n  denseBincountConfig,\n  depthToSpaceConfig,\n  depthwiseConv2dNativeConfig,\n  depthwiseConv2dNativeBackpropFilterConfig,\n  depthwiseConv2dNativeBackpropInputConfig,\n  diagConfig,\n  dilation2dConfig,\n  dilation2dBackpropInputConfig,\n  dilation2dBackpropFilterConfig,\n  realDivConfig,\n  einsumConfig,\n  eluConfig,\n  eluGradConfig,\n  equalConfig,\n  erfConfig,\n  expConfig,\n  expandDimsConfig,\n  expm1Config,\n  fftConfig,\n  fillConfig,\n  flipLeftRightConfig,\n  floorConfig,\n  floorDivConfig,\n  fusedConv2DConfig,\n  fusedDepthwiseConv2DConfig,\n  gatherNdConfig,\n  gatherV2Config,\n  greaterConfig,\n  greaterEqualConfig,\n  identityConfig,\n  ifftConfig,\n  imagConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  leakyReluConfig,\n  lessConfig,\n  lessEqualConfig,\n  linSpaceConfig,\n  logConfig,\n  log1pConfig,\n  logicalAndConfig,\n  logicalNotConfig,\n  logicalOrConfig,\n  lRNConfig,\n  lRNGradConfig,\n  maximumConfig,\n  maxPoolConfig,\n  maxPool3DConfig,\n  maxPool3DGradConfig,\n  maxPoolGradConfig,\n  maxPoolWithArgmaxConfig,\n  maxConfig,\n  meanConfig,\n  minConfig,\n  minimumConfig,\n  mirrorPadConfig,\n  modConfig,\n  multinomialConfig,\n  multiplyConfig,\n  negConfig,\n  nonMaxSuppressionV3Config,\n  nonMaxSuppressionV4Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  oneHotConfig,\n  onesLikeConfig,\n  packConfig,\n  padV2Config,\n  powConfig,\n  preluConfig,\n  prodConfig,\n  rangeConfig,\n  realConfig,\n  reciprocalConfig,\n  reluConfig,\n  relu6Config,\n  reshapeConfig,\n  resizeBilinearConfig,\n  resizeBilinearGradConfig,\n  resizeNearestNeighborConfig,\n  resizeNearestNeighborGradConfig,\n  reverseConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  scatterNdConfig,\n  selectConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  softmaxConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sparseFillEmptyRowsConfig,\n  sparseReshapeConfig,\n  sparseToDenseConfig,\n  splitVConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  stepConfig,\n  stridedSliceConfig,\n  subConfig,\n  sumConfig,\n  tanConfig,\n  tanhConfig,\n  tileConfig,\n  topKConfig,\n  transposeConfig,\n  transformConfig,\n  uniqueConfig,\n  unpackConfig,\n  unsortedSegmentSumConfig,\n  zerosLikeConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, UnsortedSegmentSum, UnsortedSegmentSumAttrs, UnsortedSegmentSumInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from './Cast';\nimport {equal} from './Equal';\nimport {expandDims} from './ExpandDims';\nimport {multiply} from './Multiply';\nimport {pack} from './Pack';\nimport {sum} from './Sum';\n\nexport function unsortedSegmentSum(args: {\n  inputs: UnsortedSegmentSumInputs,\n  backend: MathBackendCPU,\n  attrs: UnsortedSegmentSumAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, segmentIds} = inputs;\n  const {numSegments} = attrs;\n\n  assertNotComplex(x, 'unsortedSegmentSum');\n\n  const xRank = x.shape.length;\n  const segmentIdsRank = segmentIds.shape.length;\n  const res = [];\n  const intermediates: TensorInfo[] = [];\n\n  // Reshape the segment id's so that they can be broadcast with\n  // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n  const numIters = xRank - segmentIdsRank;\n  let $segmentIds = segmentIds;\n\n  for (let i = 0; i < numIters; ++i) {\n    const expanded = expandDims(\n        {inputs: {input: $segmentIds}, backend, attrs: {dim: i + 1}});\n    $segmentIds = expanded;\n    intermediates.push(expanded);\n  }\n\n  for (let i = 0; i < numSegments; ++i) {\n    const scalarValue = util.createScalarValue(i as {} as 'int32', 'int32');\n    const segmentId = backend.makeTensorInfo([], 'int32', scalarValue);\n    const mask =\n        equal({inputs: {a: segmentId, b: $segmentIds}, backend}) as TensorInfo;\n    const maskCasted =\n        cast({inputs: {x: mask}, backend, attrs: {dtype: 'float32'}});\n    const mul =\n        multiply({inputs: {a: maskCasted, b: x}, backend}) as TensorInfo;\n    const sumTensorInfo =\n        sum({inputs: {x: mul}, backend, attrs: {axis: 0, keepDims: false}});\n    res.push(sumTensorInfo);\n    intermediates.push(segmentId);\n    intermediates.push(mask);\n    intermediates.push(maskCasted);\n    intermediates.push(mul);\n    intermediates.push(sumTensorInfo);\n  }\n\n  const result = pack({inputs: res, backend, attrs: {axis: 0}});\n\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const unsortedSegmentSumConfig: KernelConfig = {\n  kernelName: UnsortedSegmentSum,\n  backendName: 'cpu',\n  kernelFunc: unsortedSegmentSum as {} as KernelFunc\n};\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '3.6.0';\nexport {version};\n"],"names":["assertNotComplex","tensor","opName","Array","isArray","forEach","t","util","assert","dtype","whereImpl","kernel_impls","_super","_this","data","DataStorage","engine","tslib_1.__extends","MathBackendCPU","nextDataId","values","shape","this","firstUse","env","get","backend_util","warn","dataId","id","set","refCount","outId","length","isString","encodedValues","map","d","encodeString","write","has","numDataIds","readSync","_a","complexTensorInfos","realValues","real","imagValues","imag","mergeRealAndImagArrays","decodedData","decodeString","Error","buffer","makeTensorFromDataId","force","disposeData","delete","tensorInfo","f","start","now","kernelMs","unreliable","reasons","condition","condVals","epsilon","KernelBackend","simpleAbsImpl","vals","resultValues","Float32Array","i","Math","abs","absConfig","kernelName","Abs","backendName","kernelFunc","args","x","cpuBackend","backend","sizeFromShape","makeOutput","createSimpleBinaryKernelImpl","op","aShape","bShape","aVals","bVals","newShape","assertAndGetBroadcastShape","resultRank","resultStrides","computeStrides","resultSize","result","getTypedArrayFromDType","aRank","bRank","aStrides","bStrides","aBroadcastDims","getBroadcastDims","bBroadcastDims","loc","indexToLoc","aLoc","slice","aIndex","locToIndex","bLoc","bIndex","complex","inputs","realVals","imagVals","complexInfo","makeTensorInfo","complexConfig","Complex","zeros","makeZerosTypedArray","identity","incRef","identityConfig","Identity","input","realVal","realConfig","Real","cast","attrs","zerosTensorInfo","floatX","disposeIntermediateTensorInfo","realPart","hasEncodingLoss","Int32Array","from","xVals","zero","toTypedArray","resultData","resultShape","castConfig","Cast","binaryKernelFunc","name","simpleImpl","complexImpl","_b","a","b","$dtype","_c","$aComplex","$aComplexVals","aReal","aImag","aRealVals","aImagVals","$bComplex","$bComplexVals","bReal","bImag","bRealVals","bImagVals","resultRealData","resultImagData","resultReal","resultImag","_d","createComplexBinaryKernelImpl","resultRealVals","resultImagVals","aIdx","bIdx","opResult","addImpl","addComplexImpl","add","Add","addConfig","bincountImpl","weightsVals","weightsDtype","weightsShape","size","weightsSize","outVals","value","bincountReduceImpl","xBuf","weightsBuf","binaryOutput","numRows","numCols","outBuf","j","createSimpleUnaryImpl","newValues","unaryKernelFunc","xSize","getArrayFromDType","unaryKernelFuncFromImpl","unaryImpl","ceilImpl","xi","ceil","Ceil","ceilConfig","concatImpl","outShape","simplyConcat","offset_1","colOffset_1","fromUint8ToStringArray","tIdx","row","resIdx","col","expImpl","exp","Exp","expConfig","expm1Impl","expm1","Expm1","expm1Config","floorImpl","floor","Floor","floorConfig","gatherV2Impl","indicesBuf","flattenOutputShape","originalLoc","batchIdx","indicesIdx","indicesIndex","originalIndex","greaterImpl","greater","Greater","greaterConfig","lessImpl","less","Less","lessConfig","linSpaceImpl","stop","num","step","logImpl","log","Log","logConfig","maxImpl","reduceSize","offset","max","maximumImpl","aValue","bValue","maximum","Maximum","maximumConfig","minimumImpl","min","minimum","Minimum","minimumConfig","multiplyImpl","multiplyComplexImpl","multiply","Multiply","multiplyConfig","negImpl","xShape","xDtype","minusOne","createScalarValue","negConfig","Neg","res","notEqualImpl","notEqual","NotEqual","notEqualConfig","transposeImpl","perm","xRank","xStrides","newStrides","newLoc","i_1","transpose","transposeConfig","Transpose","prodImpl","reductionAxes","reduceShape","outDtype","upcastType","prod_1","prodConfig","Prod","axis","keepDims","axes","parseAxisParam","permutation","getAxesPermutation","permutedX","intermediateTensorInfos","push","getInnerMostAxes","expandShapeToKeepDim","rangeImpl","numElements","rsqrtImpl","sqrt","rsqrt","Rsqrt","rsqrtConfig","sliceImpl","begin","isContinous","slice_util","isSliceContinous","flatOffset","computeFlatOffset","subarray","inBuf","outLoc","inLoc","idx","fromStringArrayToUint8","$begin","$size","assertParamsValid","sliceConfig","Slice","sparseFillEmptyRowsImpl","indices","indicesShape","indicesDType","valuesDType","denseShape","defaultValue","indicesCount","denseRows","emptyRowIndicator","reverseIndexMap","rank","outputIndices","outputValues","rowsAreOrdered","lastIndicesRow","csrOffset","fill","allRowsFull","rowEmpty","fullIndicesCount","filledCount","outputI","startingIndex","sparseReshapeImpl","inputIndices","inputIndicesShape","inputDType","inputShape","targetShape","denseSize","nnz","outputRank","outputShape","product","unknownIndex","missing","trunc","outputSize","inputRank","inputStrides","outputStrides","newIndices","squaredDifferenceImpl","diff","squaredDifference","SquaredDifference","squaredDifferenceConfig","stridedSliceImpl","strides","subImpl","subComplexImpl","sub","Sub","subConfig","tileImpl","reps","topKImpl","k","sorted","lastDim","batch","allTopKVals","allTopKIndices","valAndInd","index","sort","outOffset","topKVals","topKIndices","uniqueImpl","$axis","uniqueElements","inputBuffer","TensorBuffer","uniqueIndices","is1DTensor","element","toString","axisValues","m","n","join","undefined","uniqueIndex","Object","keys","outputTmpShape","outputBuffer","uniqueElementIndex","elu","Elu","eluConfig","leakyRelu","alpha","leakyReluConfig","LeakyRelu","preluImpl","xValue","prelu","preluConfig","Prelu","relu","Relu","reluConfig","relu6","Relu6","relu6Config","sigmoid","Sigmoid","sigmoidConfig","applyActivation","activation","preluActivationWeights","leakyreluAlpha","reshape","$shape","inferFromImplicitShape","$xSize","xData","reshapeConfig","Reshape","batchMatMul","transposeA","transposeB","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","batchDimsCompatible","concat","b3dShape","a3d","b3d","sharedDim","leftDim","rightDim","batchDim","a3dValues","b3dValues","a3dStrides","b3dStrides","aBatch","aOuterStep","aInnerStep","bInnerStep","bOuterStep","bBatch","resVals","blockSize","bi","i0","j0","k0","iBlock","jBlock","kBlock","sum","batchOffsetA","batchOffsetB","batchMatMulConfig","BatchMatMul","_fusedMatMulConfig","_FusedMatMul","current","addRes","activationRes","bias","intermediates","intermediates_1","_i","acos","Acos","acosConfig","acosh","Acosh","acoshConfig","addNConfig","AddN","tensors","currVals","allConfig","All","origAxes","permutedAxes","$x","assertAxesAreInnerMostDims","all_1","reshapedResult","anyConfig","Any","anyVal","argMaxConfig","ArgMax","outSize","maxIndex","argMinConfig","ArgMin","minIndex","asin","Asin","asinConfig","asinh","Asinh","asinhConfig","atan","Atan","atanConfig","atan2Impl","atan2","Atan2","atan2Config","atanh","Atanh","atanhConfig","pool","xValues","convInfo","poolType","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","effectiveFilterWidth","padTop","padInfo","top","padLeft","left","initialValue","Number","NEGATIVE_INFINITY","POSITIVE_INFINITY","output","outputVals","outputBatchStrides","outputRowStrides","outputColStrides","batchSize","outputBatchOffset","inputBatchOffset","inChannels","yR","outHeight","xRCorner","xRMin","xRMax","inHeight","outputRowOffset","yC","outWidth","xCCorner","xCMin","xCMax","inWidth","minMaxValue","avgValue","count","xR","xROffset","xC","pixel","isNaN","maxPoolPositions","flattenPositions","includeBatchInIndex","maxPositions","maxValue","maxPosition","wR","wC","pool3d","strideDepth","dilationDepth","effectiveFilterDepth","padFront","front","outputDepthStrides","channel","yDepth","outDepth","xDepthCorner","xDepthMin","xDepthMax","inDepth","outputDepthOffset","yRow","xRowCorner","xRowMin","xRowMax","yCol","xColCorner","xColMin","xColMax","outputColOffset","xDepth","xDepthOffset","xRow","xRowOffset","xCol","avgPoolConfig","AvgPool","filterSize","pad","dimRoundingMode","eitherStridesOrDilationsAreOne","computePool2DInfo","filterWidth","filterHeight","arraysEqual","inShape","strides_1","avgPool3DConfig","AvgPool3D","dataFormat","computePool3DInfo","avgPool3DGradConfig","AvgPool3DGrad","dy","filterDepth","dx","avgMultiplier","dyBuf","bufferSync","dxDepth","dxRow","dxCol","dyDepthCorner","dyRowCorner","dyColCorner","dotProd","wDepth","dyDepth","wRow","dyRow","wCol","dyCol","avgPoolGradConfig","AvgPoolGrad","dyData","dxR","dxC","dyRCorner","dyCCorner","dyR","dyC","batchNormConfig","FusedBatchNorm","scale","mean","variance","varianceEpsilon","mVals","varVals","sVals","offVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","batchToSpaceNDConfig","BatchToSpaceND","blockShape","crops","prod","reduce","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","sliceSize","getSliceSize","xReshaped","xTransposed","xTransposedReshaped","bincountConfig","Bincount","weights","clip","ClipByValue","clipAttrs","clipValueMax","clipValueMin","clipConfig","complexAbsConfig","ComplexAbs","complexVals","real_1","imag_1","hypot","imagVal","imagConfig","Imag","computeOutShape","$inputs","filter","shapes","assertParamsConsistent","reals","imags","realConcated","imagConcated","r","inputs2D","innerSize","inputsValShapes","finalOutShape","outInfo","concatConfig","Concat","conv2D","dilations","$dataFormat","convertConv2DDataFormat","computeConv2DInfo","isChannelsLast","y","filterStrides","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","wVals","yVals","xOffset1","yOffset1","yOffset2","wOffset1","xOffset2","yOffset3","xOffset3","wOffset3","d1","xVal","d2","outChannels","conv2DConfig","Conv2D","conv2DBackpropFilterConfig","Conv2DBackpropFilter","filterShape","dW","leftPad","topPad","dyVals","yRMin","yRMax","yCMin","yCMax","conv2DBackpropInputConfig","Conv2DBackpropInput","dyStrides","dxValues","dyValues","fltValues","fltS0","fltS1","fltS2","dyOffset","fltOffset","conv3DConfig","Conv3D","computeConv3DInfo","yF","xFCorner","wF","xF","wOffset2","yOffset4","xOffset4","wOffset4","conv3DBackpropFilterV2Config","Conv3DBackpropFilterV2","dw","dwValues","dwS0","dwS1","dwS2","dwS3","dyS0","dyS1","dyS2","dyS3","xS0","xS1","xS2","xS3","frontPad","yFMin","yFMax","conv3DBackpropInputV2Config","Conv3DBackpropInputV2","dxS0","dxS1","dxS2","dxS3","fltS3","xFMin","cos","Cos","cosConfig","cosh","Cosh","coshConfig","cropAndResizeConfig","CropAndResize","image","boxes","boxInd","cropSize","method","extrapolationValue","imageHeight","imageWidth","numChannels","numBoxes","cropHeight","cropWidth","boxVals","boxIndVals","imageVals","inStride","outStride","startInd","y1","x1","y2","x2","bInd","heightScale","widthScale","yInd","c","ind","topInd","bottomInd","yLerp","xInd","leftInd","rightInd","xLerp","topLeft","topRight","bottomLeft","top_1","bottom","closestX","round","closestY","inInd","outInd","cumsumConfig","Cumsum","exclusive","reverse","permutedAxis","resultDtype","finalDim","indexAdjuster","prevIdx","reverseTransposedResult","getUndoAxesPermutation","denseBincountConfig","DenseBincount","depthToSpaceConfig","DepthToSpace","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","outputIdx","h","inH","offsetH","w","inW","offsetD","inputIdx","depthwiseConv2dNative","$dilations","chMul","q","depthwiseConv2dNativeConfig","DepthwiseConv2dNative","depthwiseConv2dNativeBackpropFilterConfig","DepthwiseConv2dNativeBackpropFilter","dm","depthwiseConv2dNativeBackpropInputConfig","DepthwiseConv2dNativeBackpropInput","diagConfig","Diag","dilation2dConfig","Dilation2D","filterVals","filterRank","outRank","hOut","hBeg","wOut","wBeg","curVal","MIN_SAFE_INTEGER","hIn","wIn","xIndex","filterIndex","val","dilation2dBackpropFilterConfig","Dilation2DBackpropFilter","toNestedArray","$filter","$dy","gradients","makeZerosNestedTypedArray","hMax","wMax","dilation2dBackpropInputConfig","Dilation2DBackpropInput","hInMax","wInMax","sum_1","oldResult","sumConfig","Sum","einsumConfig","Einsum","equation","allDims","summedDims","idDims","checkEinsumDimSizes","path","steps","nSteps","out","numDimsRemaining","tensorsToDispose","idTerm","dimsToExpand","isIdentityPermutation","splice","tensorsToDispose_1","_e","eluGradConfig","EluGrad","v","equalImpl","equal","Equal","equalConfig","p","ERF_P","a1","ERF_A1","a2","ERF_A2","a3","ERF_A3","a4","ERF_A4","a5","ERF_A5","erf","Erf","sign","erfConfig","expandDims","dim","$dim","expandDimsConfig","ExpandDims","realDivImpl","div","RealDiv","realDivConfig","fftBatch","inverse","innerDim","inputVals","real2D","imag2D","input_1","getComplexWithIndex","$realInfo","$imagInfo","fftImpl","inputSize","fftRadix2","half","evenComplex","complexWithEvenIndex","evenRealVals","evenImagVals","evenShape","evenRealInfo","evenImagInfo","evenTensorInfo","oddComplex","complexWithOddIndex","oddRealVals","oddImagVals","oddShape","oddRealInfo","oddImagInfo","oddTensorInfo","$evenComplex","$evenRealVals","$evenImagVals","$evenShape","$evenRealInfo","$evenImagInfo","$evenTensorInfo","$oddComplex","$oddRealVals","$oddImagVals","$oddShape","$oddRealInfo","$oddImagInfo","$oddTensorInfo","e","exponents","eShape","eRealInfo","eImagInfo","exponentInfo","addPart","subPart","addPartReal","subPartReal","addPartImag","subPartImag","$real","$imag","$realVals","$imagVals","realInfo","imagInfo","sizeInfo","sizeInfoCopy","divRealInfo","divImagInfo","divRealVals","divImagVals","rawOutput","ret","real_2","imag_2","exponent","term","assignToTypedArray","fourierTransformByMatmul","splitRealAndImagArrays","fftConfig","FFT","innerDimensionSize","input2D","resultReshaped","inferDtype","fillValues","fillConfig","Fill","flipLeftRightConfig","FlipLeftRight","batchOffset","rowOffset","colOffset","coordX","outIdx","outputValue","floorDivImpl","floorDiv","FloorDiv","floorDivConfig","fusedConv2DConfig","FusedConv2D","resultOld","fusedDepthwiseConv2DConfig","FusedDepthwiseConv2D","gatherNdConfig","GatherNd","params","paramsSize","sliceRank","numSlices","indicesData","paramsData","flattenIndex","gatherV2Config","GatherV2","batchDims","$batchDims","indicesSize","parsedAxis","shapeInfo","segment_util","collectGatherOpShapeInfo","flattenX","outerSize","dimSize","greaterEqualImpl","greaterEqual","GreaterEqual","greaterEqualConfig","ifftConfig","IFFT","isFinite","IsFinite","isFiniteConfig","isInf","IsInf","Infinity","isInfConfig","IsNan","isNaNConfig","lessEqualImpl","lessEqual","LessEqual","lessEqualConfig","linSpaceConfig","LinSpace","log1p","Log1p","log1pConfig","logicalAndImpl","logicalAnd","LogicalAnd","logicalAndConfig","logicalNot","LogicalNot","logicalNotConfig","logicalOrImpl","logicalOr","LogicalOr","logicalOrConfig","lRNConfig","LRN","depthRadius","beta","channels","maxD","sumAcrossChannels","currentChannel","beginSumOffset","endSumOffset","z","pow","lRNGradConfig","LRNGrad","dySize","yValues","depthBegin","depthEnd","norm","dyi","reductionIndices","maxOutShape","maxConfig","Max","maxPoolConfig","MaxPool","maxPool3DConfig","MaxPool3D","maxPool3DGradConfig","MaxPool3DGrad","maxPosBuf","maxPool3dPositions","mask","maxPoolGradConfig","MaxPoolGrad","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","maxPools","pooled","indexes","pooledDataId","indexesDataId","meanConfig","Mean","computeOutAndReduceShapes","toDispose","reduceSizeScalar","minConfig","Min","min_1","mirrorPadConfig","MirrorPad","paddings","mode","end","coords","inIndex","modImpl","rem","mod","Mod","modConfig","softmax","logits","logitsRank","maxLogit","expandedShape","maxLogitReshaped","sumExp","sumReshaped","softmaxConfig","Softmax","multinomialConfig","Multinomial","numSamples","seed","normalized","probabilities","numEvents","probVals","resShape","cdf","event_1","random","seedrandom.alea","sampleId","event_2","nonMaxSuppressionV3Impl","nonMaxSuppressionV3Config","NonMaxSuppressionV3","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","selectedIndices","nonMaxSuppressionV4Impl","nonMaxSuppressionV4Config","NonMaxSuppressionV4","padToMaxOutputSize","validOutputs","nonMaxSuppressionV5Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","selectedScores","oneHotConfig","OneHot","depth","onValue","offValue","indicesVal","zerosLike","imagPart","zerosLikeConfig","ZerosLike","onesLikeConfig","OnesLike","onesLike","pack","assertShapesMatch","expandedT","packConfig","Pack","padV2Config","PadV2","constantValue","outCoords","powImpl","Pow","powConfig","rangeConfig","Range","reciprocal","Reciprocal","reciprocalConfig","resizeBilinearConfig","ResizeBilinear","images","alignCorners","halfPixelCenters","imagesStrides","newHeight","newWidth","oldHeight","oldWidth","effectiveInputSize","effectiveOutputSize","effectiveRowSizeRatio","effectiveColSizeRatio","sourceFracRow","sourceRowFloor","rowFrac","sourceRowCeil","topRowOffset","botRowOffset","sourceFracCol","sourceColFloor","colFrac","sourceColCeil","topLeftOffest","botLeftOffset","topRightOffset","botRightOffest","newValue","resizeBilinearGradConfig","ResizeBilinearGrad","xHeight","xWidth","yHeight","yWidth","effectiveXSize","effectiveYSize","bOffset","topDxRIndex","bottomDxRIndex","topDxROffset","bottomDxROffset","dxRLerp","inverseDxRLerp","leftDxCIndex","rightDxCIndex","dxCLerp","inverseDxCLerp","topLeftRCOffset","topRightRCOffset","bottomLeftRCOffset","bottomRightRCOffset","inverseDxRLerpTimesInverseDxCLerp","inverseDxRLerpTimesDxCLerp","dxRLerpTimesInverseDxCLerp","dxRLerpTimesDxCLerp","dyVal","resizeNearestNeighborConfig","ResizeNearestNeighbor","outputOffset","sourceNearestRow","sourceNearestCol","newVal","resizeNearestNeighborGradConfig","ResizeNearestNeighborGrad","invHeightScale","invWidthScale","winHeight","winWidth","startRLerp","startDyR","startCLerp","startDyC","accum","dyRIndex","dyROffset","dyCIndex","dyCOffset","reverseConfig","Reverse","dims","$dims","rotateWithOffsetConfig","RotateWithOffset","radians","fillValue","center","centerX","centerY","sinFactor","sin","cosFactor","coordY","Round","base","roundConfig","scatterImpl","updates","numUpdates","sumDupeIndices","flattenShape","updatesData","scatterNdConfig","ScatterNd","selectConfig","Select","conditionRank","tValues","eValues","scaleAlpha","SELU_SCALEALPHA","SELU_SCALE","selu","Selu","seluConfig","Sign","signConfig","Sin","sinConfig","sinh","Sinh","sinhConfig","threshold","softplus","Softplus","tooLarge","tooSmall","expX","softplusConfig","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","paddedX","reshapedPaddedShape","permutedReshapedPaddedPermutation","paddedXReshaped","paddedXT","sparseFillEmptyRowsConfig","SparseFillEmptyRows","$indices","$values","$denseShape","$defaultValue","outputIndicesShape","Uint8Array","sparseReshapeConfig","SparseReshape","$inputShape","$inputIndices","sparseToDenseConfig","SparseToDense","sparseIndices","sparseValues","splitVConfig","SplitV","numOrSizeSplits","splitSizes","prepareSplitSize","s","sliceT","Sqrt","sqrtConfig","squareConfig","Square","Step","stepAttrs","NaN","stepConfig","stridedSliceConfig","StridedSlice","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","nonStrided","$strides","sliced","some","tan","Tan","tanConfig","tanh","Tanh","tanhConfig","tileConfig","Tile","topKConfig","TopK","transformConfig","Transform","transforms","interpolation","fillMode","batchStride","rowStride","colStride","transformVals","transform_1","outY","outX","projection","inX","inY","mapCoord","nearestInterpolation","bilinearInterpolation","outCoord","len","inCoord","sz2","clamp","mapCoordReflect","sz","mapCoordWrap","mapCoordNearest","mapCoordConstant","readWithFillValue","yFloor","xFloor","yCeil","xCeil","uniqueConfig","Unique","unpackConfig","Unpack","valueRank","outIndex","tempRes","unsortedSegmentSumConfig","UnsortedSegmentSum","segmentIds","numSegments","numIters","$segmentIds","expanded","scalarValue","segmentId","maskCasted","mul","sumTensorInfo","kernelConfigs_1","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;o0DAmBgBA,EACZC,EAAiCC,GAC9BC,MAAMC,QAAQH,KACjBA,EAAS,CAACA,IAEZA,EAAOI,SAAQ,SAAAC,GACJ,MAALA,GACFC,OAAKC,OACW,cAAZF,EAAEG,OACF,WAAM,OACFP,kECVd,IAAMQ,EAAYC,eAAaD,wBA2B7B,aAAA,MACEE,0BAVKC,YAAY,GAGXA,YAAW,EAQjBA,EAAKC,KAAO,IAAIC,cAAYF,EAAMG,cA0LtC,kIAtMoCC,MAM1BC,uBAAR,WACE,OAAOA,EAAeC,cAQxBD,kBAAA,SAAME,EAAoCC,EAAiBZ,GAErDa,KAAKC,WACPD,KAAKC,UAAW,EACZC,QAAMC,IAAI,YACZC,eAAaC,KACT,4dAYR,IAAMC,EAAS,CAACC,GAAIP,KAAKH,cAIzB,OAFAG,KAAKR,KAAKgB,IAAIF,EAAQ,CAACR,SAAQX,QAAOsB,SAAU,IAEzCH,GASTV,2BAAA,SACIG,EAAiBZ,EACjBW,GACF,IAAIY,EACJ,GAAc,WAAVvB,GAAgC,MAAVW,GAAkBA,EAAOa,OAAS,GACxD1B,OAAK2B,SAASd,EAAO,IAAK,CAC5B,IAAMe,EACDf,EAA0BgB,KAAI,SAAAC,GAAK,OAAA9B,OAAK+B,aAAaD,MAE1DL,EAAQV,KAAKiB,MAAMJ,EAAed,EAAOZ,QAEzCuB,EAAQV,KAAKiB,MAAMnB,EAAsBC,EAAOZ,GAGlD,MAAO,CAACmB,OAAQI,EAAOX,QAAOZ,UAIhCS,qBAAA,SAASU,GACP,OAAIN,KAAKR,KAAK0B,IAAIZ,GACGN,KAAKR,KAAKW,IAAIG,GACfG,SAEb,GAITb,mBAAA,SAAOU,GACcN,KAAKR,KAAKW,IAAIG,GACtBG,YAIbb,mBAAA,SAAOU,GACDN,KAAKR,KAAK0B,IAAIZ,IACGN,KAAKR,KAAKW,IAAIG,GACtBG,YAIfb,iBAAA,SACIU,EAAgBR,EAAoCC,EACpDZ,EAAiBsB,GACnBT,KAAKR,KAAKgB,IAAIF,EAAQ,CAACR,SAAQX,QAAOsB,cAGxCb,uBAAA,WACE,OAAOI,KAAKR,KAAK2B,cAGbvB,iBAAN,SAAWU,sEACT,SAAON,KAAKoB,SAASd,WAEvBV,qBAAA,SAASU,GACD,IAAAe,mBAAClC,UAAOmC,uBAEd,GAAc,cAAVnC,EAAuB,CACzB,IAAMoC,EACFvB,KAAKoB,SAASE,EAAmBE,KAAKlB,QACpCmB,EACFzB,KAAKoB,SAASE,EAAmBI,KAAKpB,QAC1C,OAAOF,eAAauB,uBAAuBJ,EAAYE,GAGzD,OAAOzB,KAAKR,KAAKW,IAAIG,GAAQR,QAG/BF,uBAAA,SAA2BZ,GACzB,IAAMQ,EAAOQ,KAAKoB,SAASpC,EAAEsB,QACzBsB,EAAcpC,EAClB,GAAgB,WAAZR,EAAEG,MACJ,IAEEyC,EAAepC,EAAsBsB,KAAI,SAAAC,GAAK,OAAA9B,OAAK4C,aAAad,MAChE,SACA,MAAM,IAAIe,MAAM,oDAGpB,OAAOC,SAAO/C,EAAEe,MAAsBf,EAAEG,MAAOyC,IAIjDhC,uBAAA,SACIE,EAAoCC,EAAiBZ,GACvD,IAAMmB,EAASN,KAAKiB,MAAMnB,EAAQC,EAAOZ,GACzC,OAAOO,WAASsC,qBAAqB1B,EAAQP,EAAOZ,EAAOa,OAU7DJ,wBAAA,SAAYU,EAAgB2B,GAC1B,gBAD0BA,MACtBjC,KAAKR,KAAK0B,IAAIZ,GAAS,CAEzB,GADAN,KAAKR,KAAKW,IAAIG,GAAQG,YACjBwB,GAASjC,KAAKR,KAAKW,IAAIG,GAAQG,SAAW,EAC7C,OAAO,EAGF,IAAAa,sCAEmB,MAAtBA,IACFtB,KAAKkC,YAAYZ,EAAmBE,KAAKlB,QAAQ,GACjDN,KAAKkC,YAAYZ,EAAmBI,KAAKpB,QAAQ,IAGnDN,KAAKR,KAAK2C,OAAO7B,GAEnB,OAAO,GAGTV,0CAAA,SAA8BwC,GAC5BpC,KAAKkC,YAAYE,EAAW9B,SAGxBV,iBAAN,SAAWyC,4EAIT,OAHMC,EAAQrD,OAAKsD,MACnBF,OAEO,CAACG,SADSvD,OAAKsD,MAAQD,WAIhC1C,mBAAA,WACE,MAAO,CAEL6C,YAAY,EACZC,QACI,CAAC,wHAKT9C,kBAAA,SAAM+C,GACJjE,EAAiB,CAACiE,GAAY,SAE9B,IAAMC,EAAW5C,KAAKoB,SAASuB,EAAUrC,QACzC,OAAOlB,EAAUuD,EAAU5C,MAAO6C,IAGpChD,oBAAA,aAEAA,2BAAA,WACE,OAAO,IAITA,oBAAA,WACE,OAAON,YAAMuD,oBA/LAjD,aAAa,KALMkD,0BCdpBC,EAAcC,GAE5B,IADA,IAAMC,EAAe,IAAIC,aAAaF,EAAKrC,QAClCwC,EAAI,EAAGA,EAAIH,EAAKrC,SAAUwC,EACjCF,EAAaE,GAAKC,KAAKC,IAAIL,EAAKG,IAElC,OAAOF,EAGF,IAaMK,EAA0B,CACrCC,WAAYC,MACZC,YAAa,MACbC,WAhBiB,SAACC,GACX,IAAAC,aACDC,EAAaF,EAAKG,QAExBpF,EAAiBkF,EAAG,OAEpB,IAAIX,EAAe,IAAIC,aAAajE,OAAK8E,cAAcH,EAAE7D,QAIzD,OAFAkD,EAAeF,EADAc,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,QAGtC+D,EAAWG,WAAWf,EAAcW,EAAE7D,MAAO,sBChBtCkE,EAA6BC,GAE3C,OAAO,SAACC,EAAkBC,EAAkBC,EACpCC,EAAmBnF,GACzB,IAAMoF,EAAWnE,eAAaoE,2BAA2BL,EAAQC,GAE3DK,EAAaF,EAAS5D,OACtB+D,EAAgBzF,OAAK0F,eAAeJ,GACpCK,EAAa3F,OAAK8E,cAAcQ,GAEhCM,EACF5F,OAAK6F,uBAAuB3F,EAA0ByF,GAEpDG,EAAQZ,EAAOxD,OACfqE,EAAQZ,EAAOzD,OAEfsE,EAAWhG,OAAK0F,eAAeR,GAC/Be,EAAWjG,OAAK0F,eAAeP,GAE/Be,EAAiB/E,eAAagF,iBAAiBjB,EAAQI,GACvDc,EAAiBjF,eAAagF,iBAAiBhB,EAAQG,GAE7D,GAAIY,EAAexE,OAAS0E,EAAe1E,SAAW,EACpD,IAAK,IAAIwC,EAAI,EAAGA,EAAI0B,EAAOlE,SAAUwC,EACnC0B,EAAO1B,GAAKe,EAAGG,EAAMlB,EAAIkB,EAAM1D,QAAS2D,EAAMnB,EAAImB,EAAM3D,6BAGjDwC,GACP,IAAMmC,EAAMrG,OAAKsG,WAAWpC,EAAGsB,EAAYC,GAErCc,EAAOF,EAAIG,OAAOV,GACxBI,EAAepG,SAAQ,SAAAgC,GAAK,OAAAyE,EAAKzE,GAAK,KACtC,IAAM2E,EAASzG,OAAK0G,WAAWH,EAAMT,EAAOE,GAEtCW,EAAON,EAAIG,OAAOT,GACxBK,EAAetG,SAAQ,SAAAgC,GAAK,OAAA6E,EAAK7E,GAAK,KACtC,IAAM8E,EAAS5G,OAAK0G,WAAWC,EAAMZ,EAAOE,GAE5CL,EAAO1B,GAAKe,EAAGG,EAAMqB,GAASpB,EAAMuB,KAXtC,IAAS1C,EAAI,EAAGA,EAAI0B,EAAOlE,SAAUwC,IAA5BA,GAeX,MAAO,CAAC0B,EAAQN,aC7CJuB,EAAQnC,GAEf,IAAAoC,WAAQjC,YACRtC,SAAME,SAEPsE,EAAWlC,EAAQtE,KAAKW,IAAIqB,EAAKlB,QAAQR,OACzCmG,EAAWnC,EAAQtE,KAAKW,IAAIuB,EAAKpB,QAAQR,OAEzCoG,EAAcpC,EAAQqC,eAAe3E,EAAKzB,MAAO,aAYvD,OAVgB+D,EAAQtE,KAAKW,IAAI+F,EAAY5F,QAKrCgB,mBAAqB,CAC3BE,KAAMsC,EAAQqC,eAAe3E,EAAKzB,MAAO,UAAWiG,GACpDtE,KAAMoC,EAAQqC,eAAezE,EAAK3B,MAAO,UAAWkG,IAG/CC,EAGF,IAAME,EAA8B,CACzC7C,WAAY8C,UACZ5C,YAAa,MACbC,WAAYoC,YCpBEQ,EACZxC,EAAyB/D,EACzBZ,GACF,gBADEA,aACY,cAAVA,EAIF,OAAO2G,EAAQ,CAACC,OAAQ,CAACvE,KAHZ8E,EAAMxC,EAAS/D,EAAO,WAGJ2B,KAFlB4E,EAAMxC,EAAS/D,EAAO,YAEG+D,YAGxC,IAAMhE,EAASb,OAAKsH,oBAAoBtH,OAAK8E,cAAchE,GAAQZ,GAEnE,OAAO2E,EAAQqC,eAAepG,EAAOZ,EAAOW,YClB9B0G,EACZ7C,GACK,IAAAoC,WAAQjC,YACRF,MAIP,OAFAE,EAAQ2C,OAAO7C,EAAEtD,QAEV,CAACA,OAAQsD,EAAEtD,OAAQP,MAAO6D,EAAE7D,MAAOZ,MAAOyE,EAAEzE,OAG9C,IAAMuH,EAA+B,CAC1CnD,WAAYoD,WACZlD,YAAa,MACbC,WAAY8C,YCbEhF,EAAKmC,GAEZ,IAAAoC,WAAQjC,YACR8C,UAEDpF,EAAOsC,EAAQtE,KAAKW,IAAIyG,EAAMtG,QAAQgB,mBAAmBE,KACzDqF,EAAU/C,EAAQtE,KAAKW,IAAIqB,EAAKlB,QAAQR,OAK9C,OAAOgE,EAAQqC,eAAe3E,EAAKzB,MAAOyB,EAAKrC,MAAO0H,GAGjD,IAAMC,EAA2B,CACtCvD,WAAYwD,OACZtD,YAAa,MACbC,WAAYlC,YCZEwF,EACZrD,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAzE,UAGP,GAAc,cAAVA,EAAuB,CACzB,GAAgB,cAAZyE,EAAEzE,MACJ,OAAOqH,EAAS,CAACT,OAAQ,CAACnC,KAAIE,YAGhC,IAAMoD,EAAkBZ,EAAMxC,EAASF,EAAE7D,MAAO6D,EAAEzE,OAC5CgI,EAASH,EAAK,CAACjB,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC9H,MAAO,aAEpD0F,EACFiB,EAAQ,CAACC,OAAQ,CAACvE,KAAM2F,EAAQzF,KAAMwF,GAAkBpD,YAK5D,OAHAA,EAAQsD,8BAA8BF,GACtCpD,EAAQsD,8BAA8BD,GAE/BtC,EAIT,GAAgB,cAAZjB,EAAEzE,MAAuB,CAC3B,IAAMkI,EAAW7F,EAAK,CAACuE,OAAQ,CAACa,MAAOhD,GAAIE,YACrCe,EAASmC,EAAK,CAACjB,OAAQ,CAACnC,EAAGyD,GAAWvD,UAASmD,MAAO,CAAC9H,WAI7D,OAFA2E,EAAQsD,8BAA8BC,GAE/BxC,EAGT,IAAK5F,OAAKqI,gBAAgB1D,EAAEzE,MAAOA,GAIjC,MAAO,CAACmB,QADFuE,EAAS2B,EAAS,CAACT,OAAQ,CAACnC,KAAIE,aACfxD,OAAQP,MAAO8E,EAAO9E,MAAOZ,SAGtD,GAAc,UAAVA,EAAmB,CACrB,IAAMW,EAASgE,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACpCmD,EAAesE,WAAWC,KAAK1H,GACrC,OAAOgE,EAAQqC,eAAevC,EAAE7D,MAAO,QAASkD,GAGlD,GAAc,SAAV9D,EAAkB,CAIpB,IAAMsI,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnC4H,EAAOzI,OAAK0I,aAAa,CAAC,GAAI/D,EAAEzE,OAEhCkC,8DAACuG,OAAYC,OAGnB,OAAO/D,EAAQqC,eAAe0B,EAAa,OAAQD,GAGrD,MAAM,IAAI9F,MAAM,iCAAiC8B,EAAEzE,aAAYA,GAG1D,IAAM2I,EAA2B,CACtCvE,WAAYwE,OACZtE,YAAa,MACbC,WAAYsD,YCxDEgB,EACZC,EAAcC,EACdC,EAAuChJ,GACzC,OAAmB,MAAfgJ,EACK,SAAC9G,OAAC0E,WAAQjC,YACTsE,IAACC,MAAGC,MACJzE,EAAaC,EAEnBpF,EAAiB,CAAC2J,EAAGC,GAAIL,GAEzB,IAAM5D,EAAQR,EAAWrE,KAAKW,IAAIkI,EAAE/H,QAAQR,OACtCwE,EAAQT,EAAWrE,KAAKW,IAAImI,EAAEhI,QAAQR,OAEtCyI,EAASpJ,GAASkJ,EAAElJ,MAEpBqJ,2BAACZ,OAAYC,OAGnB,OAAOhE,EAAWsC,eAAe0B,EAAaU,EAAQX,IAInD,SAACvG,OAAC0E,WAAQjC,YACTsE,IAACC,MAAGC,MACJzE,EAAaC,EAEnB,GAAgB,cAAZuE,EAAElJ,OAAqC,cAAZmJ,EAAEnJ,MAAuB,CACtD,IAAMsJ,EAAYzB,EACd,CAACjB,OAAQ,CAACnC,EAAGyE,GAAIvE,QAASD,EAAYoD,MAAO,CAAC9H,MAAO,eAEnDuJ,EAAgB7E,EAAWrE,KAAKW,IAAIsI,EAAUnI,QAE9CqI,EAAQD,EAAcpH,mBAAmBE,KACzCoH,EAAQF,EAAcpH,mBAAmBI,KAEzCmH,EACFhF,EAAWrE,KAAKW,IAAIwI,EAAMrI,QAAQR,OAChCgJ,EACFjF,EAAWrE,KAAKW,IAAIyI,EAAMtI,QAAQR,OAEhCiJ,EAAY/B,EACd,CAACjB,OAAQ,CAACnC,EAAG0E,GAAIxE,QAASD,EAAYoD,MAAO,CAAC9H,MAAO,eAEnD6J,EAAgBnF,EAAWrE,KAAKW,IAAI4I,EAAUzI,QAE9C2I,EAAQD,EAAc1H,mBAAmBE,KACzC0H,EAAQF,EAAc1H,mBAAmBI,KAEzCyH,EACFtF,EAAWrE,KAAKW,IAAI8I,EAAM3I,QAAQR,OAChCsJ,EACFvF,EAAWrE,KAAKW,IAAI+I,EAAM5I,QAAQR,OAEhC0I,6BAACa,OAAgBC,OAAgBzB,OAGjC0B,EACF1F,EAAWsC,eAAe0B,EAAa,UAAWwB,GAEhDG,EACF3F,EAAWsC,eAAe0B,EAAa,UAAWyB,GAEhDzE,EAASiB,EACX,CAACC,OAAQ,CAACvE,KAAM+H,EAAY7H,KAAM8H,GAAa1F,QAASD,IAO5D,OALAA,EAAWuD,8BAA8BqB,GACzC5E,EAAWuD,8BAA8B2B,GACzClF,EAAWuD,8BAA8BmC,GACzC1F,EAAWuD,8BAA8BoC,GAElC3E,EAEP,IAAMR,EAAQR,EAAWrE,KAAKW,IAAIkI,EAAE/H,QAAQR,OACtCwE,EAAQT,EAAWrE,KAAKW,IAAImI,EAAEhI,QAAQR,OAEtCyI,EAASpJ,GAASkJ,EAAElJ,MAEpBsK,2BAAC7B,OAAYC,OAGnB,OAAOhE,EAAWsC,eAAe0B,EAAaU,EAAQX,aAS5C8B,EAA8BxF,GAE5C,OAAO,SAACC,EAAkBC,EAAkByE,EACpCC,EAAyBK,EACzBC,GACN,IAAMvB,EAAczH,eAAaoE,2BAA2BL,EAAQC,GAC9DQ,EAAa3F,OAAK8E,cAAc8D,GAChCpD,EAAaoD,EAAYlH,OACzB+D,EAAgBzF,OAAK0F,eAAekD,GAEpC8B,EAAiB1K,OAAK6F,uBAAuB,UAAWF,GACxDgF,EAAiB3K,OAAK6F,uBAAuB,UAAWF,GAExDO,EAAiB/E,eAAagF,iBAAiBjB,EAAQ0D,GACvDxC,EAAiBjF,eAAagF,iBAAiBhB,EAAQyD,GAEvDxD,EAAQjE,eAAauB,uBAAuBkH,EAAWC,GACvDxE,EAAQlE,eAAauB,uBAAuBwH,EAAWC,GAEvDrE,EAAQZ,EAAOxD,OACfsE,EAAWhG,OAAK0F,eAAeR,GAE/Ba,EAAQZ,EAAOzD,OACfuE,EAAWjG,OAAK0F,eAAeP,GAErC,GAAIe,EAAexE,OAAS0E,EAAe1E,SAAW,EACpD,IAAK,IAAIwC,EAAI,EAAGA,EAAIwG,EAAehJ,OAAQwC,IAAK,CAC9C,IAAM0G,EAAO1G,EAAIkB,EAAM1D,OACjBmJ,EAAO3G,EAAImB,EAAM3D,OAEjBkE,EACFX,EAAGG,EAAa,EAAPwF,GAAWxF,EAAa,EAAPwF,EAAW,GAAIvF,EAAa,EAAPwF,GAC5CxF,EAAa,EAAPwF,EAAW,IAExBH,EAAexG,GAAK0B,EAAOrD,KAC3BoI,EAAezG,GAAK0B,EAAOnD,yBAGpByB,GACP,IAAMmC,EAAMrG,OAAKsG,WAAWpC,EAAGsB,EAAYC,GAErCc,EAAOF,EAAIG,OAAOV,GACxBI,EAAepG,SAAQ,SAAAgC,GAAK,OAAAyE,EAAKzE,GAAK,KACtC,IAAM2E,EAASzG,OAAK0G,WAAWH,EAAMT,EAAOE,GAEtCW,EAAON,EAAIG,OAAOT,GACxBK,EAAetG,SAAQ,SAAAgC,GAAK,OAAA6E,EAAK7E,GAAK,KACtC,IAAM8E,EAAS5G,OAAK0G,WAAWC,EAAMZ,EAAOE,GAEtC6E,EACF7F,EAAGG,EAAe,EAATqB,GAAarB,EAAe,EAATqB,EAAa,GAAIpB,EAAe,EAATuB,GAChDvB,EAAe,EAATuB,EAAa,IAE1B8D,EAAexG,GAAK4G,EAASvI,KAC7BoI,EAAezG,GAAK4G,EAASrI,MAhB/B,IAASyB,EAAI,EAAGA,EAAIwG,EAAehJ,OAAQwC,MAAlCA,GAmBX,MAAO,CAACwG,EAAgBC,EAAgB/B,ICjKrC,IAAMmC,EAAU/F,YAA+BoE,EAAGC,GAAM,OAAAD,EAAIC,KACtD2B,EACTP,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CAAC1H,KAAMmH,EAAQM,EAAOvH,KAAMkH,EAAQM,MAGpCgB,EAAMlC,EAAiBmC,MAAKH,EAASC,GAErCG,EAA0B,CACrC7G,WAAY4G,MACZ1G,YAAa,MACbC,WAAYwG,YCdEG,EACZ5C,EAAmB6C,EAAyBC,EAC5CC,EAAwBC,GAI1B,IAHA,IAAMC,EAAczL,OAAK8E,cAAcyG,GACjCG,EAAU1L,OAAKsH,oBAAoBkE,EAAMF,GAEtCpH,EAAI,EAAGA,EAAIsE,EAAM9G,OAAQwC,IAAK,CACrC,IAAMyH,EAAQnD,EAAMtE,GACpB,GAAIyH,EAAQ,EACV,MAAM,IAAI9I,MAAM,iCAGd8I,GAASH,IAKXE,EAAQC,IADNF,EAAc,EACEJ,EAAYnH,GAEZ,GAItB,OAAOwH,WAGOE,EACZC,EAAuBC,EAA6BN,EACpDO,gBAAAA,MAMF,IALA,IAAMC,EAAUH,EAAK/K,MAAM,GACrBmL,EAAUJ,EAAK/K,MAAM,GAErBoL,EAASpJ,SAAO,CAACkJ,EAASR,GAAOM,EAAW5L,OAEzCgE,EAAI,EAAGA,EAAI8H,EAAS9H,IAC3B,IAAK,IAAIiI,EAAI,EAAGA,EAAIF,EAASE,IAAK,CAChC,IAAMR,EAAQE,EAAK3K,IAAIgD,EAAGiI,GAC1B,GAAIR,EAAQ,EACV,MAAM,IAAI9I,MAAM,iCAGd8I,GAASH,IAITO,EACFG,EAAO3K,IAAI,EAAG2C,EAAGyH,GAEbG,EAAWN,KAAO,EACpBU,EAAO3K,IAAI2K,EAAOhL,IAAIgD,EAAGyH,GAASG,EAAW5K,IAAIgD,EAAGiI,GAAIjI,EAAGyH,GAE3DO,EAAO3K,IAAI2K,EAAOhL,IAAIgD,EAAGyH,GAAS,EAAGzH,EAAGyH,IAMhD,OAAOO,WCpDOE,EAAsBnH,GAEpC,OAAO,SAACpE,EAAQX,EAAO8H,GAGrB,IAFA,IAAMqE,EACFrM,OAAK6F,uBAAuB3F,EAA0BW,EAAOa,QACxDwC,EAAI,EAAGA,EAAIrD,EAAOa,SAAUwC,EACnCmI,EAAUnI,GAAKe,EAAGpE,EAAOqD,GAAI8D,GAE/B,OAAOqE,YCAKC,EACZtD,EAAc/D,EAA0B/E,GAC1C,OAAO,SAACkC,OAAC0E,WAAQkB,UAAOnD,YACfF,MAEP,GADAlF,EAAiBkF,EAAGqE,GACJ,WAAZrE,EAAEzE,OAAgC,WAAVA,EAC1B,MAAM,IAAI2C,MAAM,wDAQlB,IALA,IAAM+B,EAAaC,EACbhE,EAAS+D,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACvC0L,EAAQvM,OAAK8E,cAAcH,EAAE7D,OAC7BwI,EAASpJ,GAASyE,EAAEzE,MACpBmM,EAAYrM,OAAKwM,kBAAkBlD,EAAQiD,GACxCrI,EAAI,EAAGA,EAAIqI,IAASrI,EAC3BmI,EAAUnI,GAAKe,EAAGpE,EAAOqD,GAAI8D,GAE/B,OAAOpD,EAAWsC,eAAevC,EAAE7D,MAAOwI,EAAQ+C,aAatCI,EACZzD,EAAc0D,EAA4BxM,GAC5C,OAAO,SAACkC,OAAC0E,WAAQkB,UAAOnD,YACfF,MAEP,GADAlF,EAAiBkF,EAAGqE,GACJ,WAAZrE,EAAEzE,OAAgC,WAAVA,EAC1B,MAAM,IAAI2C,MAAM,wDAGlB,IAAM+B,EAAaC,EACbhE,EAAS+D,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACvCyI,EAASpJ,GAASyE,EAAEzE,MACpBmM,EAAYK,EAAU7L,EAAQyI,EAAQtB,GAC5C,OAAOpD,EAAWsC,eAAevC,EAAE7D,MAAOwI,EAAQ+C,ICrD/C,IAAMM,EAAWP,GAAsB,SAACQ,GAAO,OAAAzI,KAAK0I,KAAKD,MACnDC,EAAOJ,EAAwBK,OAAMH,GAErCI,EAA2B,CACtCzI,WAAYwI,OACZtI,YAAa,MACbC,WAAYoI,YCTEG,EACZlG,EAAuDmG,EACvD/M,EAAiBgN,GACnB,IAAMxB,EAAU1L,OAAKwM,kBAAkBtM,EAAOF,OAAK8E,cAAcmI,IAEjE,GAAIC,GAA0B,WAAVhN,EAAoB,CAEtC,IAAIiN,EAAS,EACbrG,EAAOhH,SAAQ,SAAA6H,GACb,IAAM6D,EAAOxL,OAAK8E,cAAc6C,EAAM7G,OAErC4K,EAAuBnK,IAAIoG,EAAM5D,KAAoBoJ,GACtDA,GAAU3B,SAEP,CACL,IAAI4B,EAAY,EAEhBtG,EAAOhH,SAAQ,SAAA6H,GAOb,IANA,IAAMhF,EAAwB,WAAVzC,EAChBiB,eAAakM,uBAAuB1F,EAAM5D,MAC1C4D,EAAM5D,KAENuJ,EAAO,EAEFC,EAAM,EAAGA,EAAM5F,EAAM7G,MAAM,KAAMyM,EAExC,IADA,IAAMC,EAASD,EAAMN,EAAS,GAAKG,EAC1BK,EAAM,EAAGA,EAAM9F,EAAM7G,MAAM,KAAM2M,EACxC/B,EAAQ8B,EAASC,GAAO9K,EAAY2K,KAIxCF,GAAazF,EAAM7G,MAAM,MAI7B,OAAO4K,EChCF,IAAMgC,EAAUtB,GAAsB,SAACQ,GAAO,OAAAzI,KAAKwJ,IAAIf,MACjDe,EAAMlB,EAAwBmB,MAAKF,GAEnCG,EAA0B,CACrCvJ,WAAYsJ,MACZpJ,YAAa,MACbC,WAAYkJ,GCNDG,EAAY1B,GAAsB,SAACQ,GAAO,OAAAzI,KAAK4J,MAAMnB,MACrDmB,EAAQtB,EAAwBuB,QAAOF,GAEvCG,EAA4B,CACvC3J,WAAY0J,QACZxJ,YAAa,MACbC,WAAYsJ,GCNDG,EAAY9B,GAAsB,SAACQ,GAAO,OAAAzI,KAAKgK,MAAMvB,MACrDuB,EAAQ1B,EAAwB2B,QAAOF,GAEvCG,EAA4B,CACvC/J,WAAY8J,QACZ5J,YAAa,MACbC,WAAY0J,YCTEG,EACZzC,EAA0B0C,EAC1BC,GAEF,IADA,IAAMtC,EAASpJ,SAAO0L,EAAoB3C,EAAK3L,OACtCgE,EAAI,EAAGA,EAAIgI,EAAOV,OAAQtH,EAAG,CACpC,IAEMuK,EAFSvC,EAAO5F,WAAWpC,GAEIsC,QAC/BkI,EAAWD,EAAY,GACvBE,EAAaF,EAAY,GACzBG,EAAeL,EAAW7H,WAAW,CAACgI,EAAUC,IACtDF,EAAY,GAAKF,EAAW1N,OAAO+N,GAEnC,IAAMC,EAAgBhD,EAAKnF,WAAW+H,GACtCvC,EAAOrL,OAAOqD,GAAK2H,EAAKhL,OAAOgO,GAGjC,OAAO3C,ECdF,IAAM4C,EACT9J,GAA6B,SAACoE,EAAWC,GAAc,OAACD,EAAIC,EAAK,EAAI,KAC5D0F,EACThG,EAAiBiG,UAASF,EAAa,KAAwB,QAEtDG,EAA8B,CACzC3K,WAAY0K,UACZxK,YAAa,MACbC,WAAYsK,GCRDG,EACTlK,GAA6B,SAACoE,EAAWC,GAAc,OAACD,EAAIC,EAAK,EAAI,KAC5D8F,EACTpG,EAAiBqG,OAAMF,EAAU,KAAwB,QAEhDG,EAA2B,CACtC/K,WAAY8K,OACZ5K,YAAa,MACbC,WAAY0K,YCXEG,EACZjM,EAAekM,EAAcC,GAC/B,IAAMC,GAAQF,EAAOlM,IAAUmM,EAAM,GAE/B3O,EAASb,OAAKsH,oBAAoBkI,EAAK,WAC7C3O,EAAO,GAAKwC,EACZ,IAAK,IAAIa,EAAI,EAAGA,EAAIrD,EAAOa,OAAQwC,IACjCrD,EAAOqD,GAAKrD,EAAOqD,EAAI,GAAKuL,EAG9B,OAAO5O,ECPF,IAAM6O,EAAUtD,GAAsB,SAACQ,GAAO,OAAAzI,KAAKwL,IAAI/C,MACjD+C,GAAMlD,EAAwBmD,MAAKF,GAEnCG,GAA0B,CACrCvL,WAAYsL,MACZpL,YAAa,MACbC,WAAYkL,aCTEG,GACZ1K,EAAmB2K,EAAoB9C,EACvC/M,GAIF,IAHA,IAAM6D,EAAO/D,OAAK6F,uBACd3F,EAA0BF,OAAK8E,cAAcmI,IAExC/I,EAAI,EAAGA,EAAIH,EAAKrC,SAAUwC,EAAG,CAGpC,IAFA,IAAM8L,EAAS9L,EAAI6L,EACfE,EAAM7K,EAAM4K,GACP7D,EAAI,EAAGA,EAAI4D,IAAc5D,EAAG,CACnC,IAAMR,EAAQvG,EAAM4K,EAAS7D,GACzBR,EAAQsE,IACVA,EAAMtE,GAGV5H,EAAKG,GAAK+L,EAEZ,OAAOlM,ECdF,IAAMmM,GAAclL,YACrBmL,EAAQC,GAAW,OAAAjM,KAAK8L,IAAIE,EAAQC,MAC7BC,GAAUtH,EAAiBuH,UAASJ,IAEpCK,GAA8B,CACzCjM,WAAYgM,UACZ9L,YAAa,MACbC,WAAY4L,ICPDG,GAAcxL,YACrBmL,EAAQC,GAAW,OAAAjM,KAAKsM,IAAIN,EAAQC,MAC7BM,GAAU3H,EAAiB4H,UAASH,IAEpCI,GAA8B,CACzCtM,WAAYqM,UACZnM,YAAa,MACbC,WAAYiM,ICRDG,GACT7L,YAA+BmL,EAAQC,GAAW,OAAAD,EAASC,KAClDU,GACTrG,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CACL1H,KAAMmH,EAAQM,EAAQL,EAAQM,EAC9BxH,KAAMiH,EAAQO,EAAQN,EAAQK,MAIzB+G,GACThI,EAAiBiI,WAAUH,GAAcC,IAEhCG,GAA+B,CAC1C3M,WAAY0M,WACZxM,YAAa,MACbC,WAAYsM,aCdEG,GAAQ1I,EAAmB2I,EAAkBC,GAE3D,IAAMC,EACFrR,OAAKsR,mBAAmB,EAAsBF,GAClD,OAAOP,GAAa,GAAIM,EAAQE,EAAU7I,EAAO4I,GAgB5C,IAAMG,GAA0B,CACrCjN,WAAYkN,MACZhN,YAAa,MACbC,oBAhBkBC,GAEX,IAAAoC,WAAQjC,YACRF,MAEPlF,EAAiBkF,EAAG,OAEpB,IACMvC,KADQyC,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,wBAClC4Q,OAAKnM,OAEZ,OAAOT,EAAQqC,eAAe5B,EAAUX,EAAEzE,MAAOuR,KClBtCC,GACT1M,YAA+BoE,EAAGC,GAAM,OAACD,IAAMC,EAAK,EAAI,KAC/CsI,GACT5I,EAAiB6I,WAAUF,GAAc,KAAsB,QAEtDG,GAA+B,CAC1CvN,WAAYsN,WACZpN,YAAa,MACbC,WAAYkN,aCVEG,GACZtJ,EAAmB2I,EAAkBjR,EAAiB6R,EACtDzM,GASF,IARA,IAAM0M,EAAQb,EAAOzP,OACf6K,EAAQvM,OAAK8E,cAAcqM,GAC3Bc,EAAWjS,OAAK0F,eAAeyL,GAC/Be,EAAalS,OAAK0F,eAAeJ,GAEjCM,EAAS5F,OAAK6F,uBAChB3F,EAA0BF,OAAK8E,cAAcQ,IAExCpB,EAAI,EAAGA,EAAIqI,IAASrI,EAAG,CAK9B,IAJA,IAAMmC,EAAMrG,OAAKsG,WAAWpC,EAAG8N,EAAOC,GAGhCE,EAAmB,IAAIvS,MAAMyG,EAAI3E,QAC9B0Q,EAAI,EAAGA,EAAID,EAAOzQ,OAAQ0Q,IACjCD,EAAOC,GAAK/L,EAAI0L,EAAKK,IAIvBxM,EADiB5F,OAAK0G,WAAWyL,EAAQH,EAAOE,IAC7B1J,EAAMtE,GAE3B,OAAO0B,WCnBOyM,GAAU3N,GAKjB,IAAAoC,WAAQkB,UAAOnD,YACfF,MACAoN,SAEPtS,EAAiBkF,EAAG,aAKpB,IAHA,IAAMqN,EAAQrN,EAAE7D,MAAMY,OAEhB4D,EAAqB,IAAI1F,MAAMoS,GAC5B9N,EAAI,EAAGA,EAAIoB,EAAS5D,OAAQwC,IACnCoB,EAASpB,GAAKS,EAAE7D,MAAMiR,EAAK7N,IAG7B,IACM0B,EAASkM,GADAjN,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACL8D,EAAE7D,MAAO6D,EAAEzE,MAAO6R,EAAMzM,GAG7D,MAAO,CAACjE,OADOwD,EAAQ7C,MAAM4D,EAAQN,EAAUX,EAAEzE,OACjCY,MAAOwE,EAAUpF,MAAOyE,EAAEzE,OAGrC,IAAMoS,GAAgC,CAC3ChO,WAAYiO,YACZ/N,YAAa,MACbC,WAAY4N,aC7BEG,GACZrB,EAAkBC,EAAkB5I,EACpCiK,GASF,IAPM,IAAArQ,gDAAC6K,OAAUyF,OAEXC,EAAWC,aAAWxB,EAAQ,SAC9B1F,EAAU1L,OAAKsH,oBACDtH,OAAK8E,cAAcmI,GAAW0F,GAC5C5C,EAAa/P,OAAK8E,cAAc4N,GAE7BxO,EAAI,EAAGA,EAAIwH,EAAQhK,SAAUwC,EAAG,CAGvC,IAFA,IAAM8L,EAAS9L,EAAI6L,EACf8C,EAAO,EACF1G,EAAI,EAAGA,EAAI4D,IAAc5D,EAChC0G,GAAQrK,EAAMwH,EAAS7D,GAEzBT,EAAQxH,GAAK2O,EAGf,MAAO,CAACnH,UAASuB,WAAU0F,YAwCtB,IAAMG,GAA2B,CACtCxO,WAAYyO,OACZvO,YAAa,MACbC,oBAvCEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAqO,SAAMC,aAEbxT,EAAiBkF,EAAG,QAEpB,IAAMqN,EAAQrN,EAAE7D,MAAMY,OAChBwR,EAAOlT,OAAKmT,eAAeH,EAAMrO,EAAE7D,OAEnCsS,EAAcjS,eAAakS,mBAAmBH,EAAMlB,GACtDS,EAAgBS,EAChBI,EAAY3O,EACV4O,EAA0B,GACb,MAAfH,IACFE,EAAYjB,GAAU,CAACvL,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC+J,KAAMqB,KAC3DG,EAAwBC,KAAKF,GAC7Bb,EAAgBtR,eAAasS,iBAAiBhB,EAAc/Q,OAAQsQ,IAGtE,IAAMxJ,EAAQ3D,EAAQtE,KAAKW,IAAIoS,EAAUjS,QAAQR,OAC3CuB,0BAACsJ,YAASuB,aAAU0F,aAGtB/J,EAAcqE,EAQlB,OAPIgG,IACFrK,EAAczH,eAAauS,qBAAqBzG,EAAUiG,IAG5DK,EAAwBzT,SACpB,SAAAC,GAAK,OAAA8E,EAAQsD,8BAA8BpI,MAExC8E,EAAQqC,eAAe0B,EAAa+J,EAAUjH,cC7DvCiI,GACZtQ,EAAekM,EAAcE,EAC7BvP,GAKF,GAJsBmD,IAAUkM,GACIlM,EAAQkM,GAAQE,EAAO,GACvBF,EAAOlM,GAASoM,EAAO,EAIzD,OAAOzP,OAAKsH,oBAAoB,EAAGpH,GAGrC,IAAM0T,EAAczP,KAAKC,IAAID,KAAK0I,MAAM0C,EAAOlM,GAASoM,IAClD5O,EAASb,OAAKsH,oBAAoBsM,EAAa1T,GAEjDqP,EAAOlM,GAAkB,IAAToM,IAGlBA,GAAQ,GAGV5O,EAAO,GAAKwC,EACZ,IAAK,IAAIa,EAAI,EAAGA,EAAIrD,EAAOa,OAAQwC,IACjCrD,EAAOqD,GAAKrD,EAAOqD,EAAI,GAAKuL,EAE9B,OAAO5O,ECtBF,IAAMgT,GAAYzH,GAAsB,SAACQ,GAAO,OAAA,EAAIzI,KAAK2P,KAAKlH,MACxDmH,GAAQtH,EAAwBuH,QAAOH,IAEvCI,GAA4B,CACvC3P,WAAY0P,QACZxP,YAAa,MACbC,WAAYsP,aCNEG,GACZnQ,EAAqBoQ,EAAiB3I,EAAgB1K,EACtDZ,GACF,IAAMkU,EAAcC,aAAWC,iBAAiBxT,EAAOqT,EAAO3I,GACxD9J,EAAS1B,OAAK8E,cAAc0G,GAC5ByG,EAAWjS,OAAK0F,eAAe5E,GAErC,GAAIsT,EAAa,CACf,IAAMG,EAAaF,aAAWG,kBAAkBL,EAAOlC,GAEvD,MAAc,WAAV/R,EACM6D,EAAsByC,MAAM+N,EAAYA,EAAa7S,GAGvDqC,EAAoB0Q,SAASF,EAAYA,EAAa7S,GAShE,IANA,IAAMiB,EAAwB,WAAVzC,EAChBiB,eAAakM,uBAAuBtJ,GACpCA,EAEE2Q,EAAQ5R,SAAOhC,EAAOZ,EAAOyC,GAC7BuJ,EAASpJ,SAAO0I,EAAMtL,GACnBgE,EAAI,EAAGA,EAAIgI,EAAOV,OAAQtH,EAAG,CACpC,IAAMyQ,EAASzI,EAAO5F,WAAWpC,GAC3B0Q,EAAQD,EAAO9S,KAAI,SAACgT,EAAa1I,GAAM,OAAA0I,EAAMV,EAAMhI,MACzDD,EAAO3K,UAAP2K,GAAWwI,EAAMxT,UAANwT,EAAaE,WAAWD,IAGrC,MAAc,WAAVzU,EACKiB,eAAa2T,uBAAuB5I,EAAOrL,QAE7CqL,EAAOrL,gBAGA2F,GACZ9B,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAwP,UAAO3I,SAEd/L,EAAiBkF,EAAG,SAEd,IAAAvC,uCAAC2S,OAAQC,OACfX,aAAWY,kBAAkBtQ,EAAGoQ,EAAQC,GAExC,IACMtJ,EAAUwI,GADHrP,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACRkU,EAAQC,EAAOrQ,EAAE7D,MAAO6D,EAAEzE,OAC1D,OAAO2E,EAAQqC,eAAe8N,EAAOrQ,EAAEzE,MAAOwL,GAGzC,IAAMwJ,GAA4B,CACvC5Q,WAAY6Q,QACZ3Q,YAAa,MACbC,WAAY+B,aC1DE4O,GACZC,EAAqBC,EAAwBC,EAC7C1U,EAAoB2U,EAAuBC,EAC3CC,GAEF,IAAMC,EAAeL,EAAa,GAC5BM,EAAYH,EAAW,GAEvBI,EAA+B,IAAIjW,MAAMgW,GACzCE,EAA4B,IAAIlW,MAAM+V,GAEtCI,EAAOT,EAAa,GAE1B,GAAkB,IAAdM,EAAiB,CACnB,GAAqB,IAAjBD,EACF,MAAM,IAAI9S,MAAM,iFACQ8S,GAI1B,MAAO,CAFDK,EAAgBhW,OAAKwM,kBAAkB+I,EAAc,GAG1C,CAAC,EAAGQ,GAFfE,EAAejW,OAAKwM,kBAAkBgJ,EAAa,GAEfK,EAAmBC,GAQ/D,IAJA,IAAII,GAAiB,EACjBC,EAAiB,EACfC,EAAsB,IAAIxW,MAAMgW,GAAWS,KAAK,GAE7CnS,EAAI,EAAGA,EAAIyR,IAAgBzR,EAAG,CAGrC,IADMqJ,EAAM8H,EAAQnR,EAAI6R,IACd,EACR,MAAM,IAAIlT,MAAM,WAAWqB,sBAAqBqJ,UAElD,GAAIA,GAAOqI,EACT,MAAM,IAAI/S,MAAM,WAAWqB,sBAAqBqJ,SAAUqI,KAE1DQ,EAAU7I,GACZ2I,EAAiBA,GAAmB3I,GAAO4I,EAC3CA,EAAiB5I,EAInB,IADA,IAAI+I,GAAc,EACT/I,EAAM,EAAGA,EAAMqI,IAAarI,EAAK,CAExC,IAAMgJ,EAA+B,IAAnBH,EAAU7I,GAC5BsI,EAAkBtI,GAAOgJ,EACzBD,EAAcA,IAAgBC,EAE9BH,EAAU7I,GAAOpJ,KAAK8L,IAAImG,EAAU7I,GAAM,GAOtCA,EAAM,IACR6I,EAAU7I,IAAQ6I,EAAU7I,EAAM,IAItC,GAAI+I,GAAeJ,EAAgB,CACjC,IAAMF,EAA4BX,EAC5BY,EAA2BpV,EACjC,IAASqD,EAAI,EAAGA,EAAIyR,IAAgBzR,EAClC4R,EAAgB5R,GAAKA,EAEvB,MAAO,CACL8R,EAAe,CAACL,EAAcI,GAAOE,EAAcJ,EACnDC,GAGF,IAAMU,EAAmBJ,EAAUR,EAAY,GAMzCa,GALAT,EACFhW,OAAKwM,kBAAkB+I,EAAciB,EAAmBT,GAEtDE,EACFjW,OAAKwM,kBAAkBgJ,EAAagB,GACV,IAAI5W,MAAMgW,GAAWS,KAAK,IAGxD,IAASnS,EAAI,EAAGA,EAAIyR,IAAgBzR,EAAG,CAErC,IACM8L,EAASyG,EADTlJ,EAAM8H,EAAQnR,EAAI6R,IAElBW,GAAoB,IAARnJ,EAAa,EAAI6I,EAAU7I,EAAM,IAAMyC,EACzDyG,EAAYlJ,KACZ,IAAK,IAAIpB,EAAI,EAAGA,EAAI4J,IAAQ5J,EAE1B6J,EAAcU,EAAUX,EAAO5J,GAAKkJ,EAAQnR,EAAI6R,EAAO5J,GAEzD8J,EAAaS,GAAW7V,EAAOqD,GAE/B4R,EAAgB5R,GAAKwS,EAIvB,IAASnJ,EAAM,EAAGA,EAAMqI,IAAarI,EAAK,CAExC,GAAiB,IADAkJ,EAAYlJ,GACT,CAClB,IAAMoJ,EAAyB,IAARpJ,EAAa,EAAI6I,EAAU7I,EAAM,GAIxDyI,EAAcW,EAAgBZ,EAAO,GAAKxI,EAC1C,IAAK,IAAIE,EAAM,EAAGA,EAAMsI,IAAQtI,EAC9BuI,EAAcW,EAAgBZ,EAAOtI,GAAO,EAE9CwI,EAAaU,GAAiBjB,GAGlC,MAAO,CACLM,EAAe,CAACL,EAAcI,GAAOE,EAAcJ,EACnDC,YClHUc,GACZC,EAA0BC,EAA6BC,EACvDC,EACAC,GAUF,IATA,IAAMC,EAAYlX,OAAK8E,cAAckS,GAC/BG,EAAML,EAAkB,GACxBM,EAAaH,EAAYvV,OAIzB2V,EAAwB,GAC1BC,EAAU,EACVC,GAAgB,EACXzV,EAAI,EAAGA,EAAIsV,IAActV,EAAG,CACnC,IAAM0J,EAAOyL,EAAYnV,GACzB,IAAc,IAAV0J,EAAa,CACf,IAAsB,IAAlB+L,EACF,MAAM,IAAI1U,MAAM,iDACZ0U,UAAoBzV,GAE1ByV,EAAezV,EACfuV,EAAY7D,KAAK,OACZ,CACL,GAAIhI,EAAO,EACT,MAAM,IAAI3I,MAAM,QAAQf,gCAA+B0J,GAEzD8L,GAAW9L,EACX6L,EAAY7D,KAAKhI,IAGrB,IAAsB,IAAlB+L,EAAqB,CACvB,GAAID,GAAW,EACb,MAAM,IAAIzU,MACN,iHAIN,IAAM2U,EAAUrT,KAAKsT,MAAMP,EAAYI,GACvC,GAAIA,EAAUE,IAAYN,EACxB,MAAM,IAAIrU,MAAM,2CAA2CqU,8EAEvDI,kBAAuBN,mBAA2BK,GAGxDA,EAAYE,GAAgBC,EAE9B,IAAME,EAAa1X,OAAK8E,cAAcuS,GACtC,GAAIK,IAAeR,EACjB,MAAM,IAAIrU,MAAM,qCACZqU,gDACAQ,kBAA0BV,kBAA0BK,GAG1D,IAAMM,EAAYX,EAAWtV,OACvBkW,EAAyB,GAC/B,GAAID,EAAY,EAAG,CACjBC,EAAaD,EAAY,GAAK,EAC9B,IAAS7V,EAAI6V,EAAY,EAAG7V,GAAK,IAAKA,EACpC8V,EAAa9V,GAAK8V,EAAa9V,EAAI,GAAKkV,EAAWlV,EAAI,GAI3D,IAAM+V,EAA0B,GAChC,GAAIT,EAAa,EAAG,CAClBS,EAAcT,EAAa,GAAK,EAChC,IAAStV,EAAIsV,EAAa,EAAGtV,GAAK,IAAKA,EACrC+V,EAAc/V,GAAK+V,EAAc/V,EAAI,GAAKuV,EAAYvV,EAAI,GAM9D,IAFA,IAAMgW,EACF9X,OAAKwM,kBAAkBuK,EAAYI,EAAMC,GACpClT,EAAI,EAAGA,EAAIiT,IAAOjT,EAAG,CAE5B,IADA,IAAI5C,EAAK,EACA6K,EAAI,EAAGA,EAAIwL,IAAaxL,EAE/B7K,GAAMuV,EAAa3S,EAAIyT,EAAYxL,GAAKyL,EAAazL,GAEvD,IAASA,EAAI,EAAGA,EAAIiL,IAAcjL,EAEhC2L,EAAW5T,EAAIkT,EAAajL,GAAKhI,KAAKsT,MAAMnW,EAAKuW,EAAc1L,IAC/D7K,GAAMuW,EAAc1L,GAGxB,MAAO,CAAC2L,EAAY,CAACX,EAAKC,GAAaC,GCjFlC,IAAMU,GAAwB/S,YAA+BoE,EAAGC,GACrE,IAAM2O,EAAO5O,EAAIC,EACjB,OAAO2O,EAAOA,KAEHC,GACTlP,EAAiBmP,oBAAmBH,IAE3BI,GAAwC,CACnD7T,WAAY4T,oBACZ1T,YAAa,MACbC,WAAYwT,aCbEG,GACZnL,EAAoBpB,EAAuBwM,EAC3ClE,GAGF,IAFA,IAAMjI,EAASpJ,SAAOmK,EAAUpB,EAAK3L,OAE5BgE,EAAI,EAAGA,EAAIgI,EAAOV,KAAMtH,IAAK,CAIpC,IAHA,IAAMmC,EAAM6F,EAAO5F,WAAWpC,GAExBiO,EAAmB,IAAIvS,MAAMyG,EAAI3E,QAC9ByK,EAAI,EAAGA,EAAIgG,EAAOzQ,OAAQyK,IACjCgG,EAAOhG,GAAK9F,EAAI8F,GAAKkM,EAAQlM,GAAKgI,EAAMhI,GAE1CD,EAAO3K,UAAP2K,GAAWL,EAAK3K,UAAL2K,EAAYsG,WAAY9L,IAGrC,OAAO6F,ECZF,IAAMoM,GACTtT,YAA+BmL,EAAQC,GAAW,OAAAD,EAASC,KAClDmI,GACT9N,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CAAC1H,KAAMmH,EAAQM,EAAOvH,KAAMkH,EAAQM,MAEpCuO,GAAMzP,EAAiB0P,MAAKH,GAASC,IAErCG,GAA0B,CACrCpU,WAAYmU,MACZjU,YAAa,MACbC,WAAY+T,aCTEG,GACZ9M,EACA+M,GAEF,IADA,IAAMtT,EAAqB,IAAI1F,MAAMiM,EAAKkK,MACjC7R,EAAI,EAAGA,EAAIoB,EAAS5D,OAAQwC,IACnCoB,EAASpB,GAAK2H,EAAK/K,MAAMoD,GAAK0U,EAAK1U,GAErC,IAAM0B,EAAS9C,SAAOwC,EAAUuG,EAAK3L,OACrC,IAASgE,EAAI,EAAGA,EAAI0B,EAAO/E,OAAOa,SAAUwC,EAAG,CAI7C,IAHA,IAAMiO,EAASvM,EAAOU,WAAWpC,GAE3BuK,EAAwB,IAAI7O,MAAMiM,EAAKkK,MACpC5J,EAAI,EAAGA,EAAIsC,EAAY/M,OAAQyK,IACtCsC,EAAYtC,GAAKgG,EAAOhG,GAAKN,EAAK/K,MAAMqL,GAG1C,IAAM0C,EAAgBhD,EAAKnF,WAAW+H,GAEtC7I,EAAO/E,OAAOqD,GAAK2H,EAAKhL,OAAOgO,GAEjC,OAAOjJ,WCvBOiT,GACZlU,EAAewM,EAAkBC,EAAyB0H,EAC1DC,GAQF,IALA,IAAMC,EAAU7H,EAAOA,EAAOzP,OAAS,GACjCU,iBAAC6W,OAAOzN,OACR0N,EAAclZ,OAAK6F,uBAAuBuL,EAAQ6H,EAAQH,GAC1DK,EAAiBnZ,OAAK6F,uBAAuB,QAASoT,EAAQH,GAE3DzP,EAAI,EAAGA,EAAI4P,EAAO5P,IAAK,CAI9B,IAHA,IAAM2G,EAAS3G,EAAImC,EACbzH,EAAOY,EAAE8P,SAASzE,EAAQA,EAASxE,GACnC4N,EAAmD,GAChDlV,EAAI,EAAGA,EAAIH,EAAKrC,OAAQwC,IAC/BkV,EAAU5F,KAAK,CAAC7H,MAAO5H,EAAKG,GAAImV,MAAOnV,IAEzCkV,EAAUE,MAAK,SAAClQ,EAAGC,GAAM,OAAAA,EAAEsC,MAAQvC,EAAEuC,SAErC,IAAM4N,EAAYlQ,EAAIyP,EAChBU,EAAWN,EAAYzE,SAAS8E,EAAWA,EAAYT,GACvDW,EAAcN,EAAe1E,SAAS8E,EAAWA,EAAYT,GACnE,IAAS5U,EAAI,EAAGA,EAAI4U,EAAG5U,IACrBsV,EAAStV,GAAKkV,EAAUlV,GAAGyH,MAC3B8N,EAAYvV,GAAKkV,EAAUlV,GAAGmV,MAKlC,IAAMhC,EAAclG,EAAO3K,QAG3B,OAFA6Q,EAAYA,EAAY3V,OAAS,GAAKoX,EAE/B,CACLhW,SAAOuU,EAA4BjG,EAAQ8H,GAC3CpW,SAAOuU,EAA4B,QAAS8B,aCpChCO,GACZ7Y,EAAuBmS,EAAclS,EAAiBZ,GAgExD,IA1DA,IAAMyZ,EAAQ3Z,OAAKmT,eAAeH,EAAMlS,GAAO,GAyDzCwE,EAAW,CAAC,EAAGxE,EAAM,GAAI,GACtBoD,EAAI,EAAGA,EAAIyV,EAAOzV,IACzBoB,EAAS,IAAMxE,EAAMoD,GAEvBoB,EAAS,GAAKxE,EAAM6Y,GACpB,IAASzV,EAAIyV,EAAQ,EAAGzV,EAAIpD,EAAMY,OAAQwC,IACxCoB,EAAS,IAAMxE,EAAMoD,GAKvB,IAAM0V,EAA0C,GAG1CvE,EAAU,IAAI/M,WAAWxH,EAAM6Y,IAE/BE,EAAc,IAAIC,eAAaxU,EAAUpF,EAAOW,GAGhDkZ,EAA0B,GAC1BC,EAA6B,IAAhB1U,EAAS,IAA4B,IAAhBA,EAAS,GACjD,IAASpB,EAAI,EAAGA,EAAIpD,EAAM6Y,GAAQzV,IAAK,CAErC,IAAI+V,SACJ,GAAID,EAEFC,EAAUpZ,EAAOqD,GAAGgW,eACf,CAEL,IADA,IAAMC,EAAa,GACVC,EAAI,EAAGA,EAAI9U,EAAS,GAAI8U,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAI/U,EAAS,GAAI+U,IAC/BF,EAAW3G,KAAKqG,EAAY3Y,IAAIkZ,EAAGlW,EAAGmW,IAG1CJ,EAAUE,EAAWG,KAAK,KAI5B,QAAgCC,IAA5BX,EAAeK,GACjB5E,EAAQnR,GAAK0V,EAAeK,OACvB,CACL,IAAMO,EAAcC,OAAOC,KAAKd,GAAgBlY,OAChDkY,EAAeK,GAAWO,EAC1BnF,EAAQnR,GAAKsW,EACbT,EAAcvG,KAAKtP,IAOvB,IAAMyW,EAAiBrV,EAASkB,QAChCmU,EAAe,GAAKF,OAAOC,KAAKd,GAAgBlY,OAChD,IAAMkZ,EAAe,IAAId,eAAaa,EAAgBza,GACtD6Z,EAAcja,SAAQ,SAAC+a,EAAoB3W,GACzC,IAAK,IAAIkW,EAAI,EAAGA,EAAI9U,EAAS,GAAI8U,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAI/U,EAAS,GAAI+U,IAC/BO,EAAarZ,IAAIsY,EAAY3Y,IAAIkZ,EAAGS,EAAoBR,GAAID,EAAGlW,EAAGmW,MAOxE,IAAMhD,EAAcvW,EAAM0F,QAG1B,OAFA6Q,EAAYsC,GAASgB,EAAe,GAE7B,CACL1E,aAAc2E,EAAa/Z,OAC3BwW,cACAhC,ohBC3HY,OAAO,WAAM,OAAA,IAAI1U,IAAkB,GCT5C,IAAMma,GACTxO,EAAgByO,OAAK,SAACnO,GAAO,OAAAA,GAAM,EAAIA,EAAMzI,KAAKwJ,IAAIf,GAAM,KAEnDoO,GAA0B,CACrC1W,WAAYyW,MACZvW,YAAa,MACbC,WAAYqW,aCLEG,GAAUvW,GAKjB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAuW,UAEPzb,EAAiB,CAACkF,GAAI,aAMtB,IAJA,IAAM4H,EAAQvM,OAAK8E,cAAcH,EAAE7D,OAC7B0H,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnC6K,EAAU1L,OAAK6F,uBAAuB,UAAW0G,GAE9CrI,EAAI,EAAGA,EAAIsE,EAAM9G,OAAQwC,IAChCwH,EAAQxH,GAAKsE,EAAMtE,GAAK,EAAIgX,EAAQ1S,EAAMtE,GAAKsE,EAAMtE,GAGvD,OAAOW,EAAQqC,eAAevC,EAAE7D,MAAO,UAAW4K,GAG7C,IAAMyP,GAAgC,CAC3C7W,WAAY8W,YACZ5W,YAAa,MACbC,WAAYwW,ICxBRI,GAAYrW,GACd,SAACsW,EAAgBnL,GAAmB,OAAAmL,EAAS,EAAInL,EAASmL,EAASA,cAEvDC,GAAM7W,GAEb,IAAAoC,WAAQjC,YACRF,MAAGuW,UAEVzb,EAAiB,CAACkF,EAAGuW,GAAQ,SAE7B,IAAM9V,EAAQP,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnCwE,EAAQR,EAAQtE,KAAKW,IAAIga,EAAM7Z,QAAQR,OAEvCuB,kCAACuG,OAAYC,OAGnB,OAAO/D,EAAQqC,eAAe0B,EAAajE,EAAEzE,MAAOyI,GAG/C,IAAM6S,GAA4B,CACvClX,WAAYmX,QACZjX,YAAa,MACbC,WAAY8W,ICxBDG,GAAOpP,EAAgBqP,QAAM,SAAC/O,GAAO,OAAAzI,KAAK8L,IAAI,EAAGrD,MAEjDgP,GAA2B,CACtCtX,WAAYqX,OACZnX,YAAa,MACbC,WAAYiX,ICLDG,GACTvP,EAAgBwP,SAAO,SAAClP,GAAO,OAAAzI,KAAKsM,IAAItM,KAAK8L,IAAI,EAAGrD,GAAK,MAEhDmP,GAA4B,CACvCzX,WAAYwX,QACZtX,YAAa,MACbC,WAAYoX,ICNDG,GACT1P,EAAgB2P,WAAS,SAACrP,GAAO,OAAA,GAAK,EAAIzI,KAAKwJ,KAAKf,OAE3CsP,GAA8B,CACzC5X,WAAY2X,UACZzX,YAAa,MACbC,WAAYuX,aCCEG,GACZtX,EAAyBF,EAAeyX,EACxCC,EAAqCC,GACvC,GAAmB,WAAfF,EACF,OAAO7U,EAAS,CAACT,OAAQ,CAACnC,KAAIE,YACzB,GAAmB,SAAfuX,EACT,OAAOV,GAAK,CAAC5U,OAAQ,CAACnC,KAAIE,YACrB,GAAmB,QAAfuX,EACT,OAAOtB,GAAI,CAAChU,OAAQ,CAACnC,KAAIE,YACpB,GAAmB,UAAfuX,EACT,OAAOP,GAAM,CAAC/U,OAAQ,CAACnC,KAAIE,YACtB,GAAmB,UAAfuX,EACT,OAAOb,GAAM,CAACzU,OAAQ,CAACnC,IAAGuW,MAAOmB,GAAyBxX,YACrD,GAAmB,cAAfuX,EACT,OAAOnB,GAAU,CAACnU,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAACkT,MAAOoB,KAClD,GAAmB,YAAfF,EACT,OAAOJ,GAAQ,CAAClV,OAAQ,CAACnC,KAAIE,YAE/B,MAAM,IAAIhC,MACN,cAAcuZ,6DC1BJG,GACZ7X,GAGK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACA7D,UAEDyL,EAAQvM,OAAK8E,cAAcH,EAAE7D,OAC7B0b,EAASxc,OAAKyc,uBAAuB3b,EAAOyL,GAC5CmQ,EAAS1c,OAAK8E,cAAc0X,GAElCxc,OAAKC,OACDsM,IAAUmQ,GACV,WAAM,MAAA,kBAAkBF,WAAeE,EAAjC,gCACQ/X,EAAE7D,eAAcyL,EADxB,mFAIV1H,EAAQ2C,OAAO7C,EAAEtD,QAEjB,IAAMsb,EAAQ9X,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAEjC,GAAgC,MAA5Bsb,EAAMta,mBAA4B,CACpC,IAAME,EAAOoa,EAAMta,mBAAmBE,KAChCE,EAAOka,EAAMta,mBAAmBI,KAEtCF,EAAKzB,MAAQ0b,EACb/Z,EAAK3B,MAAQ0b,EAGf,MAAO,CAACnb,OAAQsD,EAAEtD,OAAQP,MAAO0b,EAAQtc,MAAOyE,EAAEzE,OAG7C,IAAM0c,GAA8B,CACzCtY,WAAYuY,UACZrY,YAAa,MACbC,WAAY8X,aCjCEO,GAAYpY,GAKnB,IAAAoC,WAAQjC,YAASmD,UACjBoB,MAAGC,MACH0T,eAAYC,eAEnBvd,EAAiB,CAAC2J,EAAGC,GAAI,UAEzB,IAAMvD,EAAQsD,EAAEtI,MAAMY,OAChBqE,EAAQsD,EAAEvI,MAAMY,OAEhBub,EAAcF,EAAa3T,EAAEtI,MAAMgF,EAAQ,GAAKsD,EAAEtI,MAAMgF,EAAQ,GAChEoX,EAAcF,EAAa3T,EAAEvI,MAAMiF,EAAQ,GAAKsD,EAAEvI,MAAMiF,EAAQ,GAEhEoX,EAAcJ,EAAa3T,EAAEtI,MAAMgF,EAAQ,GAAKsD,EAAEtI,MAAMgF,EAAQ,GAChEsX,EAAcJ,EAAa3T,EAAEvI,MAAMiF,EAAQ,GAAKsD,EAAEvI,MAAMiF,EAAQ,GAEhEsX,EAAajU,EAAEtI,MAAM0F,MAAM,GAAI,GAC/B8W,EAAajU,EAAEvI,MAAM0F,MAAM,GAAI,GAE/B+W,EAAYvd,OAAK8E,cAAcuY,GAC/BG,EAAYxd,OAAK8E,cAAcwY,GAE/BG,EACFF,IAAcC,GAA2B,IAAdD,GAAiC,IAAdC,EAElDxd,OAAKC,OACD6F,GAAS,GAAKC,GAAS,GAAK0X,GAC5B,WAAM,MAAA,uJAEsBJ,YAAoBC,UAEpD,IAEMrQ,GADFsQ,EAAYC,EAAYpU,EAAEtI,MAAM0F,MAAM,GAAI,GAAK6C,EAAEvI,MAAM0F,MAAM,GAAI,IAClCkX,OAAO,CAACP,EAAaC,IAExDpd,OAAKC,OACDgd,IAAgBC,GAChB,WAAM,MAAA,kCAAkCD,YACjCC,8BAAuC9T,EAAEtI,cACzCuI,EAAEvI,yBAAwBic,EAC7B,mBAAmBC,oBAmC3B,IAjCA,IAEMW,EAAWX,EAAa,CAACQ,EAAWJ,EAAaF,GACzB,CAACM,EAAWN,EAAaE,GAGjDQ,EAAMrB,GAAQ,CAACzV,OAAQ,CAACnC,EAAGyE,GAAIvE,UAASmD,MAAO,CAAClH,MANrCic,EAAa,CAACQ,EAAWN,EAAaE,GACzB,CAACI,EAAWJ,EAAaF,MAMjDY,EAAMtB,GAAQ,CAACzV,OAAQ,CAACnC,EAAG0E,GAAIxE,UAASmD,MAAO,CAAClH,MAAO6c,KAEvDG,EAAYf,EAAaa,EAAI9c,MAAM,GAAK8c,EAAI9c,MAAM,GAClDid,EAAUhB,EAAaa,EAAI9c,MAAM,GAAK8c,EAAI9c,MAAM,GAChDkd,EAAWhB,EAAaa,EAAI/c,MAAM,GAAK+c,EAAI/c,MAAM,GACjDmd,EAAW9Z,KAAK8L,IAAIsN,EAAWC,GAE/BU,EAAYrZ,EAAQtE,KAAKW,IAAI0c,EAAIvc,QAAQR,OACzCsd,EAAYtZ,EAAQtE,KAAKW,IAAI2c,EAAIxc,QAAQR,OAEzCud,EAAape,OAAK0F,eAAekY,EAAI9c,OACrCud,EAAare,OAAK0F,eAAemY,EAAI/c,OAErCsB,gCAACkc,OAAQC,OAAYC,OAGrBrV,gCAACsV,OAAYC,OAAYC,OAIzBnT,EAAOuS,EAAUC,EACjBpY,EAAS9C,SAAO,CAACmb,EAAUF,EAASC,GAAWJ,EAAI1d,OAEnD0e,EAAUhZ,EAAO/E,OACjBge,EAAYha,EAAQga,UAEjBC,EAAK,EAAGA,EAAKb,EAAUa,IAC9B,IAAK,IAAIC,EAAK,EAAGA,EAAKhB,EAASgB,GAAMF,EACnC,IAAK,IAAIG,EAAK,EAAGA,EAAKhB,EAAUgB,GAAMH,EACpC,IAAK,IAAII,EAAK,EAAGA,EAAKnB,EAAWmB,GAAMJ,EAMrC,IAJA,IAAMK,EAAS/a,KAAKsM,IAAIsO,EAAKF,EAAWd,GAClCoB,EAAShb,KAAKsM,IAAIuO,EAAKH,EAAWb,GAClCoB,EAASjb,KAAKsM,IAAIwO,EAAKJ,EAAWf,GAE/B5Z,EAAI6a,EAAI7a,EAAIgb,EAAQhb,IAC3B,IAAK,IAAIiI,EAAI6S,EAAI7S,EAAIgT,EAAQhT,IAAK,CAGhC,IAFA,IAAIkT,GAAM,EAEDvG,GAAImG,EAAInG,GAAIsG,EAAQtG,KAAK,CAChC,IAAMwG,GAAenb,KAAKsM,IAAIqO,EAAIvB,EAAY,GAAKe,EAC7CiB,GAAepb,KAAKsM,IAAIqO,EAAItB,EAAY,GAAKmB,EAKnDU,IAHInB,EAAUoB,GAAepb,EAAIqa,EAAazF,GAAI0F,GAE9CL,EAAUrF,GAAI2F,EAAatS,EAAIuS,EAAaa,IAGlDX,EAAQE,EAAKtT,GAAQtH,EAAI8Z,EAAW7R,KAAOkT,GAYvD,OAJAxa,EAAQsD,8BAA8ByV,GACtC/Y,EAAQsD,8BAA8B0V,GAG/BhZ,EAAQqC,eACX+F,EAAUrH,EAAO1F,MAAO0F,EAAO/E,QAG9B,IAAM2e,GAAkC,CAC7Clb,WAAYmb,cACZjb,YAAa,MACbC,WAAYqY,ICjFP,IAAM4C,GAAmC,CAC9Cpb,WAAYqb,eACZnb,YAAa,MACbC,oBAzC2BC,GAKpB,IAIHkb,EACAC,EACAC,EANGhZ,WAAQjC,YAASmD,UACjBoB,MAAGC,MAAG0W,SAAM1D,2BACZU,eAAYC,eAAYZ,eAAYE,mBAMrC0D,EAA8B,GAIpCJ,EADI9C,GAAY,CAAChW,OAAQ,CAACsC,IAAGC,KAAIrB,MAAO,CAAC+U,aAAYC,cAAanY,YAG9Dkb,IACFF,EAAS5U,EAAI,CAACnE,OAAQ,CAACsC,EAAGwW,EAASvW,EAAG0W,GAAOlb,YAC7Cmb,EAAcxM,KAAKoM,GACnBA,EAAUC,GAERzD,IACF0D,EAAgB3D,GACZtX,EAAS+a,EAASxD,EAAYC,EAAwBC,GAC1D0D,EAAcxM,KAAKoM,GACnBA,EAAUE,GAGZ,IAAgB,QAAAG,IAAAC,WAAAA,IAAe,CAA1B,IAAMhc,OACTW,EAAQsD,8BAA8BjE,GAGxC,OAAO0b,ICvCIO,GAAO7T,EAAgB8T,QAAM,SAACxT,GAAO,OAAAzI,KAAKgc,KAAKvT,MAE/CyT,GAA2B,CACtC/b,WAAY8b,OACZ5b,YAAa,MACbC,WAAY0b,ICLDG,GAAQhU,EAAgBiU,SAAO,SAAC3T,GAAO,OAAAzI,KAAKmc,MAAM1T,MAElD4T,GAA4B,CACvClc,WAAYic,QACZ/b,YAAa,MACbC,WAAY6b,ICiBP,IAAMG,GAA2B,CACtCnc,WAAYoc,OACZlc,YAAa,MACbC,oBAxBmBC,GAEZ,IAAAoC,WAAQjC,YACT8b,EAAU7Z,EAEhBrH,EAAiBqH,EAAQ,QAMzB,IAJA,IAAM/C,EACF4c,EAAQ9e,KAAI,SAAA9B,GAAK,OAAA8E,EAAQtE,KAAKW,IAAInB,EAAEsB,QAAQR,UAC1CqL,EAASpJ,SAAO6d,EAAQ,GAAG7f,MAAO6f,EAAQ,GAAGzgB,OAC7CwL,EAAUQ,EAAOrL,OACdqD,EAAI,EAAGA,EAAIyc,EAAQjf,OAAQwC,IAElC,IADA,IAAM0c,EAAW7c,EAAKG,GACbiI,EAAI,EAAGA,EAAIT,EAAQhK,OAAQyK,IAClCT,EAAQS,IAAMyU,EAASzU,GAI3B,OAAOtH,EAAQqC,eAAegF,EAAOpL,MAAOoL,EAAOhM,MAAOgM,EAAOrL,UCsC5D,IAAMggB,GAA0B,CACrCvc,WAAYwc,MACZtc,YAAa,MACbC,oBAxDEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAqO,SAAMC,aAEbxT,EAAiBkF,EAAG,OAEpB,IAAMoc,EAAW/gB,OAAKmT,eAAeH,EAAMrO,EAAE7D,OACzCoS,EAAO6N,EACLC,EAAe7f,eAAakS,mBAAmBH,EAAMvO,EAAE7D,MAAMY,QAC/Duf,EAAKtc,EACW,MAAhBqc,IACFC,EAAK5O,GAAU,CAACvL,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC+J,KAAMiP,KACpD9N,EAAO/R,eAAasS,iBAAiBP,EAAKxR,OAAQiD,EAAE7D,MAAMY,SAG5DP,eAAa+f,2BAA2B,MAAOhO,EAAM+N,EAAGngB,MAAMY,QAO9D,IANM,IAAAU,sDAAC6K,OAAUyF,OAEX3C,EAAa/P,OAAK8E,cAAc4N,GAChC3O,EAAO/D,OAAKsH,oBAAoBtH,OAAK8E,cAAcmI,GAAWgU,EAAG/gB,OAEjEkF,EAAQP,EAAQtE,KAAKW,IAAI+f,EAAG5f,QAAQR,OACjCqD,EAAI,EAAGA,EAAIH,EAAKrC,SAAUwC,EAAG,CAGpC,IAFA,IAAM8L,EAAS9L,EAAI6L,EACfoR,EAAM/b,EAAM4K,GACP7D,EAAI,EAAGA,EAAI4D,IAAc5D,EAAG,CACnC,IAAMR,EAAQvG,EAAM4K,EAAS7D,GAC7BgV,EAAMA,GAAOxV,EAEf5H,EAAKG,GAAKid,EAGQ,MAAhBH,GACFnc,EAAQsD,8BAA8B8Y,GAGxC,IAAMrb,EAASf,EAAQqC,eAAe+F,EAAUgU,EAAG/gB,MAAO6D,GAE1D,GAAIkP,EAAU,CACZ,IACMmO,EACF7E,GAAQ,CAACzV,OAAQ,CAACnC,EAAGiB,GAASf,UAASmD,MAAO,CAAClH,MAF7BK,eAAauS,qBAAqBzG,EAAU8T,MAMlE,OAFAlc,EAAQsD,8BAA8BvC,GAE/Bwb,EAGT,OAAOxb,ICGF,IAAMyb,GAA0B,CACrC/c,WAAYgd,MACZ9c,YAAa,MACbC,oBAxDEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAqO,SAAMC,aAEbxT,EAAiBkF,EAAG,OAEpB,IAAMoc,EAAW/gB,OAAKmT,eAAeH,EAAMrO,EAAE7D,OACzCoS,EAAO6N,EACLC,EAAe7f,eAAakS,mBAAmBH,EAAMvO,EAAE7D,MAAMY,QAC/Duf,EAAKtc,EACW,MAAhBqc,IACFC,EAAK5O,GAAU,CAACvL,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC+J,KAAMiP,KACpD9N,EAAO/R,eAAasS,iBAAiBP,EAAKxR,OAAQiD,EAAE7D,MAAMY,SAG5DP,eAAa+f,2BAA2B,MAAOhO,EAAM+N,EAAGngB,MAAMY,QAO9D,IANM,IAAAU,sDAAC6K,OAAUyF,OAEX3C,EAAa/P,OAAK8E,cAAc4N,GAChC3O,EAAO/D,OAAKsH,oBAAoBtH,OAAK8E,cAAcmI,GAAWgU,EAAG/gB,OAEjEkF,EAAQP,EAAQtE,KAAKW,IAAI+f,EAAG5f,QAAQR,OACjCqD,EAAI,EAAGA,EAAIH,EAAKrC,SAAUwC,EAAG,CAGpC,IAFA,IAAM8L,EAAS9L,EAAI6L,EACfwR,EAASnc,EAAM4K,GACV7D,EAAI,EAAGA,EAAI4D,IAAc5D,EAAG,CACnC,IAAMR,EAAQvG,EAAM4K,EAAS7D,GAC7BoV,EAASA,GAAU5V,EAErB5H,EAAKG,GAAKqd,EAGQ,MAAhBP,GACFnc,EAAQsD,8BAA8B8Y,GAGxC,IAAMrb,EAASf,EAAQqC,eAAe+F,EAAUgU,EAAG/gB,MAAO6D,GAE1D,GAAIkP,EAAU,CACZ,IACMmO,EACF7E,GAAQ,CAACzV,OAAQ,CAACnC,EAAGiB,GAASf,UAASmD,MAAO,CAAClH,MAF7BK,eAAauS,qBAAqBzG,EAAU8T,MAMlE,OAFAlc,EAAQsD,8BAA8BvC,GAE/Bwb,EAGT,OAAOxb,ICHF,IAAM4b,GAA6B,CACxCld,WAAYmd,SACZjd,YAAa,MACbC,oBAnDEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAqO,SAEPvT,EAAiBkF,EAAG,UAEpB,IAAIuO,EAAOlT,OAAKmT,eAAeH,EAAMrO,EAAE7D,OACjCkgB,EAAe7f,eAAakS,mBAAmBH,EAAMvO,EAAE7D,MAAMY,QAC/Duf,EAAKtc,EACH4O,EAA0B,GACZ,MAAhByN,IACFC,EAAK5O,GAAU,CAACvL,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC+J,KAAMiP,KACpDzN,EAAwBC,KAAKyN,GAC7B/N,EAAO/R,eAAasS,iBAAiBP,EAAKxR,OAAQuf,EAAGngB,MAAMY,SAG7DwR,EAAO,CAACA,EAAK,IACb/R,eAAa+f,2BAA2B,SAAUhO,EAAM+N,EAAGngB,MAAMY,QASjE,IARM,IAAAU,sDAAC6K,OAAUyF,OAGXgP,EAAU1hB,OAAK8E,cAAcmI,GAC7BlJ,EAAO/D,OAAKsH,oBAAoBoa,EAAS,SACzC3R,EAAa/P,OAAK8E,cAAc4N,GAEhCtN,EAAQP,EAAQtE,KAAKW,IAAI+f,EAAG5f,QAAQR,OACjCqD,EAAI,EAAGA,EAAIH,EAAKrC,SAAUwC,EAAG,CAIpC,IAHA,IAAM8L,EAAS9L,EAAI6L,EACfE,EAAM7K,EAAM4K,GACZ2R,EAAW,EACNxV,EAAI,EAAGA,EAAI4D,IAAc5D,EAAG,CACnC,IAAMR,EAAQvG,EAAM4K,EAAS7D,GACzBR,EAAQsE,IACVA,EAAMtE,EACNgW,EAAWxV,GAGfpI,EAAKG,GAAKyd,EAMZ,OAHApO,EAAwBzT,SACpB,SAAAC,GAAK,OAAA8E,EAAQsD,8BAA8BpI,MAExC8E,EAAQqC,eAAe+F,EAAU,QAASlJ,KCG5C,IAAM6d,GAA6B,CACxCtd,WAAYud,SACZrd,YAAa,MACbC,oBAnDEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAqO,SAEPvT,EAAiBkF,EAAG,UAEpB,IAAIuO,EAAOlT,OAAKmT,eAAeH,EAAMrO,EAAE7D,OACjCkgB,EAAe7f,eAAakS,mBAAmBH,EAAMvO,EAAE7D,MAAMY,QAC/Duf,EAAKtc,EACH4O,EAA0B,GACZ,MAAhByN,IACFC,EAAK5O,GAAU,CAACvL,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC+J,KAAMiP,KACpDzN,EAAwBC,KAAKyN,GAC7B/N,EAAO/R,eAAasS,iBAAiBP,EAAKxR,OAAQuf,EAAGngB,MAAMY,SAG7DwR,EAAO,CAACA,EAAK,IACb/R,eAAa+f,2BAA2B,SAAUhO,EAAM+N,EAAGngB,MAAMY,QASjE,IARM,IAAAU,sDAAC6K,OAAUyF,OAGXgP,EAAU1hB,OAAK8E,cAAcmI,GAC7BlJ,EAAO/D,OAAKsH,oBAAoBoa,EAAS,SACzC3R,EAAa/P,OAAK8E,cAAc4N,GAEhCtN,EAAQP,EAAQtE,KAAKW,IAAI+f,EAAG5f,QAAQR,OACjCqD,EAAI,EAAGA,EAAIH,EAAKrC,SAAUwC,EAAG,CAIpC,IAHA,IAAM8L,EAAS9L,EAAI6L,EACfU,EAAMrL,EAAM4K,GACZ8R,EAAW,EACN3V,EAAI,EAAGA,EAAI4D,IAAc5D,EAAG,CACnC,IAAMR,EAAQvG,EAAM4K,EAAS7D,GACzBR,EAAQ8E,IACVA,EAAM9E,EACNmW,EAAW3V,GAGfpI,EAAKG,GAAK4d,EAMZ,OAHAvO,EAAwBzT,SACpB,SAAAC,GAAK,OAAA8E,EAAQsD,8BAA8BpI,MAExC8E,EAAQqC,eAAe+F,EAAU,QAASlJ,KChDtCge,GAAOzV,EAAgB0V,QAAM,SAACpV,GAAO,OAAAzI,KAAK4d,KAAKnV,MAE/CqV,GAA2B,CACtC3d,WAAY0d,OACZxd,YAAa,MACbC,WAAYsd,ICLDG,GAAQ5V,EAAgB6V,SAAO,SAACvV,GAAO,OAAAzI,KAAK+d,MAAMtV,MAElDwV,GAA4B,CACvC9d,WAAY6d,QACZ3d,YAAa,MACbC,WAAYyd,ICLDG,GAAO/V,EAAgBgW,QAAM,SAAC1V,GAAO,OAAAzI,KAAKke,KAAKzV,MAE/C2V,GAA2B,CACtCje,WAAYge,OACZ9d,YAAa,MACbC,WAAY4d,ICLDG,GAAYxd,GACrB,SAACmL,EAAQC,GAAW,OAAAjM,KAAKse,MAAMtS,EAAQC,MAE9BqS,GAAQ1Z,EAAiB2Z,QAAOF,IAEhCG,GAA4B,CACvCre,WAAYoe,QACZle,YAAa,MACbC,WAAYge,ICRDG,GAAQtW,EAAgBuW,SAAO,SAACjW,GAAO,OAAAzI,KAAKye,MAAMhW,MAElDkW,GAA4B,CACvCxe,WAAYue,QACZre,YAAa,MACbC,WAAYme,aCPEG,GACZC,EAAqB7R,EAAkBjR,EAAiBmY,EACxD4K,EACAC,GAsBF,IArBA,IAAMC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3BC,EACY,QAAbZ,EAAqBa,OAAOC,kBACPD,OAAOE,kBAE3BC,EAASphB,SAAOmgB,EAAShW,SAAU/M,GACnCikB,EAAaD,EAAOrjB,OAEpBujB,EACFnB,EAAShW,SAAS,GAAKgW,EAAShW,SAAS,GAAKgW,EAAShW,SAAS,GAC9DoX,EAAmBpB,EAAShW,SAAS,GAAKgW,EAAShW,SAAS,GAC5DqX,EAAmBrB,EAAShW,SAAS,GAElC5D,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EAGxC,IAFA,IAAMmb,EAAoBnb,EAAI+a,EACxBK,EAAmBpb,EAAIgP,EAAQ,GAC5BvW,EAAI,EAAGA,EAAImhB,EAASyB,aAAc5iB,EACzC,IAAK,IAAI6iB,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAM1C,IALA,IAAME,EAAWF,EAAKxB,EAAeM,EAC/BqB,EAAQ3gB,KAAK8L,IAAI,EAAG4U,GACpBE,EACF5gB,KAAKsM,IAAIwS,EAAS+B,SAAUzB,EAAwBsB,GAClDI,EAAkBT,EAAoBG,EAAKN,EACxCa,EAAK,EAAGA,EAAKjC,EAASkC,WAAYD,EAAI,CAQ7C,IAPA,IAAME,EAAWF,EAAK9B,EAAcQ,EAC9ByB,EAAQlhB,KAAK8L,IAAI,EAAGmV,GACpBE,EACFnhB,KAAKsM,IAAIwS,EAASsC,QAAS/B,EAAuB4B,GAClDI,EAAc1B,EACd2B,EAAW,EACXC,EAAQ,EACHC,EAAKb,EAAOa,EAAKZ,EAAOY,GAAMtC,EAAgB,CAErD,IADA,IAAMuC,EAAWnB,EAAmBkB,EAAKtN,EAAQ,GACxCwN,EAAKR,EAAOQ,EAAKP,EAAOO,GAAMvC,EAAe,CACpD,IACMwC,EAAQ9C,EADG4C,EAAWC,EAAKxN,EAAQ,GACRvW,GACf,QAAbohB,GAAsB4C,EAAQN,EACjCA,EAAcM,EACQ,QAAb5C,IACTuC,GAAYK,EACZJ,KAGJ,GAAIK,MAAMP,GACR,MAIJrB,EADqBc,EAAkBC,EAAKZ,EAAmBxiB,GAE9C,QAAbohB,EAAqBuC,EAAWC,EAAQF,EAKpD,OAAOtB,WAGO8B,GACZhD,EAAqB7R,EAAkBjR,EACvC+iB,EAAmCgD,EACnCC,gBADmCD,mBACnCC,MAYF,IAXA,IAAMC,EAAerjB,SAAOmgB,EAAShW,SAAU,SACzCkW,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3BhY,EAAO/I,SAAOqO,EAAQjR,EAAO8iB,GAC1B3Z,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EACxC,IAAK,IAAIvH,EAAI,EAAGA,EAAImhB,EAASyB,aAAc5iB,EACzC,IAAK,IAAI6iB,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAAI,CAG9C,IAFA,IAAME,EAAWF,EAAKxB,EAAeM,EACjCqB,EAAQD,EACLC,EAAQ,GACbA,GAASzB,EAKX,IAFA,IAAM0B,EACF5gB,KAAKsM,IAAIwS,EAAS+B,SAAUzB,EAAwBsB,GAC/CK,EAAK,EAAGA,EAAKjC,EAASkC,WAAYD,EAAI,CAG7C,IAFA,IAAME,EAAWF,EAAK9B,EAAcQ,EAChCyB,EAAQD,EACLC,EAAQ,GACbA,GAAS/B,EAOX,IALA,IAAMgC,EACFnhB,KAAKsM,IAAIwS,EAASsC,QAAS/B,EAAuB4B,GAClDgB,EAAWrC,OAAOC,kBAClBqC,GAAe,EAEVV,EAAKb,EAAOa,EAAKZ,EAAOY,GAAMtC,EAErC,IADA,IAAMiD,EAAKX,EAAKd,EACPgB,EAAKR,EAAOQ,EAAKP,EAAOO,GAAMvC,EAAe,CACpD,IAAMiD,EAAKV,EAAKT,EACVU,EAAQja,EAAK3K,IAAImI,EAAGsc,EAAIE,EAAI/jB,GAC9BgkB,EAAQM,IACVA,EAAWN,EAETO,EADEJ,EACYC,IACR7c,EAAI4Z,EAAS+B,SAAWW,GAAM1C,EAASsC,QAAUM,GAC3C5C,EAASyB,WACb5iB,GACH6jB,EAAK1C,EAASsC,QAAUM,GAAM5C,EAASyB,WAAa5iB,EAE3CwkB,EAAK9C,EAAuB+C,GAKlDJ,EAAa5kB,IAAI8kB,EAAahd,EAAGsb,EAAIO,EAAIpjB,IAKjD,OAAOqkB,WAGOK,GACZxD,EAAqB7R,EAAkBjR,EAAiBmY,EACxD4K,EACAC,GA4BF,IA3BA,IAAMuD,EAAcxD,EAASwD,YACvBtD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBsD,EAAgBzD,EAASyD,cACzBrD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBqD,EAAuB1D,EAAS0D,qBAChCpD,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCoD,EAAW3D,EAASS,QAAQmD,MAC5BpD,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAE3BC,EACY,QAAbZ,EAAqBa,OAAOC,kBACPD,OAAOE,kBAE3BC,EAASphB,SAAOmgB,EAAShW,SAAU/M,GACnCikB,EAAaD,EAAOrjB,OAEpBujB,EAAqBnB,EAAShW,SAAS,GAAKgW,EAAShW,SAAS,GAChEgW,EAAShW,SAAS,GAAKgW,EAAShW,SAAS,GACvC6Z,EACF7D,EAAShW,SAAS,GAAKgW,EAAShW,SAAS,GAAKgW,EAAShW,SAAS,GAC9DoX,EAAmBpB,EAAShW,SAAS,GAAKgW,EAAShW,SAAS,GAC5DqX,EAAmBrB,EAAShW,SAAS,GAElCgM,EAAQ,EAAGA,EAAQgK,EAASsB,YAAatL,EAGhD,IAFA,IAAMuL,EAAoBvL,EAAQmL,EAC5BK,EAAmBxL,EAAQZ,EAAQ,GAChC0O,EAAU,EAAGA,EAAU9D,EAASyB,aAAcqC,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS/D,EAASgE,WAAYD,EAAQ,CAGzD,IAFA,IAAME,EAAeF,EAASP,EAAcG,EACxCO,EAAYD,EACTC,EAAY,GACjBA,GAAaT,EAMf,IAJA,IAAMU,EACFjjB,KAAKsM,IAAIwS,EAASoE,QAASV,EAAuBO,GAChDI,EACF9C,EAAoBwC,EAASF,EACxBS,EAAO,EAAGA,EAAOtE,EAAS2B,YAAa2C,EAAM,CAGpD,IAFA,IAAMC,EAAaD,EAAOpE,EAAeM,EACrCgE,EAAUD,EACPC,EAAU,GACfA,GAAWpE,EAKb,IAHA,IAAMqE,EACFvjB,KAAKsM,IAAIwS,EAAS+B,SAAUzB,EAAwBiE,GAClDvC,EAAkBqC,EAAoBC,EAAOlD,EAC1CsD,EAAO,EAAGA,EAAO1E,EAASkC,WAAYwC,EAAM,CAGnD,IAFA,IAAMC,EAAaD,EAAOvE,EAAcQ,EACpCiE,EAAUD,EACPC,EAAU,GACfA,GAAWvE,EASb,IAPA,IAAMwE,EACF3jB,KAAKsM,IAAIwS,EAASsC,QAAS/B,EAAuBoE,GAEhDG,EAAkB9C,EAAkB0C,EAAOrD,EAC7CkB,EAAc1B,EACd2B,EAAW,EACXC,EAAQ,EACHsC,EAASb,EAAWa,EAASZ,EACjCY,GAAUtB,EAAe,CAE5B,IADA,IAAMuB,EAAexD,EAAmBuD,EAAS3P,EAAQ,GAChD6P,EAAOT,EAASS,EAAOR,EAASQ,GAAQ7E,EAAgB,CAE/D,IADA,IAAM8E,EAAaF,EAAeC,EAAO7P,EAAQ,GACxC+P,EAAOP,EAASO,EAAON,EAC3BM,GAAQ9E,EAAe,CAC1B,IACMwC,EAAQ9C,EADKmF,EAAaC,EAAO/P,EAAQ,GACZ0O,GAOnC,GANkB,QAAb7D,GAAsB4C,EAAQN,EACjCA,EAAcM,EACQ,QAAb5C,IACTuC,GAAYK,EACZJ,KAEEK,MAAMP,GACR,MAGJ,GAAIO,MAAMP,GACR,MAGJ,GAAIO,MAAMP,GACR,MAIJrB,EADqB4D,EAAkBhB,GAEtB,QAAb7D,EAAqBuC,EAAWC,EAAQF,IAOtD,OAAOtB,ECvMF,IAAMmE,GAA8B,CACzC/jB,WAAYgkB,UACZ9jB,YAAa,MACbC,oBAnCEC,GAGK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACPlF,EAAiBkF,EAAG,WACb,IAAA4jB,eAAYlQ,YAASmQ,QAAKC,oBAGjCzoB,OAAKC,OACDkB,eAAaunB,+BAA+BrQ,EAH9B,IAId,WAAM,MAAA,wEACaA,0BAEvB,IAGI5G,EAHEwR,EAAW9hB,eAAawnB,kBAC1BhkB,EAAE7D,MAA2CynB,EAAYlQ,EAR3C,EASHmQ,EAAKC,GAGpB,GAA6B,IAAzBxF,EAAS2F,aAA+C,IAA1B3F,EAAS4F,cACvC7oB,OAAK8oB,YAAY7F,EAAS8F,QAAS9F,EAAShW,UAC9CwE,EAAMlK,EAAS,CAACT,OAAQ,CAACnC,KAAIE,gBACxB,CACL,IAAMme,EAAUne,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACrCmoB,EAAUhpB,OAAK0F,eAAef,EAAE7D,OAChCgC,EAASigB,GAAKC,EAASre,EAAE7D,MAAO6D,EAAEzE,MAAO8oB,EAAS/F,EAAU,OAClExR,EAAM5M,EAAQqC,eACV+b,EAAShW,SAAUtI,EAAEzE,MAAO4C,EAAOjC,QAEzC,OAAO4Q,ICRF,IAAMwX,GAAgC,CAC3C3kB,WAAY4kB,YACZ1kB,YAAa,MACbC,oBAzBwBC,GAKjB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACA4jB,eAAYlQ,YAASmQ,QAAKC,oBAAiBU,eAElD1pB,EAAiBkF,EAAG,aAEpB,IAAMse,EAAW9hB,eAAaioB,kBAC1BzkB,EAAE7D,MAAmDynB,EAAYlQ,EACjE,EAAmBmQ,EAAKC,EAAiBU,GAGvCjd,EAASsa,GADC3hB,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OAE9B8D,EAAE7D,MAAO6D,EAAEzE,MAAOF,OAAK0F,eAAef,EAAE7D,OAAQmiB,EAAU,OAEvE,OAAOpe,EAAQqC,eAAegF,EAAOpL,MAAO,UAAWoL,EAAOrL,UCiEzD,IAAMwoB,GAAoC,CAC/C/kB,WAAYglB,gBACZ9kB,YAAa,MACbC,oBAxF4BC,GAKrB,IAAAoC,WAAQjC,YAASmD,UACjBuhB,OAAI5hB,UACJ4gB,eAAYlQ,YAASmQ,QAAKC,oBAEjChpB,EAAiB,CAAC8pB,EAAI5hB,GAAQ,iBA2B9B,IAzBA,IAAMsb,EAAW9hB,eAAaioB,kBAC1BzhB,EAAM7G,MAAmDynB,EACzDlQ,EAAS,EAAmBmQ,EAAKC,GAE/BhC,EAAcxD,EAASwD,YACvBtD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBoG,EAAcvG,EAASuG,YACvBX,EAAe5F,EAAS4F,aACxBD,EAAc3F,EAAS2F,YACvBlC,EAAgBzD,EAASyD,cACzBrD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBqD,EAAuB1D,EAAS0D,qBAChCpD,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCoD,EAAWD,EAAuB,EAAI1D,EAASS,QAAQmD,MACvDjD,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD8F,EAAK3mB,SAAO6E,EAAM7G,MAAO,WAEzB4oB,EAAgB,GAAKF,EAAcX,EAAeD,GAElDe,EAAQ9kB,EAAQ+kB,WAAWL,GAExBtQ,EAAQ,EAAGA,EAAQgK,EAASsB,YAAatL,EAChD,IAAK,IAAI8N,EAAU,EAAGA,EAAU9D,EAASyB,aAAcqC,EACrD,IAAK,IAAI8C,EAAU,EAAGA,EAAU5G,EAASoE,UAAWwC,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQ7G,EAAS+B,WAAY8E,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ9G,EAASsC,UAAWwE,EAAO,CAMrD,IAJA,IAAMC,EAAgBH,EAAUjD,EAC1BqD,EAAcH,EAAQrG,EACtByG,EAAcH,EAAQnG,EACxBuG,EAAU,EACLC,EAAS,EAAGA,EAASzD,EACzByD,GAAU1D,EAAe,CAC5B,IAAM2D,GAAWL,EAAgBI,GAAU3D,EAC3C,KAAI4D,EAAU,GAAKA,GAAWpH,EAASgE,UACnC9iB,KAAKgK,MAAMkc,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAO/G,EACrB+G,GAAQjH,EAAgB,CAC3B,IAAMkH,GAASN,EAAcK,GAAQnH,EACrC,KAAIoH,EAAQ,GAAKA,GAAStH,EAAS2B,WAC/BzgB,KAAKgK,MAAMoc,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAOhH,EACrBgH,GAAQlH,EAAe,CAC1B,IAAMmH,GAASP,EAAcM,GAAQpH,EACrC,KAAIqH,EAAQ,GAAKA,GAASxH,EAASkC,UAC/BhhB,KAAKgK,MAAMsc,KAAWA,GAM1BN,GADIR,EAAMzoB,IAAI+X,EAAOoR,EAASE,EAAOE,EAAO1D,KAKlD0C,EAAGloB,IACC4oB,EAAUT,EAAezQ,EAAO4Q,EAASC,EAAOC,EAAOhD,GAOrE,OAAOliB,EAAQqC,eAAeuiB,EAAG3oB,MAAO2oB,EAAGvpB,MAAOupB,EAAG5oB,UCjBhD,IAAM6pB,GAAkC,CAC7CpmB,WAAYqmB,cACZnmB,YAAa,MACbC,oBArE0BC,GAKnB,IAAAoC,WAAQjC,YAASmD,UACjBuhB,OAAI5hB,UACLhD,EAAIgD,EACVlI,EAAiB,CAAC8pB,EAAI5hB,GAAQ,eAyB9B,IAxBO,IAAA4gB,eAAYlQ,YAASmQ,QAEtBvF,EAAW9hB,eAAawnB,kBAC1BhkB,EAAE7D,MAA2CynB,EAAYlQ,EACzD,EAAmBmQ,GACjBrF,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvByF,EAAe5F,EAAS4F,aACxBD,EAAc3F,EAAS2F,YACvBvF,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD8F,EACF3mB,SAAgB6B,EAAE7D,MAA2C,WAE3D4oB,EAAgB,GAAKb,EAAeD,GAEpCgC,EAAS/lB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACrC8oB,EAAQ7mB,SACVymB,EAAGzoB,MAA2C,UAAW8pB,GAEpDvhB,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EACxC,IAAK,IAAIvH,EAAI,EAAGA,EAAImhB,EAASyB,aAAc5iB,EACzC,IAAK,IAAI+oB,EAAM,EAAGA,EAAM5H,EAAS+B,WAAY6F,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAM7H,EAASsC,UAAWuF,EAAK,CAK/C,IAHA,IAAMC,EAAYF,EAAMpH,EAClBuH,EAAYF,EAAMlH,EACpBuG,EAAU,EACL7D,EAAK,EAAGA,EAAK/C,EAAuB+C,GAAMjD,EAAgB,CACjE,IAAM4H,GAAOF,EAAYzE,GAAMnD,EAC/B,KAAI8H,EAAM,GAAKA,GAAOhI,EAAS2B,WAC3BzgB,KAAKgK,MAAM8c,KAASA,GAGxB,IAAK,IAAI1E,EAAK,EAAGA,EAAK/C,EAAsB+C,GAAMjD,EAAe,CAC/D,IAAM4H,GAAOF,EAAYzE,GAAMnD,EAC/B,KAAI8H,EAAM,GAAKA,GAAOjI,EAASkC,UAC3BhhB,KAAKgK,MAAM+c,KAASA,GAKxBf,GADcR,EAAMzoB,IAAImI,EAAG4hB,EAAKC,EAAKppB,IAIzC2nB,EAAGloB,IAAI4oB,EAAUT,EAAergB,EAAGwhB,EAAKC,EAAKhpB,GAKrD,OAAO+C,EAAQqC,eAAeuiB,EAAG3oB,MAAO2oB,EAAGvpB,MAAOupB,EAAG5oB,UCKhD,IAAMsqB,GAAgC,CAC3C7mB,WAAY8mB,iBACZ5mB,YAAa,MACbC,oBAtEwBC,GAKjB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAG0mB,UAAOrb,WAAQsb,SAAMC,aAE/BvrB,OAAKC,OACDqrB,EAAKxqB,MAAMY,SAAW6pB,EAASzqB,MAAMY,QACrC,WAAM,MAAA,kFAEV1B,OAAKC,OACS,MAAV+P,GAAkBsb,EAAKxqB,MAAMY,SAAWsO,EAAOlP,MAAMY,QACrD,WAAM,MAAA,gFAEV1B,OAAKC,OACQ,MAATorB,GAAiBC,EAAKxqB,MAAMY,SAAW2pB,EAAMvqB,MAAMY,QACnD,WAAM,MAAA,+EAGVjC,EAAiB,CAACkF,EAAG2mB,EAAMC,EAAUF,EAAOrb,GAAS,aAEhD,IAAAwb,oBACkB,MAAnBA,IACFA,EAAkB,MAsBpB,IAnBA,IAAMhjB,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnC4qB,EAAQ5mB,EAAQtE,KAAKW,IAAIoqB,EAAKjqB,QAAQR,OACtC6qB,EAAU7mB,EAAQtE,KAAKW,IAAIqqB,EAASlqB,QAAQR,OAC5C8qB,EAAQN,EAAQxmB,EAAQtE,KAAKW,IAAImqB,EAAMhqB,QAAQR,OAC/B,IAAIoD,aAAa,CAAC,IAClC2nB,EAAU5b,EACZnL,EAAQtE,KAAKW,IAAI8O,EAAO3O,QAAQR,OAChC,IAAIoD,aAAa,CAAC,IAChByH,EAAU,IAAIzH,aAAauE,EAAM9G,QAEjCmqB,EAAgBD,EAAQlqB,OACxBoqB,EAAcH,EAAMjqB,OACpBqqB,EAAgBL,EAAQhqB,OACxBsqB,EAAcP,EAAM/pB,OAEtBuqB,EAAO,EACPC,EAAK,EACLC,EAAK,EACLC,EAAK,EACAloB,EAAI,EAAGA,EAAIsE,EAAM9G,SAAUwC,EAClCwH,EAAQxH,GAAK0nB,EAAQK,MAChBzjB,EAAMtE,GAAKunB,EAAMS,MAASP,EAAMQ,KAC7BhoB,KAAK2P,KAAK4X,EAAQU,KAAQZ,GAC9BS,GAAQJ,IACVI,EAAO,GAELC,GAAMF,IACRE,EAAK,GAEHC,GAAML,IACRK,EAAK,GAEHC,GAAML,IACRK,EAAK,GAGT,OAAOvnB,EAAQqC,eAAevC,EAAE7D,MAAO6D,EAAEzE,MAAOwL,KCrB3C,IAAM2gB,GAAqC,CAChD/nB,WAAYgoB,iBACZ9nB,YAAa,MACbC,oBA3C6BC,GAKtB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACA4nB,eAAYC,UAEnB/sB,EAAiB,CAACkF,GAAI,kBAEtB,IAAM8nB,EAAOF,EAAWG,QAAO,SAACtjB,EAAGC,GAAM,OAAAD,EAAIC,KAEvCsjB,EAAWxrB,eAAayrB,YAAYjoB,EAAE7D,MAAOyrB,EAAYE,GACzDI,EAAW1rB,eAAa2rB,YAAYH,EAASjrB,OAAQ6qB,EAAW7qB,QAChEqrB,EACF5rB,eAAa6rB,oBAAoBroB,EAAE7D,MAAOyrB,EAAYE,GACpDQ,EACF9rB,eAAa+rB,oBAAoBV,EAAOD,EAAW7qB,QACjDyrB,EACFhsB,eAAaisB,aAAaL,EAAkBP,EAAOD,EAAW7qB,QAE5D2rB,EAAY9Q,GAAQ,CAACzV,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAClH,MAAO6rB,KAC1DW,EACFjb,GAAU,CAACvL,OAAQ,CAACnC,EAAG0oB,GAAYxoB,UAASmD,MAAO,CAAC+J,KAAM8a,KACxDU,EAAsBhR,GACxB,CAACzV,OAAQ,CAACnC,EAAG2oB,GAAczoB,UAASmD,MAAO,CAAClH,MAAOisB,KACjDnnB,EAASY,GAAM,CACnBM,OAAQ,CAACnC,EAAG4oB,GACZ1oB,UACAmD,MAAO,CAACmM,MAAO8Y,EAAkBzhB,KAAM2hB,KAOzC,OAJAtoB,EAAQsD,8BAA8BklB,GACtCxoB,EAAQsD,8BAA8BmlB,GACtCzoB,EAAQsD,8BAA8BolB,GAE/B3nB,ICtBF,IAAM4nB,GAA+B,CAC1ClpB,WAAYmpB,WACZjpB,YAAa,MACbC,oBArBuBC,GAKhB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAG+oB,YACHliB,SAKDE,EACFN,EAJUvG,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACrBgE,EAAQtE,KAAKW,IAAIwsB,EAAQrsB,QAAQR,OAGhB6sB,EAAQxtB,MAAOwtB,EAAQ5sB,MAAO0K,GAEnE,OAAO3G,EAAQqC,eAAe,CAACsE,GAAOkiB,EAAQxtB,MAAOwL,KChB1CiiB,GAAOrhB,EAAgBshB,eAAa,SAAChhB,EAAI5E,GACpD,IAAM6lB,EAAY7lB,EAClB,OAAI4E,EAAKihB,EAAUC,aACVD,EAAUC,aAEZlhB,EAAKihB,EAAUE,aAAeF,EAAUE,aAAenhB,KAGnDohB,GAA2B,CACtC1pB,WAAYspB,cACZppB,YAAa,MACbC,WAAYkpB,ICQDM,GAAiC,CAC5C3pB,WAAY4pB,aACZ1pB,YAAa,MACbC,WArBE,SAACC,GASC,IARO,IAAAC,aACDC,EAAaF,EAAKG,QAClBb,EAAe,IAAIC,aAAajE,OAAK8E,cAAcH,EAAE7D,QACrDqtB,EAAcvpB,EAAWrE,KAAKW,IAAIyD,EAAEtD,QACpCkB,EAAO4rB,EAAY9rB,mBAAmBE,KACtCE,EAAO0rB,EAAY9rB,mBAAmBI,KACtCsE,EAAWnC,EAAWrE,KAAKW,IAAIqB,EAAKlB,QAAQR,OAC5CmG,EAAWpC,EAAWrE,KAAKW,IAAIuB,EAAKpB,QAAQR,OACzCqD,EAAI,EAAGA,EAAI6C,EAASrF,OAAQwC,IAAK,CACxC,IAAMkqB,EAAOrnB,EAAS7C,GAChBmqB,EAAOrnB,EAAS9C,GACtBF,EAAaE,GAAKC,KAAKmqB,MAAMF,EAAMC,GAGrC,OAAOzpB,EAAWG,WAAWf,EAAcW,EAAE7D,MAAO,sBChB1C2B,GAAKiC,GAEZ,IAAAoC,WAAQjC,YACR8C,UAEDlF,EAAOoC,EAAQtE,KAAKW,IAAIyG,EAAMtG,QAAQgB,mBAAmBI,KACzD8rB,EAAU1pB,EAAQtE,KAAKW,IAAIuB,EAAKpB,QAAQR,OAK9C,OAAOgE,EAAQqC,eAAezE,EAAK3B,MAAO2B,EAAKvC,MAAOquB,GAGjD,IAAMC,GAA2B,CACtClqB,WAAYmqB,OACZjqB,YAAa,MACbC,WAAYhC,aCVEib,GACZhZ,GAEK,IAAAoC,WAAQjC,YACRmO,eAED2G,EAAQ3Z,OAAKmT,eAAeH,EAAMlM,EAAO,GAAGhG,OAAO,GACrDmM,EAAW9L,eAAautB,gBAAgB5nB,EAAOjF,KAAI,SAAA9B,GAAK,OAAAA,EAAEe,SAAQ6Y,GAEtE,GAAqC,IAAjC3Z,OAAK8E,cAAcmI,GACrB,OAAOpI,EAAQqC,eAAe+F,EAAUnG,EAAO,GAAG5G,MAAO,IAI3D,IAAMyuB,EAAU7nB,EAAO8nB,QAAO,SAAA7uB,GAAK,OAAAC,OAAK8E,cAAc/E,EAAEe,OAAS,KACjE,GAAuB,IAAnB6tB,EAAQjtB,OACV,OAAO6F,EAAS,CAACT,OAAQ,CAACnC,EAAGgqB,EAAQ,IAAK9pB,YAG5C,IAAMgqB,EAASF,EAAQ9sB,KAAI,SAAA9B,GAAK,OAAAA,EAAEe,SAGlC,GAFAK,eAAa2tB,uBAAuBD,EAAQlV,GAEnB,cAArBgV,EAAQ,GAAGzuB,MAAuB,CACpC,IAAM6uB,EAAQJ,EAAQ9sB,KAAI,SAAC9B,GAAM,OAAAwC,EAAK,CAACuE,OAAQ,CAACa,MAAO5H,GAAI8E,eACrDmqB,EAAQL,EAAQ9sB,KAAI,SAAC9B,GAAM,OAAA0C,GAAK,CAACqE,OAAQ,CAACa,MAAO5H,GAAI8E,eAErDoqB,EAAevR,GAAO,CAAC5W,OAAQioB,EAAOlqB,UAASmD,MAAO,CAACgL,KAAM2G,KAC7DuV,EAAexR,GAAO,CAAC5W,OAAQkoB,EAAOnqB,UAASmD,MAAO,CAACgL,KAAM2G,KAE7D/T,EACFiB,EAAQ,CAACC,OAAQ,CAACvE,KAAM0sB,EAAcxsB,KAAMysB,GAAerqB,YAO/D,OALAkqB,EAAMjvB,SAAQ,SAAAqvB,GAAK,OAAAtqB,EAAQsD,8BAA8BgnB,MACzDH,EAAMlvB,SAAQ,SAAAoE,GAAK,OAAAW,EAAQsD,8BAA8BjE,MACzDW,EAAQsD,8BAA8B8mB,GACtCpqB,EAAQsD,8BAA8B+mB,GAE/BtpB,EAUT,IAAMwpB,EAAWT,EAAQ9sB,KAAI,SAAA9B,GAC3B,IAAMsvB,EAAYrvB,OAAK8E,cAAc/E,EAAEe,MAAM0F,MAAMmT,IAEnD,OAAO4C,GAAQ,CAACzV,OAAQ,CAACnC,EAAG5E,GAAI8E,UAASmD,MAAO,CAAClH,MADnC,EAAE,EAAGuuB,SAIfC,EAAkBF,EAASvtB,KAAI,SAAA9B,GACnC,MAAO,CAACgE,KAAMc,EAAQtE,KAAKW,IAAInB,EAAEsB,QAAQR,OAAQC,MAAOf,EAAEe,UAI5DmM,EACI9L,eAAautB,gBAAgBU,EAASvtB,KAAI,SAAA9B,GAAK,OAAAA,EAAEe,SAAQ,GAC7D,IAAMoM,EAAwC,IAAzBkiB,EAAS,GAAGtuB,MAAM,GACjC4K,EACFsB,EAAWsiB,EAAiBriB,EAAUnG,EAAO,GAAG5G,MAAOgN,GAErDqiB,EACFpuB,eAAautB,gBAAgBC,EAAQ9sB,KAAI,SAAA9B,GAAK,OAAAA,EAAEe,SAAQ6Y,GAEtD6V,EACF3qB,EAAQqC,eAAeqoB,EAAezoB,EAAO,GAAG5G,MAAOwL,GAI3D,OAFA0jB,EAAStvB,SAAQ,SAAAC,GAAK,OAAA8E,EAAQsD,8BAA8BpI,MAErDyvB,EAGF,IAAMC,GAA6B,CACxCnrB,WAAYorB,SACZlrB,YAAa,MACbC,WAAYiZ,aCpFEiS,GACZjrB,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAGiqB,WACHvW,YAASmQ,QAAKW,eAAYyG,cAAWnH,oBAE5ChpB,EAAiB,CAACkF,EAAGiqB,GAAS,UAkC9B,IAhCA,IAAMiB,EAAc1uB,eAAa2uB,wBAAwB3G,GACnDlG,EAAW9hB,eAAa4uB,kBAC1BprB,EAAE7D,MACF8tB,EAAO9tB,MAA2CuX,EAASuX,EAAWpH,EACtEC,GAAiB,EAAuBoH,GAEtChH,EAAe5F,EAAS4F,aACxBD,EAAc3F,EAAS2F,YACvBvF,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBM,EAAUX,EAASS,QAAQG,KAC3BJ,EAASR,EAASS,QAAQC,IAC1BqM,EAAyC,iBAAxB/M,EAASkG,WAE1B8G,EAAI,IAAInW,eAAamJ,EAAShW,SAAUtI,EAAEzE,OAE1C+R,EAAWjS,OAAK0F,eAAef,EAAE7D,OACjCovB,EAAgBlwB,OAAK0F,eAAekpB,EAAO9tB,OAE3CqvB,EAAele,EAAS,GACxBme,EAAaJ,EAAiB/d,EAAS,GAAKA,EAAS,GACrDoe,EAAaL,EAAiB/d,EAAS,GAAK,EAC5Cqe,EAAiBN,EAAiB,EAAI/d,EAAS,GAC/Cse,EAAeN,EAAE5X,QAAQ,GACzBmY,EAAaR,EAAiBC,EAAE5X,QAAQ,GAAK4X,EAAE5X,QAAQ,GACvDoY,EAAaT,EAAiBC,EAAE5X,QAAQ,GAAK,EAC7CqY,EAAiBV,EAAiB,EAAIC,EAAE5X,QAAQ,GAEhD7P,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnC8vB,EAAQ9rB,EAAQtE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,OACxC+vB,EAAQX,EAAEpvB,OAEPwI,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EAGxC,IAFA,IAAMwnB,EAAWxnB,EAAI8mB,EACfW,EAAWznB,EAAIknB,EACZ5L,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAG1C,IAFA,IAAMoM,EAAWD,EAAWnM,EAAK6L,EAC3B3L,EAAWF,EAAK1B,EAASE,aAAeM,EACrC6C,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,IAAMX,EAAKd,EAAWyB,EAAKjD,EAC3B,KAAIsC,EAAK,GAAKA,GAAM1C,EAAS+B,UAK7B,IAFA,IAAMgM,EAAW1K,EAAK4J,EAAc,GAC9Be,EAAWJ,EAAWlL,EAAKyK,EACxBlL,EAAK,EAAGA,EAAKjC,EAASkC,WAAYD,EAGzC,IAFA,IAAMgM,EAAWH,EAAW7L,EAAKuL,EAC3BrL,EAAWF,EAAKjC,EAASG,YAAcQ,EACpC2C,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,IAAMV,EAAKT,EAAWmB,EAAKjD,EAC3B,KAAIuC,EAAK,GAAKA,GAAM5C,EAASsC,SAM7B,IAHA,IACM4L,EAAWF,EAAWpL,EAAKwK,EAC7Be,EAFaJ,EAAWzK,EAAK2J,EAAc,GAGtCmB,EAAK,EAAGA,EAAKpO,EAASyB,aAAc2M,EAAI,CAE/C,IADA,IAAMC,GAAO9oB,EAAM2oB,EAAWE,EAAKf,GAC1BiB,GAAK,EAAGA,GAAKtO,EAASuO,cAAeD,GAC5CX,EAAMM,EAAWK,GAAKb,IAClBY,GAAOX,EAAMS,EAAWG,IAE9BH,GAAYnO,EAASuO,cAQjC,OAAO3sB,EAAQqC,eAAe+oB,EAAEnvB,MAAOmvB,EAAE/vB,MAAO0wB,GAG3C,IAAMa,GAA6B,CACxCntB,WAAYotB,SACZltB,YAAa,MACbC,WAAYkrB,ICnBP,IAAMgC,GAA2C,CACtDrtB,WAAYstB,uBACZptB,YAAa,MACbC,oBArEmCC,GAK5B,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAG4kB,OACHlR,YAASmQ,QAAKW,eAAYV,oBAAiBoJ,gBAElDpyB,EAAiB,CAACkF,EAAG4kB,GAAK,wBAoB1B,IAlBA,IAAMsG,EAAc1uB,eAAa2uB,wBAAwB3G,GACnDlG,EAAW9hB,eAAa4uB,kBAC1BprB,EAAE7D,MAA2C+wB,EAAaxZ,EAC1D,EAAmBmQ,EAAKC,GAAiB,EACzCoH,GAEG1M,iBAAcC,gBAAayF,iBAAcD,gBAC1CoH,EAAyC,iBAAxB/M,EAASkG,WAC1B2I,EAAK,IAAIhY,eAAamJ,EAAS4O,YAAa,WAE5CE,EAAU9O,EAASS,QAAQG,KAC3BmO,EAAS/O,EAASS,QAAQC,IAC1Bnb,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnCoxB,EAASptB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OAErCgL,EAAO,IAAIiO,eAAanV,EAAE7D,MAAO6D,EAAEzE,MAAOsI,GAC1CmhB,EAAQ,IAAI7P,eAAayP,EAAGzoB,MAAOyoB,EAAGrpB,MAAO+xB,GAE1C3L,EAAK,EAAGA,EAAKuC,IAAgBvC,EAKpC,IAJA,IAAM4L,EAAQ/tB,KAAK8L,IAAI,EAAG9L,KAAK0I,MAAMmlB,EAAS1L,GAAMnD,IAC9CgP,EAAQhuB,KAAKsM,IACfwS,EAAS2B,WAAY3B,EAAS+B,SAAWgN,EAAS1L,GAAMnD,GAEnDoD,EAAK,EAAGA,EAAKqC,IAAerC,EAKnC,IAJA,IAAM6L,EAAQjuB,KAAK8L,IAAI,EAAG9L,KAAK0I,MAAMklB,EAAUxL,GAAMnD,IAC/CiP,EAAQluB,KAAKsM,IACfwS,EAASkC,UAAWlC,EAASsC,QAAUwM,EAAUxL,GAAMnD,GAElDiO,EAAK,EAAGA,EAAKpO,EAASyB,aAAc2M,EAC3C,IAAK,IAAIE,EAAK,EAAGA,EAAKtO,EAASuO,cAAeD,EAAI,CAEhD,IADA,IAAIpH,EAAU,EACL9gB,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EACxC,IAAK,IAAIsb,EAAKuN,EAAOvN,EAAKwN,IAASxN,EAEjC,IADA,IAAMgB,EAAKW,EAAK3B,EAAKxB,EAAe6O,EAC3B9M,EAAKkN,EAAOlN,EAAKmN,IAASnN,EAAI,CACrC,IAAMW,EAAKU,EAAKrB,EAAK9B,EAAc2O,EAEjC5H,GADE6F,EACUnkB,EAAK3K,IAAImI,EAAGsc,EAAIE,EAAIwL,GAC3B1H,EAAMzoB,IAAImI,EAAGsb,EAAIO,EAAIqM,GAEd1lB,EAAK3K,IAAImI,EAAGgoB,EAAI1L,EAAIE,GAC3B8D,EAAMzoB,IAAImI,EAAGkoB,EAAI5M,EAAIO,GAKlC4M,EAAGvwB,IAAI4oB,EAAS7D,EAAIC,EAAI8K,EAAIE,GAMpC,OAAO1sB,EAAQqC,eAAe4qB,EAAGhxB,MAAOgxB,EAAG5xB,MAAO4xB,EAAGjxB,UC+BhD,IAAMyxB,GAA0C,CACrDhuB,WAAYiuB,sBACZ/tB,YAAa,MACbC,oBAjGkCC,GAK3B,IAAAoC,WAAQjC,YAASmD,UACjBuhB,OAAIqF,WACJ5X,eAAYqB,YAASmQ,QAAKW,eAAYV,oBAE7ChpB,EAAiB,CAAC8pB,EAAIqF,GAAS,uBAE/B,IAAMsB,EAAgBlwB,OAAK0F,eAAekpB,EAAO9tB,OAC3C0xB,EAAYxyB,OAAK0F,eAAe6jB,EAAGzoB,OAErC+uB,EAAc1uB,eAAa2uB,wBAAwB3G,GACjDlG,EAAW9hB,eAAa4uB,kBAC1B/Y,EAAY4X,EAAO9tB,MAA2CuX,EAC9D,EAAmBmQ,EAAKC,GAAiB,EAAOoH,GAE9CpG,EAAK,IAAI3P,eAAamJ,EAAS8F,QAAS,WACxC0J,EAAWhJ,EAAG5oB,OACd6xB,EAAW7tB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACvC8xB,EAAY9tB,EAAQtE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,OAC3C+xB,OAAOC,OAAOC,OAEnBvO,cACAsE,iBACAD,gBACAlE,eACAM,aACAO,YACAiM,gBACA5M,cACAO,aACAhC,iBACAC,gBAEFyM,EAAc5M,EAASkG,WAcvB,IAbA,IAAM6I,EAASnJ,EAAe,EAAI5F,EAASS,QAAQC,IAC7CoO,EAAUnJ,EAAc,EAAI3F,EAASS,QAAQG,KAE7CmM,EAAiC,iBAAhBH,EACjBM,EAAe1G,EAAGpR,QAAQ,GAC1B+X,EAAaJ,EAAiBvG,EAAGpR,QAAQ,GAAKoR,EAAGpR,QAAQ,GACzDgY,EAAaL,EAAiBvG,EAAGpR,QAAQ,GAAK,EAC9CiY,EAAiBN,EAAiB,EAAIvG,EAAGpR,QAAQ,GACjDkY,EAAeiC,EAAU,GACzBhC,EAAaR,EAAiBwC,EAAU,GAAKA,EAAU,GACvD/B,EAAaT,EAAiBwC,EAAU,GAAK,EAC7C9B,EAAiBV,EAAiB,EAAIwC,EAAU,GAE7CnpB,EAAI,EAAGA,EAAIkb,IAAalb,EAC/B,IAAK,IAAIgoB,EAAK,EAAGA,EAAK3M,IAAc2M,EAClC,IAAK,IAAI1L,EAAK,EAAGA,EAAKX,IAAYW,EAMhC,IALA,IAAMd,EAAWc,EAAKqM,EAChBlN,EAAQ3gB,KAAK8L,IAAI,EAAG9L,KAAK0I,KAAKgY,EAAW1B,IACzCgP,EACFhuB,KAAKsM,IAAImU,GAAYiE,EAAehE,GAAY1B,GAE3C0C,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CAOnC,IANA,IAAMT,EAAWS,EAAKkM,EAChB1M,GAAQlhB,KAAK8L,IAAI,EAAG9L,KAAK0I,KAAKuY,EAAWhC,IACzCiP,GACFluB,KAAKsM,IAAI0U,GAAWyD,EAAcxD,GAAYhC,GAE9C+G,GAAU,EACLxF,GAAKG,EAAOH,GAAKwN,IAASxN,GAGjC,IAFA,IAAM2B,GAAK3B,GAAKxB,EAAe0B,EAEtBK,GAAKG,GAAOH,GAAKmN,KAASnN,GAOjC,IANA,IACM6N,GACFxC,EAAelnB,EAAImnB,EAAa7L,GAAK8L,EAAavL,GAChD8N,GAAYJ,GAAS/J,EAAe,EAAIvC,IAC1CuM,GAASjK,EAAc,GAJhB1D,GAAK9B,EAAcgC,IAIO0N,EAAQzB,EAEpCE,GAAK,EAAGA,GAAKC,IAAeD,GAAI,CAGvCpH,IAFcuI,EAASK,GAAWrC,EAAiBa,IACpCoB,EAAUK,GAAYzB,IAO3CkB,EAFiBtC,EAAe9mB,EAAI+mB,EAAazK,EAC7C0K,EAAaxK,EAAKyK,EAAiBe,GAClBlH,GAM7B,OAAOtlB,EAAQqC,eAAeuiB,EAAG3oB,MAAO2oB,EAAGvpB,MAAOupB,EAAG5oB,UCHhD,IAAMoyB,GAA6B,CACxC3uB,WAAY4uB,SACZ1uB,YAAa,MACbC,oBA1FEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAGiqB,WACHvW,YAASmQ,QAAKoH,cAErBnwB,EAAiB,CAACkF,EAAGiqB,GAAS,UA4B9B,IA1BA,IAAM3L,EAAW9hB,eAAagyB,kBAC1BxuB,EAAE7D,MACF8tB,EAAO9tB,MAAmDuX,EAC1DuX,EAAWpH,GAGbgB,gBACAX,iBACAD,gBACAlC,kBACArD,mBACAC,kBACAI,YAEIkD,EAAWlD,EAAQmD,MACnBjD,EAAUF,EAAQG,KAClBJ,EAASC,EAAQC,IACjBsM,EAAI,IAAInW,eAAamJ,EAAShW,SAAUtI,EAAEzE,OAE1CsI,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnC8vB,EAAQ9rB,EAAQtE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,OACxC+vB,EAAQX,EAAEpvB,OAEVoR,EAAWjS,OAAK0F,eAAef,EAAE7D,OACjCovB,EAAgBlwB,OAAK0F,eAAekpB,EAAO9tB,OAExCuI,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EAGxC,IAFA,IAAMwnB,EAAWxnB,EAAI4I,EAAS,GACxB6e,EAAWznB,EAAI4mB,EAAE5X,QAAQ,GACtB+a,EAAK,EAAGA,EAAKnQ,EAASgE,WAAYmM,EAGzC,IAFA,IAAMrC,EAAWD,EAAWsC,EAAKnD,EAAE5X,QAAQ,GACrCgb,EAAWD,EAAKnQ,EAASwD,YAAcG,EACpC0M,EAAK,EAAGA,EAAK9J,IAAe8J,EAAI,CACvC,IAAMC,EAAKF,EAAWC,EAAK5M,EAC3B,KAAI6M,EAAK,GAAKA,GAAMtQ,EAASoE,SAM7B,IAHA,IAAM2J,EAAWsC,EAAKpD,EAAc,GAC9Be,EAAWJ,EAAW0C,EAAKthB,EAAS,GAEjC0S,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAG1C,IAFA,IAAMuM,EAAWH,EAAWpM,EAAKsL,EAAE5X,QAAQ,GACrCwM,EAAWF,EAAK1B,EAASE,aAAeM,EACrC6C,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,IAAMX,EAAKd,EAAWyB,EAAKjD,EAC3B,KAAIsC,EAAK,GAAKA,GAAM1C,EAAS+B,UAK7B,IAFA,IAAMwO,EAAWxC,EAAW1K,EAAK4J,EAAc,GACzCiB,EAAWF,EAAWtL,EAAK1T,EAAS,GACjCiT,EAAK,EAAGA,EAAKjC,EAASkC,WAAYD,EAGzC,IAFA,IAAMuO,EAAWvC,EAAWhM,EAAKjC,EAASuO,YACpCpM,EAAWF,EAAKjC,EAASG,YAAcQ,EACpC2C,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,IAAMV,EAAKT,EAAWmB,EAAKjD,EAC3B,KAAIuC,EAAK,GAAKA,GAAM5C,EAASsC,SAM7B,IAHA,IAAM6L,EAAWoC,EAAWjN,EAAK2J,EAAc,GACzCwD,EAAWvC,EAAWtL,EAAK5C,EAASyB,WACtCiP,EAAWvC,EACNC,EAAK,EAAGA,EAAKpO,EAASyB,aAAc2M,EAAI,CAE/C,IADA,IAAMC,GAAO9oB,EAAMkrB,EAAWrC,GACrBE,GAAK,EAAGA,GAAKtO,EAASuO,cAAeD,GAC5CX,EAAM6C,EAAWlC,KAAOD,GAAOX,EAAMgD,EAAWpC,IAElDoC,GAAY1Q,EAASuO,eAUrC,OAAO3sB,EAAQqC,eAAe+oB,EAAEnvB,MAAOmvB,EAAE/vB,MAAO+vB,EAAEpvB,UCS7C,IAAM+yB,GAA6C,CACxDtvB,WAAYuvB,yBACZrvB,YAAa,MACbC,oBAjGqCC,GAK9B,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAG4kB,OACHlR,YAASmQ,QAAKqJ,gBAErBpyB,EAAiB,CAACkF,EAAG4kB,GAAK,0BA4B1B,IA1BA,IAAMtX,EAAWjS,OAAK0F,eAAef,EAAE7D,OACjC0xB,EAAYxyB,OAAK0F,eAAe6jB,EAAGzoB,OAEnCmiB,EAAW9hB,eAAagyB,kBAC1BxuB,EAAE7D,MAAmD+wB,EAAaxZ,EAClE,EAAmBmQ,GAEjB/B,EAAcxD,EAASwD,YACvBtD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBoG,EAAcvG,EAASuG,YACvBX,EAAe5F,EAAS4F,aACxBD,EAAc3F,EAAS2F,YAEvBkL,EAAK,IAAIha,eAAamJ,EAAS4O,YAAa,WAC5CkC,EAAWD,EAAGjzB,OACduB,YAAC4xB,OAAMC,OAAMC,OAAMC,OACnBzB,EAAW7tB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACtCuzB,OAAMC,OAAMC,OAAMC,OACnBvR,EAAUne,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACpC2zB,OAAKC,OAAKC,OAAKC,OAEhBC,EAAW3R,EAASS,QAAQmD,MAC5BkL,EAAU9O,EAASS,QAAQG,KAC3BmO,EAAS/O,EAASS,QAAQC,IAEvB2P,EAAK,EAAGA,EAAK9J,IAAe8J,EAMnC,IALA,IAAMuB,EAAQ1wB,KAAK8L,IAAI,EAAG9L,KAAK0I,MAAM+nB,EAAWtB,GAAM7M,IAChDqO,EAAQ3wB,KAAKsM,IACfwS,EAASgE,UAAWhE,EAASoE,QAAUuN,EAAWtB,GAAM7M,GACtDuK,EAAWsC,EAAKU,EAEb1N,EAAK,EAAGA,EAAKuC,IAAgBvC,EAMpC,IALA,IAAM4L,EAAQ/tB,KAAK8L,IAAI,EAAG9L,KAAK0I,MAAMmlB,EAAS1L,GAAMnD,IAC9CgP,EAAQhuB,KAAKsM,IACfwS,EAAS2B,WAAY3B,EAAS+B,SAAWgN,EAAS1L,GAAMnD,GACtDqQ,EAAWlN,EAAK2N,EAAOjD,EAEpBzK,EAAK,EAAGA,EAAKqC,IAAerC,EAMnC,IALA,IAAM6L,EAAQjuB,KAAK8L,IAAI,EAAG9L,KAAK0I,MAAMklB,EAAUxL,GAAMnD,IAC/CiP,EAAQluB,KAAKsM,IACfwS,EAASkC,UAAWlC,EAASsC,QAAUwM,EAAUxL,GAAMnD,GACrDgO,EAAW7K,EAAK2N,EAAOV,EAEpBnC,EAAK,EAAGA,EAAKpO,EAASyB,aAAc2M,EAG3C,IAFA,IAAMsC,EAAWtC,EAAK8C,EAAO/C,EAEpBG,GAAK,EAAGA,GAAKtO,EAASuO,cAAeD,GAAI,CAEhD,IADA,IAAIpH,GAAU,EACL9gB,GAAI,EAAGA,GAAI4Z,EAASsB,YAAalb,GAIxC,IAHA,IAAMwnB,GAAWxnB,GAAImrB,EACf1D,GAAWznB,GAAI+qB,EAEZhB,GAAKyB,EAAOzB,GAAK0B,IAAS1B,GAKjC,IAJA,IACMnC,IADKqC,EAAKF,GAAK3M,EAAcmO,GACbH,EAAM5D,GACtBE,GAAWqC,GAAKiB,EAAOvD,GAEpBnM,GAAKuN,EAAOvN,GAAKwN,IAASxN,GAKjC,IAJA,IACMwM,IADK7K,EAAK3B,GAAKxB,EAAe6O,GACd0C,EAAMzD,GACtBC,GAAWvM,GAAK2P,EAAOvD,GAEpB7L,GAAKkN,EAAOlN,GAAKmN,IAASnN,GAAI,CACrC,IAEMuO,GAAWvO,GAAKqP,EAAOrD,GAE7B/G,IAAWnH,GAJAuD,EAAKrB,GAAK9B,EAAc2O,GACb4C,EAAMxD,GAGEE,GAAMqB,EAASe,GAAWlC,IAKhEwC,EAASJ,EAAWpC,IAAMpH,GAOpC,OAAOtlB,EAAQqC,eAAe4sB,EAAGhzB,MAAOgzB,EAAG5zB,MAAO4zB,EAAGjzB,UCUhD,IAAMk0B,GAA4C,CACvDzwB,WAAY0wB,wBACZxwB,YAAa,MACbC,oBAxGoCC,GAK7B,IAAAoC,WAAQjC,YAASmD,UACjBuhB,OAAIqF,WACJpG,QAAKnQ,YAASrB,eAErBvX,EAAiB,CAAC8pB,GAAK,yBAqCvB,IAnCA,IAAMiJ,EAAYxyB,OAAK0F,eAAe6jB,EAAGzoB,OACnCovB,EAAgBlwB,OAAK0F,eAAekpB,EAAO9tB,OAE3CmiB,EAAW9hB,eAAagyB,kBAC1Bnc,EAAY4X,EAAO9tB,MACnBuX,EAAS,EAAmBmQ,GAE1BiB,EAAK,IAAI3P,eAAamJ,EAAS8F,QAAS,WACxC0J,EAAWhJ,EAAG5oB,OACduB,YAAC6yB,OAAMC,OAAMC,OAAMC,OACnB1C,EAAW7tB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACtCuzB,OAAMC,OAAMC,OAAMC,OACnB5B,EAAY9tB,EAAQtE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,OAC3C+xB,OAAOC,OAAOC,OAAOuC,OAE1B9Q,cACAiF,gBACAX,iBACAD,gBACAlE,eACA2C,YACArC,aACAO,YACAiM,gBACAvK,aACArC,cACAO,aACAsB,gBACAtD,iBACAC,gBAEIwR,EAAWpL,EAAc,EAAIvG,EAASS,QAAQmD,MAC9CmL,EAASnJ,EAAe,EAAI5F,EAASS,QAAQC,IAC7CoO,EAAUnJ,EAAc,EAAI3F,EAASS,QAAQG,KAE1Cxa,EAAI,EAAGA,EAAIkb,IAAalb,EAC/B,IAAK,IAAIgoB,EAAK,EAAGA,EAAK3M,IAAc2M,EAElC,IAAK,IAAIkC,EAAK,EAAGA,EAAKlM,IAAWkM,EAO/B,IANA,IAAMF,EAAWE,EAAKqB,EAChBU,EAAQnxB,KAAK8L,IAAI,EAAG9L,KAAK0I,KAAKwmB,EAAW5M,IACzCqO,GACF3wB,KAAKsM,IAAIwW,GAAWuC,EAAc6J,GAAY5M,GAGzCd,GAAK,EAAGA,GAAKX,IAAYW,GAMhC,IALA,IAAMd,GAAWc,GAAKqM,EAChBlN,GAAQ3gB,KAAK8L,IAAI,EAAG9L,KAAK0I,KAAKgY,GAAW1B,IACzCgP,GACFhuB,KAAKsM,IAAImU,GAAYiE,EAAehE,IAAY1B,GAE3C0C,GAAK,EAAGA,GAAKN,IAAWM,GAAI,CAOnC,IANA,IAAMT,GAAWS,GAAKkM,EAChB1M,GAAQlhB,KAAK8L,IAAI,EAAG9L,KAAK0I,KAAKuY,GAAWhC,IACzCiP,GACFluB,KAAKsM,IAAI0U,GAAWyD,EAAcxD,IAAYhC,GAE9C+G,GAAU,EACLiJ,GAAKkC,EAAOlC,GAAK0B,KAAS1B,GAGjC,IAFA,IAAME,GAAKF,GAAK3M,EAAc4M,EAErB1O,GAAKG,GAAOH,GAAKwN,KAASxN,GAGjC,IAFA,IAAM2B,GAAK3B,GAAKxB,EAAe0B,GAEtBK,GAAKG,GAAOH,GAAKmN,KAASnN,GAOjC,IANA,IACM6N,GAAWqB,EAAO/qB,EAAIgrB,EAAOjB,GAAKkB,EAAO3P,GAAK4P,EAAOrP,GACrD8N,GAAYJ,GAASpJ,EAAc,EAAI8J,IACzCT,GAAShK,EAAe,EAAIvC,IAC5BwM,GAASlK,EAAc,GAJhB1D,GAAK9B,EAAcgC,KAIOiQ,EAAQhE,EAEpCE,GAAK,EAAGA,GAAKC,IAAeD,GAAI,CAGvCpH,IAFcuI,EAASK,GAAWxB,IACnBoB,EAAUK,GAAYzB,IAM7CkB,EAASwC,EAAO5rB,EAAI6rB,EAAO3B,EAAK4B,EAAOxP,GAAKyP,EAAOvP,GAAKwL,GACpDlH,GAOd,OAAOtlB,EAAQqC,eAAeuiB,EAAG3oB,MAAO2oB,EAAGvpB,MAAOupB,EAAG5oB,UCnG1C00B,GAAMjpB,EAAgBkpB,OAAK,SAAC5oB,GAAO,OAAAzI,KAAKoxB,IAAI3oB,MAE5C6oB,GAA0B,CACrCnxB,WAAYkxB,MACZhxB,YAAa,MACbC,WAAY8wB,ICLDG,GAAOppB,EAAgBqpB,QAAM,SAAC/oB,GAAO,OAAAzI,KAAKuxB,KAAK9oB,MAE/CgpB,GAA2B,CACtCtxB,WAAYqxB,OACZnxB,YAAa,MACbC,WAAYixB,ICuIP,IAAMG,GAAoC,CAC/CvxB,WAAYwxB,gBACZtxB,YAAa,MACbC,oBA/I4BC,GA4B5B,IAvBO,IAAAoC,WAAQjC,YAASmD,UACjB+tB,UAAOC,UAAOC,WACdC,aAAUC,WAAQC,uBAEnBh0B,UAAC6W,OAAOod,OAAaC,OAAYC,OACjCC,EAAWR,EAAMl1B,MAAM,GAEtB21B,OAAYC,OACbxS,EACFphB,SAAO,CAAC0zB,EAAUC,EAAYC,EAAWH,GAAc,WAErDI,EAAU9xB,EAAQtE,KAAKW,IAAI80B,EAAM30B,QAAQR,OACzC+1B,EAAa/xB,EAAQtE,KAAKW,IAAI+0B,EAAO50B,QAAQR,OAC7Cg2B,EAAYhyB,EAAQtE,KAAKW,IAAI60B,EAAM10B,QAAQR,OAE3Ci2B,EACF92B,OAAK0F,eAAeqwB,EAAMj1B,OACxBi2B,EAAY/2B,OAAK0F,eACnBwe,EAAOpjB,OAKFuI,EAAI,EAAGA,EAAImtB,EAAUntB,IAAK,CACjC,IAAM2tB,EAAe,EAAJ3tB,EACX4tB,EAAKN,EAAQK,GACbE,EAAKP,EAAQK,EAAW,GACxBG,EAAKR,EAAQK,EAAW,GACxBI,EAAKT,EAAQK,EAAW,GAExBK,EAAeT,EAAWvtB,GAChC,KAAIguB,GAAQpe,GASZ,IALA,IAAMqe,EACDb,EAAa,GAAMU,EAAKF,IAAOZ,EAAc,IAAMI,EAAa,GAAK,EACpEc,EACDb,EAAY,GAAMU,EAAKF,IAAOZ,EAAa,IAAMI,EAAY,GAAK,EAE9DzG,EAAI,EAAGA,EAAIwG,EAAYxG,IAAK,CACnC,IAAMuH,EAAgBf,EAAa,EAC/BQ,GAAMZ,EAAc,GAAKpG,IACzB,IAAOgH,EAAKE,IAAOd,EAAc,GAErC,GAAImB,EAAO,GAAKA,EAAOnB,EAAc,EACnC,IAAK,IAAI1xB,EAAI,EAAGA,EAAI+xB,EAAW/xB,IAC7B,IAAK,IAAI8yB,EAAI,EAAGA,EAAIlB,EAAakB,IAAK,CACpC,IAAMC,EACFD,EAAI9yB,EAAIoyB,EAAU,GAAK9G,EAAI8G,EAAU,GAAK1tB,EAAI0tB,EAAU,GAC5D7S,EAAOrjB,OAAO62B,GAAOtB,OAM3B,GAAe,aAAXD,EACF,CAAA,IAAMwB,EAASxzB,KAAKgK,MAAMqpB,GACpBI,EAAYzzB,KAAK0I,KAAK2qB,GACtBK,EAAQL,EAAOG,EAErB,IAAShzB,EAAI,EAAGA,EAAI+xB,EAAW/xB,IAAK,CAKlC,IAJMmzB,EAAQpB,EAAY,EACtBQ,GAAMZ,EAAa,GAAK3xB,EAAI4yB,EAC5B,IAAOL,EAAKE,IAAOd,EAAa,IAEzB,GAAKwB,EAAOxB,EAAa,EAClC,IAASmB,EAAI,EAAGA,EAAIlB,EAAakB,IAAK,CAC9BC,EACFD,EAAI9yB,EAAIoyB,EAAU,GAAK9G,EAAI8G,EAAU,GAAK1tB,EAAI0tB,EAAU,GAC5D7S,EAAOrjB,OAAO62B,GAAOtB,MAKzB,CAAA,IAAM2B,EAAU5zB,KAAKgK,MAAM2pB,GACrBE,EAAW7zB,KAAK0I,KAAKirB,GACrBG,EAAQH,EAAOC,EAErB,IAASN,EAAI,EAAGA,EAAIlB,EAAakB,IAAK,CACpC,IAEMS,EAAUrB,EAFZa,EAAMD,EAAIM,EAAUjB,EAAS,GAAKa,EAASb,EAAS,GACpDO,EAAOP,EAAS,IAKdqB,EAAWtB,EAFjBa,EAAMD,EAAIO,EAAWlB,EAAS,GAAKa,EAASb,EAAS,GACjDO,EAAOP,EAAS,IAKdsB,EAAavB,EAFnBa,EAAMD,EAAIM,EAAUjB,EAAS,GAAKc,EAAYd,EAAS,GACnDO,EAAOP,EAAS,IAOduB,EAAMH,GAAWC,EAAWD,GAAWD,EACvCK,EAASF,GAHKvB,EAFpBa,EAAMD,EAAIO,EAAWlB,EAAS,GAAKc,EAAYd,EAAS,GACpDO,EAAOP,EAAS,IAIuBsB,GAAcH,EAEzDP,EAAMD,EAAI9yB,EAAIoyB,EAAU,GAAK9G,EAAI8G,EAAU,GAAK1tB,EAAI0tB,EAAU,GAC9D7S,EAAOrjB,OAAO62B,GAAOW,GAAQC,EAASD,GAAOR,UAIjD,IAASlzB,EAAI,EAAGA,EAAI+xB,IAAa/xB,EAAG,CAClC,IAAMmzB,EAIN,IAJMA,EAAQpB,EAAY,EACtBQ,GAAMZ,EAAa,GAAK3xB,EAAI4yB,EAC5B,IAAOL,EAAKE,IAAOd,EAAa,IAEzB,GAAKwB,EAAOxB,EAAa,EAClC,IAASmB,EAAI,EAAGA,EAAIlB,EAAakB,IAAK,CAC9BC,EACFD,EAAI9yB,EAAIoyB,EAAU,GAAK9G,EAAI8G,EAAU,GAAK1tB,EAAI0tB,EAAU,GAC5D7S,EAAOrjB,OAAO62B,GAAOtB,MAKzB,CAAA,IAAMmC,EAAWp0B,KAAKq0B,MAAMV,GACtBW,EAAWt0B,KAAKq0B,MAAMhB,GAC5B,IAASC,EAAI,EAAGA,EAAIlB,EAAakB,IAAK,CACpC,IAAMiB,EAAQjB,EAAIc,EAAWzB,EAAS,GAAK2B,EAAW3B,EAAS,GAC3DO,EAAOP,EAAS,GACd6B,GACFlB,EAAI9yB,EAAIoyB,EAAU,GAAK9G,EAAI8G,EAAU,GAAK1tB,EAAI0tB,EAAU,GAC5D7S,EAAOrjB,OAAO83B,IAAU9B,EAAU6B,OAO5C,OAAO7zB,EAAQqC,eAAegd,EAAOpjB,MAAOojB,EAAOhkB,MAAOgkB,EAAOrjB,UC3E5D,IAAM+3B,GAA6B,CACxCt0B,WAAYu0B,SACZr0B,YAAa,MACbC,oBA9DEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAqO,SAAM8lB,cAAWC,YAExBt5B,EAAiBkF,EAAG,UAEpB,IAAMyO,EAAcjS,eAAakS,mBAAmB,CAACL,GAAOrO,EAAE7D,MAAMY,QAChEuf,EAAKtc,EACU,MAAfyO,IACF6N,EAAK5O,GAAU,CAACvL,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC+J,KAAMqB,MAEtD,IAAM4lB,EAAe73B,eAAasS,iBAAiB,EAAG9O,EAAE7D,MAAMY,QAAQ,GAEtE,GAAIs3B,IAAiB/X,EAAGngB,MAAMY,OAAS,EACrC,MAAM,IAAImB,MACN,qDACQoe,EAAGngB,MAAMY,OAAS,oBAAkBs3B,GAYlD,IATA,IAAMC,EAAcrmB,aAAWqO,EAAG/gB,MAAO,SACnC6D,EAAO/D,OAAKsH,oBACDtH,OAAK8E,cAAcmc,EAAGngB,OAAQm4B,GAEzC7zB,EAAQP,EAAQtE,KAAKW,IAAI+f,EAAG5f,QAAQR,OACpCq4B,EAAWjY,EAAGngB,MAAMmgB,EAAGngB,MAAMY,OAAS,GACtCy3B,EAAgBJ,EAClB,SAAC70B,EAAWiI,GAAc,OAAAjI,EAAIg1B,EAAW/sB,EAAI,GAC7C,SAACjI,EAAWiI,GAAc,OAAAjI,EAAIiI,GACzBjI,EAAI,EAAGA,EAAIkB,EAAM1D,OAAQwC,GAAKg1B,EACrC,IAAK,IAAI/sB,EAAI,EAAGA,EAAI+sB,EAAU/sB,IAAK,CACjC,IAAM0I,EAAMskB,EAAcj1B,EAAGiI,GAC7B,GAAU,IAANA,EACFpI,EAAK8Q,GAAOikB,EAAY,EAAI1zB,EAAMyP,OAC7B,CACL,IAAMukB,EAAUD,EAAcj1B,EAAGiI,EAAI,GACrCpI,EAAK8Q,GAAOikB,EAAY1zB,EAAMg0B,GAAWr1B,EAAKq1B,GACtBh0B,EAAMyP,GAAO9Q,EAAKq1B,IAKhD,IAAMxzB,EAASf,EAAQqC,eAAe+Z,EAAGngB,MAAOm4B,EAAal1B,GAE7D,GAAmB,MAAfqP,EAAqB,CACvB,IACMimB,EAA0BhnB,GAC5B,CAACvL,OAAQ,CAACnC,EAAGiB,GAASf,UAASmD,MAAO,CAAC+J,KAFhB5Q,eAAam4B,uBAAuBlmB,MAO/D,OAHAvO,EAAQsD,8BAA8BvC,GACtCf,EAAQsD,8BAA8B8Y,GAE/BoY,EAGT,OAAOzzB,IC3BF,IAAM2zB,GAAoC,CAC/Cj1B,WAAYk1B,gBACZh1B,YAAa,MACbC,oBAlC4BC,GAKrB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAG+oB,YACHliB,SAAMO,iBAEb,GAAuB,IAAnBpH,EAAE7D,MAAMY,OAAc,CACxB,IAGMgK,EACFN,EAJUvG,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACrBgE,EAAQtE,KAAKW,IAAIwsB,EAAQrsB,QAAQR,OAGhB6sB,EAAQxtB,MAAOwtB,EAAQ5sB,MAAO0K,GAEnE,OAAO3G,EAAQqC,eAAe,CAACsE,GAAOkiB,EAAQxtB,MAAOwL,GAChD,GAAuB,IAAnB/G,EAAE7D,MAAMY,OAAc,CAC/B,IAGMwK,EAASN,EAHF/G,EAAQ+kB,WAAWjlB,GACbE,EAAQ+kB,WAAW8D,GAEcliB,EAAMO,GAE1D,OAAOlH,EAAQqC,eAAegF,EAAOpL,MAAO4sB,EAAQxtB,MAAOgM,EAAOrL,QAGpE,MAAM,IAAIgC,MACN,qEACG8B,EAAE7D,MAAMY,cCwBV,IAAM+3B,GAAmC,CAC9Cn1B,WAAYo1B,eACZl1B,YAAa,MACbC,oBAxD2BC,GAKpB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAka,cAAWsK,eAElBnpB,OAAKC,OACc,SAAfkpB,GACA,WAAM,MAAA,+DACFA,KACRnpB,OAAKC,OACD4e,EAAY,GACZ,WAAM,MAAA,sDAAsDA,KAgBhE,IAdA,IAAM0F,EAAY5f,EAAE7D,MAAM,GACpB64B,EAAch1B,EAAE7D,MAAM,GACtB84B,EAAaj1B,EAAE7D,MAAM,GACrB+4B,EAAal1B,EAAE7D,MAAM,GAErBg5B,EAAeH,EAAc9a,EAC7Bkb,EAAcH,EAAa/a,EAC3Bmb,EAAcH,GAAchb,EAAYA,GAExCmE,EAAUne,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACrC+E,EACF,IAAI3B,aAAasgB,EAAYuV,EAAeC,EAAcC,GAE1DC,EAAY,EACP5wB,EAAI,EAAGA,EAAIkb,IAAalb,EAC/B,IAAK,IAAI6wB,EAAI,EAAGA,EAAIJ,IAAgBI,EAGlC,IAFA,IAAMC,EAAMh2B,KAAKgK,MAAM+rB,EAAIrb,GACrBub,EAAWF,EAAIrb,EACZwb,EAAI,EAAGA,EAAIN,IAAeM,EAIjC,IAHA,IAAMC,EAAMn2B,KAAKgK,MAAMksB,EAAIxb,GAErB0b,GAAWH,EAAUvb,EADVwb,EAAIxb,GAC6Bmb,EACzCl4B,EAAI,EAAGA,EAAIk4B,IAAel4B,EAAG,CACpC,IACM04B,EADM14B,EAAIy4B,EAENV,GAAcS,EAAMV,GAAcO,EAAMR,EAActwB,IAChEzD,EAAOq0B,KAAejX,EAAQwX,GAMtC,OAAO31B,EAAQqC,eACX,CAACqd,EAAWuV,EAAcC,EAAaC,GAAcr1B,EAAEzE,MAAO0F,cCjDpD60B,GAAsB/1B,GAK7B,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAGiqB,WACHvW,YAASmQ,QAAKoH,cAAWnH,oBAEhChpB,EAAiB,CAACkF,EAAGiqB,GAAS,yBAE9B,IAAM3c,EAAWjS,OAAK0F,eAAef,EAAE7D,OACjCovB,EAAgBlwB,OAAK0F,eAAekpB,EAAO9tB,OAE7C45B,EAAa9K,EACC,MAAd8K,IACFA,EAAa,CAAC,EAAG,IAGnB16B,OAAKC,OACDkB,eAAaunB,+BAA+BrQ,EAASqiB,IACrD,WAAM,MAAA,gFACgBriB,qBAA0BqiB,SAiBpD,IAfA,IAAMzX,EAAW9hB,eAAa4uB,kBAC1BprB,EAAE7D,MACF8tB,EAAO9tB,MAA2CuX,EAASqiB,EAC3DlS,EAAKC,GAAiB,GAEnBI,iBAAcD,gBAAavF,mBAAgBC,kBAAeI,YAE3DE,EAAUF,EAAQG,KAClBJ,EAASC,EAAQC,IACjBgX,EAAQ1X,EAASuO,YAAcvO,EAASyB,WACxCuL,EAAI,IAAInW,eAAamJ,EAAShW,SAAUtI,EAAEzE,OAC1CsI,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnC8vB,EAAQ9rB,EAAQtE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,OACxC+vB,EAAQX,EAAEpvB,OAEPwI,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EAGxC,IAFA,IAAMwnB,EAAWxnB,EAAI4I,EAAS,GACxB6e,EAAWznB,EAAI4mB,EAAE5X,QAAQ,GACtBsM,EAAK,EAAGA,EAAK1B,EAAS2B,YAAaD,EAG1C,IAFA,IAAMoM,EAAWD,EAAWnM,EAAKsL,EAAE5X,QAAQ,GACrCwM,EAAWF,EAAK1B,EAASE,aAAeM,EACrC6C,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,IAAMX,EAAKd,EAAWyB,EAAKjD,EAC3B,KAAIsC,EAAK,GAAKA,GAAM1C,EAAS+B,UAK7B,IAFA,IAAMgM,EAAW1K,EAAK4J,EAAc,GAC9Be,EAAWJ,EAAWlL,EAAK1T,EAAS,GACjCiT,EAAK,EAAGA,EAAKjC,EAASkC,WAAYD,EAGzC,IAFA,IAAMgM,EAAWH,EAAW7L,EAAK+K,EAAE5X,QAAQ,GACrC+M,EAAWF,EAAKjC,EAASG,YAAcQ,EACpC2C,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,IAAMV,EAAKT,EAAWmB,EAAKjD,EAC3B,KAAIuC,EAAK,GAAKA,GAAM5C,EAASsC,SAO7B,IAJA,IAAMiO,EAAWxC,EAAWzK,EAAK2J,EAAc,GACzCiB,EAAWF,EAAWpL,EAAK5C,EAASyB,WACtC+O,EAAWvC,EACXE,EAAWoC,EACNnC,EAAK,EAAGA,EAAKpO,EAASyB,aAAc2M,EAAI,CAE/C,IADA,IAAMC,EAAO9oB,EAAM2oB,EAAWE,GACrBuJ,EAAI,EAAGA,EAAID,IAASC,EAC3BhK,EAAM6C,EAAWmH,IAAMtJ,EAAOX,EAAMS,EAAWwJ,GAEjDnH,GAAYkH,EACZvJ,GAAYuJ,IAQxB,OAAO91B,EAAQqC,eAAe+oB,EAAEnvB,MAAOmvB,EAAE/vB,MAAO+vB,EAAEpvB,QAG7C,IAAMg6B,GAA4C,CACvDv2B,WAAYw2B,wBACZt2B,YAAa,MACbC,WAAYg2B,ICxBP,IAAMM,GAA0D,CACrEz2B,WAAY02B,sCACZx2B,YAAa,MACbC,oBA/DkDC,GAK3C,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAG4kB,OACHlR,YAASuX,cAAWpH,QAAKC,oBAAiBoJ,gBAEjDpyB,EAAiB,CAACkF,EAAG4kB,GAAK,uCAkB1B,IAhBA,IAAMtG,EAAW9hB,eAAa4uB,kBAC1BprB,EAAE7D,MAA2C+wB,EAAaxZ,EAC1DuX,EAAWpH,EAAKC,GAAiB,GAE9BtF,iBAAcC,gBAAayF,iBAAcD,gBAE1CkJ,EAAK,IAAIhY,eAAamJ,EAAS4O,YAAa,WAE5CE,EAAU9O,EAASS,QAAQG,KAC3BmO,EAAS/O,EAASS,QAAQC,IAC1BgX,EAAQ1X,EAASuO,YAAcvO,EAASyB,WAExClc,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnCgL,EAAO,IAAIiO,eAAanV,EAAE7D,MAAO6D,EAAEzE,MAAOsI,GAC1CypB,EAASptB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACrC8oB,EAAQ,IAAI7P,eAAayP,EAAGzoB,MAAOyoB,EAAGrpB,MAAO+xB,GAC1C3L,EAAK,EAAGA,EAAKuC,IAAgBvC,EAKpC,IAJA,IAAM4L,EAAQ/tB,KAAK8L,IAAI,EAAG9L,KAAK0I,MAAMmlB,EAAS1L,GAAMnD,IAC9CgP,EAAQhuB,KAAKsM,IACfwS,EAAS2B,WAAY3B,EAAS+B,SAAWgN,EAAS1L,GAAMnD,GAEnDoD,EAAK,EAAGA,EAAKqC,IAAerC,EAKnC,IAJA,IAAM6L,EAAQjuB,KAAK8L,IAAI,EAAG9L,KAAK0I,MAAMklB,EAAUxL,GAAMnD,IAC/CiP,EAAQluB,KAAKsM,IACfwS,EAASkC,UAAWlC,EAASsC,QAAUwM,EAAUxL,GAAMnD,GAElDmO,EAAK,EAAGA,EAAKtO,EAASuO,cAAeD,EAAI,CAKhD,IAJA,IAAMF,EAAKltB,KAAKsT,MAAM8Z,EAAKoJ,GACrBM,EAAK1J,EAAKoJ,EAEZxQ,EAAU,EACL9gB,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EACxC,IAAK,IAAIsb,EAAKuN,EAAOvN,EAAKwN,IAASxN,EAEjC,IADA,IAAMgB,EAAKW,EAAK3B,EAAKxB,EAAe6O,EAC3B9M,EAAKkN,EAAOlN,EAAKmN,IAASnN,EAAI,CACrC,IAAMW,EAAKU,EAAKrB,EAAK9B,EAAc2O,EACnC5H,GAAYte,EAAK3K,IAAImI,EAAGsc,EAAIE,EAAIwL,GAC3B1H,EAAMzoB,IAAImI,EAAGsb,EAAIO,EAAIqM,GAIhCO,EAAGvwB,IAAI4oB,EAAS7D,EAAIC,EAAI8K,EAAI4J,GAKlC,OAAOp2B,EAAQqC,eAAe4qB,EAAGhxB,MAAOgxB,EAAG5xB,MAAO4xB,EAAGjxB,UC0BhD,IAAMq6B,GAAyD,CACpE52B,WAAY62B,qCACZ32B,YAAa,MACbC,oBAtFiDC,GAK1C,IAAAoC,WAAQjC,YAASmD,UACjBuhB,OAAIqF,WACJvW,YAASuX,cAAWpH,QAAKC,oBAAiBzR,eAEjDvX,EAAiB,CAAC8pB,EAAIqF,GAAS,sCAiC/B,IA/BA,IAAM4D,EAAYxyB,OAAK0F,eAAe6jB,EAAGzoB,OACnCovB,EAAgBlwB,OAAK0F,eAAekpB,EAAO9tB,OAE3CmiB,EAAW9hB,eAAa4uB,kBAC1B/Y,EAAY4X,EAAO9tB,MAA2CuX,EAC9DuX,EAAWpH,EAAKC,GAAiB,GAE/BgB,EAAK,IAAI3P,eAAamJ,EAAS8F,QAAS,WACxC0J,EAAWhJ,EAAG5oB,OACduB,YAAC6yB,OAAMC,OAAMC,OACbzC,EAAW7tB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACtCuzB,OAAMC,OAAMC,OACb3B,EAAY9tB,EAAQtE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,OAC3C+xB,OAAOC,OAAOC,OAEnBvO,cACAsE,iBACAD,gBACAlE,eACAM,aACAO,YACAiM,gBACA5M,cACAO,aACAhC,iBACAC,gBAEI4O,EAASnJ,EAAe,EAAI5F,EAASS,QAAQC,IAC7CoO,EAAUnJ,EAAc,EAAI3F,EAASS,QAAQG,KAC7C8W,EAAQnJ,EAAc9M,EAEnBrb,EAAI,EAAGA,EAAIkb,IAAalb,EAC/B,IAAK,IAAIgoB,EAAK,EAAGA,EAAK3M,IAAc2M,EAClC,IAAK,IAAI1L,EAAK,EAAGA,EAAKX,IAAYW,EAMhC,IALA,IAAMd,EAAWc,EAAKqM,EAChBlN,EAAQ3gB,KAAK8L,IAAI,EAAG9L,KAAK0I,KAAKgY,EAAW1B,IACzCgP,EACFhuB,KAAKsM,IAAImU,GAAYiE,EAAehE,GAAY1B,GAE3C0C,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CAOnC,IANA,IAAMT,EAAWS,EAAKkM,EAChB1M,EAAQlhB,KAAK8L,IAAI,EAAG9L,KAAK0I,KAAKuY,EAAWhC,IACzCiP,EACFluB,KAAKsM,IAAI0U,GAAWyD,EAAcxD,GAAYhC,GAE9C+G,GAAU,EACLxF,GAAKG,EAAOH,GAAKwN,IAASxN,GAGjC,IAFA,IAAM2B,GAAK3B,GAAKxB,EAAe0B,EAEtBK,GAAKG,EAAOH,GAAKmN,IAASnN,GAMjC,IALA,IACM6N,GAAWqB,EAAO/qB,EAAIgrB,EAAO1P,GAAK2P,EAAOpP,GACzC8N,GAAYJ,GAAS/J,EAAe,EAAIvC,IAC1CuM,GAASjK,EAAc,GAHhB1D,GAAK9B,EAAcgC,IAGO0N,EAAQzB,EAEpC4J,GAAK,EAAGA,GAAKN,IAASM,GAAI,CAIjC9Q,IAFcuI,EAASK,IADZ1B,EAAKsJ,EAAQM,KAETtI,EAAUK,GAAYiI,IAK3CxI,EAASwC,EAAO5rB,EAAI6rB,EAAOvP,EAAKwP,EAAOtP,EAAKwL,GAAMlH,GAM1D,OAAOtlB,EAAQqC,eAAeuiB,EAAG3oB,MAAO2oB,EAAGvpB,MAAOupB,EAAG5oB,UC9DhD,IAAMu6B,GAA2B,CACtC92B,WAAY+2B,OACZ72B,YAAa,MACbC,oBAtBmBC,GAUnB,IARO,IAAAoC,WAAQjC,YACRF,MAED4H,EAAQvM,OAAK8E,cAAcH,EAAE7D,OAE7B0H,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnCqL,EAASpJ,SAAO,CAACyJ,EAAOA,GAAQ5H,EAAEzE,OAClC6D,EAAOmI,EAAOrL,OACXqD,EAAI,EAAGA,EAAIsE,EAAM9G,OAAQwC,IAChCH,EAAKG,EAAIqI,EAAQrI,GAAKsE,EAAMtE,GAG9B,IAAM+I,EAAetI,EAAE7D,aAAU6D,EAAE7D,OAEnC,OAAO+D,EAAQqC,eAAe+F,EAAUf,EAAOhM,MAAOgM,EAAOrL,UChBlDy6B,GAAiC,CAC5Ch3B,WAAYi3B,aACZ/2B,YAAa,MACbC,WAAY,SAACrC,GAwCX,QAxCY0E,WAAQjC,YAASmD,UACvBmB,IAACxE,MAAGiqB,WACJrlB,IAAC8O,YAASmQ,QAAKoH,cACfhrB,EAAaC,EAEb2D,EAAQ5D,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACtCmR,EAAQrN,EAAE7D,MAAMY,OAEhB85B,EAAa52B,EAAWrE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,OAChD46B,EAAa7M,EAAO9tB,MAAMY,OAE1B8I,qEACJ+Z,cACAS,aACAO,YACAb,eACAE,cACAO,aACAzB,YACAP,iBACAC,gBACAyF,iBACAD,gBACAvF,mBACAC,kBACArW,aAOIyU,EAAU1hB,OAAK8E,cAAcmI,GAC7ByuB,EAAUzuB,EAASvL,OACnByiB,EAAankB,OAAKwM,kBAAkB7H,EAAEzE,MAAOwhB,GAM1CrY,EAAI,EAAGA,EAAIkb,IAAalb,EAC/B,IAAK,IAAIsyB,EAAO,EAAGA,EAAO/W,IAAa+W,EAErC,IADA,IAAMC,EAAOD,EAAOxY,EAAeO,EAAQC,IAClCkY,EAAO,EAAGA,EAAO1W,IAAY0W,EAEpC,IADA,IAAMC,EAAOD,EAAOzY,EAAcM,EAAQG,KACjC/hB,EAAI,EAAGA,EAAI4iB,IAAc5iB,EAAG,CAEnC,IADA,IAAIi6B,EAAShY,OAAOiY,iBACX9B,EAAI,EAAGA,EAAIrR,IAAgBqR,EAAG,CACrC,IAAM+B,EAAML,EAAO1B,EAAI7W,EACvB,GAAI4Y,GAAO,GAAKA,EAAMjX,EACpB,IAAK,IAAIqV,EAAI,EAAGA,EAAIzR,IAAeyR,EAAG,CACpC,IAAM6B,EAAMJ,EAAOzB,EAAI/W,EACvB,GAAI4Y,GAAO,GAAKA,EAAM3W,EAAS,CAC7B,IAAM4W,EAASn8B,OAAK0G,WAChB,CAAC2C,EAAG4yB,EAAKC,EAAKp6B,GAAIkQ,EAAOhS,OAAK0F,eAAef,EAAE7D,QAC7Cs7B,EAAcp8B,OAAK0G,WACrB,CAACwzB,EAAGG,EAAGv4B,GAAI25B,EACXz7B,OAAK0F,eAAekpB,EAAO9tB,QACzBu7B,EAAM7zB,EAAM2zB,GAAUX,EAAWY,GACnCC,EAAMN,IACRA,EAASM,KAQnBlY,EAFoBnkB,OAAK0G,WACrB,CAAC2C,EAAGsyB,EAAME,EAAM/5B,GAAI45B,EAAS17B,OAAK0F,eAAeuH,KAC3B8uB,EASlC,MAAO,CAAC16B,OAHOuD,EAAW5C,MACtBhC,OAAK0I,aAAayb,EAAYxf,EAAEzE,OAAQ+M,EAAUtI,EAAEzE,OAExCY,MAAOmM,EAAU/M,MAAOyE,EAAEzE,SC/EjCo8B,GAA+C,CAC1Dh4B,WAAYi4B,2BACZ/3B,YAAa,MACbC,WAAY,SAACrC,OAAC0E,WAAQjC,YAASmD,UACvBmB,IAACxE,MAAGiqB,WAAQrF,OAEZhgB,IAAC8O,YAASmQ,QAAKoH,cACfhrB,EAAaC,EAEboc,EACFjhB,OAAKw8B,cACD73B,EAAE7D,MAAO8D,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,QAGzC47B,EAAUz8B,OAAKw8B,cACD5N,EAAO9tB,MACP8D,EAAWrE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,QAGjD2J,qEACJ+Z,cACAS,aACAO,YACAb,eACAE,cACAO,aACAzB,YACAP,iBACAC,gBACAyF,iBACAD,gBACAvF,mBACAC,kBACArW,aAOFjN,OAAKC,OACDspB,EAAGxT,OAAS9I,EAASvL,QACrB,WAAM,MAAA,YAAY66B,2BAAZ,0CACmCtvB,EAASvL,oBAC3C6nB,EAAGxT,QAiBd,IAfA,IAAM2mB,EACF18B,OAAKw8B,cACDvvB,EAAUrI,EAAWrE,KAAKW,IAAIqoB,EAAGloB,QAAQR,QAK3C87B,EAAY38B,OAAK48B,0BACDhO,EAAO9tB,MAAO8tB,EAAO1uB,OAOlCmJ,EAAI,EAAGA,EAAIkb,IAAalb,EAC/B,IAAK,IAAIsyB,EAAO,EAAGA,EAAO/W,IAAa+W,EAErC,IADA,IAAMC,EAAOD,EAAOxY,EAAeO,EAAQC,IAClCkY,EAAO,EAAGA,EAAO1W,IAAY0W,EAEpC,IADA,IAAMC,EAAOD,EAAOzY,EAAcM,EAAQG,KACjC/hB,EAAI,EAAGA,EAAI4iB,IAAc5iB,EAAG,CAInC,IAHA,IAAIi6B,EAAShY,OAAOiY,iBAChBa,EAAO,EACPC,EAAO,EACF5C,EAAI,EAAGA,EAAIrR,IAAgBqR,EAAG,CACrC,IAAM+B,EAAML,EAAO1B,EAAI7W,EACvB,GAAI4Y,GAAO,GAAKA,EAAMjX,EACpB,IAAK,IAAIqV,EAAI,EAAGA,EAAIzR,IAAeyR,EAAG,CACpC,IAAM6B,EAAMJ,EAAOzB,EAAI/W,EACvB,GAAI4Y,GAAO,GAAKA,EAAM3W,EAAS,CAC7B,IAAM8W,EAAMpb,EAAG5X,GAAG4yB,GAAKC,GAAKp6B,GAAK26B,EAAQvC,GAAGG,GAAGv4B,GAC3Cu6B,EAAMN,IACRA,EAASM,EACTQ,EAAO3C,EACP4C,EAAOzC,KAMjBsC,EAAUE,GAAMC,GAAMh7B,IAAM46B,EAAIrzB,GAAGsyB,GAAME,GAAM/5B,GASvD,MAAO,CAACT,OAHOuD,EAAW5C,MACtBhC,OAAK0I,aAAai0B,EAAWh4B,EAAEzE,OAAQ0uB,EAAO9tB,MAAO8tB,EAAO1uB,OAEhDY,MAAO8tB,EAAO9tB,MAAOZ,MAAO0uB,EAAO1uB,SC/F1C68B,GAA8C,CACzDz4B,WAAY04B,0BACZx4B,YAAa,MACbC,WAAY,SAACrC,OAAC0E,WAAQjC,YAASmD,UACvBmB,IAACxE,MAAGiqB,WAAQrF,OAEZhgB,IAAC8O,YAASmQ,QAAKoH,cACfhrB,EAAaC,EAEboc,EACFjhB,OAAKw8B,cACD73B,EAAE7D,MAAO8D,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,QAGzC47B,EAAUz8B,OAAKw8B,cACD5N,EAAO9tB,MACP8D,EAAWrE,KAAKW,IAAI0tB,EAAOvtB,QAAQR,QAGjD2J,qEACJ+Z,cACAS,aACAO,YACAb,eACAE,cACAO,aACAzB,YACAP,iBACAC,gBACAyF,iBACAD,gBACAvF,mBACAC,kBACArW,aAOFjN,OAAKC,OACDspB,EAAGxT,OAAS9I,EAASvL,QACrB,WAAM,MAAA,YAAYs7B,0BAAZ,0CACmC/vB,EAASvL,oBAC3C6nB,EAAGxT,QAiBd,IAfA,IAAM2mB,EACF18B,OAAKw8B,cACDvvB,EAAUrI,EAAWrE,KAAKW,IAAIqoB,EAAGloB,QAAQR,QAK3C87B,EACF38B,OAAK48B,0BAA0Bj4B,EAAE7D,MAAO6D,EAAEzE,OAOrCmJ,EAAI,EAAGA,EAAIkb,IAAalb,EAC/B,IAAK,IAAIsyB,EAAO,EAAGA,EAAO/W,IAAa+W,EAErC,IADA,IAAMC,EAAOD,EAAOxY,EAAeO,EAAQC,IAClCkY,EAAO,EAAGA,EAAO1W,IAAY0W,EAEpC,IADA,IAAMC,EAAOD,EAAOzY,EAAcM,EAAQG,KACjC/hB,EAAI,EAAGA,EAAI4iB,IAAc5iB,EAAG,CAInC,IAHA,IAAIi6B,EAAShY,OAAOiY,iBAChBiB,EAAUrB,EAAO,EAAK,EAAIA,EAC1BsB,EAAUpB,EAAO,EAAK,EAAIA,EACrB5B,EAAI,EAAGA,EAAIrR,IAAgBqR,EAAG,CACrC,IAAM+B,EAAML,EAAO1B,EAAI7W,EACvB,GAAI4Y,GAAO,GAAKA,EAAMjX,EACpB,IAAK,IAAIqV,EAAI,EAAGA,EAAIzR,IAAeyR,EAAG,CACpC,IAAM6B,EAAMJ,EAAOzB,EAAI/W,EACvB,GAAI4Y,GAAO,GAAKA,EAAM3W,EAAS,CAC7B,IAAM8W,EAAMpb,EAAG5X,GAAG4yB,GAAKC,GAAKp6B,GAAK26B,EAAQvC,GAAGG,GAAGv4B,GAC3Cu6B,EAAMN,IACRA,EAASM,EACTY,EAAShB,EACTiB,EAAShB,KAMnBS,EAAUtzB,GAAG4zB,GAAQC,GAAQp7B,IAAM46B,EAAIrzB,GAAGsyB,GAAME,GAAM/5B,GAS9D,MAAO,CAACT,OAHOuD,EAAW5C,MACtBhC,OAAK0I,aAAai0B,EAAWh4B,EAAEzE,OAAQyE,EAAE7D,MAAO6D,EAAEzE,OAEtCY,MAAO6D,EAAE7D,MAAOZ,MAAOyE,EAAEzE,kBC1F7Bmf,GACZ3a,GAEK,IAMHuc,EANGna,WAAQjC,YAASmD,UACjBrD,MACAqO,SAAMC,aAEbxT,EAAiBkF,EAAG,OASpB,IAAMqN,GALJiP,EADc,SAAZtc,EAAEzE,MACC6H,EAAK,CAACjB,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC9H,MAAO,WAE3CqH,EAAS,CAACT,OAAQ,CAACnC,KAAIE,aAGb/D,MAAMY,OACjBwR,EAAOlT,OAAKmT,eAAeH,EAAMiO,EAAGngB,OACpCsS,EAAcjS,eAAakS,mBAAmBH,EAAMlB,GAEtDS,EAAgBS,EAChBI,EAAY2N,EACG,MAAf7N,IACFE,EACIjB,GAAU,CAACvL,OAAQ,CAACnC,EAAGsc,GAAKpc,UAASmD,MAAO,CAAC+J,KAAMqB,KACvDX,EAAgBtR,eAAasS,iBAAiBhB,EAAc/Q,OAAQsQ,IAGtE7Q,eAAa+f,2BACT,MAAOzO,EAAea,EAAUxS,MAAMY,QAU1C,IARM,IAAAU,sDAAC6K,OAAUyF,OAGb9M,EAASyB,EAAMxC,EAASoI,EADR9L,eAAayR,WAAWU,EAAUpT,MAAO,UAEvD6P,EAAa/P,OAAK8E,cAAc4N,GAChC3O,EAAOc,EAAQtE,KAAKW,IAAI0E,EAAOvE,QAAQR,OAEvCuE,EAAQP,EAAQtE,KAAKW,IAAIoS,EAAUjS,QAAQR,OACxCqD,EAAI,EAAGA,EAAIH,EAAKrC,SAAUwC,EAAG,CAGpC,IAFA,IAAM8L,EAAS9L,EAAI6L,EACfotB,EAAM,EACDhxB,EAAI,EAAGA,EAAI4D,IAAc5D,EAChCgxB,GAAO/3B,EAAM4K,EAAS7D,GAExBpI,EAAKG,GAAKi5B,EAGZ,GAAIlqB,EAAU,CACZ,IACMmqB,EAAYx3B,EAClBA,EAAS2W,GAAQ,CAACzV,OAAQ,CAACnC,EAAGiB,GAASf,UAASmD,MAAO,CAAClH,MAFvCK,eAAauS,qBAAqB9N,EAAO9E,MAAOoS,MAGjErO,EAAQsD,8BAA8Bi1B,GASxC,OANAv4B,EAAQsD,8BAA8B8Y,GAEnB,MAAf7N,GACFvO,EAAQsD,8BAA8BmL,GAGjC1N,EAGF,IAAMy3B,GAA0B,CACrC/4B,WAAYg5B,MACZ94B,YAAa,MACbC,WAAY4a,ICGP,IAAMke,GAA6B,CACxCj5B,WAAYk5B,SACZh5B,YAAa,MACbC,oBAzEEC,GAEK,IAAAoC,WAAQjC,YACR44B,mBACD9c,EAAU7Z,EAEV1E,kDAACs7B,YAASC,eAAYC,WAE5Bz8B,eAAa08B,oBAAoBH,EAAQh8B,OAAQk8B,EAAQjd,GAOzD,IANM,IAAAxX,2CAAC20B,SAAMC,UAEPC,EAASD,EAAMr8B,OACjBu8B,EAAuB,KACvBC,EAAmBR,EAAQh8B,OACzBy8B,EAAiC,GAC9Bj6B,EAAI,EAAGA,EAAI85B,IAAU95B,EAAG,CAC/B,IAAqB,QAAAqF,EAAAw0B,EAAM75B,GAANgc,WAAAA,IAAU,CAA1B,IAAMke,OACH5zB,8CAACuH,uBAA0BssB,eAE7B15B,SACAxD,eAAam9B,sBAAsBvsB,GACrCpN,EAAIgc,EAAQyd,IAEZz5B,EAAI0N,GAAU,CAACvL,OAAQ,CAACnC,EAAGgc,EAAQyd,IAAUv5B,UAASmD,MAAO,CAAC+J,UAC9DosB,EAAiB3qB,KAAK7O,IAGxB,IADA,IAAMsS,EAAwBtS,EAAE7D,MAAM0F,QAC7BsS,EAAI,EAAGA,EAAIulB,EAAa38B,SAAUoX,EACzC7B,EAAYsnB,OAAOF,EAAavlB,GAAI,EAAG,GAGpC9Y,OAAK8oB,YAAYnkB,EAAE7D,MAAOmW,KAC7BtS,EAAI4X,GAAQ,CAACzV,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAClH,MAAOmW,KAClDknB,EAAiB3qB,KAAK7O,IAEZ,OAARs5B,EACFA,EAAMt5B,GAGNs5B,EAAMltB,GAAS,CAACjK,OAAQ,CAACsC,EAAGzE,EAAG0E,EAAG40B,GAAMp5B,YACxCs5B,EAAiB3qB,KAAKyqB,IAGtB/5B,EAAI85B,EAAS,IACXF,EAAK55B,IAAM,IACb+5B,EAAM5e,GAAI,CACRvY,OAAQ,CAACnC,EAAGs5B,GACZp5B,UACAmD,MAAO,CACLgL,KAAM8qB,EAAK55B,IAAMw5B,EAAQh8B,OAASw8B,GAClCjrB,UAAU,KAGdkrB,EAAiB3qB,KAAKyqB,IAExBC,KAKJ,IAAyB,QAAAM,IAAAC,WAAAA,IAAkB,CAAtC,IAAMt7B,OACLA,IAAe86B,GAGnBp5B,EAAQsD,8BAA8BhF,GAGxC,OAAO86B,IClDF,IAAMS,GAA8B,CACzCp6B,WAAYq6B,UACZn6B,YAAa,MACbC,oBAzBsBC,GAEf,IAAAoC,WAAQjC,YACR0kB,OAAI0G,MAEXxwB,EAAiB,CAAC8pB,EAAI0G,GAAI,WAK1B,IAHA,IAAMjsB,EAAe,IAAIC,aAAajE,OAAK8E,cAAcmrB,EAAEnvB,QACrDD,EAASgE,EAAQtE,KAAKW,IAAI+uB,EAAE5uB,QAAQR,OACpC6xB,EAAW7tB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACpCqD,EAAI,EAAGA,EAAIrD,EAAOa,SAAUwC,EAAG,CACtC,IAAM06B,EAAI/9B,EAAOqD,GAEfF,EAAaE,GADX06B,GAAK,EACWlM,EAASxuB,GAETwuB,EAASxuB,IAAM06B,EAAI,GAIzC,OAAO/5B,EAAQqC,eAAe+oB,EAAEnvB,MAAO,UAAWkD,KCnBvC66B,GACT75B,GAA6B,SAACoE,EAAWC,GAAc,OAACD,IAAMC,EAAK,EAAI,KAC9Dy1B,GACT/1B,EAAiBg2B,QAAOF,GAAW,KAAwB,QAElDG,GAA4B,CACvC16B,WAAYy6B,QACZv6B,YAAa,MACbC,WAAYq6B,ICTRG,GAAI99B,eAAa+9B,MACjBC,GAAKh+B,eAAai+B,OAClBC,GAAKl+B,eAAam+B,OAClBC,GAAKp+B,eAAaq+B,OAClBC,GAAKt+B,eAAau+B,OAClBC,GAAKx+B,eAAay+B,OAEXC,GAAMvzB,EACfwzB,OACA,SAAClzB,GACC,IAAMmzB,EAAO57B,KAAK47B,KAAKnzB,GACjBgyB,EAAIz6B,KAAKC,IAAIwI,GACb7M,EAAI,GAAO,EAAMk/B,GAAIL,GAC3B,OAAOmB,GACF,MACKJ,GAAK5/B,EAAI0/B,IAAM1/B,EAAKw/B,IAAMx/B,EAAIs/B,IAAMt/B,EAAIo/B,IAAMp/B,EAC/CoE,KAAKwJ,KAAKixB,EAAIA,OAIhBoB,GAA0B,CACrC17B,WAAYw7B,MACZt7B,YAAa,MACbC,WAAYo7B,aCtBEI,GAAWv7B,GAKlB,IAAAoC,WAAQjC,YAASmD,UACjBL,UACAu4B,QAEDvoB,EAAYhQ,EAAM7G,MAAMY,OACxB4D,EAAWqC,EAAM7G,MAAM0F,QACzB25B,EAAOD,EAWX,OAVIA,EAAM,IAERlgC,OAAKC,SACC0X,EAAY,IAAMuoB,GACpB,WAAM,MAAA,mCAAoCvoB,EAAY,QAClDA,SACRwoB,EAAOxoB,EAAYuoB,EAAM,GAE3B56B,EAASi5B,OAAO4B,EAAM,EAAG,GAElB5jB,GAAQ,CAACzV,OAAQ,CAACnC,EAAGgD,GAAQ9C,UAASmD,MAAO,CAAClH,MAAOwE,KAGvD,IAAM86B,GAAiC,CAC5C97B,WAAY+7B,aACZ77B,YAAa,MACbC,WAAYw7B,IC5BDK,GACTt7B,GAA6B,SAACoE,EAAWC,GAAc,OAAAD,EAAIC,KAClDk3B,GAAMx3B,EAAiBy3B,UAASF,IAEhCG,GAA8B,CACzCn8B,WAAYk8B,UACZh8B,YAAa,MACbC,WAAY87B,aCKEG,GACZ/4B,EAAmBg5B,EACnB/7B,GAgBF,IAfA,IAAMoS,EAAarP,EAAM7G,MACnBmY,EAAQjC,EAAW,GACnB4pB,EAAW5pB,EAAW,GAEtB6pB,EAAYj8B,EAAWrE,KAAKW,IAAIyG,EAAMtG,QAEtCy/B,EAASD,EAAUx+B,mBAAmBE,KACtCw+B,EAASF,EAAUx+B,mBAAmBI,KAGtCmG,EAAc,CAACqQ,EAAO2nB,GACtBj7B,EAAa3F,OAAK8E,cAAc8D,GAChC0B,EAAatK,OAAK6F,uBAAuB,UAAWF,GACpD4E,EAAavK,OAAK6F,uBAAuB,UAAWF,GAEjD0D,EAAI,EAAGA,EAAI4P,EAAO5P,IAAK,CAmB9B,IAjBA,IAAM8lB,EAAI3oB,GAAM,CACdM,OAAQ,CAACnC,EAAGm8B,GACZj8B,QAASD,EACToD,MAAO,CAACmM,MAAO,CAAC9K,EAAG,GAAImC,KAAM,CAAC,EAAGo1B,MAE7B18B,EAAIsC,GAAM,CACdM,OAAQ,CAACnC,EAAGo8B,GACZl8B,QAASD,EACToD,MAAO,CAACmM,MAAO,CAAC9K,EAAG,GAAImC,KAAM,CAAC,EAAGo1B,MAG7BI,EAAQn6B,EAAQ,CAACC,OAAQ,CAACvE,KAAM4sB,EAAG1sB,KAAMyB,GAAIW,QAASD,IAGtDxC,YAACgsB,SAAMC,SACP5c,EAAMtQ,eAAauB,uBAAuB0rB,EAAMC,GAE7CvsB,EAAI,EAAGA,EAAI8+B,EAAU9+B,IAAK,CACjC,IAAM21B,EAAIt2B,eAAa8/B,oBAAoBxvB,EAAK3P,GAChDwI,EAAWjB,EAAIu3B,EAAW9+B,GAAK21B,EAAEl1B,KACjCgI,EAAWlB,EAAIu3B,EAAW9+B,GAAK21B,EAAEh1B,KAGnCmC,EAAWuD,8BAA8BgnB,GACzCvqB,EAAWuD,8BAA8BjE,GACzCU,EAAWuD,8BAA8B64B,GAG3C,IAAME,EACFt8B,EAAWsC,eAAe0B,EAAa,UAAW0B,GAChD62B,EACFv8B,EAAWsC,eAAe0B,EAAa,UAAW2B,GAEhD3E,EAASiB,EACX,CAACC,OAAQ,CAACvE,KAAM2+B,EAAWz+B,KAAM0+B,GAAYt8B,QAASD,IAK1D,OAHAA,EAAWuD,8BAA8B+4B,GACzCt8B,EAAWuD,8BAA8Bg5B,GAElCv7B,WAGOw7B,GACZz5B,EAAmBg5B,EACnB/7B,GACF,IAAMy8B,EAAYrhC,OAAK8E,cAAc6C,EAAM7G,OAErC+/B,EAAYj8B,EAAWrE,KAAKW,IAAIyG,EAAMtG,QAEtC0F,EACFnC,EAAWrE,KAAKW,IAAI2/B,EAAUx+B,mBAAmBE,KAAKlB,QAAQR,OAG5DmG,EACFpC,EAAWrE,KAAKW,IAAI2/B,EAAUx+B,mBAAmBI,KAAKpB,QAAQR,OAGlE,GAsD6B,KADR2K,EArDH61B,GAsDH71B,EAAO,GAtDQ,CAC5B,IAAM5F,EAyDV,SAAS07B,EACLv6B,EAAwBC,EAAwBwE,EAChDm1B,EACA/7B,GACF,GAAa,IAAT4G,EACF,MAAO,CAACjJ,KAAMwE,EAAUtE,KAAMuE,GAGhC,IAAMzG,EAAOY,eAAauB,uBAAuBqE,EAAUC,GAErDu6B,EAAO/1B,EAAO,EAEdg2B,EAAcrgC,eAAasgC,qBAAqBlhC,GAEhDmhC,EAAeF,EAAYj/B,KAC3Bo/B,EAAeH,EAAY/+B,KAE3Bm/B,EAAY,CAACF,EAAahgC,QAE1BmgC,EACFj9B,EAAWsC,eAAe06B,EAAW,UAAWF,GAC9CI,EACFl9B,EAAWsC,eAAe06B,EAAW,UAAWD,GAE9CI,EAAiBl7B,EACnB,CAACC,OAAQ,CAACvE,KAAMs/B,EAAcp/B,KAAMq/B,GAAej9B,QAASD,IAE1Do9B,EAAa7gC,eAAa8gC,oBAAoB1hC,GAE9C2hC,EAAcF,EAAWz/B,KACzB4/B,EAAcH,EAAWv/B,KAEzB2/B,EAAW,CAACF,EAAYxgC,QAExB2gC,EACFz9B,EAAWsC,eAAek7B,EAAU,UAAWF,GAC7CI,EACF19B,EAAWsC,eAAek7B,EAAU,UAAWD,GAE7CI,EAAgB17B,EAClB,CAACC,OAAQ,CAACvE,KAAM8/B,EAAa5/B,KAAM6/B,GAAcz9B,QAASD,IAGxD49B,EACFlB,EAAUI,EAAcC,EAAcJ,EAAMZ,EAAS/7B,GAEnD69B,EAAgBD,EAAajgC,KAC7BmgC,EAAgBF,EAAa//B,KAE7BkgC,EAAa,CAACF,EAAc/gC,QAE5BkhC,EACFh+B,EAAWsC,eAAey7B,EAAY,UAAWF,GAC/CI,EACFj+B,EAAWsC,eAAey7B,EAAY,UAAWD,GAE/CI,EAAkBj8B,EAAQ,CAC9BC,OAAQ,CAACvE,KAAMqgC,EAAengC,KAAMogC,GACpCh+B,QAASD,IAGLm+B,EACFzB,EAAUY,EAAaC,EAAaZ,EAAMZ,EAAS/7B,GAEjDo+B,EAAeD,EAAYxgC,KAC3B0gC,EAAeF,EAAYtgC,KAE3BygC,EAAY,CAACF,EAAathC,QAE1ByhC,EACFv+B,EAAWsC,eAAeg8B,EAAW,UAAWF,GAC9CI,EACFx+B,EAAWsC,eAAeg8B,EAAW,UAAWD,GAE9CI,EAAiBx8B,EACnB,CAACC,OAAQ,CAACvE,KAAM4gC,EAAc1gC,KAAM2gC,GAAev+B,QAASD,IAE1D0+B,EAAIniC,eAAaoiC,UAAU/3B,EAAMm1B,GACjC6C,EAAS,CAACF,EAAE/gC,KAAKb,QAEjB+hC,EAAY7+B,EAAWsC,eAAes8B,EAAQ,UAAWF,EAAE/gC,MAC3DmhC,EAAY9+B,EAAWsC,eAAes8B,EAAQ,UAAWF,EAAE7gC,MAE3DwE,EAAcJ,EAChB,CAACC,OAAQ,CAACvE,KAAMkhC,EAAWhhC,KAAMihC,GAAY7+B,QAASD,IAEpD++B,EACF5yB,GACI,CAACjK,OAAQ,CAACsC,EAAGnC,EAAaoC,EAAGg6B,GAAiBx+B,QAASD,IAGzDg/B,EAAU34B,EAAI,CACFnE,OAAQ,CAACsC,EAAG05B,EAAiBz5B,EAAGs6B,GAChC9+B,QAASD,IAErBi/B,EAAUrrB,GAAI,CACF1R,OAAQ,CAACsC,EAAG05B,EAAiBz5B,EAAGs6B,GAChC9+B,QAASD,IAGrBk/B,EAAcvhC,EAAK,CAACuE,OAAQ,CAACa,MAAOi8B,GAAU/+B,QAASD,IACvDm/B,EAAcxhC,EAAK,CAACuE,OAAQ,CAACa,MAAOk8B,GAAUh/B,QAASD,IAEvDo/B,EAAcvhC,GAAK,CAACqE,OAAQ,CAACa,MAAOi8B,GAAU/+B,QAASD,IACvDq/B,EAAcxhC,GAAK,CAACqE,OAAQ,CAACa,MAAOk8B,GAAUh/B,QAASD,IAEvDs/B,EAAQxmB,GAAO,CACnB5W,OAAQ,CAACg9B,EAAuBC,GAChCl/B,QAASD,EACToD,MAAO,CAACgL,KAAM,KAEVmxB,EAAQzmB,GAAO,CACnB5W,OAAQ,CAACk9B,EAAuBC,GAChCp/B,QAASD,EACToD,MAAO,CAACgL,KAAM,KAGVoxB,GAAYx/B,EAAWrE,KAAKW,IAAIgjC,EAAM7iC,QAAQR,OAC9CwjC,GAAYz/B,EAAWrE,KAAKW,IAAIijC,EAAM9iC,QAAQR,OA2BpD,OAzBA+D,EAAWuD,8BAA8B05B,GACzCj9B,EAAWuD,8BAA8B25B,GACzCl9B,EAAWuD,8BAA8B45B,GACzCn9B,EAAWuD,8BAA8Bk6B,GACzCz9B,EAAWuD,8BAA8Bm6B,GACzC19B,EAAWuD,8BAA8Bo6B,GACzC39B,EAAWuD,8BAA8By6B,GACzCh+B,EAAWuD,8BAA8B06B,GACzCj+B,EAAWuD,8BAA8B26B,GACzCl+B,EAAWuD,8BAA8Bg7B,GACzCv+B,EAAWuD,8BAA8Bi7B,GACzCx+B,EAAWuD,8BAA8Bk7B,GACzCz+B,EAAWuD,8BAA8Bs7B,GACzC7+B,EAAWuD,8BAA8Bu7B,GACzC9+B,EAAWuD,8BAA8BlB,GACzCrC,EAAWuD,8BAA8Bw7B,GACzC/+B,EAAWuD,8BAA8By7B,GACzCh/B,EAAWuD,8BAA8B07B,GACzCj/B,EAAWuD,8BAA8B27B,GACzCl/B,EAAWuD,8BAA8B67B,GACzCp/B,EAAWuD,8BAA8B47B,GACzCn/B,EAAWuD,8BAA8B87B,GACzCr/B,EAAWuD,8BAA8B+7B,GACzCt/B,EAAWuD,8BAA8Bg8B,GAElC,CAAC5hC,KAAM6hC,GAAW3hC,KAAM4hC,IAzMzB/C,CAAUv6B,EAAUC,EAAUq6B,EAAWV,EAAS/7B,GAEhDgE,EAAc,CAACjB,EAAM7G,MAAM,GAAI6G,EAAM7G,MAAM,IAEjD,GAAI6/B,EAAS,CACX,IAAM2D,EACF1/B,EAAWsC,eAAe0B,EAAa,UAAWhD,EAAOrD,MACvDgiC,EACF3/B,EAAWsC,eAAe0B,EAAa,UAAWhD,EAAOnD,MAEvD+hC,EAAuB5/B,EAAWsC,eACpC,GAAI,UACJlH,OAAKsR,kBAAkB+vB,EAA8B,YACnDoD,EACFl9B,EAAS,CAACT,OAAQ,CAACnC,EAAG6/B,GAAW3/B,QAASD,IAExC8/B,EACFjE,GAAch8B,WACV,CAACqC,OAAQ,CAACsC,EAAGk7B,EAAUj7B,EAAGm7B,GAAW3/B,QAASD,IAEhD+/B,EACFlE,GAAch8B,WACV,CAACqC,OAAQ,CAACsC,EAAGm7B,EAAUl7B,EAAGo7B,GAAe5/B,QAASD,IAGpDggC,EACFhgC,EAAWrE,KAAKW,IAAIwjC,EAAYrjC,QAAQR,OACtCgkC,EACFjgC,EAAWrE,KAAKW,IAAIyjC,EAAYtjC,QAAQR,OAS5C,OAPA+D,EAAWuD,8BAA8Bm8B,GACzC1/B,EAAWuD,8BAA8Bo8B,GACzC3/B,EAAWuD,8BAA8Bq8B,GACzC5/B,EAAWuD,8BAA8Bs8B,GACzC7/B,EAAWuD,8BAA8Bu8B,GACzC9/B,EAAWuD,8BAA8Bw8B,GAElC,CAACpiC,KAAMqiC,EAAaniC,KAAMoiC,GAGnC,OAAOj/B,EAEP,IASmB4F,EAPbs5B,EAiKV,SACIvkC,EAAkBiL,EAAcm1B,GAGlC,IAFA,IAAMoE,EAAM,IAAI9gC,aAAoB,EAAPuH,GAEpB2jB,EAAI,EAAGA,EAAI3jB,EAAM2jB,IAAK,CAG7B,IAFA,IAAI6V,EAAO,EACPC,EAAO,EACFxN,EAAI,EAAGA,EAAIjsB,EAAMisB,IAAK,CAC7B,IAAM6L,EAAIniC,eAAa+jC,SAAS/V,EAAIsI,EAAGjsB,EAAMm1B,GACvCwE,EAAOhkC,eAAa8/B,oBAAoB1gC,EAAsBk3B,GACpEuN,GAAQG,EAAK5iC,KAAO+gC,EAAE/gC,KAAO4iC,EAAK1iC,KAAO6gC,EAAE7gC,KAC3CwiC,GAAQE,EAAK5iC,KAAO+gC,EAAE7gC,KAAO0iC,EAAK1iC,KAAO6gC,EAAE/gC,KAEzCo+B,IACFqE,GAAQx5B,EACRy5B,GAAQz5B,GAEVrK,eAAaikC,mBAAmBL,EAAKC,EAAMC,EAAM9V,GAEnD,OAAO4V,EAnLDM,CAHSlkC,eAAauB,uBAAuBqE,EAAUC,GAGxBq6B,EAAWV,GAE9C,OAAOx/B,eAAamkC,uBAAuBR,GC7GxC,IAAMS,GAA0B,CACrCjhC,WAAYkhC,MACZhhC,YAAa,MACbC,oBA/BkBC,GAEX,IAAAoC,WAAQjC,YACR8C,UAED05B,EAAYrhC,OAAK8E,cAAc6C,EAAM7G,OAGrC2kC,EAAqB99B,EAAM7G,MAAM6G,EAAM7G,MAAMY,OAAS,GAGtDgkC,EAAUnpB,GAAQ,CACtBzV,OAAQ,CAACnC,EAAGgD,GACZ9C,UACAmD,MAAO,CAAClH,MAAO,CALHugC,EAAYoE,EAKDA,MAGnB7/B,EAAS86B,GAASgF,GAAS,EAAO7gC,GAElC8gC,EACFppB,GAAQ,CAACzV,OAAQ,CAACnC,EAAGiB,GAASf,UAASmD,MAAO,CAAClH,MAAO6G,EAAM7G,SAKhE,OAHA+D,EAAQsD,8BAA8Bu9B,GACtC7gC,EAAQsD,8BAA8BvC,GAE/B+/B,aC3BOtvB,GAAK3R,GAEZ,IAAAG,YAASmD,UACTlH,UAAO6K,UAERrC,WAAkBtJ,OAAK4lC,WAAWj6B,GAClC9K,EAASb,OAAKwM,kBAAkBlD,EAAQtJ,OAAK8E,cAAchE,IAGjE,OASF,SACID,EAAoB8K,EAAsBzL,GAEzCW,EAAoBwV,KAAK1K,GAd5Bk6B,CAAWhlC,EAAQ8K,GAEZ9G,EAAQqC,eAAepG,EAAOwI,EAAQzI,GAGxC,IAAMilC,GAA2B,CACtCxhC,WAAYyhC,OACZvhC,YAAa,MACbC,WAAY4R,ICdP,IAAM2vB,GAAoC,CAC/C1hC,WAAY2hC,gBACZzhC,YAAa,MACbC,WAAY,SAACrC,GAUX,QAVY0E,WAAejC,sBACpBkxB,UACDnxB,EAAaC,EAEbqf,EAASlkB,OAAK6F,uBAChBkwB,EAAM71B,MAA0BF,OAAK8E,cAAcixB,EAAMj1B,QACvDqI,UAAC8P,OAAOod,OAAaC,OAAYC,OAEjCM,EAAYjyB,EAAWrE,KAAKW,IAAI60B,EAAM10B,QAAQR,OAE3C6N,EAAW,EAAGA,EAAWuK,EAAOvK,IAGvC,IAFA,IAAMw3B,EAAcx3B,EAAW4nB,EAAaD,EAAcE,EAEjDhpB,EAAM,EAAGA,EAAM8oB,EAAa9oB,IAGnC,IAFA,IAAM44B,EAAY54B,GAAO+oB,EAAaC,GAE7B9oB,EAAM,EAAGA,EAAM6oB,EAAY7oB,IAGlC,IAFA,IAAM24B,EAAY34B,EAAM8oB,EAEfxP,EAAU,EAAGA,EAAUwP,EAAaxP,IAAW,CACtD,IAEMpiB,EAFS,CAACsU,EAAO1L,EAAKE,EAAKsZ,GAEhB,GAEXsf,EAASliC,KAAKq0B,MAAMlC,EAAa3xB,GACjC2hC,EAASJ,EAAcC,EAAYC,EAAYrf,EAEjDwf,EAAc1P,EAAUyP,GAE5B,GAAID,GAAU,GAAKA,EAAS/P,EAK1BiQ,EAAc1P,EADVqP,EAAcC,EAFOE,EAAS9P,EAEexP,GAGnD7C,EAAOoiB,GAAUC,EAOzB,MAAO,CAACllC,OADOuD,EAAW5C,MAAMkiB,EAAQ6R,EAAMj1B,MAAOi1B,EAAM71B,OAC3CY,MAAOi1B,EAAMj1B,MAAOZ,MAAO61B,EAAM71B,SC9CxCsmC,GACTxhC,GAA6B,SAACoE,EAAWC,GAAc,OAAAlF,KAAKgK,MAAM/E,EAAIC,MAC7Do9B,GACT19B,EAAiB29B,WAAUF,GAAc,KAAwB,SAExDG,GAA+B,CAC1CriC,WAAYoiC,WACZliC,YAAa,MACbC,WAAYgiC,ICiCP,IAAMG,GAAkC,CAC7CtiC,WAAYuiC,cACZriC,YAAa,MACbC,oBA1C0BC,GAKnB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAGiqB,WAAQ7O,SAAM1D,2BAEtBhE,YACAmQ,QACAW,eACAyG,cACAnH,oBACArM,eACAE,mBAGE1W,EAAS+pB,GAAO,CAClB7oB,OAAQ,CAACnC,IAAGiqB,UACZ/pB,UACAmD,MAAO,CAACqQ,UAASmQ,MAAKW,aAAYyG,YAAWnH,qBAG/C,GAAI1I,EAAM,CACR,IAAM+mB,EAAYlhC,EAClBA,EAASqF,EAAI,CAACnE,OAAQ,CAACsC,EAAGxD,EAAQyD,EAAG0W,GAAOlb,YAC5CA,EAAQsD,8BAA8B2+B,GAGxC,GAAI1qB,EAAY,CACR0qB,EAAYlhC,EAClBA,EAASuW,GACLtX,EAASe,EAAQwW,EAAYC,EAAwBC,GACzDzX,EAAQsD,8BAA8B2+B,GAGxC,OAAOlhC,ICEF,IAAMmhC,GAA2C,CACtDziC,WAAY0iC,uBACZxiC,YAAa,MACbC,oBAzCmCC,GAK5B,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAGiqB,WAAQ7O,SAAM1D,2BAEtBhE,YACAmQ,QACAW,eACAyG,cACAnH,oBACArM,eACAE,mBAGE1W,EAAS60B,GAAsB,CACjC3zB,OAAQ,CAACnC,IAAGiqB,UACZ/pB,UACAmD,MAAO,CAACqQ,UAASmQ,MAAKW,aAAYyG,YAAWnH,qBAG/C,GAAI1I,EAAM,CACR,IAAMqd,EAAYx3B,EAClBA,EAASqF,EAAI,CAACnE,OAAQ,CAACsC,EAAGxD,EAAQyD,EAAG0W,GAAOlb,YAC5CA,EAAQsD,8BAA8Bi1B,GAExC,GAAIhhB,EAAY,CACRghB,EAAYx3B,EAClBA,EAASuW,GACLtX,EAASe,EAAQwW,EAAYC,EAAwBC,GACzDzX,EAAQsD,8BAA8Bi1B,GAGxC,OAAOx3B,ICIF,IAAMqhC,GAA+B,CAC1C3iC,WAAY4iC,WACZ1iC,YAAa,MACbC,oBA5CEC,GACK,IAAAoC,WAAQjC,YACRsiC,WAAQ9xB,YAET+xB,EAAapnC,OAAK8E,cAAcqiC,EAAOrmC,OAEvCwU,EAAeD,EAAQvU,MACvBumC,EAAY/xB,EAAaA,EAAa5T,OAAS,GAE/CU,yCAACwG,OAAa0+B,OAAWna,OAAW9U,OAE1C,GAAkB,IAAdivB,EACF,OAAOziC,EAAQqC,eAAe0B,EAAau+B,EAAOjnC,MAAO,IAO3D,IAJA,IAAMgM,EAASpJ,SAAO,CAACwkC,EAAWna,GAAYga,EAAOjnC,OAC/CqnC,EAAc1iC,EAAQtE,KAAKW,IAAImU,EAAQhU,QAAQR,OAC/C2mC,EAAa3iC,EAAQtE,KAAKW,IAAIimC,EAAO9lC,QAAQR,OAE1CqD,EAAI,EAAGA,EAAIojC,EAAWpjC,IAAK,CAGlC,IAFA,IAAMmV,EAAQ,GACVouB,EAAe,EACVt7B,EAAI,EAAGA,EAAIk7B,EAAWl7B,IAAK,CAClC,IAAM+zB,EAAMqH,EAAYrjC,EAAImjC,EAAYl7B,GACxCs7B,GAAgBvH,EAAM7nB,EAAQlM,GAC9BkN,EAAM7F,KAAK0sB,GAEb,GAAIuH,EAAe,GAAKA,GAAgBL,EAAaja,EACnD,MAAM,IAAItqB,MACN,oBAAoBwW,0BAA6B8tB,EAAOrmC,OAG9D,IAAK,IAAIgY,EAAI,EAAGA,EAAIqU,EAAWrU,IAC7B5M,EAAOrL,OAAOqD,EAAIipB,EAAYrU,GAC1B0uB,EAAWC,EAAeta,EAAYrU,GAI9C,OAAOjU,EAAQqC,eAAe0B,EAAasD,EAAOhM,MAAOgM,EAAOrL,UCoB3D,IAAM6mC,GAA+B,CAC1CpjC,WAAYqjC,WACZnjC,YAAa,MACbC,oBA3DuBC,GAKhB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAG0Q,YACHrC,SAAM40B,cAEbnoC,EAAiB,CAACkF,EAAG0Q,GAAU,YAE/B,IAAIwyB,EAAaD,EAEA,MAAbA,IACFC,EAAa,GAGf,IAAMC,EAAc9nC,OAAK8E,cAAcuQ,EAAQvU,OAEzCinC,EAAa/nC,OAAKmT,eAAeH,EAAMrO,EAAE7D,OAAO,GAChDknC,EAAY7mC,eAAa8mC,aAAaC,yBACxCvjC,EAAG0Q,EAAS0yB,EAAYF,GAEtBM,EAAW5rB,GAAQ,CACvBzV,OAAQ,CAACnC,KACTE,UACAmD,MAAO,CACLlH,MAAO,CACLknC,EAAUzjB,UAAWyjB,EAAUI,UAAWJ,EAAUK,QACpDL,EAAU7a,cAKVsa,EAAelrB,GAAQ,CAC3BzV,OAAQ,CAACnC,EAAG0Q,GACZxQ,UACAmD,MAAO,CAAClH,MAAO,CAACknC,EAAUzjB,UAAWujB,EAAcE,EAAUzjB,cAGzD/V,EAAqB,CACzBw5B,EAAUzjB,UAAWyjB,EAAUI,UAAWN,EAAcE,EAAUzjB,UAClEyjB,EAAU7a,WAGN5e,EAAa1J,EAAQ+kB,WAAW6d,GAEhCv7B,EAASoC,EADFzJ,EAAQ+kB,WAAWue,GACE55B,EAAYC,GAK9C,OAHA3J,EAAQsD,8BAA8BggC,GACtCtjC,EAAQsD,8BAA8Bs/B,GAE/B5iC,EAAQqC,eACX8gC,EAAU3wB,YAAanL,EAAOhM,MAAOgM,EAAOrL,UCvDrCynC,GACTtjC,GAA6B,SAACoE,EAAWC,GAAc,OAACD,GAAKC,EAAK,EAAI,KAC7Dk/B,GAAex/B,EACxBy/B,eAAcF,GAAkB,KAAwB,QAE/CG,GAAmC,CAC9CnkC,WAAYkkC,eACZhkC,YAAa,MACbC,WAAY8jC,ICqBP,IAAMG,GAA2B,CACtCpkC,WAAYqkC,OACZnkC,YAAa,MACbC,oBA/BmBC,GAEZ,IAAAoC,WAAQjC,YACR8C,UAED05B,EAAYrhC,OAAK8E,cAAc6C,EAAM7G,OAGrC2kC,EAAqB99B,EAAM7G,MAAM6G,EAAM7G,MAAMY,OAAS,GAGtDgkC,EAAUnpB,GAAQ,CACtBzV,OAAQ,CAACnC,EAAGgD,GACZ9C,UACAmD,MAAO,CAAClH,MAAO,CALHugC,EAAYoE,EAKDA,MAGnB7/B,EAAS86B,GAASgF,GAAS,EAAM7gC,GAEjC8gC,EACFppB,GAAQ,CAACzV,OAAQ,CAACnC,EAAGiB,GAASf,UAASmD,MAAO,CAAClH,MAAO6G,EAAM7G,SAKhE,OAHA+D,EAAQsD,8BAA8Bu9B,GACtC7gC,EAAQsD,8BAA8BvC,GAE/B+/B,IC3BIiD,GACTt8B,EAAgBu8B,YAAU,SAACj8B,GAAO,OAAAmX,OAAO6kB,SAASh8B,GAAM,EAAI,IAAG,QAEtDk8B,GAA+B,CAC1CxkC,WAAYukC,WACZrkC,YAAa,MACbC,WAAYmkC,ICNDG,GACTz8B,EAAgB08B,SAAO,SAACp8B,GAAO,OAAAzI,KAAKC,IAAIwI,KAAQq8B,EAAAA,EAAW,EAAI,IAAG,QAEzDC,GAA4B,CACvC5kC,WAAY0kC,QACZxkC,YAAa,MACbC,WAAYskC,ICNDhjB,GACTzZ,EAAgB68B,SAAO,SAACv8B,GAAO,OAAAmX,OAAOgC,MAAMnZ,GAAM,EAAI,IAAG,QAEhDw8B,GAA4B,CACvC9kC,WAAY6kC,QACZ3kC,YAAa,MACbC,WAAYshB,ICLDsjB,GACTrkC,GAA6B,SAACoE,EAAWC,GAAc,OAACD,GAAKC,EAAK,EAAI,KAC7DigC,GACTvgC,EAAiBwgC,YAAWF,GAAe,KAAwB,QAE1DG,GAAgC,CAC3CllC,WAAYilC,YACZ/kC,YAAa,MACbC,WAAY6kC,ICEP,IAAMG,GAA+B,CAC1CnlC,WAAYolC,WACZllC,YAAa,MACbC,oBAbuBC,GAEhB,IAAAG,YAASmD,UAGV0D,EAAU4D,wBAEhB,OAAOzK,EAAQqC,eAAe,CAACwE,EAAQhK,QAAS,UAAWgK,KCRhDi+B,GAAQr9B,EAAgBs9B,SAAO,SAACh9B,GAAO,OAAAzI,KAAKwlC,MAAM/8B,MAElDi9B,GAA4B,CACvCvlC,WAAYslC,QACZplC,YAAa,MACbC,WAAYklC,ICJDG,GACT9kC,GAA6B,SAACoE,EAAWC,GAAc,OAAAD,GAAKC,KACnD0gC,GAAahhC,EACtBihC,aAAYF,GAAgB,KAAwB,QAE3CG,GAAiC,CAC5C3lC,WAAY0lC,aACZxlC,YAAa,MACbC,WAAYslC,ICTDG,GACT59B,EAAgB69B,cAAY,SAACv9B,GAAO,OAAAA,EAAK,EAAI,IAAG,QAEvCw9B,GAAiC,CAC5C9lC,WAAY6lC,aACZ3lC,YAAa,MACbC,WAAYylC,ICLDG,GACTrlC,GAA6B,SAACoE,EAAWC,GAAc,OAAAD,GAAKC,KACnDihC,GACTvhC,EAAiBwhC,YAAWF,GAAe,KAAwB,QAE1DG,GAAgC,CAC3ClmC,WAAYimC,YACZ/lC,YAAa,MACbC,WAAY6lC,IC+BP,IAAMG,GAA0B,CACrCnmC,WAAYomC,MACZlmC,YAAa,MACbC,oBAzCEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAgmC,gBAAa5qB,SAAM7E,UAAO0vB,SAEjCnrC,EAAiBkF,EAAG,OAEpB,IAAMkmC,EAAWlmC,EAAE7D,MAAM,GACnBgqC,EAAOD,EAAW,EAClB7nB,EAAUne,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACrC2K,EAAOxL,OAAK8E,cAAcH,EAAE7D,OAC5B8E,EAAS,IAAI3B,aAAauH,GAEhC,SAASu/B,EAAkB/6B,GAQzB,IAPA,IAAMg7B,EAAiBh7B,EAAS66B,EAC5BI,EACAj7B,EAASg7B,EAAiB7mC,KAAK8L,IAAI,EAAG+6B,EAAiBL,GACrDO,EACFl7B,EAASg7B,EAAiB7mC,KAAKsM,IAAIu6B,EAAiBL,EAAaG,GAEjEzrB,EAAM,EACH4rB,GAAkBC,EAAcD,IAAkB,CACvD,IAAME,EAAInoB,EAAQioB,GAClB5rB,GAAO8rB,EAAIA,EAEb,OAAO9rB,EAGT,IAAK,IAAIrP,EAAS,EAAGA,EAASxE,EAAMwE,IAAU,CAC5C,IAAMqP,EAAM0rB,EAAkB/6B,GACxBqsB,EAAMrZ,EAAQhT,GAAU7L,KAAKinC,IAAIrrB,EAAO7E,EAAQmE,GAAMurB,GAC5DhlC,EAAOoK,GAAUqsB,EAGnB,OAAOx3B,EAAQqC,eAAevC,EAAE7D,MAAO6D,EAAEzE,MAAO0F,KCS3C,IAAMylC,GAA8B,CACzC/mC,WAAYgnC,UACZ9mC,YAAa,MACbC,oBA/CEC,GAGK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAGsrB,MAAG1G,OACNohB,gBAAa5qB,SAAM7E,UAAO0vB,SAEjCnrC,EAAiB8pB,EAAI,WAWrB,IATA,IAAMgiB,EAASvrC,OAAK8E,cAAcykB,EAAGzoB,OAE/B+pC,EAAWthB,EAAGzoB,MAAM,GACpB4xB,EAAW7tB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACvCmiB,EAAUne,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACrC2qC,EAAU3mC,EAAQtE,KAAKW,IAAI+uB,EAAE5uB,QAAQR,OACrC+E,EAAS,IAAI3B,aAAasnC,GAC1B//B,EAAO+/B,EAEJv7B,EAAS,EAAGA,EAASxE,EAAMwE,IAAU,CAQ5C,IAPA,IAAMg7B,EAAiBh7B,EAAS66B,EAC1BY,EACDz7B,EAASg7B,EAAkB7mC,KAAK8L,IAAI,EAAG+6B,EAAiBL,GACvDe,EAAY17B,EAASg7B,EACvB7mC,KAAKsM,IAAIo6B,EAAUG,EAAiBL,EAAc,GAElDgB,EAAO,EACF7yB,EAAI2yB,EAAY3yB,EAAI4yB,EAAU5yB,IACrC6yB,GAAQxnC,KAAKinC,IAAIpoB,EAAQlK,GAAI,GAE/B6yB,EAAOzwB,EAAQywB,EAAO5rB,EAEtB,IAASjH,EAAI2yB,EAAY3yB,EAAI4yB,EAAU5yB,IAAK,CAC1C,IAAI8yB,GAAO,EAAI1wB,EAAQ0vB,EAAO5nB,EAAQlK,GAAK0yB,EAAQx7B,GAAU27B,EACzD37B,IAAW8I,IACb8yB,GAAOznC,KAAKinC,IAAIO,GAAOf,IAEzBgB,GAAOlZ,EAAS1iB,GAChBpK,EAAOkT,IAAM8yB,GAIjB,OAAO/mC,EAAQqC,eAAeqiB,EAAGzoB,MAAO6D,EAAEzE,MAAO0F,cCrCnCqK,GACZvL,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAknC,qBAAkB54B,aACnBrO,EAAaC,EACfsM,EAASxM,EAAE7D,MACTkR,EAAQb,EAAOzP,OAEfqf,EAAW/gB,OAAKmT,eAAe04B,EAAkB16B,GACnD+B,EAAO6N,EACLC,EAAe7f,eAAakS,mBAAmBH,EAAMlB,GACvDxJ,EAAQ5D,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,OAC1C,GAAoB,MAAhBmgB,EAAsB,CAExB,IADA,IAAM1b,EAAqB,IAAI1F,MAAMoS,GAC5B9N,EAAI,EAAGA,EAAIoB,EAAS5D,OAAQwC,IACnCoB,EAASpB,GAAKiN,EAAO6P,EAAa9c,IAGpCsE,EAAQsJ,GAActJ,EAAO2I,EAAQxM,EAAEzE,MAAO8gB,EAAc1b,GAC5D4N,EAAO/R,eAAasS,iBAAiBP,EAAKxR,OAAQsQ,GAElDb,EAAS7L,EAGX7F,EAAiBkF,EAAG,OACpBxD,eAAa+f,2BAA2B,MAAOhO,EAAMlB,GAC/C,IAAA5P,gDAAC0pC,OAAap5B,OAKd9M,EAASkK,GAAQtH,EAFJxI,OAAK8E,cAAc4N,GAEIo5B,EAAannC,EAAEzE,OACnDmB,EAASuD,EAAW5C,MAAM4D,EAAQkmC,EAAannC,EAAEzE,OAEnD+M,EAAW6+B,EACX74B,IAGFhG,EADM3H,EAAWnE,eAAauS,qBAAqBo4B,EAAa/qB,IAIlE,MAAO,CAAC1f,SAAQP,MAAOmM,EAAU/M,MAAOyE,EAAEzE,OAGrC,IAAM6rC,GAA0B,CACrCznC,WAAY0nC,MACZxnC,YAAa,MACbC,WAAYwL,ICpBP,IAAMg8B,GAA8B,CACzC3nC,WAAY4nC,UACZ1nC,YAAa,MACbC,oBAnCEC,GAGK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACPlF,EAAiBkF,EAAG,WACb,IAAA4jB,eAAYlQ,YAASmQ,QAAKC,oBAGjCzoB,OAAKC,OACDkB,eAAaunB,+BAA+BrQ,EAH9B,IAId,WAAM,MAAA,wEACaA,0BAEvB,IAGI5G,EAHEwR,EAAW9hB,eAAawnB,kBAC1BhkB,EAAE7D,MAA2CynB,EAAYlQ,EAR3C,EASHmQ,EAAKC,GAGpB,GAA6B,IAAzBxF,EAAS2F,aAA+C,IAA1B3F,EAAS4F,cACvC7oB,OAAK8oB,YAAY7F,EAAS8F,QAAS9F,EAAShW,UAC9CwE,EAAMlK,EAAS,CAACT,OAAQ,CAACnC,KAAIE,gBACxB,CACL,IAAMme,EAAUne,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACrCmoB,EAAUhpB,OAAK0F,eAAef,EAAE7D,OAChCgC,EAASigB,GAAKC,EAASre,EAAE7D,MAAO6D,EAAEzE,MAAO8oB,EAAS/F,EAAU,OAClExR,EAAM5M,EAAQqC,eACV+b,EAAShW,SAAUtI,EAAEzE,MAAO4C,EAAOjC,QAEzC,OAAO4Q,ICRF,IAAM06B,GAAgC,CAC3C7nC,WAAY8nC,YACZ5nC,YAAa,MACbC,oBAzBwBC,GAKjB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACA4jB,eAAYlQ,YAASmQ,QAAKC,oBAAiBU,eAElD1pB,EAAiBkF,EAAG,aAEpB,IAAMse,EAAW9hB,eAAaioB,kBAC1BzkB,EAAE7D,MAAmDynB,EAAYlQ,EACjE,EAAmBmQ,EAAKC,EAAiBU,GAGvCjd,EAASsa,GADC3hB,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OAE9B8D,EAAE7D,MAAO6D,EAAEzE,MAAOF,OAAK0F,eAAef,EAAE7D,OAAQmiB,EAAU,OAEvE,OAAOpe,EAAQqC,eAAegF,EAAOpL,MAAO,UAAWoL,EAAOrL,UC4EzD,IAAMwrC,GAAoC,CAC/C/nC,WAAYgoC,gBACZ9nC,YAAa,MACbC,oBAlG4BC,GAKrB,IAAAoC,WAAQjC,YAASmD,UACjBuhB,OAAI5hB,UACJ4gB,eAAYlQ,YAASmQ,QAAKC,oBAEjChpB,EAAiB,CAAC8pB,EAAI5hB,GAAQ,iBAwB9B,IAtBA,IAAMsb,EAAW9hB,eAAaioB,kBAC1BzhB,EAAM7G,MAAmDynB,EACzDlQ,EAAS,EAAmBmQ,EAAKC,GAG/B8jB,W/D4NJ1gC,EACAoX,GAeF,IAdA,IAAMkD,EAAerjB,SAAOmgB,EAAShW,SAAU,SACzCwZ,EAAcxD,EAASwD,YACvBtD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBsD,EAAgBzD,EAASyD,cACzBrD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBqD,EAAuB1D,EAAS0D,qBAChCpD,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCoD,EAAW3D,EAASS,QAAQmD,MAC5BpD,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQG,KAExB5K,EAAQ,EAAGA,EAAQgK,EAASsB,YAAatL,EAChD,IAAK,IAAI8N,EAAU,EAAGA,EAAU9D,EAASyB,aAAcqC,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS/D,EAASgE,WAAYD,EAAQ,CAGzD,IAFA,IAAME,EAAeF,EAASP,EAAcG,EACxCO,EAAYD,EACTC,EAAY,GACjBA,GAAaT,EAIf,IAFA,IAAMU,EACFjjB,KAAKsM,IAAIwS,EAASoE,QAASV,EAAuBO,GAC7CK,EAAO,EAAGA,EAAOtE,EAAS2B,YAAa2C,EAAM,CAGpD,IAFA,IAAMC,EAAaD,EAAOpE,EAAeM,EACrCgE,EAAUD,EACPC,EAAU,GACfA,GAAWpE,EAIb,IAFA,IAAMqE,EACFvjB,KAAKsM,IAAIwS,EAAS+B,SAAUzB,EAAwBiE,GAC/CG,EAAO,EAAGA,EAAO1E,EAASkC,WAAYwC,EAAM,CAGnD,IAFA,IAAMC,EAAaD,EAAOvE,EAAcQ,EACpCiE,EAAUD,EACPC,EAAU,GACfA,GAAWvE,EASb,IAPA,IAAMwE,EACF3jB,KAAKsM,IAAIwS,EAASsC,QAAS/B,EAAuBoE,GAGlDxB,EAAWrC,OAAOC,kBAClBqC,GAAe,EAEV2B,EAASb,EAAWa,EAASZ,EACjCY,GAAUtB,EAEb,IADA,IAAM0D,EAASpC,EAASd,EACfgB,EAAOT,EAASS,EAAOR,EAASQ,GAAQ7E,EAE/C,IADA,IAAMiH,EAAOpC,EAAOV,EACXY,EAAOP,EAASO,EAAON,EAC3BM,GAAQ9E,EAAe,CAC1B,IAAMkH,EAAOpC,EAAOR,EACd9B,EAAQja,EAAK3K,IAAI+X,EAAO+O,EAAQE,EAAME,EAAMrB,GAC9CjB,GAASM,IACXA,EAAWN,EACXO,EACI+D,EAAS7G,EAAwBC,EACjC8G,EAAO/G,EAAwBiH,GAM3CrE,EAAa5kB,IAAI8kB,EAAapN,EAAO+N,EAAQO,EAAMI,EAAMZ,KAOnE,OAAOZ,E+DrSWqmB,CADD3nC,EAAQ+kB,WAAWjiB,GACWsb,GACzCwD,EAAcxD,EAASwD,YACvBtD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBsD,EAAgBzD,EAASyD,cACzBrD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBqD,EAAuB1D,EAAS0D,qBAChCpD,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCoD,EAAWD,EAAuB,EAAI1D,EAASS,QAAQmD,MACvDjD,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD8F,EAAK3mB,SAAO6E,EAAM7G,MAAO,WAEzB6oB,EAAQ9kB,EAAQ+kB,WAAWL,GAExBtQ,EAAQ,EAAGA,EAAQgK,EAASsB,YAAatL,EAChD,IAAK,IAAI8N,EAAU,EAAGA,EAAU9D,EAASyB,aAAcqC,EACrD,IAAK,IAAI8C,EAAU,EAAGA,EAAU5G,EAASoE,UAAWwC,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQ7G,EAAS+B,WAAY8E,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ9G,EAASsC,UAAWwE,EAAO,CAMrD,IAJA,IAAMC,EAAgBH,EAAUjD,EAC1BqD,EAAcH,EAAQrG,EACtByG,EAAcH,EAAQnG,EACxBuG,EAAU,EACLC,EAAS,EAAGA,EAASzD,EACzByD,GAAU1D,EAAe,CAC5B,IAAM2D,GAAWL,EAAgBI,GAAU3D,EAC3C,KAAI4D,EAAU,GAAKA,GAAWpH,EAASgE,UACnC9iB,KAAKgK,MAAMkc,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAO/G,EACrB+G,GAAQjH,EAAgB,CAC3B,IAAMkH,GAASN,EAAcK,GAAQnH,EACrC,KAAIoH,EAAQ,GAAKA,GAAStH,EAAS2B,WAC/BzgB,KAAKgK,MAAMoc,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAOhH,EACrBgH,GAAQlH,EAAe,CAC1B,IAAMmH,GAASP,EAAcM,GAAQpH,EACrC,KAAIqH,EAAQ,GAAKA,GAASxH,EAASkC,UAC/BhhB,KAAKgK,MAAMsc,KAAWA,GAD1B,CAKA,IASMgiB,EATS9lB,EAAuBpD,EAC9BC,EACJ,EACC+oB,EAAUrrC,IAAI+X,EAAOoR,EAASE,EAAOE,EAAO1D,KAG7CqD,EAAS7G,EAAwBC,EACjC8G,EAAO9G,EAAuBgH,EAED,EAAI,EACrC,GAAa,IAATiiB,EAMJtiB,GADIR,EAAMzoB,IAAI+X,EAAOoR,EAASE,EAAOE,EAAO1D,GACzB0lB,KAIzBhjB,EAAGloB,IAAI4oB,EAASlR,EAAO4Q,EAASC,EAAOC,EAAOhD,GAOxD,OAAOliB,EAAQqC,eAAeuiB,EAAG3oB,MAAO2oB,EAAGvpB,MAAOupB,EAAG5oB,UCnBhD,IAAM6rC,GAAkC,CAC7CpoC,WAAYqoC,cACZnoC,YAAa,MACbC,oBA7E0BC,GAKnB,IAAAoC,WAAQjC,YAASmD,UACjBuhB,OAAI5hB,UACLhD,EAAIgD,EACVlI,EAAiB,CAACkI,YAAgB,eAyBlC,IAxBO,IAAA4gB,eAAYlQ,YAASmQ,QAAKC,oBAE3BxF,EAAW9hB,eAAawnB,kBAC1BhkB,EAAE7D,MAA2CynB,EAAYlQ,EACzD,EAAmBmQ,EAAKC,GACtBzF,EAAUne,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACrC0rC,EAAYzpC,SACdmgB,EAAShW,SAAUtI,EAAEzE,MACrB8lB,GAAiBhD,EAASre,EAAE7D,MAAO6D,EAAEzE,MAAO+iB,GAAUpiB,QACpDsiB,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQG,KACtDJ,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtD8F,EACF3mB,SAAgB6B,EAAE7D,MAA2C,WAE3D8pB,EAAS/lB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACrC8oB,EAAQ7mB,SACVymB,EAAGzoB,MAA2C,UAAW8pB,GAEpDvhB,EAAI,EAAGA,EAAI4Z,EAASsB,YAAalb,EACxC,IAAK,IAAIvH,EAAI,EAAGA,EAAImhB,EAASyB,aAAc5iB,EACzC,IAAK,IAAI+oB,EAAM,EAAGA,EAAM5H,EAAS+B,WAAY6F,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAM7H,EAASsC,UAAWuF,EAAK,CAK/C,IAHA,IAAMC,EAAYF,EAAMpH,EAClBuH,EAAYF,EAAMlH,EACpBuG,EAAU,EACL7D,EAAK,EAAGA,EAAK/C,EAAuB+C,GAAMjD,EAAgB,CACjE,IAAM4H,GAAOF,EAAYzE,GAAMnD,EAC/B,KAAI8H,EAAM,GAAKA,GAAOhI,EAAS2B,WAC3BzgB,KAAKgK,MAAM8c,KAASA,GAGxB,IAAK,IAAI1E,EAAK,EAAGA,EAAK/C,EAAsB+C,GAAMjD,EAAe,CAC/D,IAAM4H,GAAOF,EAAYzE,GAAMnD,EAC/B,KAAI8H,EAAM,GAAKA,GAAOjI,EAASkC,UAC3BhhB,KAAKgK,MAAM+c,KAASA,GADxB,CAIA,IAIMuhB,EAJSlpB,EAAwBC,EAAuB,EACzD+oB,EAAUrrC,IAAImI,EAAG4hB,EAAKC,EAAKppB,KACjBwkB,EAAK9C,EAAuB+C,EAEV,EAAI,EACrC,GAAa,IAATkmB,EAKJtiB,GADcR,EAAMzoB,IAAImI,EAAG4hB,EAAKC,EAAKppB,GAClB2qC,IAGvBhjB,EAAGloB,IAAI4oB,EAAS9gB,EAAGwhB,EAAKC,EAAKhpB,GAKrC,OAAO+C,EAAQqC,eAAeuiB,EAAG3oB,MAAO2oB,EAAGvpB,MAAOupB,EAAG5oB,UCrEhD,IAAM+rC,GAAwC,CACnDtoC,WAAYuoC,oBACZroC,YAAa,MACbC,WAAY,SAACrC,OAAC0E,WAAQkB,UAAOnD,YACpBF,MACDwE,IAACof,eAAYlQ,YAASmQ,QAAKtC,wBAE3BthB,EAAaC,EACnBpF,EAAiBkF,EAAG,qBAEpB,IAAM9D,EAAS+D,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACvCoiB,EAAW9hB,eAAawnB,kBAC1BhkB,EAAE7D,MAA2CynB,EAAYlQ,EACzD,CAAC,EAAG,GAAImQ,GACNjf,WClBNyZ,EAAqB7R,EAAkBjR,EACvCgmB,EAA8BjD,GAChC,IACM6pB,EAAW/pB,GAAKC,EAAS7R,EAAQjR,EADvBF,OAAK0F,eAAeyL,GACmB8R,EAAU,OAC3DkD,EAAeH,GACjBhD,EAAS7R,EAAQjR,EAAO+iB,GAAU,EAAMiD,GAE5C,MAAO,CAAC4mB,EAASjsC,OAAQslB,EAAatlB,gCDW7BksC,OAAQC,OAGTC,EACFroC,EAAW5C,MAAM+qC,EAAwB9pB,EAAShW,SAAUtI,EAAEzE,OAC5DgtC,EACFtoC,EAAW5C,MAAMgrC,EAAuB/pB,EAAShW,SAAUtI,EAAEzE,OACjE,MAAO,CACL,CAACmB,OAAQ4rC,EAAcnsC,MAAOmiB,EAAShW,SAAU/M,MAAOyE,EAAEzE,OAC1D,CAACmB,OAAQ6rC,EAAepsC,MAAOmiB,EAAShW,SAAU/M,MAAO,YEOxD,IAAMitC,GAA2B,CACtC7oC,WAAY8oC,OACZ5oC,YAAa,MACbC,oBAhCEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAqO,SAAMC,aAEPC,EAAOlT,OAAKmT,eAAeH,EAAMrO,EAAE7D,OAEnC4R,EADSvR,eAAaksC,0BAA0B1oC,EAAE7D,MAAOoS,GACpC,GACrBnD,EAAa/P,OAAK8E,cAAc4N,GAChC46B,EAAY,GACZC,EACF1oC,EAAQqC,eAAe,GAAI,UAAW,IAAIjD,aAAa,CAAC8L,KAC5Du9B,EAAU95B,KAAK+5B,GAEf,IAAMtsB,EAAKlZ,EAAK,CAACjB,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC9H,MAAO,aACtDotC,EAAU95B,KAAKyN,GAEf,IAAMxP,EACF8uB,GAAI,CAACz5B,OAAQ,CAACsC,EAAG6X,EAAI5X,EAAGkkC,GAAmB1oC,YAC/CyoC,EAAU95B,KAAK/B,GAEf,IAAM7L,EAASyZ,GAAI,CAACvY,OAAQ,CAACnC,EAAG8M,GAAM5M,UAASmD,MAAO,CAACgL,OAAMC,cAI7D,OAFAq6B,EAAUxtC,SAAQ,SAAAC,GAAK,OAAA8E,EAAQsD,8BAA8BpI,MAEtD6F,IC6BF,IAAM4nC,GAA0B,CACrClpC,WAAYmpC,MACZjpC,YAAa,MACbC,oBA1DEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAqO,SAAMC,aAEbxT,EAAiBkF,EAAG,OAEpB,IAAMoc,EAAW/gB,OAAKmT,eAAeH,EAAMrO,EAAE7D,OACzCoS,EAAO6N,EACLC,EAAe7f,eAAakS,mBAAmBH,EAAMvO,EAAE7D,MAAMY,QAC/Duf,EAAKtc,EACW,MAAhBqc,IACFC,EAAK5O,GAAU,CAACvL,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAC+J,KAAMiP,KACpD9N,EAAO/R,eAAasS,iBAAiBP,EAAKxR,OAAQiD,EAAE7D,MAAMY,SAG5DP,eAAa+f,2BAA2B,MAAOhO,EAAM+N,EAAGngB,MAAMY,QAO9D,IANM,IAAAU,sDAAC6K,OAAUyF,OAEX3C,EAAa/P,OAAK8E,cAAc4N,GAChC3O,EAAO/D,OAAKsH,oBAAoBtH,OAAK8E,cAAcmI,GAAWgU,EAAG/gB,OAEjEkF,EAAQP,EAAQtE,KAAKW,IAAI+f,EAAG5f,QAAQR,OACjCqD,EAAI,EAAGA,EAAIH,EAAKrC,SAAUwC,EAAG,CAGpC,IAFA,IAAM8L,EAAS9L,EAAI6L,EACf29B,EAAMtoC,EAAM4K,GACP7D,EAAI,EAAGA,EAAI4D,IAAc5D,EAAG,CACnC,IAAMR,EAAQvG,EAAM4K,EAAS7D,GACzBR,EAAQ+hC,IACVA,EAAM/hC,GAGV5H,EAAKG,GAAKwpC,EAGQ,MAAhB1sB,GACFnc,EAAQsD,8BAA8B8Y,GAGxC,IAAMrb,EAASf,EAAQqC,eAAe+F,EAAUgU,EAAG/gB,MAAO6D,GAE1D,GAAIkP,EAAU,CACZ,IACMmO,EACF7E,GAAQ,CAACzV,OAAQ,CAACnC,EAAGiB,GAASf,UAASmD,MAAO,CAAClH,MAF7BK,eAAauS,qBAAqBzG,EAAU8T,MAMlE,OAFAlc,EAAQsD,8BAA8BvC,GAE/Bwb,EAGT,OAAOxb,ICNF,IAAM+nC,GAAgC,CAC3CrpC,WAAYspC,YACZppC,YAAa,MACbC,oBApDwBC,GAKjB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAkpC,aAAUC,SAEjBruC,EAAiBkF,EAAG,aAmBpB,IAjBA,IAAMsI,EAAW4gC,EAAShsC,KACtB,SAACo9B,EAAG/6B,GAAM,OAAA+6B,EAAE,GAAqBt6B,EAAE7D,MAAMoD,GAAK+6B,EAAE,MAE9C57B,EAAQwqC,EAAShsC,KAAI,SAAAo9B,GAAK,OAAAA,EAAE,MAC5B8O,EAAMF,EAAShsC,KAAI,SAACo9B,EAAG/6B,GAAM,OAAA+6B,EAAE,GAAKt6B,EAAE7D,MAAMoD,MAC5C8L,EAAkB,YAAT89B,EAAqB,EAAI,EAElCtlC,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnCmR,EAAQrN,EAAE7D,MAAMY,OAChBuQ,EAAWjS,OAAK0F,eAAef,EAAE7D,OAEjC6E,EAAa3F,OAAK8E,cAAcmI,GAChCzH,EAAayH,EAASvL,OACtB+D,EAAgBzF,OAAK0F,eAAeuH,GACpC2R,EACF5e,OAAK6F,uBAAuBlB,EAAEzE,MAA0ByF,GAEnDzB,EAAI,EAAGA,EAAIyB,EAAYzB,IAAK,CAEnC,IADA,IAAI8pC,EAAShuC,OAAKsG,WAAWpC,EAAGsB,EAAYC,GACnC2M,EAAI,EAAGA,EAAI5M,EAAY4M,IAC1B47B,EAAO57B,GAAK/O,EAAM+O,GACpB47B,EAAO57B,GAAgB,EAAX/O,EAAM+O,GAAS47B,EAAO57B,GAAKpC,EAC9Bg+B,EAAO57B,IAAM27B,EAAI37B,KAC1B47B,EAAO57B,GAAoB,GAAd27B,EAAI37B,GAAK,GAAS47B,EAAO57B,GAAKpC,GAG/Cg+B,EAASA,EAAOnsC,KAAI,SAAC41B,EAAGvzB,GAAM,OAAAuzB,EAAIp0B,EAAMa,MAExC,IAAM+pC,EAAUjuC,OAAK0G,WAAWsnC,EAAQh8B,EAAOC,GAE/C2M,EAAQ1a,GAAKsE,EAAMylC,GAKrB,MAAO,CAAC5sC,OAFMwD,EAAQ7C,MAAM4c,EAAS3R,EAAUtI,EAAEzE,OAE1BY,MAAOmM,EAAU/M,MAAOyE,EAAEzE,SC9CtCguC,GAAUlpC,YAA+BmL,EAAQC,GAC5D,IAAM+9B,EAAMh+B,EAASC,EACrB,OAAKD,EAAS,GAAKC,EAAS,GAAOD,GAAU,GAAKC,GAAU,EACnD+9B,GAECA,EAAM/9B,GAAUA,KAIfg+B,GAAMrlC,EAAiBslC,MAAKH,IAE5BI,GAA0B,CACrChqC,WAAY+pC,MACZ7pC,YAAa,MACbC,WAAY2pC,aCREG,GACZ7pC,GAGK,IAAAoC,WAAQjC,YAASmD,UACjBwmC,WACAtO,QAEDuO,EAAaD,EAAO1tC,MAAMY,OAE5By+B,EAAOD,EAIX,IAHc,IAAVC,IACFA,EAAOsO,EAAa,GAElBtO,IAASsO,EAAa,EACxB,MAAM5rC,MACF,4EACmB4rC,kBAA0BtO,GAGnD,IAAMjtB,EAAOlT,OAAKmT,eAAe,CAACgtB,GAAOqO,EAAO1tC,OAC1C4tC,EAAWz+B,GAAI,CACnBnJ,OAAQ,CAACnC,EAAG6pC,GACZ3pC,UACAmD,MAAO,CAAC6jC,iBAAkB34B,EAAMD,UAAU,KAEtC07B,EAAgBxtC,eAAauS,qBAAqBg7B,EAAS5tC,MAAOoS,GAElE07B,EACFryB,GAAQ,CAACzV,OAAQ,CAACnC,EAAG+pC,GAAW7pC,UAASmD,MAAO,CAAClH,MAAO6tC,KACtDvlC,EACFoP,GAAI,CAAC1R,OAAQ,CAACsC,EAAGolC,EAAQnlC,EAAGulC,GAAmB/pC,YAC7CwE,EAAIsE,EAAI,CAAC7G,OAAQ,CAACnC,EAAGyE,GAAIvE,YACzBgqC,EACFxvB,GAAI,CAACvY,OAAQ,CAACnC,EAAG0E,GAAIxE,UAASmD,MAAO,CAACgL,KAAME,EAAMD,UAAU,KAC1D67B,EACFvyB,GAAQ,CAACzV,OAAQ,CAACnC,EAAGkqC,GAAShqC,UAASmD,MAAO,CAAClH,MAAO6tC,KAEpD/oC,EAAS26B,GAAI,CAACz5B,OAAQ,CAACsC,EAAGC,EAAGA,EAAGylC,GAAcjqC,YASpD,OAPAA,EAAQsD,8BAA8BumC,GACtC7pC,EAAQsD,8BAA8BymC,GACtC/pC,EAAQsD,8BAA8BiB,GACtCvE,EAAQsD,8BAA8BkB,GACtCxE,EAAQsD,8BAA8B0mC,GACtChqC,EAAQsD,8BAA8B2mC,GAE/BlpC,EAGF,IAAMmpC,GAA8B,CACzCzqC,WAAY0qC,UACZxqC,YAAa,MACbC,WAAY8pC,ICAP,IAAMU,GAAkC,CAC7C3qC,WAAY4qC,cACZ1qC,YAAa,MACbC,oBA3D0BC,GAKnB,IAAAoC,WAAQjC,YAASmD,UACjBwmC,WACAW,eAAYC,SAAMC,eAEzB5vC,EAAiB+uC,EAAQ,eAazB,IAXA,IAAMc,EAAgBD,EAClBb,EACAD,GAAQ,CAACznC,OAAQ,CAAC0nC,UAAS3pC,UAASmD,MAAO,CAACk4B,KAAM,KAEhD3b,EAAY+qB,EAAcxuC,MAAM,GAChCyuC,EAAYD,EAAcxuC,MAAM,GAChC0uC,EAAW3qC,EAAQtE,KAAKW,IAAIouC,EAAcjuC,QAAQR,OAClD4uC,EAAW,CAAClrB,EAAW4qB,GACvBvwB,EACF5e,OAAKsH,oBAAoBtH,OAAK8E,cAAc2qC,GAAW,SAElDpmC,EAAI,EAAGA,EAAIkb,IAAalb,EAAG,CAClC,IAAM2G,EAAS3G,EAAIkmC,EAGbG,EAAM,IAAIzrC,aAAasrC,EAAY,GACzCG,EAAI,GAAKF,EAASx/B,GAClB,IAAK,IAAI2/B,EAAQ,EAAGA,EAAQD,EAAIhuC,SAAUiuC,EACxCD,EAAIC,GAASD,EAAIC,EAAQ,GAAKH,EAASx/B,EAAS2/B,GAKlD,IAFA,IAAMC,EAASC,OAAgBT,EAAKl1B,YAC9BX,EAAYlQ,EAAI8lC,EACbW,EAAW,EAAGA,EAAWX,IAAcW,EAAU,CACxD,IAAM3gB,EAAIygB,IAGVhxB,EAAQrF,EAAYu2B,GAAYJ,EAAIhuC,OAEpC,IAAK,IAAIquC,EAAQ,EAAGA,EAAQL,EAAIhuC,OAAQquC,IACtC,GAAI5gB,EAAIugB,EAAIK,GAAQ,CAClBnxB,EAAQrF,EAAYu2B,GAAYC,EAChC,QAUR,OAJKV,GACHxqC,EAAQsD,8BAA8BmnC,GAGjCzqC,EAAQqC,eAAeuoC,EAAU,QAAS7wB,KC3D7CoxB,GAA0B5vC,eAAa4vC,wBA0BtC,IAAMC,GAA0C,CACrD3rC,WAAY4rC,sBACZ1rC,YAAa,MACbC,oBAxBkCC,GAK3B,IAAAoC,WAAQjC,YAASmD,UACjBguB,UAAOma,WACPC,kBAAeC,iBAAcC,mBAEpC7wC,EAAiBu2B,EAAO,qBAExB,IAAMua,EAAY1rC,EAAQtE,KAAKW,IAAI80B,EAAM30B,QAAQR,OAC3C2vC,EAAa3rC,EAAQtE,KAAKW,IAAIivC,EAAO9uC,QAAQR,OAE5C4vC,gCAGP,OAAO5rC,EAAQqC,eACX,CAACupC,EAAgB/uC,QAAS,QAAS,IAAI4G,WAAWmoC,MCvBlDC,GAA0BtwC,eAAaswC,wBA6BtC,IAAMC,GAA0C,CACrDrsC,WAAYssC,sBACZpsC,YAAa,MACbC,oBA5BkCC,GAK3B,IAAAoC,WAAQjC,YAASmD,UACjBguB,UAAOma,WACPC,kBAAeC,iBAAcC,mBAAgBO,uBAGpDpxC,EAAiBu2B,EAAO,2BAExB,IAAMua,EAAY1rC,EAAQtE,KAAKW,IAAI80B,EAAM30B,QAAQR,OAC3C2vC,EAAa3rC,EAAQtE,KAAKW,IAAIivC,EAAO9uC,QAAQR,OAE7CuB,kBAACquC,oBAAiBK,iBAIxB,MAAO,CACLjsC,EAAQqC,eACJ,CAACupC,EAAgB/uC,QAAS,QAAS,IAAI4G,WAAWmoC,IACtD5rC,EAAQqC,eAAe,GAAI,QAAS,IAAIoB,WAAW,CAACwoC,QC1BlDC,GAA0B3wC,eAAa2wC,wBAmCtC,IAAMC,GAA0C,CACrD1sC,WAAY2sC,sBACZzsC,YAAa,MACbC,oBAlCkCC,GAK3B,IAAAoC,WAAQjC,YAASmD,UACjBguB,UAAOma,WACPC,kBAAeC,iBAAcC,mBAAgBY,iBAEpDzxC,EAAiBu2B,EAAO,8BAExB,IAAMua,EAAY1rC,EAAQtE,KAAKW,IAAI80B,EAAM30B,QAAQR,OAC3C2vC,EAAa3rC,EAAQtE,KAAKW,IAAIivC,EAAO9uC,QAAQR,OAO7CuB,SALmBguC,EACDC,EACEC,EACFY,GAEjBT,oBAAiBU,mBAIxB,MAAO,CACLtsC,EAAQqC,eACJ,CAACupC,EAAgB/uC,QAAS,QAAS,IAAI4G,WAAWmoC,IACtD5rC,EAAQqC,eACJ,CAACiqC,EAAezvC,QAAS,UAAW,IAAIuC,aAAaktC,OCJtD,IAAMC,GAA6B,CACxC9sC,WAAY+sC,SACZ7sC,YAAa,MACbC,oBA1BEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBqN,YACAi8B,UAAOC,YAASC,aAEvB/xC,EAAiB4V,EAAS,UAE1B,IAAMyyB,EAAc9nC,OAAK8E,cAAcuQ,EAAQvU,OAEzC2Q,EAAM,IAAIxN,aAAa6jC,EAAcwJ,GAC3C7/B,EAAI4E,KAAKm7B,GAGT,IAFA,IAAMC,EAAa5sC,EAAQtE,KAAKW,IAAImU,EAAQhU,QAAQR,OAE3C8uC,EAAQ,EAAGA,EAAQ7H,IAAe6H,EACrC8B,EAAW9B,IAAU,GAAK8B,EAAW9B,GAAS2B,IAChD7/B,EAAIk+B,EAAQ2B,EAAQG,EAAW9B,IAAU4B,GAI7C,OAAO1sC,EAAQqC,eAAmBmO,EAAQvU,cAAOwwC,IAAQ,QAAS7/B,cCjBpDigC,GACZhtC,GACK,IAAAoC,WAAQjC,YACRF,MAEP,GAAgB,WAAZA,EAAEzE,MACJ,MAAM,IAAI2C,MAAM,iDACX,GAAgB,cAAZ8B,EAAEzE,MAAuB,CAClC,IAAMkI,EAAW7F,EAAK,CAACuE,OAAQ,CAACa,MAAOhD,GAAIE,YACrCsqB,EAAIuiB,GAAU,CAAC5qC,OAAQ,CAACnC,EAAGyD,GAAWvD,YACtC8sC,EAAWlvC,GAAK,CAACqE,OAAQ,CAACa,MAAOhD,GAAIE,YACrCX,EAAIwtC,GAAU,CAAC5qC,OAAQ,CAACnC,EAAGgtC,GAAW9sC,YAEtCe,EAASiB,EAAQ,CAACC,OAAQ,CAACvE,KAAM4sB,EAAG1sB,KAAMyB,GAAIW,YAOpD,OALAA,EAAQsD,8BAA8BC,GACtCvD,EAAQsD,8BAA8BgnB,GACtCtqB,EAAQsD,8BAA8BwpC,GACtC9sC,EAAQsD,8BAA8BjE,GAE/B0B,EAEP,OAAOyQ,GAAK,CAACxR,UAASmD,MAAO,CAAClH,MAAO6D,EAAE7D,MAAO6K,MAAO,EAAGzL,MAAOyE,EAAEzE,SAI9D,IAAM0xC,GAAgC,CAC3CttC,WAAYutC,YACZrtC,YAAa,MACbC,WAAYitC,ICHP,IAAMI,GAA+B,CAC1CxtC,WAAYytC,WACZvtC,YAAa,MACbC,oBA7BcutC,EACZttC,GACK,IAAAoC,WAAQjC,YACRF,MAEP,GAAgB,WAAZA,EAAEzE,MACJ,MAAM,IAAI2C,MAAM,gDACX,GAAgB,cAAZ8B,EAAEzE,MAAuB,CAClC,IAAMkI,EAAW7F,EAAK,CAACuE,OAAQ,CAACa,MAAOhD,GAAIE,YACrCsqB,EAAI6iB,EAAS,CAAClrC,OAAQ,CAACnC,EAAGyD,GAAWvD,YACrC8sC,EAAWlvC,GAAK,CAACqE,OAAQ,CAACa,MAAOhD,GAAIE,YACrCX,EAAIwtC,GAAU,CAAC5qC,OAAQ,CAACnC,EAAGgtC,GAAW9sC,YAEtCe,EAASiB,EAAQ,CAACC,OAAQ,CAACvE,KAAM4sB,EAAG1sB,KAAMyB,GAAIW,YAOpD,OALAA,EAAQsD,8BAA8BC,GACtCvD,EAAQsD,8BAA8BgnB,GACtCtqB,EAAQsD,8BAA8BwpC,GACtC9sC,EAAQsD,8BAA8BjE,GAE/B0B,EAEP,OAAOyQ,GAAK,CAACxR,UAASmD,MAAO,CAAClH,MAAO6D,EAAE7D,MAAO6K,MAAO,EAAGzL,MAAOyE,EAAEzE,oBCzBrD+xC,GACZvtC,GAEK,IAAAoC,WAAQjC,YACRmO,eAEP,GAAsB,IAAlBlM,EAAOpF,OACT,OAAOu+B,GACH,CAACn5B,OAAQ,CAACa,MAAOb,EAAO,IAAKjC,UAASmD,MAAO,CAACk4B,IAAKltB,KAGzD,IAAMlS,EAAQgG,EAAO,GAAGhG,MAClBZ,EAAQ4G,EAAO,GAAG5G,MAExB4G,EAAOhH,SAAQ,SAAAC,GACbC,OAAKkyC,kBACDpxC,EAAOf,EAAEe,MACT,yDACJd,OAAKC,OACDC,IAAUH,EAAEG,OACZ,WAAM,MAAA,8DAGZ,IAAMqT,EAAwC,GAQxC3N,EAAS8X,GAAO,CAAC5W,OAPCA,EAAOjF,KAAI,SAAA9B,GACjC,IAAMoyC,EACFlS,GAAW,CAACn5B,OAAQ,CAACa,MAAO5H,GAAI8E,UAASmD,MAAO,CAACk4B,IAAKltB,KAE1D,OADAO,EAAwBC,KAAK2+B,GACtBA,KAGuCttC,UAASmD,MAAO,CAACgL,UAKjE,OAHAO,EAAwBzT,SACpB,SAAAC,GAAK,OAAA8E,EAAQsD,8BAA8BpI,MAExC6F,EAGF,IAAMwsC,GAA2B,CACtC9tC,WAAY+tC,OACZ7tC,YAAa,MACbC,WAAYwtC,ICDP,IAAMK,GAA4B,CACvChuC,WAAYiuC,QACZ/tC,YAAa,MACbC,oBA5CEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAkpC,aAAU2E,kBAEjB/yC,EAAiBkF,EAAG,OAEpB,IAAMsI,EAAW4gC,EAAShsC,KACtB,SAACo9B,EAAG/6B,GAAM,OAAA+6B,EAAE,GAAqBt6B,EAAE7D,MAAMoD,GAAK+6B,EAAE,MAE9C57B,EAAQwqC,EAAShsC,KAAI,SAAAo9B,GAAK,OAAAA,EAAE,MAE5Bz2B,EAAQ3D,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACnC0L,EAAQvM,OAAK8E,cAAcH,EAAE7D,OAC7BkR,EAAQrN,EAAE7D,MAAMY,OAChBuQ,EAAWjS,OAAK0F,eAAef,EAAE7D,OAEjC6E,EAAa3F,OAAK8E,cAAcmI,GAChCzH,EAAayH,EAASvL,OACtB+D,EAAgBzF,OAAK0F,eAAeuH,GACpC2R,EACF5e,OAAK6F,uBAAuBlB,EAAEzE,MAA0ByF,GAEtC,IAAlB6sC,GACF5zB,EAAQvI,KAAKm8B,GAGf,IAAK,IAAItuC,EAAI,EAAGA,EAAIqI,EAAOrI,IAAK,CAC9B,IACMuuC,EADSzyC,OAAKsG,WAAWpC,EAAG8N,EAAOC,GAChBpQ,KAAI,SAAC41B,EAAGvzB,GAAM,OAAAuzB,EAAIp0B,EAAMa,MAGjD0a,EAFiB5e,OAAK0G,WAAW+rC,EAAWjtC,EAAYC,IAEpC+C,EAAMtE,GAK5B,MAAO,CAAC7C,OAFMwD,EAAQ7C,MAAM4c,EAAS3R,EAAUtI,EAAEzE,OAE1BY,MAAOmM,EAAU/M,MAAOyE,EAAEzE,SCvCtCwyC,GACT1tC,GAA6B,SAACoE,EAAWC,GAAc,OAAAlF,KAAKinC,IAAIhiC,EAAGC,MAC1D+hC,GAAMriC,EAAiB4pC,MAAKD,IAE5BE,GAA0B,CACrCtuC,WAAYquC,MACZnuC,YAAa,MACbC,WAAY2mC,ICEP,IAAMyH,GAA4B,CACvCvuC,WAAYwuC,QACZtuC,YAAa,MACbC,oBAZoBC,GAEb,IAAAG,YAASmD,UACT3E,UAAOkM,SAAMrP,UAEdW,EAAS8S,GAAUtQ,EAAOkM,SAAYrP,GAC5C,OAAO2E,EAAQqC,eAAe,CAACrG,EAAOa,QAASxB,EAAOW,KCP3CkyC,GAAazmC,EAAgB0mC,cAAY,SAACpmC,GAAO,OAAA,EAAIA,KAErDqmC,GAAiC,CAC5C3uC,WAAY0uC,aACZxuC,YAAa,MACbC,WAAYsuC,ICgFP,IAAMG,GAAqC,CAChD5uC,WAAY6uC,iBACZ3uC,YAAa,MACbC,oBAvF6BC,GAKtB,IAAAoC,WAAQjC,YAASmD,UACjBorC,WACAC,iBAAcC,qBAAkB9nC,SAEvC/L,EAAiB2zC,EAAQ,kBAsBzB,IApBA,IAAMG,EAAgBvzC,OAAK0F,eAAe0tC,EAAOtyC,OAC1C0yC,OAAWC,OAEZrxC,UAAC6W,OAAOy6B,OAAWC,OAAUpd,OAC7BvT,EAAUne,EAAQtE,KAAKW,IAAIkyC,EAAO/xC,QAAQR,OAC1C+E,EAAS,IAAI3B,aACfjE,OAAK8E,cAAc,CAACmU,EAAOu6B,EAAWC,EAAUld,KAE9Cqd,EAAuC,CAC1CP,GAAgBG,EAAY,EAAKE,EAAY,EAAIA,EACjDL,GAAgBI,EAAW,EAAKE,EAAW,EAAIA,GAG5CE,EAAwC,CAC3CR,GAAgBG,EAAY,EAAKA,EAAY,EAAIA,EACjDH,GAAgBI,EAAW,EAAKA,EAAW,EAAIA,GAE9CxZ,EAAY,EACV6Z,EAAwBF,EAAmB,GAAKC,EAAoB,GACpEE,EAAwBH,EAAmB,GAAKC,EAAoB,GACjExqC,EAAI,EAAGA,EAAI4P,EAAO5P,IACzB,IAAK,IAAI8lB,EAAI,EAAGA,EAAIqkB,EAAWrkB,IAAK,CAClC,IAAI6kB,SAEFA,EADEV,EACcQ,GAAyB3kB,EAAI,IAAO,GAEpC2kB,EAAwB3kB,EAU1C,IAPA,IAAM8kB,EAAiB9vC,KAAK8L,IAAI,EAAG9L,KAAKgK,MAAM6lC,IACxCE,EAAUF,EAAgBC,EAC1BE,EAAgBhwC,KAAKsM,IAAIijC,EAAY,EAAGvvC,KAAK0I,KAAKmnC,IAClDI,EACF/qC,EAAIkqC,EAAc,GAAKU,EAAiBV,EAAc,GACpDc,EACFhrC,EAAIkqC,EAAc,GAAKY,EAAgBZ,EAAc,GAChD9b,EAAI,EAAGA,EAAIgc,EAAUhc,IAAK,CACjC,IAAI6c,SAEFA,EADEhB,EACcS,GAAyBtc,EAAI,IAAO,GAEpCsc,EAAwBtc,EAS1C,IAPA,IAAM8c,EAAiBpwC,KAAK8L,IAAI,EAAG9L,KAAKgK,MAAMmmC,IACxCE,EAAUF,EAAgBC,EAC1BE,EAAgBtwC,KAAKsM,IAAIkjC,EAAW,EAAGxvC,KAAK0I,KAAKynC,IACjDI,EAAgBN,EAAeG,EAAiBhB,EAAc,GAC9DoB,EAAgBN,EAAeE,EAAiBhB,EAAc,GAC9DqB,EAAiBR,EAAeK,EAAgBlB,EAAc,GAC9DsB,EAAiBR,EAAeI,EAAgBlB,EAAc,GAC3DzxC,EAAI,EAAGA,EAAIy0B,EAAaz0B,IAAK,CAIpC,IAAMo2B,EAAUlV,EAAQ0xB,EAAgB5yC,GAClCs2B,EAAapV,EAAQ2xB,EAAgB7yC,GAIrCu2B,EAAMH,GAHKlV,EAAQ4xB,EAAiB9yC,GAGRo2B,GAAWsc,EAEvCM,EAAWzc,GADFD,GAHKpV,EAAQ6xB,EAAiB/yC,GAGFs2B,GAAcoc,EACxBnc,GAAO6b,EAExCtuC,EAAOq0B,KAAe6a,IAM9B,OAAOjwC,EAAQqC,eACX,CAAC+R,EAAOu6B,EAAWC,EAAUld,GAAc,UAAW3wB,KCQrD,IAAMmvC,GAAyC,CACpDzwC,WAAY0wC,qBACZxwC,YAAa,MACbC,oBA5FiCC,GAK1B,IAAAoC,WAAQjC,YAASmD,UACjBorC,WAAQ7pB,OACR8pB,iBAEP5zC,EAAiB,CAAC8pB,EAAI6pB,GAAS,sBAgC/B,IA9BA,IAAMG,EAAgBvzC,OAAK0F,eAAe0tC,EAAOtyC,OAE3CsB,UAAC6W,OAAOg8B,OAASC,OAAQ5D,OACzBnoC,UAAGgsC,OAASC,OAEZlxB,EAAS,IAAIjgB,aAAagV,EAAQg8B,EAAUC,EAAS5D,GAOrD+D,EAAmC,CACtChC,GAAgB8B,EAAU,EAAKF,EAAU,EAAIA,EAC7C5B,GAAgB+B,EAAS,EAAKF,EAAS,EAAIA,GAGxCI,EAAmC,CACtCjC,GAAgB8B,EAAU,EAAKA,EAAU,EAAIA,EAC7C9B,GAAgB+B,EAAS,EAAKA,EAAS,EAAIA,GAGxC9d,EAAc+d,EAAe,GAAKC,EAAe,GACjD/d,EAAa8d,EAAe,GAAKC,EAAe,GAKhD5iB,EAAW7tB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OACzCmP,EAAS,EACJ3G,EAAI,EAAGA,EAAI4P,EAAO5P,IAEzB,IADA,IAAMksC,EAAUlsC,EAAIkqC,EAAc,GACzBpkB,EAAI,EAAGA,EAAIgmB,EAAShmB,IAU3B,IATA,IAAMtE,EAAMsE,EAAImI,EACVke,EAAcrxC,KAAKgK,MAAM0c,GACzB4qB,EAAiBtxC,KAAKsM,IAAItM,KAAK0I,KAAKge,GAAMoqB,EAAU,GAEpDS,EAAeH,EAAUC,EAAcjC,EAAc,GACrDoC,EAAkBJ,EAAUE,EAAiBlC,EAAc,GAE3DqC,EAAU/qB,EAAM2qB,EAChBK,EAAiB,EAAMD,EACpBne,EAAI,EAAGA,EAAI2d,EAAQ3d,IAoB1B,IAnBA,IAAM3M,EAAM2M,EAAIF,EACVue,EAAe3xC,KAAKgK,MAAM2c,GAC1BirB,EAAgB5xC,KAAKsM,IAAItM,KAAK0I,KAAKie,GAAMoqB,EAAS,GAClDc,EAAUlrB,EAAMgrB,EAChBG,EAAiB,EAAMD,EAEvBE,EAAkBR,EAAeI,EAAevC,EAAc,GAC9D4C,EACFT,EAAeK,EAAgBxC,EAAc,GAC3C6C,EACFT,EAAkBG,EAAevC,EAAc,GAC7C8C,EACFV,EAAkBI,EAAgBxC,EAAc,GAE9C+C,EACFT,EAAiBI,EACfM,EAA6BV,EAAiBG,EAC9CQ,EAA6BZ,EAAUK,EACvCQ,EAAsBb,EAAUI,EAC7Bl0C,EAAI,EAAGA,EAAIwvC,EAAOxvC,IAAK,CAC9B,IAAM40C,EAAQhkB,EAAS1iB,KACvBkU,EAAOgyB,EAAkBp0C,IACrB40C,EAAQJ,EACZpyB,EAAOiyB,EAAmBr0C,IAAM40C,EAAQH,EACxCryB,EAAOkyB,EAAqBt0C,IAAM40C,EAAQF,EAC1CtyB,EAAOmyB,EAAsBv0C,IAAM40C,EAAQD,EAMnD,OAAO5xC,EAAQqC,eACX,CAAC+R,EAAOi8B,EAAQD,EAAS3D,GAAQ,UAAWptB,KCf3C,IAAMyyB,GAA4C,CACvDryC,WAAYsyC,wBACZpyC,YAAa,MACbC,oBA1EoCC,GAK7B,IAAAoC,WAAQjC,YAASmD,UACjBorC,WACAC,iBAAcC,qBAAkB9nC,SAEvC/L,EAAiB2zC,EAAQ,yBAuBzB,IArBA,IAAMG,EAAgBvzC,OAAK0F,eAAe0tC,EAAOtyC,OAC1C0yC,OAAWC,OAEZrxC,UAAC6W,OAAOy6B,OAAWC,OAAUpd,OAC7BvT,EAAUne,EAAQtE,KAAKW,IAAIkyC,EAAO/xC,QAAQR,OAC1CqjB,EAAS,IAAIjgB,aAAagV,EAAQu6B,EAAYC,EAAWld,GAEzDqd,EAAuC,CAC1CP,GAAgBG,EAAY,EAAKE,EAAY,EAAIA,EACjDL,GAAgBI,EAAW,EAAKE,EAAW,EAAIA,GAG5CE,EAAwC,CAC3CR,GAAgBG,EAAY,EAAKA,EAAY,EAAIA,EACjDH,GAAgBI,EAAW,EAAKA,EAAW,EAAIA,GAG5CK,EAAwBF,EAAmB,GAAKC,EAAoB,GACpEE,EAAwBH,EAAmB,GAAKC,EAAoB,GAEtEgD,EAAe,EACVxtC,EAAI,EAAGA,EAAI4P,EAAO5P,IAEzB,IADA,IAAM68B,EAAc78B,EAAIkqC,EAAc,GAC7BpkB,EAAI,EAAGA,EAAIqkB,EAAWrkB,IAAK,CAClC,IAAM6kB,EAAgBV,EAClBQ,GAAyB3kB,EAAI,IAC7B2kB,EAAwB3kB,EACxB2nB,EAAmB3yC,KAAKsM,IACxBijC,EAAY,EACZL,EAAelvC,KAAKq0B,MAAMwb,GAAiB7vC,KAAKgK,MAAM6lC,IACtDV,IACFwD,EAAmB3yC,KAAK8L,IAAI,EAAG6mC,IAGjC,IADA,IAAM3Q,EAAYD,EAAc4Q,EAAmBvD,EAAc,GACxD9b,EAAI,EAAGA,EAAIgc,EAAUhc,IAAK,CACjC,IAAM6c,EAAgBhB,EAClBS,GAAyBtc,EAAI,IAC7Bsc,EAAwBtc,EACxBsf,EAAmB5yC,KAAKsM,IACxBkjC,EAAW,EACXN,EAAelvC,KAAKq0B,MAAM8b,GACXnwC,KAAKgK,MAAMmmC,IAC1BhB,IACFyD,EAAmB5yC,KAAK8L,IAAI,EAAG8mC,IAGjC,IADA,IAAM3Q,EAAYD,EAAY4Q,EAAmBxD,EAAc,GACtDzxC,EAAI,EAAGA,EAAIy0B,EAAaz0B,IAAK,CAGpC,IAAMk1C,EAASh0B,EAAQojB,EAAYtkC,GACnCoiB,EAAO2yB,KAAkBG,IAMjC,OAAOnyC,EAAQqC,eACX,CAAC+R,EAAOu6B,EAAWC,EAAUld,GAAc6c,EAAOlzC,MAAOgkB,KCuCxD,IAAM+yB,GAAgD,CAC3D3yC,WAAY4yC,4BACZ1yC,YAAa,MACbC,oBA9GwCC,GAKjC,IAAAoC,WAAQjC,YAASmD,UACjBorC,WAAQ7pB,OACR8pB,iBAEP5zC,EAAiB,CAAC8pB,EAAI6pB,GAAS,6BAmC/B,IAjCA,IAAMG,EAAgBvzC,OAAK0F,eAAe0tC,EAAOtyC,OAC3C0xB,EAAYxyB,OAAK0F,eAAe6jB,EAAGzoB,OACnCsB,UAAC6W,OAAOg8B,OAASC,OAAQ5D,OACzBnoC,UAAGgsC,OAASC,OAEZlxB,EAAS,IAAIjgB,aAAagV,EAAQg8B,EAAUC,EAAS5D,GACrD5e,EAAW7tB,EAAQtE,KAAKW,IAAIqoB,EAAGloB,QAAQR,OAKvCw0C,EAAmC,CACtChC,GAAgB8B,EAAU,EAAKF,EAAU,EAAIA,EAC7C5B,GAAgB+B,EAAS,EAAKF,EAAS,EAAIA,GAGxCI,EAAmC,CACtCjC,GAAgB8B,EAAU,EAAKA,EAAU,EAAIA,EAC7C9B,GAAgB+B,EAAS,EAAKA,EAAS,EAAIA,GAGxC9d,EAAc+d,EAAe,GAAKC,EAAe,GACjD/d,EAAa8d,EAAe,GAAKC,EAAe,GAEhD6B,EAAiB,EAAI7f,EACrB8f,EAAgB,EAAI7f,EAIpB8f,EAAyC,EAA5BlzC,KAAK0I,KAAKsqC,GAAuB,EAC9CG,EAAuC,EAA3BnzC,KAAK0I,KAAKuqC,GAAsB,EAGzC/tC,EAAI,EAAGA,EAAI4P,EAAO5P,IAEzB,IADA,IAAM68B,EAAc78B,EAAIkqC,EAAc,GAC7BpkB,EAAI,EAAGA,EAAI8lB,EAAS9lB,IAM3B,IALA,IAAMgX,EAAYD,EAAc/W,EAAIokB,EAAc,GAG5CgE,EAAapzC,KAAKgK,MAAMghB,EAAIgoB,GAC5BK,EAAWrzC,KAAKgK,MAAMopC,EAAcF,EAAY,GAC7C5f,EAAI,EAAGA,EAAIyd,EAAQzd,IAO1B,IANA,IAAM2O,EAAYD,EAAY1O,EAAI8b,EAAc,GAG1CkE,EAAatzC,KAAKgK,MAAMspB,EAAI2f,GAC5BM,EAAWvzC,KAAKgK,MAAMspC,EAAcH,EAAW,GAE5Cx1C,EAAI,EAAGA,EAAIwvC,EAAOxvC,IAAK,CAI9B,IAHA,IAAI61C,EAAQ,EAGHC,EAAW,EAAGA,EAAWP,EAAWO,IAAY,CACvD,IAAM3sB,EAAM2sB,EAAWJ,EAEvB,KAAIvsB,EAAM,GAAKA,GAAOkqB,GAAtB,CAIA,IAAM0C,EAAY3R,EAAcjb,EAAMuH,EAAU,GAC1CwhB,EAAgB/oB,EAAMqM,EAK5B,GAAInI,IAJqBhrB,KAAKsM,IAC1BwkC,EAAU,EACV5B,EAAelvC,KAAKq0B,MAAMwb,GACX7vC,KAAKgK,MAAM6lC,IAI9B,IAAK,IAAI8D,EAAW,EAAGA,EAAWR,EAAUQ,IAAY,CACtD,IAAM5sB,EAAM4sB,EAAWJ,EAEvB,KAAIxsB,EAAM,GAAKA,GAAOkqB,GAAtB,CAIA,IAAM2C,EAAYF,EAAY3sB,EAAMsH,EAAU,GACxC8hB,EAAgBppB,EAAMqM,EAMxBE,IALqBtzB,KAAKsM,IAC1BykC,EAAS,EACT7B,EAAelvC,KAAKq0B,MAAM8b,GACXnwC,KAAKgK,MAAMmmC,MAG5BqD,GAASjlB,EAASqlB,EAAYj2C,OAIpCoiB,EAAOkiB,EAAYtkC,GAAK61C,EAMhC,OAAO9yC,EAAQqC,eAAeksC,EAAOtyC,MAAOsyC,EAAOlzC,MAAOgkB,KCzErD,IAAM8zB,GAA8B,CACzC1zC,WAAY2zC,UACZzzC,YAAa,MACbC,oBAhCEC,GAGK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAuzC,SAEPz4C,EAAiBkF,EAAG,WAEpB,IAAMqN,EAAQrN,EAAE7D,MAAMY,OAEhBy2C,EAAQn4C,OAAKmT,eAAe+kC,EAAMvzC,EAAE7D,OAC1C,GAAc,IAAVkR,EACF,OAAOzK,EAAS,CAACT,OAAQ,CAACnC,KAAIE,YAMhC,IAHA,IAAMqH,EAAS,IAAI4N,eAAanV,EAAE7D,MAAO6D,EAAEzE,OACrC2L,EAAOhH,EAAQ+kB,WAAWjlB,cAEvBT,GACP,IAAMyQ,EAASzI,EAAO5F,WAAWpC,GAC3B0Q,EAAQD,EAAOnO,QACrB2xC,EAAMr4C,SAAQ,SAAAgC,GAAK,OAAA8S,EAAM9S,GAAK6C,EAAE7D,MAAMgB,GAAK,EAAI8S,EAAM9S,MACrDoK,EAAO3K,UAAP2K,GAAWL,EAAK3K,UAAL2K,EAAY+I,WAAWD,KAJ3BzQ,EAAI,EAAGA,EAAIgI,EAAOV,KAAMtH,MAAxBA,GAOT,OAAOW,EAAQqC,eAAegF,EAAOpL,MAAOoL,EAAOhM,MAAOgM,EAAOrL,UC5BtDu3C,GAAuC,CAClD9zC,WAAY+zC,mBACZ7zC,YAAa,MACbC,WAAY,SAACrC,GAiBX,QAjBY0E,WAAQkB,UAAOnD,YACpBkxB,UACD5sB,IAACmvC,YAASC,cAAWC,WACrB5zC,EAAaC,EAEbqf,EAASlkB,OAAK6F,uBAChBkwB,EAAM71B,MAA0BF,OAAK8E,cAAcixB,EAAMj1B,QACvDyI,UAAC0P,OAAOod,OAAaC,OAAYC,OAEjC/rB,uCAACiuC,OAASC,OAIVC,EAAYx0C,KAAKy0C,IAAIN,GACrBO,EAAY10C,KAAKoxB,IAAI+iB,GACrBzhB,EAAYjyB,EAAWrE,KAAKW,IAAI60B,EAAM10B,QAAQR,OAE3C6N,EAAW,EAAGA,EAAWuK,EAAOvK,IAGvC,IAFA,IAAMw3B,EAAcx3B,EAAW4nB,EAAaD,EAAcE,EAEjDhpB,EAAM,EAAGA,EAAM8oB,EAAa9oB,IAGnC,IAFA,IAAM44B,EAAY54B,GAAO+oB,EAAaC,GAE7B9oB,EAAM,EAAGA,EAAM6oB,EAAY7oB,IAGlC,IAFA,IAAM24B,EAAY34B,EAAM8oB,EAEfxP,EAAU,EAAGA,EAAUwP,EAAaxP,IAAW,CACtD,IAAMinB,EAAS,CAAC/0B,EAAO1L,EAAKE,EAAKsZ,GAE3BpiB,EAAIqpC,EAAO,GACX/d,EAAI+d,EAAO,GAGb3H,GAAU1hC,EAAI8zC,GAAWI,GAAa5oB,EAAIyoB,GAAWC,EACrDG,GAAUn0C,EAAI8zC,GAAWE,GAAa1oB,EAAIyoB,GAAWG,EACzDxS,EAASliC,KAAKq0B,MAAM6N,EAASoS,GAC7BK,EAAS30C,KAAKq0B,MAAMsgB,EAASJ,GAE7B,IAAInS,EAAcgS,EAUlB,GATyB,iBAAdA,IAEPhS,EADc,IAAZxf,EA7BW,IAgCCwxB,EAAUxxB,IAKxBsf,GAAU,GAAKA,EAAS/P,GAAcwiB,GAAU,GAChDA,EAASziB,EAMXkQ,EAAc1P,EADVqP,EAHqB4S,GAAUxiB,EAAaC,GACvB8P,EAAS9P,EAEsBxP,GAK1D7C,EADegiB,EAAcC,EAAYC,EAAYrf,GACpCwf,EAOzB,MAAO,CAACllC,OADOuD,EAAW5C,MAAMkiB,EAAQ6R,EAAMj1B,MAAOi1B,EAAM71B,OAC3CY,MAAOi1B,EAAMj1B,MAAOZ,MAAO61B,EAAM71B,SCtExCs4B,GAAQlsB,EAAgBysC,SAAO,SAACnsC,GAE3C,IAAMosC,EAAO70C,KAAKgK,MAAMvB,GACxB,OAAIA,EAAKosC,EAAO,GACP70C,KAAKgK,MAAMvB,GACTA,EAAKosC,EAAO,GACd70C,KAAK0I,KAAKD,GAEbosC,EAAO,GAAQ,EACVA,EAEAA,EAAO,KAKPC,GAA4B,CACvC30C,WAAYy0C,QACZv0C,YAAa,MACbC,WAAY+zB,aCtBE0gB,GACZ7jC,EAA0B8jC,EAA0Br4C,EACpD4W,EAAoByV,EAAmBisB,EACvC/R,EAAmBhvB,EAAmB3C,EACtC2jC,GACF,IAAMC,EAAe,CAAC5hC,EAAayV,EAAWA,GAExCoa,EAAclyB,EAAQxU,OACtB04C,EAAcJ,EAAQt4C,OAE5B,GAAmB,IAAf6W,EACF,OAAO5U,SAAOhC,EAAsBq4C,EAAQj5C,OAG9C,IAAMgM,EAASpJ,SAAOw2C,EAAcH,EAAQj5C,OAC3CgM,EAAOrL,OAAsBwV,KAAKX,GAEnC,IAAK,IAAIxR,EAAI,EAAGA,EAAIk1C,EAAYl1C,IAAK,CAGnC,IAFA,IAAMmV,EAAQ,GACVouB,EAAe,EACVt7B,EAAI,EAAGA,EAAIk7B,EAAWl7B,IAAK,CAClC,IAAM+zB,EAAMqH,EAAYrjC,EAAImjC,EAAYl7B,GACxCkN,EAAM7F,KAAK0sB,GACXuH,GAAgBvH,EAAM7nB,EAAQlM,GAGhC,GAAIs7B,EAAe,GAAKA,GAAgB/vB,EAAayV,EACnD,MAAM,IAAItqB,MAAM,oBAAoBwW,0BAA6BvY,GAGnE,IAAK,IAAIgY,EAAI,EAAGA,EAAIqU,EAAWrU,IACzBugC,EACFntC,EAAOrL,OAAO4mC,EAAeta,EAAYrU,IACrCygC,EAAYr1C,EAAIipB,EAAYrU,GAEhC5M,EAAOrL,OAAO4mC,EAAeta,EAAYrU,GAAsB,IAAjBqgC,EAAQpjC,KAClDwjC,EAAY,GACZA,EAAYr1C,EAAIipB,EAAYrU,GAKtC,OAAO5M,ECfF,IAAMstC,GAAgC,CAC3Cl1C,WAAYm1C,YACZj1C,YAAa,MACbC,oBA1BwBC,GAKjB,IAAAoC,WAAQjC,YAASmD,UACjBqN,YAAS8jC,YACTr4C,UAEDsB,wCAACilC,cAAW+R,eAAYjsB,cAAW9U,YAASX,eAO5CxL,EAASgtC,GAHIr0C,EAAQ+kB,WAAWvU,GACnBxQ,EAAQ+kB,WAAWuvB,GAGVr4C,EAAO4W,EAAYyV,EAAWisB,EACtD/R,EAAWhvB,EAAS,GAPD,GASvB,OAAOxT,EAAQqC,eAAepG,EAAOoL,EAAOhM,MAAOgM,EAAOrL,UCcrD,IAAM64C,GAA6B,CACxCp1C,WAAYq1C,SACZn1C,YAAa,MACbC,oBArCqBC,GAEd,IAAAoC,WAAQjC,YACRnB,cAAW3D,MAAGujC,MAErB7jC,EAAiB,CAACiE,EAAW3D,EAAGujC,GAAI,UAgBpC,IAfA,IAAMsW,EAAgBl2C,EAAU5C,MAAMY,OAEhCb,EAASgE,EAAQtE,KAAKW,IAAIwC,EAAUrC,QAAQR,OAC5Cg5C,EAAUh1C,EAAQtE,KAAKW,IAAInB,EAAEsB,QAAQR,OACrCi5C,EAAUj1C,EAAQtE,KAAKW,IAAIoiC,EAAEjiC,QAAQR,OACrCo4B,EAAcrmB,aAAW7S,EAAEG,MAAOojC,EAAEpjC,OACpCmM,EACFrM,OAAKsH,oBAAoBtH,OAAK8E,cAAc/E,EAAEe,OAAQm4B,GAEtD5f,EAAQ,EACNrJ,EACgB,IAAlB4pC,GAAuBA,EAAgB,GAAwB,IAAnB75C,EAAEe,MAAMY,OACpD,EACA1B,OAAK8E,cAAc/E,EAAEe,MAAM0F,MAAM,IAE5BtC,EAAI,EAAGA,EAAIrD,EAAOa,OAAQwC,IACjC,IAAK,IAAIiI,EAAI,EAAGA,EAAI6D,EAAQ7D,IACR,IAAdtL,EAAOqD,GACTmI,EAAUgN,KAAWwgC,EAAQ31C,GAE7BmI,EAAUgN,KAAWygC,EAAQ51C,GAKnC,OAAOW,EAAQqC,eAAenH,EAAEe,MAAOm4B,EAAa5sB,KChChD0tC,GAAa54C,eAAa64C,gBAC1B3uB,GAAQlqB,eAAa84C,WAEdC,GAAO5tC,EAAgB6tC,QAAM,SAACvtC,GACzC,OAAIA,GAAM,EACDye,GAAQze,EAERmtC,IAAc51C,KAAKwJ,IAAIf,GAAM,MAI3BwtC,GAA2B,CACtC91C,WAAY61C,OACZ31C,YAAa,MACbC,WAAYy1C,ICdDna,GAAOzzB,EAAgB+tC,QAAM,SAACztC,GACzC,OAAIA,EAAK,GACC,EACCA,EAAK,EACP,EAEA,KAIE0tC,GAA2B,CACtCh2C,WAAY+1C,OACZ71C,YAAa,MACbC,WAAYs7B,ICbD6Y,GAAMtsC,EAAgBiuC,OAAK,SAAC3tC,GAAO,OAAAzI,KAAKy0C,IAAIhsC,MAE5C4tC,GAA0B,CACrCl2C,WAAYi2C,MACZ/1C,YAAa,MACbC,WAAYm0C,ICLD6B,GAAOnuC,EAAgBouC,QAAM,SAAC9tC,GAAO,OAAAzI,KAAKs2C,KAAK7tC,MAE/C+tC,GAA2B,CACtCr2C,WAAYo2C,OACZl2C,YAAa,MACbC,WAAYg2C,ICCRG,GAAYz2C,KAAKwL,IADP,uBACsB,EAEzBkrC,GAAWvuC,EAAgBwuC,YAAU,SAACluC,GAGjD,IAAMmuC,EAAWnuC,GAAMguC,GAIjBI,EAAWpuC,EAAKguC,GAEhBK,EAAO92C,KAAKwJ,IAAIf,GAUtB,OAPIouC,EACOC,EACAF,EACAnuC,EAEAzI,KAAKwL,IAAI,EAAMsrC,MAKfC,GAA+B,CAC1C52C,WAAYw2C,WACZt2C,YAAa,MACbC,WAAYo2C,IC8BP,IAAMM,GAAqC,CAChD72C,WAAY82C,iBACZ52C,YAAa,MACbC,oBA7D6BC,GAKtB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACA4nB,eAAYshB,aAEnBpuC,EAAiB,CAACkF,GAAI,kBAEtB,IAAM8nB,EAAOzsB,OAAK8E,cAAcynB,GAE1B8uB,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiB7nC,WAAjB6nC,EAA0BxN,GAE1B,IAAK,IAAI3pC,EAAI,EAAIqoB,EAAW7qB,OAAQwC,EAAIS,EAAE7D,MAAMY,SAAUwC,EACxDm3C,EAAiB7nC,KAAK,CAAC,EAAG,IAG5B,IAAM8nC,EAAUhJ,GAAY7tC,WAAW,CACrCqC,OAAQ,CAACnC,KACTE,UACAmD,MAAO,CAAC6lC,SAAUwN,EAAkB7I,cAAe,KAG/C+I,EACFp6C,eAAayrB,YAAY0uB,EAAQx6C,MAAOyrB,EAAYE,GAAM,GAExD+uB,EAAoCr6C,eAAa2rB,YACnDyuB,EAAoB75C,OAAQ6qB,EAAW7qB,QAAQ,GAE7C43C,EACFn4C,eAAa6rB,oBAAoBsuB,EAAQx6C,MAAOyrB,EAAYE,GAAM,GAIhEgvB,EACFl/B,GAAQ,CAACzV,OAHwB,CAACnC,EAAG22C,GAGLz2C,UAASmD,MAFV,CAAClH,MAAOy6C,KAOrCG,EACFrpC,GAAU,CAACvL,OAJ0B,CAACnC,EAAG82C,GAIL52C,UAASmD,MAF5B,CAAC+J,KAAMypC,KAMtB51C,EAAS2W,GACX,CAACzV,OAHsC,CAACnC,EAAG+2C,GAGb72C,UAASmD,MAFF,CAAClH,MAAOw4C,KAQjD,OAJAz0C,EAAQsD,8BAA8BmzC,GACtCz2C,EAAQsD,8BAA8BszC,GACtC52C,EAAQsD,8BAA8BuzC,GAE/B91C,ICVF,IAAM+1C,GAA0C,CACrDr3C,WAAYs3C,sBACZp3C,YAAa,MACbC,oBAnDkCC,GAI3B,IAAAoC,WAAQjC,YACRwQ,YAASxU,WAAQ4U,eAAYC,iBACpC,GAAgC,IAA5BD,EAAW3U,MAAMY,OACnB,MAAM,IAAImB,MAAM,+CACV4S,EAAW3U,OAEnB,GAA6B,IAAzBuU,EAAQvU,MAAMY,OAChB,MAAM,IAAImB,MAAM,2CACVwS,EAAQvU,OAEhB,GAA4B,IAAxBD,EAAOC,MAAMY,OACf,MAAM,IAAImB,MAAM,0CACVhC,EAAOC,OAEf,GAAkC,IAA9B4U,EAAa5U,MAAMY,OACrB,MAAM,IAAImB,MAAM,iDACV6S,EAAa5U,OAGrB,IAAM+6C,EAAWh3C,EAAQtE,KAAKW,IAAImU,EAAQhU,QAAQR,OAC5Ci7C,EAAUj3C,EAAQtE,KAAKW,IAAIL,EAAOQ,QAAQR,OAC1Ck7C,EAAcl3C,EAAQtE,KAAKW,IAAIuU,EAAWpU,QAAQR,OAClDm7C,EACFn3C,EAAQtE,KAAKW,IAAIwU,EAAarU,QAAQR,OAAO,GAE3CuB,sCAAC4T,OAAeimC,OAAoBhmC,OACnCJ,OAAmBC,OAI1B,MAAO,CACLjR,EAAQqC,eAAe+0C,EAAoB5mC,EAAQnV,MAAO8V,GAC1DnR,EAAQqC,eACJ,CAAC+0C,EAAmB,IAAKp7C,EAAOX,MAAO+V,GAC3CpR,EAAQqC,eACJ,CAAC2O,EAAkBnU,QAAS,OAC5B,IAAIw6C,WACArmC,EAAkBhU,KAAI,SAAC8J,GAAmB,OAAAoY,OAAOpY,QACzD9G,EAAQqC,eACJ,CAAC4O,EAAgBpU,QAAS2T,EAAQnV,MAClC,IAAIoI,WAAWwN,OCRhB,IAAMqmC,GAAoC,CAC/C73C,WAAY83C,gBACZ53C,YAAa,MACbC,oBAtCEC,GAEK,IAAAoC,WAAQjC,YACRgS,iBAAcG,eAAY1R,aACjC,GAAkC,IAA9BuR,EAAa/V,MAAMY,OACrB,MAAM,IAAImB,MAAM,gEACVgU,EAAa/V,OAErB,GAAgC,IAA5BkW,EAAWlW,MAAMY,OACnB,MAAM,IAAImB,MAAM,8DACVmU,EAAWlW,OAGnB,GAA8B,IAA1BwE,EAASxE,MAAMY,OACjB,MAAM,IAAImB,MACN,sDAAsDyC,EAASxE,OAGrE,IAAMu7C,EACFz8C,MAAM2I,KAAK1D,EAAQtE,KAAKW,IAAI8V,EAAW3V,QAAQR,QAC7Cy7C,EACFz3C,EAAQtE,KAAKW,IAAI2V,EAAaxV,QAAQR,OACpCoW,EACFrX,MAAM2I,KAAK1D,EAAQtE,KAAKW,IAAIoE,EAASjE,QAAQR,QAE3CuB,4BAAC0V,OAAYxC,OAAc+B,OAGjC,MAAO,CACLxS,EAAQqC,eAAeoO,EAAcuB,EAAa3W,MAAO4X,GACzDjT,EAAQqC,eACJ,CAACmQ,EAAY3V,QAAS4D,EAASpF,MAAO,IAAIoI,WAAW+O,OCRtD,IAAMklC,GAAoC,CAC/Cj4C,WAAYk4C,gBACZh4C,YAAa,MACbC,oBA5B4BC,GAKrB,IAAAoC,WAAQjC,YAASmD,UACjBy0C,kBAAeC,iBAAchnC,iBAC7B2B,gBAEDjV,wCAACilC,cAAW+R,eAAYjsB,cAAW9U,YAASX,eAS5CxL,EAASgtC,GALIr0C,EAAQ+kB,WAAW6yB,GACnB53C,EAAQ+kB,WAAW8yB,GAKVrlC,EAAaK,EAAYyV,EAAWisB,EAC5D/R,EAAWhvB,EAJXxT,EAAQtE,KAAKW,IAAIwU,EAAarU,QAAQR,OAAO,IAL1B,GAWvB,OAAOgE,EAAQqC,eAAemQ,EAAanL,EAAOhM,MAAOgM,EAAOrL,UCC3D,IAAM87C,GAA6B,CACxCr4C,WAAYs4C,SACZp4C,YAAa,MACbC,oBAxBEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAk4C,oBAAiB7pC,SAElB2G,EAAQ3Z,OAAKmT,eAAeH,EAAMrO,EAAE7D,OAAO,GAC3Cg8C,EAAa37C,eAAa47C,iBAAiBp4C,EAAGk4C,EAAiBljC,GAE/DxF,EAAQ,IAAIvU,MAAM+E,EAAE7D,MAAMY,QAAQ2U,KAAK,GACvC7K,EAAO7G,EAAE7D,MAAM0F,QACrB,OAAOs2C,EAAWj7C,KAAI,SAAAm7C,GACpB,IAAM7vB,EAAgB3hB,UACtB2hB,EAAUxT,GAASqjC,EACnB,IAAMC,EACFz2C,GAAM,CAACM,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAACmM,QAAO3I,KAAM2hB,KAEtD,OADAhZ,EAAMwF,IAAUqjC,EACTC,OCpBEnpC,GAAOxH,EAAgB4wC,QAAM,SAACtwC,GAAO,OAAAzI,KAAK2P,KAAKlH,MAE/CuwC,GAA2B,CACtC74C,WAAY44C,OACZ14C,YAAa,MACbC,WAAYqP,ICJDspC,GAA6B,CACxC94C,WAAY+4C,SACZ74C,YAAa,MACbC,WAAY,SAACrC,OAAC0E,WAAQjC,YACbF,MACDC,EAAaC,EACnBpF,EAAiBkF,EAAG,UAIpB,IAFA,IAAM9D,EAAS+D,EAAWrE,KAAKW,IAAIyD,EAAEtD,QAAQR,OACvCwL,EAAY,IAAIpI,aAAapD,EAAOa,QACjCwC,EAAI,EAAGA,EAAIrD,EAAOa,SAAUwC,EAAG,CACtC,IAAMyH,EAAQ9K,EAAOqD,GACrBmI,EAAUnI,GAAKyH,EAAQA,EAGzB,MAAO,CAACtK,OADOuD,EAAW5C,MAAMqK,EAAW1H,EAAE7D,MAAO6D,EAAEzE,OACtCY,MAAO6D,EAAE7D,MAAOZ,MAAOyE,EAAEzE,SChBhCuP,GAAOnD,EAAgBgxC,QAAM,SAAC1wC,EAAI5E,GAC7C,IAAMu1C,EAAYv1C,EAClB,OAAI+d,MAAMnZ,GACD4wC,IAEA5wC,EAAK,EAAI,EAAI2wC,EAAUriC,SAIrBuiC,GAA2B,CACtCn5C,WAAYg5C,OACZ94C,YAAa,MACbC,WAAYgL,IC4CP,IAAMiuC,GAAmC,CAC9Cp5C,WAAYq5C,eACZn5C,YAAa,MACbC,oBAvD2BC,GAKpB,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAELwP,UACA45B,QACA11B,YACAulC,cACAC,YACAC,iBACAC,gBACAC,mBAGFv+C,EAAiBkF,EAAG,gBAEd,IAOFiB,EAPExD,kDAAC67C,eAAYlpC,WAAQmpC,aAAU1yC,SAAMlG,aAAU2H,aAK/CgU,EAAK1E,GAAQ,CAACzV,OAAQ,CAACnC,KAAIE,UAASmD,MAAO,CAAClH,MAAOwE,KAGzD,GAAI24C,EAAY,CACd,IAAME,EACF33C,GAAM,CAACM,OAAQ,CAACnC,EAAGsc,GAAKpc,UAASmD,MAAO,CAACmM,MAAOY,EAAQvJ,UAC5D5F,EAAS2W,GAAQ,CAACzV,OAAQ,CAACnC,EAAGw5C,GAASt5C,UAASmD,MAAO,CAAClH,MAAOmM,KAE/DpI,EAAQsD,8BAA8Bg2C,QACjC,GAAIlxC,EAASmxC,MAAK,SAAAprC,GAAQ,OAAS,IAATA,KAC/BpN,EAASf,EAAQqC,eAAe+F,EAAUtI,EAAEzE,MAAO,QAC9C,CACL,IACMgM,EAASkM,GAAiBnL,EADnBpI,EAAQ+kB,WAAW3I,GACgBi9B,EAAUnpC,GAE1DnP,EAASf,EAAQqC,eAAegF,EAAOpL,MAAOoL,EAAOhM,MAAOgM,EAAOrL,QAGrE,IAAM8kC,EACFppB,GAAQ,CAACzV,OAAQ,CAACnC,EAAGiB,GAASf,UAASmD,MAAO,CAAClH,MAAOmM,KAK1D,OAHApI,EAAQsD,8BAA8B8Y,GACtCpc,EAAQsD,8BAA8BvC,GAE/B+/B,ICrDI0Y,GAAM/xC,EAAgBgyC,OAAK,SAAC1xC,GAAO,OAAAzI,KAAKk6C,IAAIzxC,MAE5C2xC,GAA0B,CACrCj6C,WAAYg6C,MACZ95C,YAAa,MACbC,WAAY45C,ICLDG,GAAOlyC,EAAgBmyC,QAAM,SAAC7xC,GAAO,OAAAzI,KAAKq6C,KAAK5xC,MAE/C8xC,GAA2B,CACtCp6C,WAAYm6C,OACZj6C,YAAa,MACbC,WAAY+5C,ICUP,IAAMG,GAA2B,CACtCr6C,WAAYs6C,OACZp6C,YAAa,MACbC,oBAfEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAiU,SAEPnZ,EAAiBkF,EAAG,QACpB,IAAMuH,EAASyM,GAAS9T,EAAQ+kB,WAAWjlB,GAAIiU,GAE/C,OAAO/T,EAAQqC,eAAegF,EAAOpL,MAAOoL,EAAOhM,MAAOgM,EAAOrL,UCW5D,IAAMg+C,GAA2B,CACtCv6C,WAAYw6C,OACZt6C,YAAa,MACbC,oBAvBEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjBrD,MACAmU,eAEPrZ,EAAiBkF,EAAG,QAEpB,IACMvC,KADQyC,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,0BAClCqY,OAAaC,OAGpB,MAAO,CACLtU,EAAQqC,eACJgS,EAAYpY,MAAOoY,EAAYhZ,MAAOgZ,EAAYrY,QACtDgE,EAAQqC,eACJiS,EAAerY,MAAOqY,EAAejZ,MAAOiZ,EAAetY,WCuE5D,IAAMk+C,GAAgC,CAC3Cz6C,WAAY06C,YACZx6C,YAAa,MACbC,oBA7FwBC,GAKjB,IAAAoC,WAAQkB,UAAOnD,YACfkxB,UAAOkpB,eACPC,kBAAeC,aAAU5G,cAAWlhC,gBAErCjV,UAAC6W,OAAOod,OAAaC,OAAYC,OACjCptB,kBAACyb,OAAWO,OAEZlY,EAAW,CAACgM,EAAO2L,EAAWO,EAAUoR,GAExCle,EAAUrY,OAAK0F,eAAeqwB,EAAMj1B,OACpCs+C,EAAc/mC,EAAQ,GACtBgnC,EAAYhnC,EAAQ,GACpBinC,EAAYjnC,EAAQ,GAEpB3M,EAAU1L,OAAK6F,uBACjBkwB,EAAM71B,MAA0BF,OAAK8E,cAAcmI,IAEvDvB,EAAQ2K,KAAKkiC,GAQb,IANA,IAAM1hB,EAAYhyB,EAAQtE,KAAKW,IAAI60B,EAAM10B,QAAQR,OAC3C0+C,EACF16C,EAAQtE,KAAKW,IAAI+9C,EAAW59C,QAAQR,OAI/BwI,EAAI,EAAGA,EAAI4P,IAAS5P,EAAG,CAK9B,IAJA,IAAMm2C,EAAoC,IAAxBP,EAAWn+C,MAAM,GAC/By+C,EACAA,EAAc9qC,SAAa,EAAJpL,EAAW,EAAJA,EAAQ,GAEjCo2C,EAAO,EAAGA,EAAO76B,IAAa66B,EACrC,IAAK,IAAIC,EAAO,EAAGA,EAAOv6B,IAAYu6B,EACpC,IAAK,IAAI34B,EAAU,EAAGA,EAAUwP,IAAexP,EAAS,CACtD,IAAIsV,SAEEsjB,EAAaH,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAO,EAE/D,GAAmB,IAAfE,EAAJ,CAMA,IAAMC,GACDJ,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAOD,EAAU,IACvDG,EACEE,GACDL,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAOD,EAAU,IACvDG,EAEEh7C,EAAIm7C,GAASF,EAAKtpB,EAAY6oB,GAC9BlvB,EAAI6vB,GAASD,EAAKxpB,EAAa8oB,GAErC,OAAQD,GACN,IAAK,UACH7iB,EAAM0jB,GACFlpB,EAAWR,EAAaC,EAAY8oB,EAAaC,EACjDC,EAAWj2C,EAAG4mB,EAAGtrB,EAAGoiB,EAASwxB,GACjC,MACF,IAAK,WACHlc,EAAM2jB,GACFnpB,EAAWR,EAAaC,EAAY8oB,EAAaC,EACjDC,EAAWj2C,EAAG4mB,EAAGtrB,EAAGoiB,EAASwxB,GACjC,MACF,QACE,MAAM,IAAI11C,MACN,+DACuBq8C,GAM/BxzC,EAFIrC,EAAI+1C,EAAcK,EAAOJ,EAAYK,EAAOJ,EAAYv4B,GAE7CsV,GAKrB,OAAOx3B,EAAQqC,eAAe+F,EAAU8oB,EAAM71B,MAAOwL,GAIvD,MAAO,CAACrK,OADOwD,EAAQ7C,MAAM0J,EAASuB,EAAU8oB,EAAM71B,OACtCY,MAAOi1B,EAAMj1B,MAAOZ,MAAO61B,EAAM71B,SASnD,SAAS4/C,GACLG,EAAkBC,EAClBpS,GACF,OAAQA,GACN,IAAK,UACH,OAWN,SAAyBmS,EAAkBC,GAEzC,IAAIC,EAAUF,EACd,GAAIE,EAAU,EAAG,CACf,GAAID,GAAO,EACTC,EAAU,OAGNA,GADEC,EAAM,EAAIF,KAEdC,EAAUC,EAAMj8C,KAAKsT,OAAO0oC,EAAUC,GAAOD,GAE/CA,EAAUA,GAAWD,EAAMC,EAAUC,GAAOD,EAAU,OAEnD,GAAIA,EAAUD,EAAM,EAAG,CAI1B,IAAME,EAHR,GAAIF,GAAO,EACTC,EAAU,OAGVA,IADMC,EAAM,EAAIF,GACC/7C,KAAKsT,MAAM0oC,EAAUC,KACvBF,IACbC,EAAUC,EAAMD,EAAU,GAMhC,OAAOngD,OAAKqgD,MAAM,EAAGF,EAASD,EAAM,GArCzBI,CAAgBL,EAAUC,GACnC,IAAK,OACH,OAsCN,SAAsBD,EAAkBC,GAEtC,IAAIC,EAAUF,EACd,GAAIE,EAAU,EACZ,GAAID,GAAO,EACTC,EAAU,MACL,CACL,IAAMI,EAAKL,EAAM,EACjBC,GAAWD,GAAO/7C,KAAKsT,OAAO0oC,EAAUI,GAAM,QAE3C,GAAIJ,EAAUD,EAAM,EACzB,GAAIA,GAAO,EACTC,EAAU,MACL,CACCI,EAAKL,EAAM,EACjBC,GAAWD,EAAM/7C,KAAKsT,MAAM0oC,EAAUI,GAK1C,OAAOvgD,OAAKqgD,MAAM,EAAGF,EAASD,EAAM,GA1DzBM,CAAaP,EAAUC,GAChC,IAAK,UACH,OA+DN,SAAyBD,EAAkBC,GACzC,OAAOlgD,OAAKqgD,MAAM,EAAGJ,EAAUC,EAAM,GAhE1BO,CAAgBR,EAAUC,GACnC,IAAK,WACL,QACE,OAwDN,SAA0BD,EAAkBC,GAC1C,OAAOD,EAzDIS,CAAiBT,IAgE9B,SAASU,GACL9pB,EAAuBR,EAAqBC,EAC5C8oB,EAAqBC,EAAmBC,EAAmBrmC,EAC3DgX,EAAWtrB,EAAWoiB,EAAiBwxB,GAEzC,OAAI,GAAKtoB,GAAKA,EAAIoG,GAAe,GAAK1xB,GAAKA,EAAI2xB,EACtCO,EAFG5d,EAAQmmC,EAAcnvB,EAAIovB,EAAY16C,EAAI26C,EAAYv4B,GAIzDwxB,EAIX,SAASwH,GACLlpB,EAAuBR,EAAqBC,EAC5C8oB,EAAqBC,EAAmBC,EAAmBrmC,EAC3DgX,EAAWtrB,EAAWoiB,EAAiBwxB,GAIzC,OAAOoI,GACH9pB,EAAWR,EAAaC,EAAY8oB,EAAaC,EAAWC,EAC5DrmC,EALO9U,KAAKq0B,MAAMvI,GACX9rB,KAAKq0B,MAAM7zB,GAIHoiB,EAASwxB,GAG9B,SAASyH,GACLnpB,EAAuBR,EAAqBC,EAC5C8oB,EAAqBC,EAAmBC,EAAmBrmC,EAC3DgX,EAAWtrB,EAAWoiB,EAAiBwxB,GACzC,IAAMqI,EAASz8C,KAAKgK,MAAM8hB,GACpB4wB,EAAS18C,KAAKgK,MAAMxJ,GACpBm8C,EAAQF,EAAS,EACjBG,EAAQF,EAAS,EAyBvB,OAAQC,EAAQ7wB,KArBX8wB,EAAQp8C,GACLg8C,GACI9pB,EAAWR,EAAaC,EAAY8oB,EAAaC,EACjDC,EAAWrmC,EAAO2nC,EAAQC,EAAQ95B,EAASwxB,IAClD5zC,EAAIk8C,GACDF,GACI9pB,EAAWR,EAAaC,EAAY8oB,EAAaC,EACjDC,EAAWrmC,EAAO2nC,EAAQG,EAAOh6B,EAASwxB,KAclBtoB,EAAI2wB,KAVnCG,EAAQp8C,GACLg8C,GACI9pB,EAAWR,EAAaC,EAAY8oB,EAAaC,EACjDC,EAAWrmC,EAAO6nC,EAAOD,EAAQ95B,EAASwxB,IACjD5zC,EAAIk8C,GACDF,GACI9pB,EAAWR,EAAaC,EAAY8oB,EAAaC,EACjDC,EAAWrmC,EAAO6nC,EAAOC,EAAOh6B,EAASwxB,IC7MhD,IAAMyI,GAA6B,CACxC18C,WAAY28C,SACZz8C,YAAa,MACbC,oBAnBEC,GAEK,IAAAoC,WAAQkB,UAAOnD,YACfmO,SACArO,MACPlF,EAAiBkF,EAAG,UAEpB,IACMvC,KADSyC,EAAQtE,KAAKW,IAAIyD,EAAEtD,QAAQR,0BACnCoV,iBAAcoB,gBAAahC,YAElC,MAAO,CACLxQ,EAAQqC,eAAemQ,EAAa1S,EAAEzE,MAAO+V,GAC7CpR,EAAQqC,eAAe,CAACmO,EAAQ3T,QAAS,QAAS2T,MCsB/C,IAAM6rC,GAA6B,CACxC58C,WAAY68C,SACZ38C,YAAa,MACbC,oBAtCEC,GAEK,IAAAoC,WAAQjC,YAASmD,UACjB2D,UACFqH,SAEDA,EAAO,IACTA,GAAQrH,EAAM7K,MAAMY,QAQtB,IALA,IAAM0/C,EAAYz1C,EAAM7K,MAAMY,OAExB8N,EAAM7D,EAAM7K,MAAMkS,GAClB/F,EAAqB,IAAIrN,MAAMwhD,EAAY,GAC7CC,EAAW,EACNn9C,EAAI,EAAGA,EAAIk9C,EAAWl9C,IACzBA,IAAM8O,IACR/F,EAASo0C,KAAc11C,EAAM7K,MAAMoD,IAIvC,IAAMiQ,EAAQ,IAAIvU,MAAMwhD,GAAW/qC,KAAK,GAClC7K,EAAOG,EAAM7K,MAAM0F,QACzBgF,EAAKwH,GAAQ,EACb,IAAMvB,EAAM,IAAI7R,MAAM4P,GACtB,IAAStL,EAAI,EAAGA,EAAIuN,EAAI/P,OAAQwC,IAAK,CACnCiQ,EAAMnB,GAAQ9O,EACd,IAAMo9C,EAAU96C,GAAM,CAACM,OAAQ,CAACnC,EAAGgH,GAAQ9G,UAASmD,MAAO,CAACmM,QAAO3I,UACnEiG,EAAIvN,GAAKqY,GAAQ,CAACzV,OAAQ,CAACnC,EAAG28C,GAAUz8C,UAASmD,MAAO,CAAClH,MAAOmM,KAChEpI,EAAQsD,8BAA8Bm5C,GAGxC,OAAO7vC,IC4RT,IClQO,IAAM8vC,GAAyC,CACpDj9C,WAAYk9C,qBACZh9C,YAAa,MACbC,oBAzDiCC,GAK1B,IAAAoC,WAAQjC,YAASmD,UACjBrD,MAAG88C,eACHC,gBAEPjiD,EAAiBkF,EAAG,sBAYpB,IAVA,IAEM8M,EAAM,GACNuO,EAA8B,GAI9B2hC,EAPQh9C,EAAE7D,MAAMY,OACC+/C,EAAW3gD,MAAMY,OAOpCkgD,EAAcH,EAETv9C,EAAI,EAAGA,EAAIy9C,IAAYz9C,EAAG,CACjC,IAAM29C,EAAW5hB,GACb,CAACn5B,OAAQ,CAACa,MAAOi6C,GAAc/8C,UAASmD,MAAO,CAACk4B,IAAKh8B,EAAI,KAC7D09C,EAAcC,EACd7hC,EAAcxM,KAAKquC,GAGrB,IAAS39C,EAAI,EAAGA,EAAIw9C,IAAex9C,EAAG,CACpC,IAAM49C,EAAc9hD,OAAKsR,kBAAkBpN,EAAoB,SACzD69C,EAAYl9C,EAAQqC,eAAe,GAAI,QAAS46C,GAChDrV,EACF3N,GAAM,CAACh4B,OAAQ,CAACsC,EAAG24C,EAAW14C,EAAGu4C,GAAc/8C,YAC7Cm9C,EACFj6C,EAAK,CAACjB,OAAQ,CAACnC,EAAG8nC,GAAO5nC,UAASmD,MAAO,CAAC9H,MAAO,aAC/C+hD,EACFlxC,GAAS,CAACjK,OAAQ,CAACsC,EAAG44C,EAAY34C,EAAG1E,GAAIE,YACvCq9C,EACF7iC,GAAI,CAACvY,OAAQ,CAACnC,EAAGs9C,GAAMp9C,UAASmD,MAAO,CAACgL,KAAM,EAAGC,UAAU,KAC/DxB,EAAI+B,KAAK0uC,GACTliC,EAAcxM,KAAKuuC,GACnB/hC,EAAcxM,KAAKi5B,GACnBzsB,EAAcxM,KAAKwuC,GACnBhiC,EAAcxM,KAAKyuC,GACnBjiC,EAAcxM,KAAK0uC,GAGrB,IAAMt8C,EAASqsC,GAAK,CAACnrC,OAAQ2K,EAAK5M,UAASmD,MAAO,CAACgL,KAAM,KAIzD,OAFAgN,EAAclgB,SAAQ,SAAAC,GAAK,OAAA8E,EAAQsD,8BAA8BpI,MAE1D6F,SDqQkBu8C,GAhKW,CACpCziC,GACArb,EACAgc,GACAG,GACArV,EACAsV,GACAI,GACAQ,GACAG,GACAI,GACAK,GACAG,GACAG,GACAI,GACAG,GACAuF,GACAY,GACAI,GACAqB,GACAlL,GACA2L,GACAkB,GACAmB,GACA3kB,EACAkE,EACAihB,GACA7mB,EACA8mB,GACAwB,GACAkC,GACAW,GACAb,GACAmC,GACAmB,GACA9B,GACAwC,GACAG,GACAC,GACA+C,GACAW,GACAE,GACAoB,GACAE,GACAG,GACAE,GACAE,GACAyB,GACAT,GACAmE,GACAlD,GACAviB,GACA0jB,GACAM,GACAgB,GACAnyB,EACAuyB,GACAnyB,EACAs3B,GACAO,GACAE,GACA33B,EACAs4B,GACAC,GACAG,GACAE,GACAS,GACAz4B,EACAw5B,GACAhhC,EACAihC,GACAla,GACAsa,GACAI,GACAE,GACAjuB,GACA9L,EACAm6B,GACAC,GACA55B,GACAg6B,GACAI,GACAG,GACAI,GACAC,GACAY,GACA96B,GACA07B,GACAE,GACAE,GACAK,GACAE,GACAb,GACAoB,GACAK,GACA58B,GACA+8B,GACAW,GACAW,GACAh+B,GACAM,GACA0+B,GACAU,GACAK,GACAn/B,GACAu/B,GACAU,GACAM,GACAE,GACAM,GACAp3B,GACA1I,GACA+/B,GACAhrC,EACAorC,GACAr3B,GACAG,GACAa,GACAs2B,GACA6B,GACA4B,GACAM,GACAe,GACAI,GACAa,GACAhlC,GACAulC,GACAE,GACAU,GACAl+B,GACAo+B,GACAE,GACAG,GACAzlC,GACA65B,GACAmM,GACAC,GACAQ,GACAQ,GACAI,GACAI,GACAQ,GACAC,GACAjlC,GACAslC,GACAC,GACAhlC,GACA2kB,GACAkhB,GACAG,GACAC,GACAE,GACAvsC,GACAysC,GACAiC,GACAE,GACAK,GACA3P,IAGyB1xB,aAAAA,KAAe,CAArC,IAAMkiC,UACTC,iBAAeD,iDElVD"}